,model,score
0,Jeevesh8/init_bert_ft_qqp-33,0.7994771
1,Jeevesh8/init_bert_ft_qqp-33,0.8166043
2,ali2066/finetuned_sentence_itr1_2e-05_all_26_02_2022-04_03_26,0.7859383
3,ali2066/finetuned_sentence_itr1_2e-05_all_26_02_2022-04_03_26,0.8050296
4,vaariis/distilbert-base-uncased-finetuned-emotion,0.7814963
5,vaariis/distilbert-base-uncased-finetuned-emotion,0.7971256
6,heranm/finetuning-sentiment-model-3000-samples,0.80638796
7,heranm/finetuning-sentiment-model-3000-samples,0.7986597
8,marcelcastrobr/sagemaker-distilbert-emotion,0.7864152
9,marcelcastrobr/sagemaker-distilbert-emotion,0.80221266
10,jasonyim2/distilbert-base-uncased-finetuned-emotion,0.7905002
11,jasonyim2/distilbert-base-uncased-finetuned-emotion,0.81064826
12,riyadhctg/distilbert-base-uncased-finetuned-cola,0.791717
13,riyadhctg/distilbert-base-uncased-finetuned-cola,0.7862857
14,dapang/distilroberta-base-mic-sym,0.78035134
15,dapang/distilroberta-base-mic-sym,0.77663225
16,PrasunMishra/finetuning-sentiment-model-3000-samples,0.8065179
17,PrasunMishra/finetuning-sentiment-model-3000-samples,0.80051637
18,nurkayevaa/autonlp-bert-covid-407910458,0.7771346
19,nurkayevaa/autonlp-bert-covid-407910458,0.81295556
20,SetFit/distilbert-base-uncased__sst2__train-16-0,0.8036767
21,SetFit/distilbert-base-uncased__sst2__train-16-0,0.8092813
22,abdelkader/distilbert-base-uncased-finetuned-emotion,0.7817495
23,abdelkader/distilbert-base-uncased-finetuned-emotion,0.778996
24,SetFit/distilbert-base-uncased__hate_speech_offensive__train-16-1,0.7806052
25,SetFit/distilbert-base-uncased__hate_speech_offensive__train-16-1,0.817156
26,gchhablani/fnet-base-finetuned-sst2,0.74575514
27,gchhablani/fnet-base-finetuned-sst2,0.7335534
28,Capreolus/bert-base-msmarco,0.7683688
29,Capreolus/bert-base-msmarco,0.82229096
30,Splend1dchan/bert-base-uncased-slue-goldtrascription-e3-lr1e-4,0.768326
31,Splend1dchan/bert-base-uncased-slue-goldtrascription-e3-lr1e-4,0.821251
32,crcb/isear_bert,0.81165534
33,crcb/isear_bert,0.8221878
34,connectivity/cola_6ep_ft-33,0.7889614
35,connectivity/cola_6ep_ft-33,0.8177049
36,Jeevesh8/init_bert_ft_qqp-49,0.78216237
37,Jeevesh8/init_bert_ft_qqp-49,0.80838305
38,Jeevesh8/feather_berts_46,0.7745498
39,Jeevesh8/feather_berts_46,0.8218964
40,yukta10/finetuning-sentiment-model-3000-samples,0.78561956
41,yukta10/finetuning-sentiment-model-3000-samples,0.7909795
42,connectivity/cola_6ep_ft-22,0.7920104
43,connectivity/cola_6ep_ft-22,0.81937253
44,JonatanGk/roberta-base-bne-finetuned-cyberbullying-spanish,0.5906324
45,JonatanGk/roberta-base-bne-finetuned-cyberbullying-spanish,0.57843506
46,cambridgeltl/guardian_news_distilbert-base-uncased,0.76338834
47,cambridgeltl/guardian_news_distilbert-base-uncased,0.8015179
48,gchhablani/fnet-base-finetuned-cola,0.7459698
49,gchhablani/fnet-base-finetuned-cola,0.70285624
50,ncduy/roberta-imdb-sentiment-analysis,0.8070919
51,ncduy/roberta-imdb-sentiment-analysis,0.8106199
52,isakbos/Q8BERT_COLA_L_512,0.6794985
53,isakbos/Q8BERT_COLA_L_512,0.5989254
54,connectivity/bert_ft_qqp-7,0.7999494
55,connectivity/bert_ft_qqp-7,0.825692
56,moghis/distilbert-base-uncased-finetuned-emotion,0.7979326
57,moghis/distilbert-base-uncased-finetuned-emotion,0.7976337
58,uygarkurt/distilbert-base-uncased-finetuned-emotion,0.781012
59,uygarkurt/distilbert-base-uncased-finetuned-emotion,0.8078233
60,amyma21/sincere_question_classification,0.77943224
61,amyma21/sincere_question_classification,0.7642757
62,phailyoor/distilbert-base-uncased-finetuned-yahd,0.7645118
63,phailyoor/distilbert-base-uncased-finetuned-yahd,0.7564879
64,arianpasquali/distilbert-base-multilingual-cased-toxicity,0.73365194
65,arianpasquali/distilbert-base-multilingual-cased-toxicity,0.7131471
66,neibla/distilbert-base-uncased-finetuned-emotion,0.7981288
67,neibla/distilbert-base-uncased-finetuned-emotion,0.7934972
68,robertou2/roberta-base-bne-finetuned-amazon_reviews_multi,0.6920894
69,robertou2/roberta-base-bne-finetuned-amazon_reviews_multi,0.71209764
70,Anthos23/FS-distilroberta-fine-tuned,0.7993037
71,Anthos23/FS-distilroberta-fine-tuned,0.8065987
72,pietrotrope/emotion_final,0.7794282
73,pietrotrope/emotion_final,0.7982057
74,aviator-neural/bert-base-uncased-sst2,0.79420483
75,aviator-neural/bert-base-uncased-sst2,0.8032115
76,Jeevesh8/bert_ft_qqp-40,0.8071626
77,Jeevesh8/bert_ft_qqp-40,0.8229851
78,jaesun/distilbert-base-uncased-finetuned-cola,0.7974132
79,jaesun/distilbert-base-uncased-finetuned-cola,0.78443754
80,SetFit/distilbert-base-uncased__sst2__train-32-9,0.80417156
81,SetFit/distilbert-base-uncased__sst2__train-32-9,0.8026663
82,usami/distilbert-base-uncased-finetuned-cola,0.7939639
83,usami/distilbert-base-uncased-finetuned-cola,0.8137186
84,connectivity/feather_berts_28,0.7643196
85,connectivity/feather_berts_28,0.8207657
86,Jeevesh8/512seq_len_6ep_bert_ft_cola-91,0.7804061
87,Jeevesh8/512seq_len_6ep_bert_ft_cola-91,0.81378776
88,Jeevesh8/bert_ft_qqp-9,0.7866016
89,Jeevesh8/bert_ft_qqp-9,0.81513673
90,Jeevesh8/bert_ft_qqp-88,0.80523854
91,Jeevesh8/bert_ft_qqp-88,0.8240539
92,Recognai/bert-base-spanish-wwm-cased-xnli,0.73965603
93,Recognai/bert-base-spanish-wwm-cased-xnli,0.6808203
94,markt23917/finetuning-sentiment-model-3000-samples,0.7864711
95,markt23917/finetuning-sentiment-model-3000-samples,0.8159661
96,JNK789/distilbert-base-uncased-finetuned-tweets-emoji-dataset,0.62215513
97,JNK789/distilbert-base-uncased-finetuned-tweets-emoji-dataset,0.6150448
98,warwickai/fin-perceiver,0.73095983
99,warwickai/fin-perceiver,0.7282042
100,anirudh21/bert-base-uncased-finetuned-qnli,0.81641006
101,anirudh21/bert-base-uncased-finetuned-qnli,0.822214
102,Jeevesh8/6ep_bert_ft_cola-47,0.8009637
103,Jeevesh8/6ep_bert_ft_cola-47,0.82366264
104,oferweintraub/bert-base-finance-sentiment-noisy-search,0.80383646
105,oferweintraub/bert-base-finance-sentiment-noisy-search,0.8163292
106,aXhyra/demo_sentiment_31415,0.76889837
107,aXhyra/demo_sentiment_31415,0.7787054
108,milyiyo/selectra-small-finetuned-amazon-review,0.67439485
109,milyiyo/selectra-small-finetuned-amazon-review,0.6648003
110,aXhyra/presentation_sentiment_1234567,0.77255917
111,aXhyra/presentation_sentiment_1234567,0.7848109
112,Alireza1044/albert-base-v2-qnli,0.7638114
113,Alireza1044/albert-base-v2-qnli,0.7748558
114,liangyuant/distilbert-base-uncased-finetuned-num200-450-405cls,0.77905804
115,liangyuant/distilbert-base-uncased-finetuned-num200-450-405cls,0.76719147
116,DoyyingFace/bert-asian-hate-tweets-asian-unclean-freeze-4,0.76522475
117,DoyyingFace/bert-asian-hate-tweets-asian-unclean-freeze-4,0.82331455
118,connectivity/cola_6ep_ft-10,0.7892511
119,connectivity/cola_6ep_ft-10,0.8172058
120,Jeevesh8/lecun_feather_berts-3,0.7723321
121,Jeevesh8/lecun_feather_berts-3,0.8147815
122,jb2k/bert-base-multilingual-cased-language-detection,0.7255753
123,jb2k/bert-base-multilingual-cased-language-detection,0.69648606
124,Giyaseddin/distilroberta-base-finetuned-short-answer-assessment,0.7918055
125,Giyaseddin/distilroberta-base-finetuned-short-answer-assessment,0.79919964
126,connectivity/bert_ft_qqp-25,0.7876552
127,connectivity/bert_ft_qqp-25,0.8325409
128,Jeevesh8/6ep_bert_ft_cola-12,0.7742971
129,Jeevesh8/6ep_bert_ft_cola-12,0.7942699
130,JB173/distilbert-base-uncased-finetuned-emotion,0.7993425
131,JB173/distilbert-base-uncased-finetuned-emotion,0.7668805
132,aXhyra/emotion_trained_31415,0.7953468
133,aXhyra/emotion_trained_31415,0.7709323
134,aXhyra/presentation_emotion_31415,0.8044739
135,aXhyra/presentation_emotion_31415,0.78072137
136,AnonymousSub/dummy_2,0.72412163
137,AnonymousSub/dummy_2,0.7440075
138,Jeevesh8/bert_ft_qqp-55,0.786196
139,Jeevesh8/bert_ft_qqp-55,0.82056963
140,Jeevesh8/lecun_feather_berts-51,0.7738153
141,Jeevesh8/lecun_feather_berts-51,0.8269349
142,viviastaari/finetuning-sentiment-analysis-en-id,0.7156286
143,viviastaari/finetuning-sentiment-analysis-en-id,0.70159894
144,vinai/bertweet-base,0.7298512
145,vinai/bertweet-base,0.80733526
146,distilbert-base-uncased,0.79913443
147,distilbert-base-uncased,0.770426
148,bert-base-uncased,0.7901073
149,bert-base-uncased,0.81043965
150,roberta-base,0.7691088
151,roberta-base,0.7510343
152,Aureliano/distilbert-base-uncased-if,0.76968133
153,Aureliano/distilbert-base-uncased-if,0.79706377
154,rmihaylov/roberta-base-sentiment-bg,0.7453391
155,rmihaylov/roberta-base-sentiment-bg,0.748796
156,cardiffnlp/twitter-roberta-base-2021-124m,0.7430417
157,cardiffnlp/twitter-roberta-base-2021-124m,0.7798168
158,Alassea/glue_sst_classifier,0.8123215
159,Alassea/glue_sst_classifier,0.81462485
160,Nanatan/distilbert-base-uncased-finetuned-emotion,0.7818248
161,Nanatan/distilbert-base-uncased-finetuned-emotion,0.79055476
162,connectivity/bert_ft_qqp-1,0.7903989
163,connectivity/bert_ft_qqp-1,0.8178594
164,juliensimon/autonlp-imdb-demo-hf-16622767,0.7737609
165,juliensimon/autonlp-imdb-demo-hf-16622767,0.7658045
166,Jeevesh8/bert_ft_qqp-39,0.78532034
167,Jeevesh8/bert_ft_qqp-39,0.81523216
168,Jeevesh8/lecun_feather_berts-8,0.7723321
169,Jeevesh8/lecun_feather_berts-8,0.81974655
170,connectivity/bert_ft_qqp-94,0.7904193
171,connectivity/bert_ft_qqp-94,0.8164495
172,korca/bae-roberta-base-boolq,0.7771853
173,korca/bae-roberta-base-boolq,0.83276206
174,Jeevesh8/bert_ft_cola-88,0.7877555
175,Jeevesh8/bert_ft_cola-88,0.8231798
176,aditeyabaral/finetuned-sail2017-xlm-roberta-base,0.76359713
177,aditeyabaral/finetuned-sail2017-xlm-roberta-base,0.7882698
178,connectivity/bert_ft_qqp-96,0.7926175
179,connectivity/bert_ft_qqp-96,0.82252717
180,boychaboy/MNLI_roberta-base,0.8086472
181,boychaboy/MNLI_roberta-base,0.834309
182,fabriceyhc/bert-base-uncased-imdb,0.77042496
183,fabriceyhc/bert-base-uncased-imdb,0.7949431
184,emrecan/bert-base-multilingual-cased-snli_tr,0.75727993
185,emrecan/bert-base-multilingual-cased-snli_tr,0.7515976
186,elozano/tweet_offensive_eval,0.7330104
187,elozano/tweet_offensive_eval,0.6786192
188,joebobby/finetuning-sentiment-model-5000-samples3,0.75357103
189,joebobby/finetuning-sentiment-model-5000-samples3,0.8027714
190,YeRyeongLee/electra-base-discriminator-finetuned-filtered-0602,0.62942415
191,YeRyeongLee/electra-base-discriminator-finetuned-filtered-0602,0.62738734
192,Jeevesh8/feather_berts_92,0.77474195
193,Jeevesh8/feather_berts_92,0.8250466
194,ASCCCCCCCC/distilbert-base-chinese-amazon_zh_20000,0.69398475
195,ASCCCCCCCC/distilbert-base-chinese-amazon_zh_20000,0.6950237
196,Jeevesh8/6ep_bert_ft_cola-29,0.8143772
197,albert-base-v2,0.6927838
198,bert-base-cased,0.8029828
199,Hate-speech-CNERG/bert-base-uncased-hatexplain-rationale-two,0.82588625
200,matthewburke/korean_sentiment,0.6835843
201,aychang/bert-base-cased-trec-coarse,0.81828403
202,IMSyPP/hate_speech_nl,0.5773183
203,cointegrated/roberta-base-formality,0.82747835
204,XSY/albert-base-v2-imdb-calssification,0.7654818
205,philschmid/tiny-distilbert-classification,0.62118846
206,gchhablani/bert-base-cased-finetuned-wnli,0.8168617
207,moshew/bert-mini-sst2-distilled,0.75871694
208,chiragasarpota/scotus-bert,0.5880725
209,vesteinn/XLMR-ENIS-finetuned-cola,0.78578436
210,IMSyPP/hate_speech_it,0.7033556
211,Jeevesh8/init_bert_ft_qqp-24,0.8217392
212,nickmuchi/facebook-data2vec-finetuned-finance-classification,0.73144746
213,Jeevesh8/bert_ft_qqp-68,0.8239267
214,Jeevesh8/init_bert_ft_qqp-28,0.8184053
215,connectivity/bert_ft_qqp-17,0.8219095
216,dhimskyy/wiki-bert,0.6559182
217,18811449050/bert_finetuning_test,0.8214073
218,finiteautomata/betonews-tweetcontext,0.6851947
219,Jeevesh8/feather_berts_96,0.82678175
220,michiyasunaga/LinkBERT-base,0.79877645
221,navsad/navid_test_bert,0.80232614
222,Jeevesh8/bert_ft_cola-60,0.8143772
223,Jeevesh8/lecun_feather_berts-7,0.81244963
224,w11wo/sundanese-bert-base-emotion-classifier,0.66866636
225,mrm8488/codebert-base-finetuned-detect-insecure-code,0.77202535
226,socialmediaie/TRAC2020_IBEN_B_bert-base-multilingual-uncased,0.7668809
227,ishan/bert-base-uncased-mnli,0.8272595
228,zenkri/autotrain-Arabic_Poetry_by_Subject-920730230,0.79029894
229,M47Labs/spanish_news_classification_headlines_untrained,0.72535616
230,bondi/bert-semaphore-prediction-w4,0.68341976
231,gchhablani/bert-base-cased-finetuned-rte,0.8263894
232,classla/bcms-bertic-parlasent-bcs-ter,0.7536189
233,anferico/bert-for-patents,0.73650306
234,waboucay/camembert-base-finetuned-xnli_fr-finetuned-nli-rua_wl,0.61980724
235,ali2066/DistilBERTFINAL_ctxSentence_TRAIN_editorials_TEST_NULL_second_train_set_null_False,0.8370981
236,anvay/finetuning-cardiffnlp-sentiment-model,0.8634136
237,JonatanGk/roberta-base-ca-finetuned-hate-speech-offensive-catalan,0.6799442
238,mrm8488/electricidad-base-finetuned-pawsx-es,0.67598116
239,Raychanan/COVID_RandomOver,0.6107741
240,Monsia/camembert-fr-covid-tweet-classification,0.72597325
241,manueltonneau/bert-twitter-en-is-hired,0.80780184
242,CAMeL-Lab/bert-base-arabic-camelbert-mix-did-nadi,0.68388456
243,kyleinincubated/autonlp-cat333-624217911,0.73721695
244,Guscode/DKbert-hatespeech-detection,0.64017653
245,CAMeL-Lab/bert-base-arabic-camelbert-da-sentiment,0.5639195
246,ChrisUPM/BioBERT_Re_trained,0.75955886
247,roberta-large,0.72400033
