,model,score
0,Jeevesh8/init_bert_ft_qqp-33,0.83269966
1,Jeevesh8/init_bert_ft_qqp-33,0.8608141
2,Jeevesh8/init_bert_ft_qqp-49,0.8281666
3,Jeevesh8/init_bert_ft_qqp-49,0.85931623
4,connectivity/bert_ft_qqp-7,0.8281666
5,connectivity/bert_ft_qqp-7,0.8638856
6,Jeevesh8/bert_ft_qqp-40,0.8281666
7,Jeevesh8/bert_ft_qqp-40,0.85931623
8,Jeevesh8/bert_ft_qqp-9,0.8281666
9,Jeevesh8/bert_ft_qqp-9,0.8583652
10,Jeevesh8/bert_ft_qqp-88,0.8281666
11,Jeevesh8/bert_ft_qqp-88,0.85931623
12,connectivity/bert_ft_qqp-25,0.8281666
13,connectivity/bert_ft_qqp-25,0.8638856
14,Jeevesh8/bert_ft_qqp-55,0.8281666
15,Jeevesh8/bert_ft_qqp-55,0.85931623
16,connectivity/bert_ft_qqp-1,0.8289611
17,connectivity/bert_ft_qqp-1,0.85931623
18,Jeevesh8/bert_ft_qqp-39,0.8281666
19,Jeevesh8/bert_ft_qqp-39,0.85834473
20,connectivity/bert_ft_qqp-94,0.83269966
21,connectivity/bert_ft_qqp-94,0.85834473
22,connectivity/bert_ft_qqp-96,0.8289611
23,connectivity/bert_ft_qqp-96,0.86484945
24,Jeevesh8/init_bert_ft_qqp-24,0.85834473
25,Jeevesh8/bert_ft_qqp-68,0.8638856
26,Jeevesh8/init_bert_ft_qqp-28,0.85931623
27,connectivity/bert_ft_qqp-17,0.86484945
28,ali2066/finetuned_sentence_itr1_2e-05_all_26_02_2022-04_03_26,0.80830526
29,ali2066/finetuned_sentence_itr1_2e-05_all_26_02_2022-04_03_26,0.8540912
30,SetFit/distilbert-base-uncased__sst2__train-16-0,0.8256822
31,SetFit/distilbert-base-uncased__sst2__train-16-0,0.8582346
32,gchhablani/fnet-base-finetuned-sst2,0.7807952
33,gchhablani/fnet-base-finetuned-sst2,0.77748734
34,aviator-neural/bert-base-uncased-sst2,0.8334334
35,aviator-neural/bert-base-uncased-sst2,0.851742
36,SetFit/distilbert-base-uncased__sst2__train-32-9,0.819971
37,SetFit/distilbert-base-uncased__sst2__train-32-9,0.8584065
38,Alassea/glue_sst_classifier,0.7968189
39,Alassea/glue_sst_classifier,0.86674535
40,philschmid/tiny-distilbert-classification,0.58809114
41,moshew/bert-mini-sst2-distilled,0.8020179
42,ChrisUPM/BioBERT_Re_trained,0.82933205
43,vaariis/distilbert-base-uncased-finetuned-emotion,0.72611856
44,vaariis/distilbert-base-uncased-finetuned-emotion,0.80452615
45,marcelcastrobr/sagemaker-distilbert-emotion,0.7352123
46,marcelcastrobr/sagemaker-distilbert-emotion,0.8050846
47,jasonyim2/distilbert-base-uncased-finetuned-emotion,0.73839957
48,jasonyim2/distilbert-base-uncased-finetuned-emotion,0.80373406
49,abdelkader/distilbert-base-uncased-finetuned-emotion,0.7352745
50,abdelkader/distilbert-base-uncased-finetuned-emotion,0.7899164
51,moghis/distilbert-base-uncased-finetuned-emotion,0.7344001
52,moghis/distilbert-base-uncased-finetuned-emotion,0.80782163
53,uygarkurt/distilbert-base-uncased-finetuned-emotion,0.73690134
54,uygarkurt/distilbert-base-uncased-finetuned-emotion,0.80042946
55,neibla/distilbert-base-uncased-finetuned-emotion,0.7344001
56,neibla/distilbert-base-uncased-finetuned-emotion,0.8067971
57,JB173/distilbert-base-uncased-finetuned-emotion,0.7165462
58,JB173/distilbert-base-uncased-finetuned-emotion,0.7552764
59,Nanatan/distilbert-base-uncased-finetuned-emotion,0.7225983
60,Nanatan/distilbert-base-uncased-finetuned-emotion,0.7911669
61,heranm/finetuning-sentiment-model-3000-samples,0.78316516
62,heranm/finetuning-sentiment-model-3000-samples,0.8133407
63,PrasunMishra/finetuning-sentiment-model-3000-samples,0.7342408
64,PrasunMishra/finetuning-sentiment-model-3000-samples,0.8074606
65,yukta10/finetuning-sentiment-model-3000-samples,0.7317433
66,yukta10/finetuning-sentiment-model-3000-samples,0.81036764
67,ncduy/roberta-imdb-sentiment-analysis,0.8159738
68,ncduy/roberta-imdb-sentiment-analysis,0.82044184
69,markt23917/finetuning-sentiment-model-3000-samples,0.7787141
70,markt23917/finetuning-sentiment-model-3000-samples,0.8142712
71,juliensimon/autonlp-imdb-demo-hf-16622767,0.753594
72,juliensimon/autonlp-imdb-demo-hf-16622767,0.78029835
73,fabriceyhc/bert-base-uncased-imdb,0.822963
74,fabriceyhc/bert-base-uncased-imdb,0.8195927
75,XSY/albert-base-v2-imdb-calssification,0.7485604
76,riyadhctg/distilbert-base-uncased-finetuned-cola,0.8132404
77,riyadhctg/distilbert-base-uncased-finetuned-cola,0.85329777
78,connectivity/cola_6ep_ft-33,0.831153
79,connectivity/cola_6ep_ft-33,0.8626973
80,connectivity/cola_6ep_ft-22,0.831153
81,connectivity/cola_6ep_ft-22,0.8626973
82,gchhablani/fnet-base-finetuned-cola,0.77212834
83,gchhablani/fnet-base-finetuned-cola,0.7373177
84,isakbos/Q8BERT_COLA_L_512,0.7462975
85,isakbos/Q8BERT_COLA_L_512,0.6806336
86,jaesun/distilbert-base-uncased-finetuned-cola,0.81131786
87,jaesun/distilbert-base-uncased-finetuned-cola,0.85288936
88,usami/distilbert-base-uncased-finetuned-cola,0.8127243
89,usami/distilbert-base-uncased-finetuned-cola,0.85343593
90,Jeevesh8/512seq_len_6ep_bert_ft_cola-91,0.831153
91,Jeevesh8/512seq_len_6ep_bert_ft_cola-91,0.869202
92,Jeevesh8/6ep_bert_ft_cola-47,0.831153
93,Jeevesh8/6ep_bert_ft_cola-47,0.8636757
94,connectivity/cola_6ep_ft-10,0.831153
95,connectivity/cola_6ep_ft-10,0.86201495
96,Jeevesh8/6ep_bert_ft_cola-12,0.831153
97,Jeevesh8/6ep_bert_ft_cola-12,0.8626973
98,Jeevesh8/bert_ft_cola-88,0.8360747
99,Jeevesh8/bert_ft_cola-88,0.878888
100,Jeevesh8/6ep_bert_ft_cola-29,0.8626973
101,vesteinn/XLMR-ENIS-finetuned-cola,0.84382665
102,navsad/navid_test_bert,0.8451538
103,Jeevesh8/bert_ft_cola-60,0.8626973
104,dapang/distilroberta-base-mic-sym,0.74468184
105,dapang/distilroberta-base-mic-sym,0.87752104
106,Capreolus/bert-base-msmarco,0.79807013
107,Capreolus/bert-base-msmarco,0.8659651
108,Splend1dchan/bert-base-uncased-slue-goldtrascription-e3-lr1e-4,0.8050589
109,Splend1dchan/bert-base-uncased-slue-goldtrascription-e3-lr1e-4,0.8714642
110,Jeevesh8/feather_berts_46,0.8050589
111,Jeevesh8/feather_berts_46,0.8739572
112,JonatanGk/roberta-base-bne-finetuned-cyberbullying-spanish,0.5958233
113,JonatanGk/roberta-base-bne-finetuned-cyberbullying-spanish,0.6148513
114,cambridgeltl/guardian_news_distilbert-base-uncased,0.72384703
115,cambridgeltl/guardian_news_distilbert-base-uncased,0.8589614
116,amyma21/sincere_question_classification,0.7238007
117,amyma21/sincere_question_classification,0.8546843
118,phailyoor/distilbert-base-uncased-finetuned-yahd,0.7705503
119,phailyoor/distilbert-base-uncased-finetuned-yahd,0.8213514
120,arianpasquali/distilbert-base-multilingual-cased-toxicity,0.7762581
121,arianpasquali/distilbert-base-multilingual-cased-toxicity,0.7782648
122,connectivity/feather_berts_28,0.8050589
123,connectivity/feather_berts_28,0.8739572
124,warwickai/fin-perceiver,0.7749359
125,warwickai/fin-perceiver,0.7663169
126,liangyuant/distilbert-base-uncased-finetuned-num200-450-405cls,0.7259176
127,liangyuant/distilbert-base-uncased-finetuned-num200-450-405cls,0.82028687
128,DoyyingFace/bert-asian-hate-tweets-asian-unclean-freeze-4,0.79807013
129,DoyyingFace/bert-asian-hate-tweets-asian-unclean-freeze-4,0.86499566
130,Jeevesh8/lecun_feather_berts-3,0.8050589
131,Jeevesh8/lecun_feather_berts-3,0.872729
132,Giyaseddin/distilroberta-base-finetuned-short-answer-assessment,0.7531224
133,Giyaseddin/distilroberta-base-finetuned-short-answer-assessment,0.8648552
134,AnonymousSub/dummy_2,0.7709024
135,AnonymousSub/dummy_2,0.775505
136,Jeevesh8/lecun_feather_berts-51,0.8050589
137,Jeevesh8/lecun_feather_berts-51,0.8749356
138,viviastaari/finetuning-sentiment-analysis-en-id,0.7274984
139,viviastaari/finetuning-sentiment-analysis-en-id,0.74013287
140,Aureliano/distilbert-base-uncased-if,0.7298795
141,Aureliano/distilbert-base-uncased-if,0.86009985
142,rmihaylov/roberta-base-sentiment-bg,0.78814995
143,rmihaylov/roberta-base-sentiment-bg,0.81673837
144,cardiffnlp/twitter-roberta-base-2021-124m,0.7794161
145,cardiffnlp/twitter-roberta-base-2021-124m,0.80388093
146,Jeevesh8/lecun_feather_berts-8,0.8050589
147,Jeevesh8/lecun_feather_berts-8,0.8739572
148,korca/bae-roberta-base-boolq,0.8166525
149,korca/bae-roberta-base-boolq,0.8891476
150,aditeyabaral/finetuned-sail2017-xlm-roberta-base,0.8607325
151,aditeyabaral/finetuned-sail2017-xlm-roberta-base,0.85642356
152,joebobby/finetuning-sentiment-model-5000-samples3,0.8127559
153,joebobby/finetuning-sentiment-model-5000-samples3,0.8456115
154,YeRyeongLee/electra-base-discriminator-finetuned-filtered-0602,0.58252484
155,YeRyeongLee/electra-base-discriminator-finetuned-filtered-0602,0.58828235
156,Jeevesh8/feather_berts_92,0.8050589
157,Jeevesh8/feather_berts_92,0.8739572
158,ASCCCCCCCC/distilbert-base-chinese-amazon_zh_20000,0.7045243
159,ASCCCCCCCC/distilbert-base-chinese-amazon_zh_20000,0.75141984
160,matthewburke/korean_sentiment,0.7032711
161,IMSyPP/hate_speech_nl,0.5967142
162,cointegrated/roberta-base-formality,0.8891476
163,chiragasarpota/scotus-bert,0.5469204
164,IMSyPP/hate_speech_it,0.73583114
165,18811449050/bert_finetuning_test,0.8634274
166,finiteautomata/betonews-tweetcontext,0.7109894
167,Jeevesh8/feather_berts_96,0.86210644
168,Jeevesh8/lecun_feather_berts-7,0.872729
169,mrm8488/codebert-base-finetuned-detect-insecure-code,0.84676087
170,socialmediaie/TRAC2020_IBEN_B_bert-base-multilingual-uncased,0.7701947
171,zenkri/autotrain-Arabic_Poetry_by_Subject-920730230,0.8221659
172,M47Labs/spanish_news_classification_headlines_untrained,0.7735939
173,bondi/bert-semaphore-prediction-w4,0.7206196
174,classla/bcms-bertic-parlasent-bcs-ter,0.74754876
175,anferico/bert-for-patents,0.80412453
176,waboucay/camembert-base-finetuned-xnli_fr-finetuned-nli-rua_wl,0.6921453
177,ali2066/DistilBERTFINAL_ctxSentence_TRAIN_editorials_TEST_NULL_second_train_set_null_False,0.9160411
178,anvay/finetuning-cardiffnlp-sentiment-model,0.9174321
179,JonatanGk/roberta-base-ca-finetuned-hate-speech-offensive-catalan,0.7696845
180,Raychanan/COVID_RandomOver,0.52080506
181,Monsia/camembert-fr-covid-tweet-classification,0.7609911
182,CAMeL-Lab/bert-base-arabic-camelbert-mix-did-nadi,0.6765237
183,kyleinincubated/autonlp-cat333-624217911,0.7710447
184,CAMeL-Lab/bert-base-arabic-camelbert-da-sentiment,0.587196
185,nurkayevaa/autonlp-bert-covid-407910458,0.76594514
186,nurkayevaa/autonlp-bert-covid-407910458,0.8699924
187,SetFit/distilbert-base-uncased__hate_speech_offensive__train-16-1,0.8037101
188,SetFit/distilbert-base-uncased__hate_speech_offensive__train-16-1,0.86529016
189,crcb/isear_bert,0.8580637
190,crcb/isear_bert,0.8904482
191,robertou2/roberta-base-bne-finetuned-amazon_reviews_multi,0.72894025
192,robertou2/roberta-base-bne-finetuned-amazon_reviews_multi,0.7180565
193,milyiyo/selectra-small-finetuned-amazon-review,0.7029586
194,milyiyo/selectra-small-finetuned-amazon-review,0.69629216
195,Anthos23/FS-distilroberta-fine-tuned,0.7609499
196,Anthos23/FS-distilroberta-fine-tuned,0.85295415
197,oferweintraub/bert-base-finance-sentiment-noisy-search,0.83260614
198,oferweintraub/bert-base-finance-sentiment-noisy-search,0.86750025
199,pietrotrope/emotion_final,0.62745667
200,pietrotrope/emotion_final,0.7525249
201,aXhyra/emotion_trained_31415,0.74510854
202,aXhyra/emotion_trained_31415,0.7675795
203,aXhyra/presentation_emotion_31415,0.7556787
204,aXhyra/presentation_emotion_31415,0.7916729
205,Recognai/bert-base-spanish-wwm-cased-xnli,0.7563821
206,Recognai/bert-base-spanish-wwm-cased-xnli,0.69350344
207,JNK789/distilbert-base-uncased-finetuned-tweets-emoji-dataset,0.592759
208,JNK789/distilbert-base-uncased-finetuned-tweets-emoji-dataset,0.73183566
209,anirudh21/bert-base-uncased-finetuned-qnli,0.83756655
210,anirudh21/bert-base-uncased-finetuned-qnli,0.84039634
211,Alireza1044/albert-base-v2-qnli,0.75872934
212,Alireza1044/albert-base-v2-qnli,0.78197664
213,aXhyra/demo_sentiment_31415,0.77533495
214,aXhyra/demo_sentiment_31415,0.79781127
215,aXhyra/presentation_sentiment_1234567,0.7749732
216,aXhyra/presentation_sentiment_1234567,0.8228913
217,jb2k/bert-base-multilingual-cased-language-detection,0.7616346
218,jb2k/bert-base-multilingual-cased-language-detection,0.70501494
219,vinai/bertweet-base,0.7905678
220,vinai/bertweet-base,0.79813784
221,distilbert-base-uncased,0.7309211
222,distilbert-base-uncased,0.7951441
223,bert-base-uncased,0.78054494
224,bert-base-uncased,0.85449415
225,roberta-base,0.7912106
226,roberta-base,0.79212135
227,albert-base-v2,0.71948045
228,bert-base-cased,0.79153585
229,dhimskyy/wiki-bert,0.6634045
230,michiyasunaga/LinkBERT-base,0.8273123
231,roberta-large,0.84004825
232,boychaboy/MNLI_roberta-base,0.83773065
233,boychaboy/MNLI_roberta-base,0.8800392
234,ishan/bert-base-uncased-mnli,0.8868799
235,emrecan/bert-base-multilingual-cased-snli_tr,0.8000228
236,emrecan/bert-base-multilingual-cased-snli_tr,0.75361305
237,elozano/tweet_offensive_eval,0.77944916
238,elozano/tweet_offensive_eval,0.78776073
239,Hate-speech-CNERG/bert-base-uncased-hatexplain-rationale-two,0.8836684
240,aychang/bert-base-cased-trec-coarse,0.7507444
241,gchhablani/bert-base-cased-finetuned-wnli,0.8542148
242,nickmuchi/facebook-data2vec-finetuned-finance-classification,0.72608215
243,w11wo/sundanese-bert-base-emotion-classifier,0.7365293
244,gchhablani/bert-base-cased-finetuned-rte,0.8426605
245,mrm8488/electricidad-base-finetuned-pawsx-es,0.6815821
246,manueltonneau/bert-twitter-en-is-hired,0.8287226
247,Guscode/DKbert-hatespeech-detection,0.7183559
