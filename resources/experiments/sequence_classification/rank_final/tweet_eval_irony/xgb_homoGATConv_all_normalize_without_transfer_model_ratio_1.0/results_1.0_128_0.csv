,model,score
0,Guscode/DKbert-hatespeech-detection,0.5608788
1,robertou2/roberta-base-bne-finetuned-amazon_reviews_multi,0.6366103
2,milyiyo/selectra-small-finetuned-amazon-review,0.11869437
3,robertou2/roberta-base-bne-finetuned-amazon_reviews_multi,0.5995986
4,milyiyo/selectra-small-finetuned-amazon-review,0.14629677
5,SetFit/distilbert-base-uncased__hate_speech_offensive__train-16-1,0.87183267
6,SetFit/distilbert-base-uncased__hate_speech_offensive__train-16-1,0.86816305
7,vinai/bertweet-base,0.84190834
8,vinai/bertweet-base,0.87937844
9,jb2k/bert-base-multilingual-cased-language-detection,0.71849096
10,jb2k/bert-base-multilingual-cased-language-detection,0.723631
11,crcb/isear_bert,0.90296614
12,crcb/isear_bert,0.94586766
13,vaariis/distilbert-base-uncased-finetuned-emotion,0.8273096
14,marcelcastrobr/sagemaker-distilbert-emotion,0.80942696
15,jasonyim2/distilbert-base-uncased-finetuned-emotion,0.7969659
16,abdelkader/distilbert-base-uncased-finetuned-emotion,0.82813466
17,moghis/distilbert-base-uncased-finetuned-emotion,0.8304797
18,uygarkurt/distilbert-base-uncased-finetuned-emotion,0.85120636
19,neibla/distilbert-base-uncased-finetuned-emotion,0.84564894
20,JB173/distilbert-base-uncased-finetuned-emotion,0.8282037
21,Nanatan/distilbert-base-uncased-finetuned-emotion,0.7914578
22,vaariis/distilbert-base-uncased-finetuned-emotion,0.8352953
23,marcelcastrobr/sagemaker-distilbert-emotion,0.847782
24,jasonyim2/distilbert-base-uncased-finetuned-emotion,0.83354735
25,abdelkader/distilbert-base-uncased-finetuned-emotion,0.83770835
26,moghis/distilbert-base-uncased-finetuned-emotion,0.8498047
27,uygarkurt/distilbert-base-uncased-finetuned-emotion,0.85979307
28,neibla/distilbert-base-uncased-finetuned-emotion,0.8519005
29,JB173/distilbert-base-uncased-finetuned-emotion,0.7972588
30,Nanatan/distilbert-base-uncased-finetuned-emotion,0.8095456
31,riyadhctg/distilbert-base-uncased-finetuned-cola,0.86638236
32,connectivity/cola_6ep_ft-33,0.89319915
33,connectivity/cola_6ep_ft-22,0.9010192
34,gchhablani/fnet-base-finetuned-cola,0.6512577
35,isakbos/Q8BERT_COLA_L_512,0.32560244
36,jaesun/distilbert-base-uncased-finetuned-cola,0.8704017
37,usami/distilbert-base-uncased-finetuned-cola,0.86241174
38,Jeevesh8/512seq_len_6ep_bert_ft_cola-91,0.9038995
39,Jeevesh8/6ep_bert_ft_cola-47,0.87749624
40,connectivity/cola_6ep_ft-10,0.91270614
41,Jeevesh8/6ep_bert_ft_cola-12,0.8986913
42,Jeevesh8/bert_ft_cola-88,0.886092
43,riyadhctg/distilbert-base-uncased-finetuned-cola,0.86687857
44,connectivity/cola_6ep_ft-33,0.8884767
45,connectivity/cola_6ep_ft-22,0.90178484
46,gchhablani/fnet-base-finetuned-cola,0.6697715
47,vesteinn/XLMR-ENIS-finetuned-cola,0.87436306
48,isakbos/Q8BERT_COLA_L_512,0.23307566
49,jaesun/distilbert-base-uncased-finetuned-cola,0.86080253
50,usami/distilbert-base-uncased-finetuned-cola,0.87127805
51,Jeevesh8/512seq_len_6ep_bert_ft_cola-91,0.9126006
52,Jeevesh8/6ep_bert_ft_cola-47,0.9094012
53,connectivity/cola_6ep_ft-10,0.8646272
54,Jeevesh8/6ep_bert_ft_cola-12,0.8955322
55,Jeevesh8/6ep_bert_ft_cola-29,0.89097685
56,Jeevesh8/bert_ft_cola-60,0.89174455
57,navsad/navid_test_bert,0.8815257
58,Jeevesh8/bert_ft_cola-88,0.9108837
59,boychaboy/MNLI_roberta-base,0.9215682
60,ishan/bert-base-uncased-mnli,0.9044889
61,boychaboy/MNLI_roberta-base,0.9482165
62,anirudh21/bert-base-uncased-finetuned-qnli,0.9004271
63,Alireza1044/albert-base-v2-qnli,0.8290897
64,anirudh21/bert-base-uncased-finetuned-qnli,0.90713215
65,Alireza1044/albert-base-v2-qnli,0.78233266
66,Jeevesh8/init_bert_ft_qqp-33,0.8456049
67,Jeevesh8/init_bert_ft_qqp-49,0.875762
68,connectivity/bert_ft_qqp-7,0.87458
69,Jeevesh8/bert_ft_qqp-40,0.881957
70,Jeevesh8/bert_ft_qqp-9,0.8645295
71,Jeevesh8/bert_ft_qqp-88,0.8730292
72,connectivity/bert_ft_qqp-25,0.88606817
73,Jeevesh8/bert_ft_qqp-55,0.8824819
74,connectivity/bert_ft_qqp-1,0.88355696
75,Jeevesh8/bert_ft_qqp-39,0.88274777
76,connectivity/bert_ft_qqp-94,0.881598
77,connectivity/bert_ft_qqp-96,0.8732178
78,Jeevesh8/init_bert_ft_qqp-33,0.8690391
79,Jeevesh8/init_bert_ft_qqp-49,0.85090506
80,connectivity/bert_ft_qqp-7,0.8797489
81,Jeevesh8/bert_ft_qqp-40,0.875386
82,Jeevesh8/bert_ft_qqp-9,0.85659444
83,Jeevesh8/bert_ft_qqp-88,0.8757088
84,connectivity/bert_ft_qqp-25,0.9183756
85,Jeevesh8/init_bert_ft_qqp-24,0.87811816
86,Jeevesh8/bert_ft_qqp-55,0.8876535
87,Jeevesh8/bert_ft_qqp-68,0.8713748
88,connectivity/bert_ft_qqp-17,0.8732164
89,Jeevesh8/init_bert_ft_qqp-28,0.87915605
90,connectivity/bert_ft_qqp-1,0.8717371
91,Jeevesh8/bert_ft_qqp-39,0.88296306
92,connectivity/bert_ft_qqp-94,0.85815305
93,connectivity/bert_ft_qqp-96,0.8872904
94,gchhablani/bert-base-cased-finetuned-rte,0.87463766
95,ali2066/finetuned_sentence_itr1_2e-05_all_26_02_2022-04_03_26,0.8184718
96,SetFit/distilbert-base-uncased__sst2__train-16-0,0.8692515
97,gchhablani/fnet-base-finetuned-sst2,0.66307265
98,aviator-neural/bert-base-uncased-sst2,0.8549242
99,SetFit/distilbert-base-uncased__sst2__train-32-9,0.8454735
100,Alassea/glue_sst_classifier,0.8781295
101,ali2066/finetuned_sentence_itr1_2e-05_all_26_02_2022-04_03_26,0.83459413
102,philschmid/tiny-distilbert-classification,-0.018234055
103,SetFit/distilbert-base-uncased__sst2__train-16-0,0.8517819
104,gchhablani/fnet-base-finetuned-sst2,0.7009192
105,moshew/bert-mini-sst2-distilled,0.6876442
106,aviator-neural/bert-base-uncased-sst2,0.8715096
107,SetFit/distilbert-base-uncased__sst2__train-32-9,0.8500993
108,Alassea/glue_sst_classifier,0.89573073
109,ChrisUPM/BioBERT_Re_trained,0.7593744
110,gchhablani/bert-base-cased-finetuned-wnli,0.86990243
111,Hate-speech-CNERG/bert-base-uncased-hatexplain-rationale-two,0.9135127
112,heranm/finetuning-sentiment-model-3000-samples,0.826841
113,PrasunMishra/finetuning-sentiment-model-3000-samples,0.8464535
114,yukta10/finetuning-sentiment-model-3000-samples,0.8288804
115,ncduy/roberta-imdb-sentiment-analysis,0.92934513
116,markt23917/finetuning-sentiment-model-3000-samples,0.8414046
117,juliensimon/autonlp-imdb-demo-hf-16622767,0.7907615
118,fabriceyhc/bert-base-uncased-imdb,0.849815
119,heranm/finetuning-sentiment-model-3000-samples,0.8517541
120,PrasunMishra/finetuning-sentiment-model-3000-samples,0.8377265
121,yukta10/finetuning-sentiment-model-3000-samples,0.83935153
122,ncduy/roberta-imdb-sentiment-analysis,0.88680935
123,markt23917/finetuning-sentiment-model-3000-samples,0.87724024
124,juliensimon/autonlp-imdb-demo-hf-16622767,0.7953948
125,XSY/albert-base-v2-imdb-calssification,0.76585555
126,fabriceyhc/bert-base-uncased-imdb,0.8452602
127,Anthos23/FS-distilroberta-fine-tuned,0.8971964
128,oferweintraub/bert-base-finance-sentiment-noisy-search,0.88410497
129,Anthos23/FS-distilroberta-fine-tuned,0.9006463
130,oferweintraub/bert-base-finance-sentiment-noisy-search,0.8814383
131,emrecan/bert-base-multilingual-cased-snli_tr,0.71129054
132,emrecan/bert-base-multilingual-cased-snli_tr,0.7126407
133,nurkayevaa/autonlp-bert-covid-407910458,0.86610276
134,nurkayevaa/autonlp-bert-covid-407910458,0.890639
135,w11wo/sundanese-bert-base-emotion-classifier,0.34310243
136,aychang/bert-base-cased-trec-coarse,0.8933136
137,JNK789/distilbert-base-uncased-finetuned-tweets-emoji-dataset,0.050697733
138,JNK789/distilbert-base-uncased-finetuned-tweets-emoji-dataset,0.00044038674
139,pietrotrope/emotion_final,0.85553485
140,aXhyra/emotion_trained_31415,0.8410082
141,aXhyra/presentation_emotion_31415,0.85654324
142,pietrotrope/emotion_final,0.875732
143,aXhyra/emotion_trained_31415,0.8458436
144,aXhyra/presentation_emotion_31415,0.86668766
145,elozano/tweet_offensive_eval,0.35870305
146,elozano/tweet_offensive_eval,0.20849887
147,aXhyra/demo_sentiment_31415,0.8925298
148,aXhyra/presentation_sentiment_1234567,0.87701494
149,aXhyra/demo_sentiment_31415,0.8891087
150,aXhyra/presentation_sentiment_1234567,0.9092878
151,nickmuchi/facebook-data2vec-finetuned-finance-classification,0.7746125
152,manueltonneau/bert-twitter-en-is-hired,0.9068438
153,distilbert-base-uncased,0.857683
154,bert-base-uncased,0.8957744
155,roberta-base,0.9152995
156,dhimskyy/wiki-bert,0.36867395
157,bert-base-uncased,0.90012956
158,distilbert-base-uncased,0.84470654
159,roberta-base,0.9167591
160,bert-base-cased,0.881235
161,albert-base-v2,0.52812403
162,michiyasunaga/LinkBERT-base,0.85504013
163,roberta-large,0.64806825
164,Recognai/bert-base-spanish-wwm-cased-xnli,0.3773597
165,Recognai/bert-base-spanish-wwm-cased-xnli,0.36602074
166,mrm8488/electricidad-base-finetuned-pawsx-es,0.36287928
167,dapang/distilroberta-base-mic-sym,0.88424224
168,Capreolus/bert-base-msmarco,0.8887636
169,Splend1dchan/bert-base-uncased-slue-goldtrascription-e3-lr1e-4,0.87344885
170,Jeevesh8/feather_berts_46,0.894738
171,JonatanGk/roberta-base-bne-finetuned-cyberbullying-spanish,0.26433954
172,cambridgeltl/guardian_news_distilbert-base-uncased,0.83947664
173,amyma21/sincere_question_classification,0.85317767
174,phailyoor/distilbert-base-uncased-finetuned-yahd,0.8107212
175,arianpasquali/distilbert-base-multilingual-cased-toxicity,0.64542806
176,connectivity/feather_berts_28,0.90258765
177,warwickai/fin-perceiver,0.6757632
178,liangyuant/distilbert-base-uncased-finetuned-num200-450-405cls,0.8563989
179,DoyyingFace/bert-asian-hate-tweets-asian-unclean-freeze-4,0.8886738
180,Jeevesh8/lecun_feather_berts-3,0.8765095
181,Giyaseddin/distilroberta-base-finetuned-short-answer-assessment,0.86732167
182,AnonymousSub/dummy_2,0.7276861
183,Jeevesh8/lecun_feather_berts-51,0.89538705
184,viviastaari/finetuning-sentiment-analysis-en-id,0.6096957
185,Aureliano/distilbert-base-uncased-if,0.8646381
186,rmihaylov/roberta-base-sentiment-bg,0.68897116
187,cardiffnlp/twitter-roberta-base-2021-124m,0.8975939
188,Jeevesh8/lecun_feather_berts-8,0.88114375
189,korca/bae-roberta-base-boolq,0.8692587
190,aditeyabaral/finetuned-sail2017-xlm-roberta-base,0.87663776
191,joebobby/finetuning-sentiment-model-5000-samples3,0.88221276
192,YeRyeongLee/electra-base-discriminator-finetuned-filtered-0602,0.26441622
193,Jeevesh8/feather_berts_92,0.89703524
194,ASCCCCCCCC/distilbert-base-chinese-amazon_zh_20000,0.5758169
195,dapang/distilroberta-base-mic-sym,0.8710234
196,Capreolus/bert-base-msmarco,0.894626
197,Splend1dchan/bert-base-uncased-slue-goldtrascription-e3-lr1e-4,0.88397443
198,Jeevesh8/feather_berts_46,0.8863011
199,JonatanGk/roberta-base-bne-finetuned-cyberbullying-spanish,0.08348514
200,cambridgeltl/guardian_news_distilbert-base-uncased,0.87073165
201,amyma21/sincere_question_classification,0.8611253
202,phailyoor/distilbert-base-uncased-finetuned-yahd,0.7845446
203,arianpasquali/distilbert-base-multilingual-cased-toxicity,0.66873074
204,connectivity/feather_berts_28,0.8941294
205,IMSyPP/hate_speech_it,0.6311728
206,chiragasarpota/scotus-bert,0.08805433
207,warwickai/fin-perceiver,0.74894035
208,liangyuant/distilbert-base-uncased-finetuned-num200-450-405cls,0.8373487
209,DoyyingFace/bert-asian-hate-tweets-asian-unclean-freeze-4,0.88696235
210,Jeevesh8/lecun_feather_berts-3,0.90741754
211,Giyaseddin/distilroberta-base-finetuned-short-answer-assessment,0.8565165
212,18811449050/bert_finetuning_test,0.8722108
213,Jeevesh8/feather_berts_96,0.9264232
214,AnonymousSub/dummy_2,0.7076384
215,Jeevesh8/lecun_feather_berts-51,0.9365852
216,viviastaari/finetuning-sentiment-analysis-en-id,0.62330675
217,finiteautomata/betonews-tweetcontext,0.54723763
218,Aureliano/distilbert-base-uncased-if,0.84530836
219,rmihaylov/roberta-base-sentiment-bg,0.69473165
220,cardiffnlp/twitter-roberta-base-2021-124m,0.97947955
221,Jeevesh8/lecun_feather_berts-8,0.9048184
222,Jeevesh8/lecun_feather_berts-7,0.8718024
223,IMSyPP/hate_speech_nl,0.15542239
224,matthewburke/korean_sentiment,0.57004803
225,korca/bae-roberta-base-boolq,0.8852424
226,waboucay/camembert-base-finetuned-xnli_fr-finetuned-nli-rua_wl,0.23777394
227,aditeyabaral/finetuned-sail2017-xlm-roberta-base,0.8609343
228,socialmediaie/TRAC2020_IBEN_B_bert-base-multilingual-uncased,0.7840691
229,mrm8488/codebert-base-finetuned-detect-insecure-code,0.77354354
230,M47Labs/spanish_news_classification_headlines_untrained,0.55391544
231,CAMeL-Lab/bert-base-arabic-camelbert-da-sentiment,0.06823278
232,zenkri/autotrain-Arabic_Poetry_by_Subject-920730230,0.849974
233,bondi/bert-semaphore-prediction-w4,0.43291885
234,cointegrated/roberta-base-formality,0.91593975
235,JonatanGk/roberta-base-ca-finetuned-hate-speech-offensive-catalan,0.53353494
236,classla/bcms-bertic-parlasent-bcs-ter,0.6745954
237,Raychanan/COVID_RandomOver,-0.009264489
238,ali2066/DistilBERTFINAL_ctxSentence_TRAIN_editorials_TEST_NULL_second_train_set_null_False,0.9472373
239,anvay/finetuning-cardiffnlp-sentiment-model,0.97033006
240,joebobby/finetuning-sentiment-model-5000-samples3,0.8881176
241,YeRyeongLee/electra-base-discriminator-finetuned-filtered-0602,0.10071721
242,Jeevesh8/feather_berts_92,0.9028451
243,CAMeL-Lab/bert-base-arabic-camelbert-mix-did-nadi,0.43655196
244,Monsia/camembert-fr-covid-tweet-classification,0.7096373
245,kyleinincubated/autonlp-cat333-624217911,0.6535075
246,ASCCCCCCCC/distilbert-base-chinese-amazon_zh_20000,0.6067641
247,anferico/bert-for-patents,0.732215
