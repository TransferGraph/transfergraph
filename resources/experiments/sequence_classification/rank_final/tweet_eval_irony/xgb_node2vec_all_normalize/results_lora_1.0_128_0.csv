,model,score
0,Jeevesh8/init_bert_ft_qqp-33,0.89057004
1,Jeevesh8/init_bert_ft_qqp-33,0.6705549
2,Jeevesh8/init_bert_ft_qqp-33,0.6665496
3,Jeevesh8/init_bert_ft_qqp-49,0.897321
4,Jeevesh8/init_bert_ft_qqp-49,0.8533865
5,Jeevesh8/init_bert_ft_qqp-49,0.80722684
6,connectivity/bert_ft_qqp-7,0.8525228
7,connectivity/bert_ft_qqp-7,0.8857888
8,connectivity/bert_ft_qqp-7,0.8857888
9,Jeevesh8/bert_ft_qqp-40,0.9169945
10,Jeevesh8/bert_ft_qqp-40,0.86094946
11,Jeevesh8/bert_ft_qqp-40,0.8611193
12,Jeevesh8/bert_ft_qqp-9,0.9050094
13,Jeevesh8/bert_ft_qqp-9,0.852006
14,Jeevesh8/bert_ft_qqp-9,0.85450846
15,Jeevesh8/bert_ft_qqp-88,0.9037685
16,Jeevesh8/bert_ft_qqp-88,0.8617905
17,Jeevesh8/bert_ft_qqp-88,0.8617905
18,connectivity/bert_ft_qqp-25,0.90717995
19,connectivity/bert_ft_qqp-25,0.8623309
20,connectivity/bert_ft_qqp-25,0.8378737
21,Jeevesh8/bert_ft_qqp-55,0.9074308
22,Jeevesh8/bert_ft_qqp-55,0.86759835
23,Jeevesh8/bert_ft_qqp-55,0.86759835
24,connectivity/bert_ft_qqp-1,0.8858117
25,connectivity/bert_ft_qqp-1,0.84307337
26,connectivity/bert_ft_qqp-1,0.84307337
27,Jeevesh8/bert_ft_qqp-39,0.9035737
28,Jeevesh8/bert_ft_qqp-39,0.85669714
29,Jeevesh8/bert_ft_qqp-39,0.8558381
30,connectivity/bert_ft_qqp-94,0.9077879
31,connectivity/bert_ft_qqp-94,0.86053103
32,connectivity/bert_ft_qqp-94,0.837481
33,connectivity/bert_ft_qqp-96,0.8981783
34,connectivity/bert_ft_qqp-96,0.8550144
35,connectivity/bert_ft_qqp-96,0.8511167
36,Jeevesh8/init_bert_ft_qqp-24,0.86775255
37,Jeevesh8/init_bert_ft_qqp-24,0.86775255
38,Jeevesh8/bert_ft_qqp-68,0.8484817
39,Jeevesh8/bert_ft_qqp-68,0.84553385
40,Jeevesh8/init_bert_ft_qqp-28,0.8725527
41,Jeevesh8/init_bert_ft_qqp-28,0.8725527
42,connectivity/bert_ft_qqp-17,0.8660362
43,connectivity/bert_ft_qqp-17,0.8629185
44,ali2066/finetuned_sentence_itr1_2e-05_all_26_02_2022-04_03_26,0.88178813
45,ali2066/finetuned_sentence_itr1_2e-05_all_26_02_2022-04_03_26,0.85351926
46,ali2066/finetuned_sentence_itr1_2e-05_all_26_02_2022-04_03_26,0.7891146
47,SetFit/distilbert-base-uncased__sst2__train-16-0,0.8829065
48,SetFit/distilbert-base-uncased__sst2__train-16-0,0.8464217
49,SetFit/distilbert-base-uncased__sst2__train-16-0,0.83253914
50,aviator-neural/bert-base-uncased-sst2,0.9055904
51,aviator-neural/bert-base-uncased-sst2,0.8668146
52,aviator-neural/bert-base-uncased-sst2,0.86044663
53,SetFit/distilbert-base-uncased__sst2__train-32-9,0.9019658
54,SetFit/distilbert-base-uncased__sst2__train-32-9,0.86142635
55,SetFit/distilbert-base-uncased__sst2__train-32-9,0.86142635
56,Alassea/glue_sst_classifier,0.8878882
57,Alassea/glue_sst_classifier,0.86146337
58,Alassea/glue_sst_classifier,0.86146337
59,philschmid/tiny-distilbert-classification,0.52718055
60,philschmid/tiny-distilbert-classification,0.52464575
61,moshew/bert-mini-sst2-distilled,0.82901126
62,moshew/bert-mini-sst2-distilled,0.82901126
63,ChrisUPM/BioBERT_Re_trained,0.81572956
64,ChrisUPM/BioBERT_Re_trained,0.7847955
65,vaariis/distilbert-base-uncased-finetuned-emotion,0.8847033
66,vaariis/distilbert-base-uncased-finetuned-emotion,0.8197086
67,vaariis/distilbert-base-uncased-finetuned-emotion,0.8383694
68,marcelcastrobr/sagemaker-distilbert-emotion,0.88974494
69,marcelcastrobr/sagemaker-distilbert-emotion,0.81340176
70,marcelcastrobr/sagemaker-distilbert-emotion,0.8110225
71,jasonyim2/distilbert-base-uncased-finetuned-emotion,0.88092494
72,jasonyim2/distilbert-base-uncased-finetuned-emotion,0.81956476
73,jasonyim2/distilbert-base-uncased-finetuned-emotion,0.82552207
74,abdelkader/distilbert-base-uncased-finetuned-emotion,0.8807204
75,abdelkader/distilbert-base-uncased-finetuned-emotion,0.82865626
76,abdelkader/distilbert-base-uncased-finetuned-emotion,0.82418144
77,moghis/distilbert-base-uncased-finetuned-emotion,0.88156915
78,moghis/distilbert-base-uncased-finetuned-emotion,0.86183184
79,moghis/distilbert-base-uncased-finetuned-emotion,0.8591679
80,uygarkurt/distilbert-base-uncased-finetuned-emotion,0.90189403
81,uygarkurt/distilbert-base-uncased-finetuned-emotion,0.8274338
82,uygarkurt/distilbert-base-uncased-finetuned-emotion,0.8271852
83,neibla/distilbert-base-uncased-finetuned-emotion,0.87967247
84,neibla/distilbert-base-uncased-finetuned-emotion,0.8454059
85,neibla/distilbert-base-uncased-finetuned-emotion,0.82363516
86,JB173/distilbert-base-uncased-finetuned-emotion,0.90039575
87,JB173/distilbert-base-uncased-finetuned-emotion,0.8113637
88,JB173/distilbert-base-uncased-finetuned-emotion,0.81759876
89,Nanatan/distilbert-base-uncased-finetuned-emotion,0.87172556
90,Nanatan/distilbert-base-uncased-finetuned-emotion,0.8195023
91,Nanatan/distilbert-base-uncased-finetuned-emotion,0.82226473
92,heranm/finetuning-sentiment-model-3000-samples,0.89790994
93,heranm/finetuning-sentiment-model-3000-samples,0.845327
94,heranm/finetuning-sentiment-model-3000-samples,0.8224421
95,PrasunMishra/finetuning-sentiment-model-3000-samples,0.8900333
96,PrasunMishra/finetuning-sentiment-model-3000-samples,0.8381252
97,PrasunMishra/finetuning-sentiment-model-3000-samples,0.82639104
98,yukta10/finetuning-sentiment-model-3000-samples,0.885822
99,yukta10/finetuning-sentiment-model-3000-samples,0.84235895
100,yukta10/finetuning-sentiment-model-3000-samples,0.8269969
101,ncduy/roberta-imdb-sentiment-analysis,0.91015047
102,ncduy/roberta-imdb-sentiment-analysis,0.8661888
103,ncduy/roberta-imdb-sentiment-analysis,0.866019
104,markt23917/finetuning-sentiment-model-3000-samples,0.8818996
105,markt23917/finetuning-sentiment-model-3000-samples,0.86954916
106,markt23917/finetuning-sentiment-model-3000-samples,0.8509268
107,juliensimon/autonlp-imdb-demo-hf-16622767,0.90436345
108,juliensimon/autonlp-imdb-demo-hf-16622767,0.84371626
109,juliensimon/autonlp-imdb-demo-hf-16622767,0.8460303
110,fabriceyhc/bert-base-uncased-imdb,0.9018333
111,fabriceyhc/bert-base-uncased-imdb,0.8533704
112,fabriceyhc/bert-base-uncased-imdb,0.81916285
113,riyadhctg/distilbert-base-uncased-finetuned-cola,0.8819357
114,riyadhctg/distilbert-base-uncased-finetuned-cola,0.8637733
115,riyadhctg/distilbert-base-uncased-finetuned-cola,0.840765
116,connectivity/cola_6ep_ft-33,0.9019087
117,connectivity/cola_6ep_ft-33,0.87590843
118,connectivity/cola_6ep_ft-33,0.8372388
119,connectivity/cola_6ep_ft-22,0.9055748
120,connectivity/cola_6ep_ft-22,0.8687939
121,connectivity/cola_6ep_ft-22,0.8506044
122,isakbos/Q8BERT_COLA_L_512,0.75467044
123,isakbos/Q8BERT_COLA_L_512,0.6614993
124,isakbos/Q8BERT_COLA_L_512,0.6560247
125,jaesun/distilbert-base-uncased-finetuned-cola,0.8611425
126,jaesun/distilbert-base-uncased-finetuned-cola,0.8451027
127,jaesun/distilbert-base-uncased-finetuned-cola,0.8445905
128,usami/distilbert-base-uncased-finetuned-cola,0.8651683
129,usami/distilbert-base-uncased-finetuned-cola,0.8365772
130,usami/distilbert-base-uncased-finetuned-cola,0.81528383
131,Jeevesh8/512seq_len_6ep_bert_ft_cola-91,0.93157977
132,Jeevesh8/512seq_len_6ep_bert_ft_cola-91,0.8894417
133,Jeevesh8/512seq_len_6ep_bert_ft_cola-91,0.8394907
134,Jeevesh8/6ep_bert_ft_cola-47,0.90073234
135,Jeevesh8/6ep_bert_ft_cola-47,0.8744574
136,Jeevesh8/6ep_bert_ft_cola-47,0.8488354
137,connectivity/cola_6ep_ft-10,0.89670724
138,connectivity/cola_6ep_ft-10,0.85158634
139,connectivity/cola_6ep_ft-10,0.8510864
140,Jeevesh8/6ep_bert_ft_cola-12,0.92323524
141,Jeevesh8/6ep_bert_ft_cola-12,0.8808847
142,Jeevesh8/6ep_bert_ft_cola-12,0.85251296
143,Jeevesh8/bert_ft_cola-88,0.91083467
144,Jeevesh8/bert_ft_cola-88,0.85449696
145,Jeevesh8/bert_ft_cola-88,0.8707774
146,Jeevesh8/6ep_bert_ft_cola-29,0.87425876
147,Jeevesh8/6ep_bert_ft_cola-29,0.87425876
148,vesteinn/XLMR-ENIS-finetuned-cola,0.85122204
149,vesteinn/XLMR-ENIS-finetuned-cola,0.8394895
150,navsad/navid_test_bert,0.8652189
151,navsad/navid_test_bert,0.83435005
152,Jeevesh8/bert_ft_cola-60,0.87018514
153,Jeevesh8/bert_ft_cola-60,0.85297847
154,dapang/distilroberta-base-mic-sym,0.8871699
155,dapang/distilroberta-base-mic-sym,0.8548469
156,dapang/distilroberta-base-mic-sym,0.8336216
157,Capreolus/bert-base-msmarco,0.8987826
158,Capreolus/bert-base-msmarco,0.8498249
159,Capreolus/bert-base-msmarco,0.84724754
160,Splend1dchan/bert-base-uncased-slue-goldtrascription-e3-lr1e-4,0.90552086
161,Splend1dchan/bert-base-uncased-slue-goldtrascription-e3-lr1e-4,0.8504873
162,Splend1dchan/bert-base-uncased-slue-goldtrascription-e3-lr1e-4,0.843636
163,Jeevesh8/feather_berts_46,0.90440166
164,Jeevesh8/feather_berts_46,0.85603446
165,Jeevesh8/feather_berts_46,0.8464657
166,JonatanGk/roberta-base-bne-finetuned-cyberbullying-spanish,0.66711575
167,JonatanGk/roberta-base-bne-finetuned-cyberbullying-spanish,0.6089942
168,JonatanGk/roberta-base-bne-finetuned-cyberbullying-spanish,0.6314687
169,cambridgeltl/guardian_news_distilbert-base-uncased,0.8579865
170,cambridgeltl/guardian_news_distilbert-base-uncased,0.8600845
171,cambridgeltl/guardian_news_distilbert-base-uncased,0.820152
172,amyma21/sincere_question_classification,0.87819993
173,amyma21/sincere_question_classification,0.8357088
174,amyma21/sincere_question_classification,0.81514454
175,phailyoor/distilbert-base-uncased-finetuned-yahd,0.86508995
176,phailyoor/distilbert-base-uncased-finetuned-yahd,0.8239699
177,phailyoor/distilbert-base-uncased-finetuned-yahd,0.79948765
178,arianpasquali/distilbert-base-multilingual-cased-toxicity,0.8360853
179,arianpasquali/distilbert-base-multilingual-cased-toxicity,0.7728066
180,arianpasquali/distilbert-base-multilingual-cased-toxicity,0.7648882
181,connectivity/feather_berts_28,0.89735645
182,connectivity/feather_berts_28,0.85699856
183,connectivity/feather_berts_28,0.8462496
184,liangyuant/distilbert-base-uncased-finetuned-num200-450-405cls,0.9075038
185,liangyuant/distilbert-base-uncased-finetuned-num200-450-405cls,0.8445485
186,liangyuant/distilbert-base-uncased-finetuned-num200-450-405cls,0.854935
187,DoyyingFace/bert-asian-hate-tweets-asian-unclean-freeze-4,0.89287746
188,DoyyingFace/bert-asian-hate-tweets-asian-unclean-freeze-4,0.8513727
189,DoyyingFace/bert-asian-hate-tweets-asian-unclean-freeze-4,0.85154253
190,Jeevesh8/lecun_feather_berts-3,0.9012213
191,Jeevesh8/lecun_feather_berts-3,0.85922146
192,Jeevesh8/lecun_feather_berts-3,0.85922146
193,Giyaseddin/distilroberta-base-finetuned-short-answer-assessment,0.89102715
194,Giyaseddin/distilroberta-base-finetuned-short-answer-assessment,0.8531043
195,Giyaseddin/distilroberta-base-finetuned-short-answer-assessment,0.84722096
196,AnonymousSub/dummy_2,0.8212565
197,AnonymousSub/dummy_2,0.79961574
198,AnonymousSub/dummy_2,0.7745649
199,Jeevesh8/lecun_feather_berts-51,0.91321695
200,Jeevesh8/lecun_feather_berts-51,0.86612684
201,Jeevesh8/lecun_feather_berts-51,0.869089
202,viviastaari/finetuning-sentiment-analysis-en-id,0.8390277
203,viviastaari/finetuning-sentiment-analysis-en-id,0.73775655
204,viviastaari/finetuning-sentiment-analysis-en-id,0.7296759
205,Aureliano/distilbert-base-uncased-if,0.88623226
206,Aureliano/distilbert-base-uncased-if,0.8643557
207,Aureliano/distilbert-base-uncased-if,0.8616917
208,rmihaylov/roberta-base-sentiment-bg,0.8366378
209,rmihaylov/roberta-base-sentiment-bg,0.80827564
210,rmihaylov/roberta-base-sentiment-bg,0.80320257
211,cardiffnlp/twitter-roberta-base-2021-124m,0.9159561
212,cardiffnlp/twitter-roberta-base-2021-124m,0.87358004
213,cardiffnlp/twitter-roberta-base-2021-124m,0.8579524
214,Jeevesh8/lecun_feather_berts-8,0.8920964
215,Jeevesh8/lecun_feather_berts-8,0.8610192
216,Jeevesh8/lecun_feather_berts-8,0.84991574
217,korca/bae-roberta-base-boolq,0.8897499
218,korca/bae-roberta-base-boolq,0.8563523
219,korca/bae-roberta-base-boolq,0.8563523
220,aditeyabaral/finetuned-sail2017-xlm-roberta-base,0.9017499
221,aditeyabaral/finetuned-sail2017-xlm-roberta-base,0.8225131
222,aditeyabaral/finetuned-sail2017-xlm-roberta-base,0.8045892
223,joebobby/finetuning-sentiment-model-5000-samples3,0.907524
224,joebobby/finetuning-sentiment-model-5000-samples3,0.85881186
225,joebobby/finetuning-sentiment-model-5000-samples3,0.8566222
226,Jeevesh8/feather_berts_92,0.9041096
227,Jeevesh8/feather_berts_92,0.8709097
228,Jeevesh8/feather_berts_92,0.8702529
229,ASCCCCCCCC/distilbert-base-chinese-amazon_zh_20000,0.76367545
230,ASCCCCCCCC/distilbert-base-chinese-amazon_zh_20000,0.72428113
231,ASCCCCCCCC/distilbert-base-chinese-amazon_zh_20000,0.7116997
232,matthewburke/korean_sentiment,0.73545563
233,IMSyPP/hate_speech_nl,0.6378534
234,IMSyPP/hate_speech_nl,0.6216089
235,cointegrated/roberta-base-formality,0.8536336
236,cointegrated/roberta-base-formality,0.8489008
237,IMSyPP/hate_speech_it,0.75467914
238,IMSyPP/hate_speech_it,0.7276083
239,18811449050/bert_finetuning_test,0.8371902
240,18811449050/bert_finetuning_test,0.83044946
241,finiteautomata/betonews-tweetcontext,0.7044315
242,finiteautomata/betonews-tweetcontext,0.7044315
243,Jeevesh8/feather_berts_96,0.8794931
244,Jeevesh8/feather_berts_96,0.8794931
245,Jeevesh8/lecun_feather_berts-7,0.8533747
246,Jeevesh8/lecun_feather_berts-7,0.8533747
247,mrm8488/codebert-base-finetuned-detect-insecure-code,0.7989146
248,mrm8488/codebert-base-finetuned-detect-insecure-code,0.7977111
249,socialmediaie/TRAC2020_IBEN_B_bert-base-multilingual-uncased,0.8283525
250,socialmediaie/TRAC2020_IBEN_B_bert-base-multilingual-uncased,0.804097
251,zenkri/autotrain-Arabic_Poetry_by_Subject-920730230,0.8303654
252,zenkri/autotrain-Arabic_Poetry_by_Subject-920730230,0.8308524
253,M47Labs/spanish_news_classification_headlines_untrained,0.75164735
254,bondi/bert-semaphore-prediction-w4,0.72561044
255,classla/bcms-bertic-parlasent-bcs-ter,0.79455894
256,classla/bcms-bertic-parlasent-bcs-ter,0.66756046
257,anferico/bert-for-patents,0.8031099
258,anferico/bert-for-patents,0.78102666
259,ali2066/DistilBERTFINAL_ctxSentence_TRAIN_editorials_TEST_NULL_second_train_set_null_False,0.86247385
260,ali2066/DistilBERTFINAL_ctxSentence_TRAIN_editorials_TEST_NULL_second_train_set_null_False,0.8649778
261,anvay/finetuning-cardiffnlp-sentiment-model,0.8754834
262,anvay/finetuning-cardiffnlp-sentiment-model,0.8705601
263,JonatanGk/roberta-base-ca-finetuned-hate-speech-offensive-catalan,0.68368435
264,JonatanGk/roberta-base-ca-finetuned-hate-speech-offensive-catalan,0.69375104
265,Raychanan/COVID_RandomOver,0.57499635
266,Raychanan/COVID_RandomOver,0.57499635
267,kyleinincubated/autonlp-cat333-624217911,0.76150495
268,kyleinincubated/autonlp-cat333-624217911,0.76284415
269,nurkayevaa/autonlp-bert-covid-407910458,0.8764811
270,nurkayevaa/autonlp-bert-covid-407910458,0.8512934
271,nurkayevaa/autonlp-bert-covid-407910458,0.8307773
272,SetFit/distilbert-base-uncased__hate_speech_offensive__train-16-1,0.87658775
273,SetFit/distilbert-base-uncased__hate_speech_offensive__train-16-1,0.8498295
274,SetFit/distilbert-base-uncased__hate_speech_offensive__train-16-1,0.82092863
275,crcb/isear_bert,0.9005531
276,crcb/isear_bert,0.86983824
277,crcb/isear_bert,0.85413927
278,robertou2/roberta-base-bne-finetuned-amazon_reviews_multi,0.7741134
279,robertou2/roberta-base-bne-finetuned-amazon_reviews_multi,0.73481107
280,robertou2/roberta-base-bne-finetuned-amazon_reviews_multi,0.7077355
281,milyiyo/selectra-small-finetuned-amazon-review,0.6995134
282,milyiyo/selectra-small-finetuned-amazon-review,0.65447634
283,milyiyo/selectra-small-finetuned-amazon-review,0.66039467
284,Anthos23/FS-distilroberta-fine-tuned,0.8704433
285,Anthos23/FS-distilroberta-fine-tuned,0.8453893
286,Anthos23/FS-distilroberta-fine-tuned,0.81578064
287,oferweintraub/bert-base-finance-sentiment-noisy-search,0.90681326
288,oferweintraub/bert-base-finance-sentiment-noisy-search,0.8564134
289,oferweintraub/bert-base-finance-sentiment-noisy-search,0.83420694
290,pietrotrope/emotion_final,0.8975763
291,pietrotrope/emotion_final,0.8538707
292,pietrotrope/emotion_final,0.8215658
293,aXhyra/emotion_trained_31415,0.88231534
294,aXhyra/emotion_trained_31415,0.8627553
295,aXhyra/emotion_trained_31415,0.8686667
296,aXhyra/presentation_emotion_31415,0.8987961
297,aXhyra/presentation_emotion_31415,0.8458193
298,aXhyra/presentation_emotion_31415,0.8650194
299,Recognai/bert-base-spanish-wwm-cased-xnli,0.84564835
300,Recognai/bert-base-spanish-wwm-cased-xnli,0.76359683
301,anirudh21/bert-base-uncased-finetuned-qnli,0.87899774
302,anirudh21/bert-base-uncased-finetuned-qnli,0.8551671
303,anirudh21/bert-base-uncased-finetuned-qnli,0.83456475
304,aXhyra/demo_sentiment_31415,0.88702756
305,aXhyra/demo_sentiment_31415,0.87695533
306,aXhyra/demo_sentiment_31415,0.84805244
307,aXhyra/presentation_sentiment_1234567,0.9090733
308,aXhyra/presentation_sentiment_1234567,0.87334704
309,aXhyra/presentation_sentiment_1234567,0.83672935
310,jb2k/bert-base-multilingual-cased-language-detection,0.83172345
311,jb2k/bert-base-multilingual-cased-language-detection,0.75973624
312,jb2k/bert-base-multilingual-cased-language-detection,0.76012236
313,vinai/bertweet-base,0.854195
314,vinai/bertweet-base,0.85967374
315,vinai/bertweet-base,0.82367635
316,distilbert-base-uncased,0.90873694
317,distilbert-base-uncased,0.8492631
318,distilbert-base-uncased,0.8595228
319,bert-base-uncased,0.89124775
320,bert-base-uncased,0.85606587
321,bert-base-uncased,0.8591344
322,roberta-base,0.9130111
323,roberta-base,0.86922276
324,roberta-base,0.86672026
325,bert-base-cased,0.8352088
326,bert-base-cased,0.8425004
327,dhimskyy/wiki-bert,0.665219
328,dhimskyy/wiki-bert,0.6792589
329,michiyasunaga/LinkBERT-base,0.85051715
330,michiyasunaga/LinkBERT-base,0.85001916
331,bert-large-uncased,0.8202753
332,roberta-large,0.8461668
333,roberta-large,0.8525718
334,boychaboy/MNLI_roberta-base,0.92771375
335,boychaboy/MNLI_roberta-base,0.8487986
336,boychaboy/MNLI_roberta-base,0.8547871
337,ishan/bert-base-uncased-mnli,0.85007536
338,ishan/bert-base-uncased-mnli,0.8641558
339,emrecan/bert-base-multilingual-cased-snli_tr,0.8632279
340,emrecan/bert-base-multilingual-cased-snli_tr,0.77387816
341,emrecan/bert-base-multilingual-cased-snli_tr,0.78356063
342,elozano/tweet_offensive_eval,0.7908024
343,elozano/tweet_offensive_eval,0.6968678
344,elozano/tweet_offensive_eval,0.68717897
345,Hate-speech-CNERG/bert-base-uncased-hatexplain-rationale-two,0.84475857
346,Hate-speech-CNERG/bert-base-uncased-hatexplain-rationale-two,0.85443324
347,aychang/bert-base-cased-trec-coarse,0.80842555
348,aychang/bert-base-cased-trec-coarse,0.8319355
349,gchhablani/bert-base-cased-finetuned-wnli,0.8424679
350,gchhablani/bert-base-cased-finetuned-wnli,0.81111544
351,w11wo/sundanese-bert-base-emotion-classifier,0.6920055
352,w11wo/sundanese-bert-base-emotion-classifier,0.6920055
353,gchhablani/bert-base-cased-finetuned-rte,0.86505497
354,gchhablani/bert-base-cased-finetuned-rte,0.86488515
355,mrm8488/electricidad-base-finetuned-pawsx-es,0.6578269
356,manueltonneau/bert-twitter-en-is-hired,0.8710478
357,manueltonneau/bert-twitter-en-is-hired,0.84110475
358,Guscode/DKbert-hatespeech-detection,0.7255748
359,Guscode/DKbert-hatespeech-detection,0.71876246
