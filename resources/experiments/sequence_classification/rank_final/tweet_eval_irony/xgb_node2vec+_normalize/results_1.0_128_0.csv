,model,score
0,Jeevesh8/init_bert_ft_qqp-33,0.7776741
1,Jeevesh8/init_bert_ft_qqp-33,0.8061841
2,ali2066/finetuned_sentence_itr1_2e-05_all_26_02_2022-04_03_26,0.7798689
3,ali2066/finetuned_sentence_itr1_2e-05_all_26_02_2022-04_03_26,0.7927653
4,vaariis/distilbert-base-uncased-finetuned-emotion,0.7704297
5,vaariis/distilbert-base-uncased-finetuned-emotion,0.75846595
6,heranm/finetuning-sentiment-model-3000-samples,0.7889924
7,heranm/finetuning-sentiment-model-3000-samples,0.78277117
8,marcelcastrobr/sagemaker-distilbert-emotion,0.78432167
9,marcelcastrobr/sagemaker-distilbert-emotion,0.792015
10,jasonyim2/distilbert-base-uncased-finetuned-emotion,0.7837263
11,jasonyim2/distilbert-base-uncased-finetuned-emotion,0.7738291
12,riyadhctg/distilbert-base-uncased-finetuned-cola,0.7852595
13,riyadhctg/distilbert-base-uncased-finetuned-cola,0.76242214
14,dapang/distilroberta-base-mic-sym,0.795937
15,dapang/distilroberta-base-mic-sym,0.8078444
16,PrasunMishra/finetuning-sentiment-model-3000-samples,0.79006463
17,PrasunMishra/finetuning-sentiment-model-3000-samples,0.77055174
18,nurkayevaa/autonlp-bert-covid-407910458,0.7898565
19,nurkayevaa/autonlp-bert-covid-407910458,0.77997315
20,SetFit/distilbert-base-uncased__sst2__train-16-0,0.7909392
21,SetFit/distilbert-base-uncased__sst2__train-16-0,0.77668446
22,abdelkader/distilbert-base-uncased-finetuned-emotion,0.7761297
23,abdelkader/distilbert-base-uncased-finetuned-emotion,0.7468574
24,SetFit/distilbert-base-uncased__hate_speech_offensive__train-16-1,0.7883624
25,SetFit/distilbert-base-uncased__hate_speech_offensive__train-16-1,0.77811587
26,gchhablani/fnet-base-finetuned-sst2,0.75119257
27,gchhablani/fnet-base-finetuned-sst2,0.75208616
28,Capreolus/bert-base-msmarco,0.7940646
29,Capreolus/bert-base-msmarco,0.8087421
30,Splend1dchan/bert-base-uncased-slue-goldtrascription-e3-lr1e-4,0.7910834
31,Splend1dchan/bert-base-uncased-slue-goldtrascription-e3-lr1e-4,0.8024758
32,crcb/isear_bert,0.8072411
33,crcb/isear_bert,0.8129758
34,connectivity/cola_6ep_ft-33,0.7927381
35,connectivity/cola_6ep_ft-33,0.81230557
36,Jeevesh8/init_bert_ft_qqp-49,0.7909794
37,Jeevesh8/init_bert_ft_qqp-49,0.7991691
38,Jeevesh8/feather_berts_46,0.8038886
39,Jeevesh8/feather_berts_46,0.8134623
40,yukta10/finetuning-sentiment-model-3000-samples,0.7672681
41,yukta10/finetuning-sentiment-model-3000-samples,0.7633917
42,connectivity/cola_6ep_ft-22,0.7993614
43,connectivity/cola_6ep_ft-22,0.80963355
44,JonatanGk/roberta-base-bne-finetuned-cyberbullying-spanish,0.6463646
45,JonatanGk/roberta-base-bne-finetuned-cyberbullying-spanish,0.5957112
46,cambridgeltl/guardian_news_distilbert-base-uncased,0.7878138
47,cambridgeltl/guardian_news_distilbert-base-uncased,0.7867657
48,gchhablani/fnet-base-finetuned-cola,0.73545825
49,gchhablani/fnet-base-finetuned-cola,0.71515775
50,ncduy/roberta-imdb-sentiment-analysis,0.8164829
51,ncduy/roberta-imdb-sentiment-analysis,0.80648404
52,isakbos/Q8BERT_COLA_L_512,0.69962174
53,isakbos/Q8BERT_COLA_L_512,0.6436333
54,connectivity/bert_ft_qqp-7,0.79299104
55,connectivity/bert_ft_qqp-7,0.80948985
56,moghis/distilbert-base-uncased-finetuned-emotion,0.7745735
57,moghis/distilbert-base-uncased-finetuned-emotion,0.7759061
58,uygarkurt/distilbert-base-uncased-finetuned-emotion,0.7809006
59,uygarkurt/distilbert-base-uncased-finetuned-emotion,0.7833877
60,amyma21/sincere_question_classification,0.7806076
61,amyma21/sincere_question_classification,0.78165287
62,phailyoor/distilbert-base-uncased-finetuned-yahd,0.7759053
63,phailyoor/distilbert-base-uncased-finetuned-yahd,0.7534029
64,arianpasquali/distilbert-base-multilingual-cased-toxicity,0.75642675
65,arianpasquali/distilbert-base-multilingual-cased-toxicity,0.7421609
66,neibla/distilbert-base-uncased-finetuned-emotion,0.77168685
67,neibla/distilbert-base-uncased-finetuned-emotion,0.7646925
68,robertou2/roberta-base-bne-finetuned-amazon_reviews_multi,0.7198859
69,robertou2/roberta-base-bne-finetuned-amazon_reviews_multi,0.7031858
70,Anthos23/FS-distilroberta-fine-tuned,0.7971797
71,Anthos23/FS-distilroberta-fine-tuned,0.7917187
72,pietrotrope/emotion_final,0.78038555
73,pietrotrope/emotion_final,0.7771411
74,aviator-neural/bert-base-uncased-sst2,0.7759429
75,aviator-neural/bert-base-uncased-sst2,0.7897565
76,Jeevesh8/bert_ft_qqp-40,0.8127394
77,Jeevesh8/bert_ft_qqp-40,0.81375265
78,jaesun/distilbert-base-uncased-finetuned-cola,0.7676988
79,jaesun/distilbert-base-uncased-finetuned-cola,0.7599277
80,SetFit/distilbert-base-uncased__sst2__train-32-9,0.78074604
81,SetFit/distilbert-base-uncased__sst2__train-32-9,0.7811612
82,usami/distilbert-base-uncased-finetuned-cola,0.7758953
83,usami/distilbert-base-uncased-finetuned-cola,0.80174047
84,connectivity/feather_berts_28,0.80122757
85,connectivity/feather_berts_28,0.8184279
86,Jeevesh8/512seq_len_6ep_bert_ft_cola-91,0.7978178
87,Jeevesh8/512seq_len_6ep_bert_ft_cola-91,0.811019
88,Jeevesh8/bert_ft_qqp-9,0.7947561
89,Jeevesh8/bert_ft_qqp-9,0.79565114
90,Jeevesh8/bert_ft_qqp-88,0.7953832
91,Jeevesh8/bert_ft_qqp-88,0.8041916
92,Recognai/bert-base-spanish-wwm-cased-xnli,0.7205302
93,Recognai/bert-base-spanish-wwm-cased-xnli,0.70267653
94,markt23917/finetuning-sentiment-model-3000-samples,0.78910923
95,markt23917/finetuning-sentiment-model-3000-samples,0.783402
96,JNK789/distilbert-base-uncased-finetuned-tweets-emoji-dataset,0.5986173
97,JNK789/distilbert-base-uncased-finetuned-tweets-emoji-dataset,0.5971504
98,warwickai/fin-perceiver,0.7731461
99,warwickai/fin-perceiver,0.7731461
100,anirudh21/bert-base-uncased-finetuned-qnli,0.800465
101,anirudh21/bert-base-uncased-finetuned-qnli,0.79564524
102,Jeevesh8/6ep_bert_ft_cola-47,0.7918633
103,Jeevesh8/6ep_bert_ft_cola-47,0.808985
104,oferweintraub/bert-base-finance-sentiment-noisy-search,0.7874298
105,oferweintraub/bert-base-finance-sentiment-noisy-search,0.7963132
106,aXhyra/demo_sentiment_31415,0.78338903
107,aXhyra/demo_sentiment_31415,0.77776235
108,milyiyo/selectra-small-finetuned-amazon-review,0.68297094
109,milyiyo/selectra-small-finetuned-amazon-review,0.65372086
110,aXhyra/presentation_sentiment_1234567,0.7780558
111,aXhyra/presentation_sentiment_1234567,0.7862363
112,Alireza1044/albert-base-v2-qnli,0.7829964
113,Alireza1044/albert-base-v2-qnli,0.76538306
114,liangyuant/distilbert-base-uncased-finetuned-num200-450-405cls,0.7810977
115,liangyuant/distilbert-base-uncased-finetuned-num200-450-405cls,0.7659816
116,DoyyingFace/bert-asian-hate-tweets-asian-unclean-freeze-4,0.7957957
117,DoyyingFace/bert-asian-hate-tweets-asian-unclean-freeze-4,0.81082803
118,connectivity/cola_6ep_ft-10,0.7861131
119,connectivity/cola_6ep_ft-10,0.80477583
120,Jeevesh8/lecun_feather_berts-3,0.7899579
121,Jeevesh8/lecun_feather_berts-3,0.8089143
122,jb2k/bert-base-multilingual-cased-language-detection,0.74261653
123,jb2k/bert-base-multilingual-cased-language-detection,0.7289884
124,Giyaseddin/distilroberta-base-finetuned-short-answer-assessment,0.77926105
125,Giyaseddin/distilroberta-base-finetuned-short-answer-assessment,0.7902337
126,connectivity/bert_ft_qqp-25,0.794522
127,connectivity/bert_ft_qqp-25,0.8211806
128,Jeevesh8/6ep_bert_ft_cola-12,0.7953234
129,Jeevesh8/6ep_bert_ft_cola-12,0.8086999
130,JB173/distilbert-base-uncased-finetuned-emotion,0.7774317
131,JB173/distilbert-base-uncased-finetuned-emotion,0.7483741
132,aXhyra/emotion_trained_31415,0.7825314
133,aXhyra/emotion_trained_31415,0.74789864
134,aXhyra/presentation_emotion_31415,0.7745353
135,aXhyra/presentation_emotion_31415,0.75103974
136,AnonymousSub/dummy_2,0.75919366
137,AnonymousSub/dummy_2,0.7494126
138,Jeevesh8/bert_ft_qqp-55,0.7887956
139,Jeevesh8/bert_ft_qqp-55,0.8091683
140,Jeevesh8/lecun_feather_berts-51,0.80034107
141,Jeevesh8/lecun_feather_berts-51,0.8245691
142,viviastaari/finetuning-sentiment-analysis-en-id,0.7222372
143,viviastaari/finetuning-sentiment-analysis-en-id,0.70192367
144,vinai/bertweet-base,0.76324666
145,vinai/bertweet-base,0.7951768
146,distilbert-base-uncased,0.78237265
147,distilbert-base-uncased,0.75343513
148,bert-base-uncased,0.7993198
149,bert-base-uncased,0.816324
150,roberta-base,0.8031698
151,roberta-base,0.808069
152,Aureliano/distilbert-base-uncased-if,0.78916246
153,Aureliano/distilbert-base-uncased-if,0.778654
154,rmihaylov/roberta-base-sentiment-bg,0.74039096
155,rmihaylov/roberta-base-sentiment-bg,0.7305351
156,cardiffnlp/twitter-roberta-base-2021-124m,0.7997394
157,cardiffnlp/twitter-roberta-base-2021-124m,0.8277076
158,Alassea/glue_sst_classifier,0.7838682
159,Alassea/glue_sst_classifier,0.81094176
160,Nanatan/distilbert-base-uncased-finetuned-emotion,0.7768059
161,Nanatan/distilbert-base-uncased-finetuned-emotion,0.76353407
162,connectivity/bert_ft_qqp-1,0.7919519
163,connectivity/bert_ft_qqp-1,0.8015081
164,juliensimon/autonlp-imdb-demo-hf-16622767,0.77492213
165,juliensimon/autonlp-imdb-demo-hf-16622767,0.73961055
166,Jeevesh8/bert_ft_qqp-39,0.8030946
167,Jeevesh8/bert_ft_qqp-39,0.81165504
168,Jeevesh8/lecun_feather_berts-8,0.7856308
169,Jeevesh8/lecun_feather_berts-8,0.8087563
170,connectivity/bert_ft_qqp-94,0.7945919
171,connectivity/bert_ft_qqp-94,0.8049216
172,korca/bae-roberta-base-boolq,0.80449164
173,korca/bae-roberta-base-boolq,0.80049115
174,Jeevesh8/bert_ft_cola-88,0.7931013
175,Jeevesh8/bert_ft_cola-88,0.81269854
176,aditeyabaral/finetuned-sail2017-xlm-roberta-base,0.80550367
177,aditeyabaral/finetuned-sail2017-xlm-roberta-base,0.8029221
178,connectivity/bert_ft_qqp-96,0.7828983
179,connectivity/bert_ft_qqp-96,0.79445577
180,boychaboy/MNLI_roberta-base,0.8039576
181,boychaboy/MNLI_roberta-base,0.8241367
182,fabriceyhc/bert-base-uncased-imdb,0.7728447
183,fabriceyhc/bert-base-uncased-imdb,0.7871332
184,emrecan/bert-base-multilingual-cased-snli_tr,0.76164025
185,emrecan/bert-base-multilingual-cased-snli_tr,0.7530893
186,elozano/tweet_offensive_eval,0.669118
187,elozano/tweet_offensive_eval,0.583947
188,joebobby/finetuning-sentiment-model-5000-samples3,0.7901924
189,joebobby/finetuning-sentiment-model-5000-samples3,0.77853185
190,YeRyeongLee/electra-base-discriminator-finetuned-filtered-0602,0.57994246
191,YeRyeongLee/electra-base-discriminator-finetuned-filtered-0602,0.5429889
192,Jeevesh8/feather_berts_92,0.79704434
193,Jeevesh8/feather_berts_92,0.8212026
194,ASCCCCCCCC/distilbert-base-chinese-amazon_zh_20000,0.69726175
195,ASCCCCCCCC/distilbert-base-chinese-amazon_zh_20000,0.70140994
196,Jeevesh8/6ep_bert_ft_cola-29,0.8004434
197,albert-base-v2,0.68723965
198,bert-base-cased,0.7882756
199,Hate-speech-CNERG/bert-base-uncased-hatexplain-rationale-two,0.8136679
200,matthewburke/korean_sentiment,0.6903907
201,aychang/bert-base-cased-trec-coarse,0.8258829
202,IMSyPP/hate_speech_nl,0.57983017
203,cointegrated/roberta-base-formality,0.80633706
204,XSY/albert-base-v2-imdb-calssification,0.75393546
205,philschmid/tiny-distilbert-classification,0.5606428
206,gchhablani/bert-base-cased-finetuned-wnli,0.7854262
207,moshew/bert-mini-sst2-distilled,0.7159704
208,chiragasarpota/scotus-bert,0.5959527
209,vesteinn/XLMR-ENIS-finetuned-cola,0.8007533
210,IMSyPP/hate_speech_it,0.7272058
211,Jeevesh8/init_bert_ft_qqp-24,0.7998362
212,nickmuchi/facebook-data2vec-finetuned-finance-classification,0.75749665
213,Jeevesh8/bert_ft_qqp-68,0.8019762
214,Jeevesh8/init_bert_ft_qqp-28,0.8037644
215,connectivity/bert_ft_qqp-17,0.7975166
216,dhimskyy/wiki-bert,0.67423195
217,18811449050/bert_finetuning_test,0.7899184
218,finiteautomata/betonews-tweetcontext,0.69417393
219,Jeevesh8/feather_berts_96,0.8217939
220,michiyasunaga/LinkBERT-base,0.7849252
221,navsad/navid_test_bert,0.8029366
222,Jeevesh8/bert_ft_cola-60,0.78630644
223,Jeevesh8/lecun_feather_berts-7,0.7995982
224,w11wo/sundanese-bert-base-emotion-classifier,0.6308762
225,mrm8488/codebert-base-finetuned-detect-insecure-code,0.76562315
226,socialmediaie/TRAC2020_IBEN_B_bert-base-multilingual-uncased,0.76621073
227,ishan/bert-base-uncased-mnli,0.8084098
228,zenkri/autotrain-Arabic_Poetry_by_Subject-920730230,0.7785967
229,M47Labs/spanish_news_classification_headlines_untrained,0.7134108
230,bondi/bert-semaphore-prediction-w4,0.67589676
231,gchhablani/bert-base-cased-finetuned-rte,0.8113221
232,classla/bcms-bertic-parlasent-bcs-ter,0.7572964
233,anferico/bert-for-patents,0.7436683
234,waboucay/camembert-base-finetuned-xnli_fr-finetuned-nli-rua_wl,0.6515724
235,ali2066/DistilBERTFINAL_ctxSentence_TRAIN_editorials_TEST_NULL_second_train_set_null_False,0.832563
236,anvay/finetuning-cardiffnlp-sentiment-model,0.8309935
237,JonatanGk/roberta-base-ca-finetuned-hate-speech-offensive-catalan,0.6947988
238,mrm8488/electricidad-base-finetuned-pawsx-es,0.67195916
239,Raychanan/COVID_RandomOver,0.5432219
240,Monsia/camembert-fr-covid-tweet-classification,0.7172341
241,manueltonneau/bert-twitter-en-is-hired,0.8013614
242,CAMeL-Lab/bert-base-arabic-camelbert-mix-did-nadi,0.68297267
243,kyleinincubated/autonlp-cat333-624217911,0.7069318
244,Guscode/DKbert-hatespeech-detection,0.6468987
245,CAMeL-Lab/bert-base-arabic-camelbert-da-sentiment,0.55160683
246,ChrisUPM/BioBERT_Re_trained,0.76013184
247,roberta-large,0.77929616
