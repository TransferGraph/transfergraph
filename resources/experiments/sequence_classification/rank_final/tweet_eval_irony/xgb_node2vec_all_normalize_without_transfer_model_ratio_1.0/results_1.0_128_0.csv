,model,score
0,Guscode/DKbert-hatespeech-detection,0.35830644
1,robertou2/roberta-base-bne-finetuned-amazon_reviews_multi,0.5794384
2,milyiyo/selectra-small-finetuned-amazon-review,0.36838424
3,robertou2/roberta-base-bne-finetuned-amazon_reviews_multi,0.6096022
4,milyiyo/selectra-small-finetuned-amazon-review,0.35293368
5,SetFit/distilbert-base-uncased__hate_speech_offensive__train-16-1,0.8863703
6,SetFit/distilbert-base-uncased__hate_speech_offensive__train-16-1,0.8857001
7,vinai/bertweet-base,0.9311388
8,vinai/bertweet-base,0.9559911
9,jb2k/bert-base-multilingual-cased-language-detection,0.72441804
10,jb2k/bert-base-multilingual-cased-language-detection,0.6784439
11,crcb/isear_bert,0.84002227
12,crcb/isear_bert,0.89201003
13,vaariis/distilbert-base-uncased-finetuned-emotion,0.84802425
14,marcelcastrobr/sagemaker-distilbert-emotion,0.8135397
15,jasonyim2/distilbert-base-uncased-finetuned-emotion,0.8323024
16,abdelkader/distilbert-base-uncased-finetuned-emotion,0.84218854
17,moghis/distilbert-base-uncased-finetuned-emotion,0.8401581
18,uygarkurt/distilbert-base-uncased-finetuned-emotion,0.8446854
19,neibla/distilbert-base-uncased-finetuned-emotion,0.8557266
20,JB173/distilbert-base-uncased-finetuned-emotion,0.8045201
21,Nanatan/distilbert-base-uncased-finetuned-emotion,0.8242038
22,vaariis/distilbert-base-uncased-finetuned-emotion,0.8620501
23,marcelcastrobr/sagemaker-distilbert-emotion,0.85076284
24,jasonyim2/distilbert-base-uncased-finetuned-emotion,0.861366
25,abdelkader/distilbert-base-uncased-finetuned-emotion,0.8199734
26,moghis/distilbert-base-uncased-finetuned-emotion,0.87042487
27,uygarkurt/distilbert-base-uncased-finetuned-emotion,0.8338224
28,neibla/distilbert-base-uncased-finetuned-emotion,0.8664746
29,JB173/distilbert-base-uncased-finetuned-emotion,0.8077669
30,Nanatan/distilbert-base-uncased-finetuned-emotion,0.8175758
31,riyadhctg/distilbert-base-uncased-finetuned-cola,0.82629603
32,connectivity/cola_6ep_ft-33,0.8877849
33,connectivity/cola_6ep_ft-22,0.8806556
34,gchhablani/fnet-base-finetuned-cola,0.7416632
35,isakbos/Q8BERT_COLA_L_512,0.5032756
36,jaesun/distilbert-base-uncased-finetuned-cola,0.8175538
37,usami/distilbert-base-uncased-finetuned-cola,0.8249461
38,Jeevesh8/512seq_len_6ep_bert_ft_cola-91,0.8650232
39,Jeevesh8/6ep_bert_ft_cola-47,0.8170595
40,connectivity/cola_6ep_ft-10,0.87304986
41,Jeevesh8/6ep_bert_ft_cola-12,0.86725646
42,Jeevesh8/bert_ft_cola-88,0.86513877
43,riyadhctg/distilbert-base-uncased-finetuned-cola,0.82936305
44,connectivity/cola_6ep_ft-33,0.9009861
45,connectivity/cola_6ep_ft-22,0.9150742
46,gchhablani/fnet-base-finetuned-cola,0.6878914
47,vesteinn/XLMR-ENIS-finetuned-cola,0.84027404
48,isakbos/Q8BERT_COLA_L_512,0.38639367
49,jaesun/distilbert-base-uncased-finetuned-cola,0.84647644
50,usami/distilbert-base-uncased-finetuned-cola,0.84554225
51,Jeevesh8/512seq_len_6ep_bert_ft_cola-91,0.90783805
52,Jeevesh8/6ep_bert_ft_cola-47,0.9011809
53,connectivity/cola_6ep_ft-10,0.8744658
54,Jeevesh8/6ep_bert_ft_cola-12,0.8981399
55,Jeevesh8/6ep_bert_ft_cola-29,0.882982
56,Jeevesh8/bert_ft_cola-60,0.8561367
57,navsad/navid_test_bert,0.83466285
58,Jeevesh8/bert_ft_cola-88,0.88456345
59,boychaboy/MNLI_roberta-base,0.8777068
60,ishan/bert-base-uncased-mnli,0.9133497
61,boychaboy/MNLI_roberta-base,0.9035142
62,anirudh21/bert-base-uncased-finetuned-qnli,0.86031336
63,Alireza1044/albert-base-v2-qnli,0.7383771
64,anirudh21/bert-base-uncased-finetuned-qnli,0.8792805
65,Alireza1044/albert-base-v2-qnli,0.7362262
66,Jeevesh8/init_bert_ft_qqp-33,0.8077843
67,Jeevesh8/init_bert_ft_qqp-49,0.8379019
68,connectivity/bert_ft_qqp-7,0.8589217
69,Jeevesh8/bert_ft_qqp-40,0.84684706
70,Jeevesh8/bert_ft_qqp-9,0.8334951
71,Jeevesh8/bert_ft_qqp-88,0.8386713
72,connectivity/bert_ft_qqp-25,0.8424411
73,Jeevesh8/bert_ft_qqp-55,0.850431
74,connectivity/bert_ft_qqp-1,0.8353015
75,Jeevesh8/bert_ft_qqp-39,0.8364078
76,connectivity/bert_ft_qqp-94,0.87573665
77,connectivity/bert_ft_qqp-96,0.8141797
78,Jeevesh8/init_bert_ft_qqp-33,0.8518216
79,Jeevesh8/init_bert_ft_qqp-49,0.8573663
80,connectivity/bert_ft_qqp-7,0.8907896
81,Jeevesh8/bert_ft_qqp-40,0.8813544
82,Jeevesh8/bert_ft_qqp-9,0.8742349
83,Jeevesh8/bert_ft_qqp-88,0.88360006
84,connectivity/bert_ft_qqp-25,0.92058295
85,Jeevesh8/init_bert_ft_qqp-24,0.85279435
86,Jeevesh8/bert_ft_qqp-55,0.9047996
87,Jeevesh8/bert_ft_qqp-68,0.87067264
88,connectivity/bert_ft_qqp-17,0.8659319
89,Jeevesh8/init_bert_ft_qqp-28,0.8807257
90,connectivity/bert_ft_qqp-1,0.86192137
91,Jeevesh8/bert_ft_qqp-39,0.86607754
92,connectivity/bert_ft_qqp-94,0.8734282
93,connectivity/bert_ft_qqp-96,0.86229223
94,gchhablani/bert-base-cased-finetuned-rte,0.8994095
95,ali2066/finetuned_sentence_itr1_2e-05_all_26_02_2022-04_03_26,0.83768284
96,SetFit/distilbert-base-uncased__sst2__train-16-0,0.8575365
97,gchhablani/fnet-base-finetuned-sst2,0.74064416
98,aviator-neural/bert-base-uncased-sst2,0.839777
99,SetFit/distilbert-base-uncased__sst2__train-32-9,0.8382524
100,Alassea/glue_sst_classifier,0.833587
101,ali2066/finetuned_sentence_itr1_2e-05_all_26_02_2022-04_03_26,0.84583634
102,philschmid/tiny-distilbert-classification,0.07420837
103,SetFit/distilbert-base-uncased__sst2__train-16-0,0.8804906
104,gchhablani/fnet-base-finetuned-sst2,0.765161
105,moshew/bert-mini-sst2-distilled,0.6637648
106,aviator-neural/bert-base-uncased-sst2,0.8231202
107,SetFit/distilbert-base-uncased__sst2__train-32-9,0.87079203
108,Alassea/glue_sst_classifier,0.89354116
109,ChrisUPM/BioBERT_Re_trained,0.74041575
110,gchhablani/bert-base-cased-finetuned-wnli,0.8608217
111,Hate-speech-CNERG/bert-base-uncased-hatexplain-rationale-two,0.8914169
112,heranm/finetuning-sentiment-model-3000-samples,0.86276704
113,PrasunMishra/finetuning-sentiment-model-3000-samples,0.8356492
114,yukta10/finetuning-sentiment-model-3000-samples,0.82688695
115,ncduy/roberta-imdb-sentiment-analysis,0.905325
116,markt23917/finetuning-sentiment-model-3000-samples,0.83030814
117,juliensimon/autonlp-imdb-demo-hf-16622767,0.77317387
118,fabriceyhc/bert-base-uncased-imdb,0.8113903
119,heranm/finetuning-sentiment-model-3000-samples,0.87482435
120,PrasunMishra/finetuning-sentiment-model-3000-samples,0.8633356
121,yukta10/finetuning-sentiment-model-3000-samples,0.84550536
122,ncduy/roberta-imdb-sentiment-analysis,0.8931534
123,markt23917/finetuning-sentiment-model-3000-samples,0.8888289
124,juliensimon/autonlp-imdb-demo-hf-16622767,0.8024523
125,XSY/albert-base-v2-imdb-calssification,0.74635005
126,fabriceyhc/bert-base-uncased-imdb,0.8329051
127,Anthos23/FS-distilroberta-fine-tuned,0.8518448
128,oferweintraub/bert-base-finance-sentiment-noisy-search,0.8402437
129,Anthos23/FS-distilroberta-fine-tuned,0.8937897
130,oferweintraub/bert-base-finance-sentiment-noisy-search,0.87687665
131,emrecan/bert-base-multilingual-cased-snli_tr,0.7309219
132,emrecan/bert-base-multilingual-cased-snli_tr,0.6939628
133,nurkayevaa/autonlp-bert-covid-407910458,0.8477314
134,nurkayevaa/autonlp-bert-covid-407910458,0.8779336
135,w11wo/sundanese-bert-base-emotion-classifier,0.5140661
136,aychang/bert-base-cased-trec-coarse,0.8654291
137,JNK789/distilbert-base-uncased-finetuned-tweets-emoji-dataset,0.08251992
138,JNK789/distilbert-base-uncased-finetuned-tweets-emoji-dataset,0.06508848
139,pietrotrope/emotion_final,0.8748726
140,aXhyra/emotion_trained_31415,0.87559575
141,aXhyra/presentation_emotion_31415,0.8782196
142,pietrotrope/emotion_final,0.8788024
143,aXhyra/emotion_trained_31415,0.84322953
144,aXhyra/presentation_emotion_31415,0.84789574
145,elozano/tweet_offensive_eval,0.4973235
146,elozano/tweet_offensive_eval,0.24033518
147,aXhyra/demo_sentiment_31415,0.87215686
148,aXhyra/presentation_sentiment_1234567,0.84497494
149,aXhyra/demo_sentiment_31415,0.87224996
150,aXhyra/presentation_sentiment_1234567,0.8931906
151,nickmuchi/facebook-data2vec-finetuned-finance-classification,0.7325211
152,manueltonneau/bert-twitter-en-is-hired,0.8999593
153,distilbert-base-uncased,0.8553098
154,bert-base-uncased,0.820986
155,roberta-base,0.88397187
156,dhimskyy/wiki-bert,0.5683113
157,bert-base-uncased,0.907984
158,distilbert-base-uncased,0.8452343
159,roberta-base,0.89665693
160,bert-base-cased,0.84923404
161,albert-base-v2,0.54742575
162,michiyasunaga/LinkBERT-base,0.86232346
163,roberta-large,0.766914
164,Recognai/bert-base-spanish-wwm-cased-xnli,0.47616383
165,Recognai/bert-base-spanish-wwm-cased-xnli,0.44705334
166,mrm8488/electricidad-base-finetuned-pawsx-es,0.50449127
167,dapang/distilroberta-base-mic-sym,0.7905324
168,Capreolus/bert-base-msmarco,0.8332006
169,Splend1dchan/bert-base-uncased-slue-goldtrascription-e3-lr1e-4,0.80439717
170,Jeevesh8/feather_berts_46,0.8163959
171,JonatanGk/roberta-base-bne-finetuned-cyberbullying-spanish,0.3902624
172,cambridgeltl/guardian_news_distilbert-base-uncased,0.81736976
173,amyma21/sincere_question_classification,0.8228118
174,phailyoor/distilbert-base-uncased-finetuned-yahd,0.8091742
175,arianpasquali/distilbert-base-multilingual-cased-toxicity,0.68387735
176,connectivity/feather_berts_28,0.8242961
177,warwickai/fin-perceiver,0.759114
178,liangyuant/distilbert-base-uncased-finetuned-num200-450-405cls,0.8460118
179,DoyyingFace/bert-asian-hate-tweets-asian-unclean-freeze-4,0.805934
180,Jeevesh8/lecun_feather_berts-3,0.8327588
181,Giyaseddin/distilroberta-base-finetuned-short-answer-assessment,0.8512092
182,AnonymousSub/dummy_2,0.6788344
183,Jeevesh8/lecun_feather_berts-51,0.83289135
184,viviastaari/finetuning-sentiment-analysis-en-id,0.5881748
185,Aureliano/distilbert-base-uncased-if,0.85047513
186,rmihaylov/roberta-base-sentiment-bg,0.6785258
187,cardiffnlp/twitter-roberta-base-2021-124m,0.87536824
188,Jeevesh8/lecun_feather_berts-8,0.8163899
189,korca/bae-roberta-base-boolq,0.86147285
190,aditeyabaral/finetuned-sail2017-xlm-roberta-base,0.85078126
191,joebobby/finetuning-sentiment-model-5000-samples3,0.8233328
192,YeRyeongLee/electra-base-discriminator-finetuned-filtered-0602,0.081331275
193,Jeevesh8/feather_berts_92,0.83261526
194,ASCCCCCCCC/distilbert-base-chinese-amazon_zh_20000,0.543271
195,dapang/distilroberta-base-mic-sym,0.79887074
196,Capreolus/bert-base-msmarco,0.88975143
197,Splend1dchan/bert-base-uncased-slue-goldtrascription-e3-lr1e-4,0.8759761
198,Jeevesh8/feather_berts_46,0.8846023
199,JonatanGk/roberta-base-bne-finetuned-cyberbullying-spanish,0.29938456
200,cambridgeltl/guardian_news_distilbert-base-uncased,0.86297864
201,amyma21/sincere_question_classification,0.87256247
202,phailyoor/distilbert-base-uncased-finetuned-yahd,0.7699309
203,arianpasquali/distilbert-base-multilingual-cased-toxicity,0.7047659
204,connectivity/feather_berts_28,0.91737336
205,IMSyPP/hate_speech_it,0.65983075
206,chiragasarpota/scotus-bert,0.15417795
207,warwickai/fin-perceiver,0.7570438
208,liangyuant/distilbert-base-uncased-finetuned-num200-450-405cls,0.85596085
209,DoyyingFace/bert-asian-hate-tweets-asian-unclean-freeze-4,0.89698565
210,Jeevesh8/lecun_feather_berts-3,0.8786723
211,Giyaseddin/distilroberta-base-finetuned-short-answer-assessment,0.83102506
212,18811449050/bert_finetuning_test,0.772728
213,Jeevesh8/feather_berts_96,0.90688646
214,AnonymousSub/dummy_2,0.6968407
215,Jeevesh8/lecun_feather_berts-51,0.93586093
216,viviastaari/finetuning-sentiment-analysis-en-id,0.6491452
217,finiteautomata/betonews-tweetcontext,0.5270605
218,Aureliano/distilbert-base-uncased-if,0.8510772
219,rmihaylov/roberta-base-sentiment-bg,0.67693406
220,cardiffnlp/twitter-roberta-base-2021-124m,0.96534735
221,Jeevesh8/lecun_feather_berts-8,0.8875406
222,Jeevesh8/lecun_feather_berts-7,0.8668811
223,IMSyPP/hate_speech_nl,0.28547254
224,matthewburke/korean_sentiment,0.5439387
225,korca/bae-roberta-base-boolq,0.86653167
226,waboucay/camembert-base-finetuned-xnli_fr-finetuned-nli-rua_wl,0.38232216
227,aditeyabaral/finetuned-sail2017-xlm-roberta-base,0.8453399
228,socialmediaie/TRAC2020_IBEN_B_bert-base-multilingual-uncased,0.78677934
229,mrm8488/codebert-base-finetuned-detect-insecure-code,0.76053375
230,M47Labs/spanish_news_classification_headlines_untrained,0.6567922
231,CAMeL-Lab/bert-base-arabic-camelbert-da-sentiment,0.14562017
232,zenkri/autotrain-Arabic_Poetry_by_Subject-920730230,0.8610602
233,bondi/bert-semaphore-prediction-w4,0.55535215
234,cointegrated/roberta-base-formality,0.87243754
235,JonatanGk/roberta-base-ca-finetuned-hate-speech-offensive-catalan,0.54126835
236,classla/bcms-bertic-parlasent-bcs-ter,0.74325913
237,Raychanan/COVID_RandomOver,0.07675986
238,ali2066/DistilBERTFINAL_ctxSentence_TRAIN_editorials_TEST_NULL_second_train_set_null_False,0.91074014
239,anvay/finetuning-cardiffnlp-sentiment-model,0.9537516
240,joebobby/finetuning-sentiment-model-5000-samples3,0.8719809
241,YeRyeongLee/electra-base-discriminator-finetuned-filtered-0602,0.0680796
242,Jeevesh8/feather_berts_92,0.9091069
243,CAMeL-Lab/bert-base-arabic-camelbert-mix-did-nadi,0.5575863
244,Monsia/camembert-fr-covid-tweet-classification,0.68103695
245,kyleinincubated/autonlp-cat333-624217911,0.6818291
246,ASCCCCCCCC/distilbert-base-chinese-amazon_zh_20000,0.60634667
247,anferico/bert-for-patents,0.7337339
