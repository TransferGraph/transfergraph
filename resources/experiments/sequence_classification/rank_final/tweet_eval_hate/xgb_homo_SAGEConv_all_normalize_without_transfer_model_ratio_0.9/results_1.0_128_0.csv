,model,score
0,Guscode/DKbert-hatespeech-detection,0.6510092
1,robertou2/roberta-base-bne-finetuned-amazon_reviews_multi,0.70351297
2,milyiyo/selectra-small-finetuned-amazon-review,0.31837648
3,robertou2/roberta-base-bne-finetuned-amazon_reviews_multi,0.72057605
4,milyiyo/selectra-small-finetuned-amazon-review,0.55816436
5,SetFit/distilbert-base-uncased__hate_speech_offensive__train-16-1,0.7850699
6,SetFit/distilbert-base-uncased__hate_speech_offensive__train-16-1,0.8642862
7,vinai/bertweet-base,0.8983007
8,vinai/bertweet-base,0.85670364
9,justinqbui/bertweet-covid19-base-uncased-pretraining-covid-vaccine-tweets,0.9000257
10,jb2k/bert-base-multilingual-cased-language-detection,0.7550867
11,crcb/isear_bert,0.9083889
12,vaariis/distilbert-base-uncased-finetuned-emotion,0.822422
13,abdelkader/distilbert-base-uncased-finetuned-emotion,0.80536675
14,marcelcastrobr/sagemaker-distilbert-emotion,0.752658
15,moghis/distilbert-base-uncased-finetuned-emotion,0.8306226
16,uygarkurt/distilbert-base-uncased-finetuned-emotion,0.7946096
17,neibla/distilbert-base-uncased-finetuned-emotion,0.75176895
18,JB173/distilbert-base-uncased-finetuned-emotion,0.7899303
19,Nanatan/distilbert-base-uncased-finetuned-emotion,0.8008866
20,vaariis/distilbert-base-uncased-finetuned-emotion,0.88087934
21,marcelcastrobr/sagemaker-distilbert-emotion,0.8859865
22,abdelkader/distilbert-base-uncased-finetuned-emotion,0.86806226
23,moghis/distilbert-base-uncased-finetuned-emotion,0.8403312
24,uygarkurt/distilbert-base-uncased-finetuned-emotion,0.8715284
25,neibla/distilbert-base-uncased-finetuned-emotion,0.8365996
26,JB173/distilbert-base-uncased-finetuned-emotion,0.81112456
27,Nanatan/distilbert-base-uncased-finetuned-emotion,0.87004244
28,riyadhctg/distilbert-base-uncased-finetuned-cola,0.8586087
29,gchhablani/fnet-base-finetuned-cola,0.71745527
30,connectivity/cola_6ep_ft-33,0.8716135
31,jaesun/distilbert-base-uncased-finetuned-cola,0.8432271
32,connectivity/cola_6ep_ft-22,0.8716135
33,usami/distilbert-base-uncased-finetuned-cola,0.8464222
34,Jeevesh8/512seq_len_6ep_bert_ft_cola-91,0.8716135
35,Jeevesh8/6ep_bert_ft_cola-47,0.8716135
36,connectivity/cola_6ep_ft-10,0.8756377
37,Jeevesh8/6ep_bert_ft_cola-29,0.8756377
38,riyadhctg/distilbert-base-uncased-finetuned-cola,0.9042941
39,connectivity/cola_6ep_ft-33,0.8676749
40,connectivity/cola_6ep_ft-22,0.8875716
41,gchhablani/fnet-base-finetuned-cola,0.7328667
42,isakbos/Q8BERT_COLA_L_512,0.6352443
43,vesteinn/XLMR-ENIS-finetuned-cola,0.9040235
44,jaesun/distilbert-base-uncased-finetuned-cola,0.75397897
45,usami/distilbert-base-uncased-finetuned-cola,0.84007835
46,Jeevesh8/512seq_len_6ep_bert_ft_cola-91,0.8875716
47,Jeevesh8/6ep_bert_ft_cola-47,0.8875716
48,connectivity/cola_6ep_ft-10,0.8676749
49,Jeevesh8/6ep_bert_ft_cola-12,0.8875716
50,Jeevesh8/6ep_bert_ft_cola-29,0.8875716
51,Jeevesh8/bert_ft_cola-60,0.8676749
52,navsad/navid_test_bert,0.8686458
53,Jeevesh8/bert_ft_cola-88,0.8875716
54,ishan/bert-base-uncased-mnli,0.8678089
55,boychaboy/MNLI_roberta-base,0.94490147
56,anirudh21/bert-base-uncased-finetuned-qnli,0.90262276
57,Alireza1044/albert-base-v2-qnli,0.8525165
58,Jeevesh8/init_bert_ft_qqp-49,0.8672772
59,Jeevesh8/bert_ft_qqp-40,0.8708223
60,Jeevesh8/bert_ft_qqp-88,0.8708223
61,connectivity/bert_ft_qqp-25,0.8708223
62,Jeevesh8/bert_ft_qqp-55,0.8708223
63,Jeevesh8/bert_ft_qqp-39,0.8672772
64,Jeevesh8/init_bert_ft_qqp-33,0.86234283
65,Jeevesh8/init_bert_ft_qqp-49,0.8858848
66,Jeevesh8/bert_ft_qqp-40,0.86234283
67,Jeevesh8/bert_ft_qqp-9,0.8858848
68,Jeevesh8/bert_ft_qqp-88,0.8858848
69,connectivity/bert_ft_qqp-25,0.86234283
70,Jeevesh8/init_bert_ft_qqp-24,0.8858848
71,Jeevesh8/bert_ft_qqp-55,0.8858848
72,Jeevesh8/bert_ft_qqp-68,0.8858848
73,connectivity/bert_ft_qqp-17,0.8858848
74,Jeevesh8/init_bert_ft_qqp-28,0.8858848
75,connectivity/bert_ft_qqp-1,0.8858848
76,Jeevesh8/bert_ft_qqp-39,0.8858848
77,connectivity/bert_ft_qqp-94,0.8624898
78,connectivity/bert_ft_qqp-96,0.8858848
79,gchhablani/bert-base-cased-finetuned-rte,0.8835645
80,ali2066/finetuned_sentence_itr1_2e-05_all_26_02_2022-04_03_26,0.79745144
81,gchhablani/fnet-base-finetuned-sst2,0.7568369
82,SetFit/distilbert-base-uncased__sst2__train-16-0,0.86943305
83,SetFit/distilbert-base-uncased__sst2__train-32-9,0.8640426
84,aviator-neural/bert-base-uncased-sst2,0.81305313
85,Alassea/glue_sst_classifier,0.83540785
86,ali2066/finetuned_sentence_itr1_2e-05_all_26_02_2022-04_03_26,0.86653423
87,philschmid/tiny-distilbert-classification,0.00430977
88,SetFit/distilbert-base-uncased__sst2__train-16-0,0.9244884
89,gchhablani/fnet-base-finetuned-sst2,0.71403944
90,moshew/bert-mini-sst2-distilled,0.64065635
91,SetFit/distilbert-base-uncased__sst2__train-32-9,0.8508495
92,aviator-neural/bert-base-uncased-sst2,0.8212829
93,Alassea/glue_sst_classifier,0.851629
94,ChrisUPM/BioBERT_Re_trained,0.76839775
95,gchhablani/bert-base-cased-finetuned-wnli,0.834701
96,gchhablani/bert-base-cased-finetuned-wnli,0.9044135
97,Hate-speech-CNERG/bert-base-uncased-hatexplain-rationale-two,0.83675295
98,Hate-speech-CNERG/bert-base-uncased-hatexplain-rationale-two,0.9023714
99,heranm/finetuning-sentiment-model-3000-samples,0.8640023
100,PrasunMishra/finetuning-sentiment-model-3000-samples,0.8460812
101,yukta10/finetuning-sentiment-model-3000-samples,0.8460812
102,ncduy/roberta-imdb-sentiment-analysis,0.91784
103,markt23917/finetuning-sentiment-model-3000-samples,0.85039014
104,juliensimon/autonlp-imdb-demo-hf-16622767,0.8215345
105,XSY/albert-base-v2-imdb-calssification,0.7562965
106,heranm/finetuning-sentiment-model-3000-samples,0.9067347
107,PrasunMishra/finetuning-sentiment-model-3000-samples,0.8743165
108,yukta10/finetuning-sentiment-model-3000-samples,0.8839725
109,ncduy/roberta-imdb-sentiment-analysis,0.9242087
110,markt23917/finetuning-sentiment-model-3000-samples,0.9027465
111,juliensimon/autonlp-imdb-demo-hf-16622767,0.7862107
112,XSY/albert-base-v2-imdb-calssification,0.8071074
113,fabriceyhc/bert-base-uncased-imdb,0.8181503
114,Anthos23/FS-distilroberta-fine-tuned,0.88974077
115,Anthos23/FS-distilroberta-fine-tuned,0.89655745
116,oferweintraub/bert-base-finance-sentiment-noisy-search,0.8520149
117,emrecan/bert-base-multilingual-cased-snli_tr,0.7842926
118,nurkayevaa/autonlp-bert-covid-407910458,0.8286472
119,nurkayevaa/autonlp-bert-covid-407910458,0.8927172
120,w11wo/sundanese-bert-base-emotion-classifier,0.5832336
121,aychang/bert-base-cased-trec-coarse,0.85630494
122,aychang/bert-base-cased-trec-coarse,0.8095708
123,JNK789/distilbert-base-uncased-finetuned-tweets-emoji-dataset,0.15562092
124,JNK789/distilbert-base-uncased-finetuned-tweets-emoji-dataset,0.08781508
125,pietrotrope/emotion_final,0.7748364
126,aXhyra/emotion_trained_31415,0.81457
127,aXhyra/presentation_emotion_31415,0.8058873
128,pietrotrope/emotion_final,0.8553791
129,aXhyra/emotion_trained_31415,0.855289
130,aXhyra/presentation_emotion_31415,0.8346323
131,elozano/tweet_offensive_eval,0.49529427
132,aXhyra/demo_sentiment_31415,0.8353758
133,aXhyra/presentation_sentiment_1234567,0.7951669
134,aXhyra/demo_sentiment_31415,0.8799455
135,aXhyra/presentation_sentiment_1234567,0.8700002
136,nickmuchi/facebook-data2vec-finetuned-finance-classification,0.8382264
137,manueltonneau/bert-twitter-en-is-hired,0.8836831
138,distilbert-base-uncased,0.769683
139,albert-base-v2,0.7400748
140,bert-base-cased,0.7317677
141,dhimskyy/wiki-bert,0.5245495
142,bert-base-uncased,0.8682285
143,distilbert-base-uncased,0.83745193
144,roberta-base,0.9666101
145,albert-base-v2,0.8622808
146,bert-base-cased,0.88790745
147,michiyasunaga/LinkBERT-base,0.85068464
148,roberta-large,1.02412
149,bert-large-uncased,0.32146898
150,Recognai/bert-base-spanish-wwm-cased-xnli,0.64497346
151,Recognai/bert-base-spanish-wwm-cased-xnli,0.595941
152,mrm8488/electricidad-base-finetuned-pawsx-es,0.5992879
153,dapang/distilroberta-base-mic-sym,0.8813799
154,Capreolus/bert-base-msmarco,0.8520148
155,Splend1dchan/bert-base-uncased-slue-goldtrascription-e3-lr1e-4,0.8611927
156,cambridgeltl/guardian_news_distilbert-base-uncased,0.79880375
157,JonatanGk/roberta-base-bne-finetuned-cyberbullying-spanish,0.31485477
158,phailyoor/distilbert-base-uncased-finetuned-yahd,0.7344369
159,arianpasquali/distilbert-base-multilingual-cased-toxicity,0.6713162
160,amyma21/sincere_question_classification,0.7755757
161,liangyuant/distilbert-base-uncased-finetuned-num200-450-405cls,0.81156415
162,Giyaseddin/distilroberta-base-finetuned-short-answer-assessment,0.89586747
163,DoyyingFace/bert-asian-hate-tweets-asian-unclean-freeze-4,0.8520148
164,viviastaari/finetuning-sentiment-analysis-en-id,0.691499
165,Aureliano/distilbert-base-uncased-if,0.76058054
166,rmihaylov/roberta-base-sentiment-bg,0.67970866
167,korca/bae-roberta-base-boolq,0.8749273
168,matthewburke/korean_sentiment,0.64881176
169,IMSyPP/hate_speech_nl,0.5241618
170,cointegrated/roberta-base-formality,0.8749273
171,dapang/distilroberta-base-mic-sym,0.87760586
172,Splend1dchan/bert-base-uncased-slue-goldtrascription-e3-lr1e-4,0.86256105
173,Jeevesh8/feather_berts_46,0.8915027
174,Capreolus/bert-base-msmarco,0.8840479
175,cambridgeltl/guardian_news_distilbert-base-uncased,0.8326226
176,JonatanGk/roberta-base-bne-finetuned-cyberbullying-spanish,0.46828675
177,phailyoor/distilbert-base-uncased-finetuned-yahd,0.7247471
178,amyma21/sincere_question_classification,0.8175506
179,arianpasquali/distilbert-base-multilingual-cased-toxicity,0.63055205
180,connectivity/feather_berts_28,0.86256105
181,chiragasarpota/scotus-bert,0.51929367
182,IMSyPP/hate_speech_it,0.6727628
183,liangyuant/distilbert-base-uncased-finetuned-num200-450-405cls,0.8326614
184,DoyyingFace/bert-asian-hate-tweets-asian-unclean-freeze-4,0.8840479
185,Giyaseddin/distilroberta-base-finetuned-short-answer-assessment,0.9196992
186,Jeevesh8/lecun_feather_berts-3,0.86837006
187,Jeevesh8/feather_berts_96,0.86256105
188,Jeevesh8/lecun_feather_berts-51,0.8915027
189,viviastaari/finetuning-sentiment-analysis-en-id,0.58221316
190,AnonymousSub/dummy_2,0.7807656
191,finiteautomata/betonews-tweetcontext,0.60439646
192,Aureliano/distilbert-base-uncased-if,0.8351456
193,rmihaylov/roberta-base-sentiment-bg,0.7330552
194,cardiffnlp/twitter-roberta-base-2021-124m,0.93513244
195,warwickai/fin-perceiver,0.77614504
196,Jeevesh8/lecun_feather_berts-8,0.86256105
197,Jeevesh8/lecun_feather_berts-7,0.8915027
198,IMSyPP/hate_speech_nl,0.48156023
199,anferico/bert-for-patents,0.6149754
200,korca/bae-roberta-base-boolq,0.9041908
201,matthewburke/korean_sentiment,0.6408929
202,waboucay/camembert-base-finetuned-xnli_fr-finetuned-nli-rua_wl,0.55966914
203,aditeyabaral/finetuned-sail2017-xlm-roberta-base,0.8536386
204,mrm8488/codebert-base-finetuned-detect-insecure-code,0.84264284
205,socialmediaie/TRAC2020_IBEN_B_bert-base-multilingual-uncased,0.8010555
206,zenkri/autotrain-Arabic_Poetry_by_Subject-920730230,0.8499882
207,M47Labs/spanish_news_classification_headlines_untrained,0.7042923
208,cointegrated/roberta-base-formality,0.8944007
209,bondi/bert-semaphore-prediction-w4,0.62488496
210,JonatanGk/roberta-base-ca-finetuned-hate-speech-offensive-catalan,0.7138528
211,Raychanan/COVID_RandomOver,-0.0638892
212,CAMeL-Lab/bert-base-arabic-camelbert-da-sentiment,0.45149752
213,classla/bcms-bertic-parlasent-bcs-ter,0.68178463
214,ali2066/DistilBERTFINAL_ctxSentence_TRAIN_editorials_TEST_NULL_second_train_set_null_False,0.9548882
215,anvay/finetuning-cardiffnlp-sentiment-model,0.9139381
216,joebobby/finetuning-sentiment-model-5000-samples3,0.85181457
217,YeRyeongLee/electra-base-discriminator-finetuned-filtered-0602,0.062212493
218,Jeevesh8/feather_berts_92,0.8915027
219,Monsia/camembert-fr-covid-tweet-classification,0.7333834
220,CAMeL-Lab/bert-base-arabic-camelbert-mix-did-nadi,0.49422964
221,ASCCCCCCCC/distilbert-base-chinese-amazon_zh_20000,0.63295615
222,kyleinincubated/autonlp-cat333-624217911,0.51925445
223,fgaim/tiroberta-geezswitch,0.5455906
