,model,score
0,Guscode/DKbert-hatespeech-detection,0.57890075
1,robertou2/roberta-base-bne-finetuned-amazon_reviews_multi,0.7168588
2,milyiyo/selectra-small-finetuned-amazon-review,0.5610196
3,robertou2/roberta-base-bne-finetuned-amazon_reviews_multi,0.71073097
4,milyiyo/selectra-small-finetuned-amazon-review,0.5363522
5,SetFit/distilbert-base-uncased__hate_speech_offensive__train-16-1,0.8465415
6,SetFit/distilbert-base-uncased__hate_speech_offensive__train-16-1,0.8489093
7,vinai/bertweet-base,0.7823889
8,vinai/bertweet-base,0.775524
9,justinqbui/bertweet-covid19-base-uncased-pretraining-covid-vaccine-tweets,0.8750828
10,jb2k/bert-base-multilingual-cased-language-detection,0.7157959
11,crcb/isear_bert,0.8718962
12,vaariis/distilbert-base-uncased-finetuned-emotion,0.8090898
13,abdelkader/distilbert-base-uncased-finetuned-emotion,0.8479782
14,marcelcastrobr/sagemaker-distilbert-emotion,0.8390986
15,moghis/distilbert-base-uncased-finetuned-emotion,0.840429
16,uygarkurt/distilbert-base-uncased-finetuned-emotion,0.84493697
17,neibla/distilbert-base-uncased-finetuned-emotion,0.85543245
18,JB173/distilbert-base-uncased-finetuned-emotion,0.8472393
19,Nanatan/distilbert-base-uncased-finetuned-emotion,0.8543291
20,vaariis/distilbert-base-uncased-finetuned-emotion,0.8354131
21,marcelcastrobr/sagemaker-distilbert-emotion,0.8638222
22,abdelkader/distilbert-base-uncased-finetuned-emotion,0.86152196
23,moghis/distilbert-base-uncased-finetuned-emotion,0.83092034
24,uygarkurt/distilbert-base-uncased-finetuned-emotion,0.8805281
25,neibla/distilbert-base-uncased-finetuned-emotion,0.81909186
26,JB173/distilbert-base-uncased-finetuned-emotion,0.7790385
27,Nanatan/distilbert-base-uncased-finetuned-emotion,0.8249922
28,riyadhctg/distilbert-base-uncased-finetuned-cola,0.8657718
29,gchhablani/fnet-base-finetuned-cola,0.8064535
30,connectivity/cola_6ep_ft-33,0.8848226
31,jaesun/distilbert-base-uncased-finetuned-cola,0.8679578
32,connectivity/cola_6ep_ft-22,0.8770934
33,usami/distilbert-base-uncased-finetuned-cola,0.8670267
34,Jeevesh8/512seq_len_6ep_bert_ft_cola-91,0.88598096
35,Jeevesh8/6ep_bert_ft_cola-47,0.8670141
36,connectivity/cola_6ep_ft-10,0.86669433
37,Jeevesh8/6ep_bert_ft_cola-29,0.7968546
38,riyadhctg/distilbert-base-uncased-finetuned-cola,0.87943655
39,connectivity/cola_6ep_ft-33,0.8957811
40,connectivity/cola_6ep_ft-22,0.8936637
41,gchhablani/fnet-base-finetuned-cola,0.7593877
42,isakbos/Q8BERT_COLA_L_512,0.650326
43,vesteinn/XLMR-ENIS-finetuned-cola,0.918476
44,jaesun/distilbert-base-uncased-finetuned-cola,0.8295679
45,usami/distilbert-base-uncased-finetuned-cola,0.85484433
46,Jeevesh8/512seq_len_6ep_bert_ft_cola-91,0.90192246
47,Jeevesh8/6ep_bert_ft_cola-47,0.8778893
48,connectivity/cola_6ep_ft-10,0.85237247
49,Jeevesh8/6ep_bert_ft_cola-12,0.89102393
50,Jeevesh8/6ep_bert_ft_cola-29,0.85310036
51,Jeevesh8/bert_ft_cola-60,0.8871936
52,navsad/navid_test_bert,0.8976222
53,Jeevesh8/bert_ft_cola-88,0.8763071
54,ishan/bert-base-uncased-mnli,0.8617543
55,boychaboy/MNLI_roberta-base,0.92271924
56,anirudh21/bert-base-uncased-finetuned-qnli,0.8883234
57,Alireza1044/albert-base-v2-qnli,0.8387837
58,Jeevesh8/init_bert_ft_qqp-49,0.80820656
59,Jeevesh8/bert_ft_qqp-40,0.86020905
60,Jeevesh8/bert_ft_qqp-88,0.8535362
61,connectivity/bert_ft_qqp-25,0.84519285
62,Jeevesh8/bert_ft_qqp-55,0.88107646
63,Jeevesh8/bert_ft_qqp-39,0.8740639
64,Jeevesh8/init_bert_ft_qqp-33,0.84801155
65,Jeevesh8/init_bert_ft_qqp-49,0.8571538
66,Jeevesh8/bert_ft_qqp-40,0.8546131
67,Jeevesh8/bert_ft_qqp-9,0.8596072
68,Jeevesh8/bert_ft_qqp-88,0.8749431
69,connectivity/bert_ft_qqp-25,0.82974076
70,Jeevesh8/init_bert_ft_qqp-24,0.8941058
71,Jeevesh8/bert_ft_qqp-55,0.8841088
72,Jeevesh8/bert_ft_qqp-68,0.87888044
73,connectivity/bert_ft_qqp-17,0.86755246
74,Jeevesh8/init_bert_ft_qqp-28,0.86428434
75,connectivity/bert_ft_qqp-1,0.880112
76,Jeevesh8/bert_ft_qqp-39,0.8640164
77,connectivity/bert_ft_qqp-94,0.8703348
78,connectivity/bert_ft_qqp-96,0.8683377
79,gchhablani/bert-base-cased-finetuned-rte,0.87726825
80,ali2066/finetuned_sentence_itr1_2e-05_all_26_02_2022-04_03_26,0.8235212
81,gchhablani/fnet-base-finetuned-sst2,0.7521255
82,SetFit/distilbert-base-uncased__sst2__train-16-0,0.86760587
83,SetFit/distilbert-base-uncased__sst2__train-32-9,0.86360717
84,aviator-neural/bert-base-uncased-sst2,0.8093458
85,Alassea/glue_sst_classifier,0.845885
86,ali2066/finetuned_sentence_itr1_2e-05_all_26_02_2022-04_03_26,0.9101374
87,philschmid/tiny-distilbert-classification,-0.013427101
88,SetFit/distilbert-base-uncased__sst2__train-16-0,0.8626691
89,gchhablani/fnet-base-finetuned-sst2,0.7277526
90,moshew/bert-mini-sst2-distilled,0.72408676
91,SetFit/distilbert-base-uncased__sst2__train-32-9,0.84699786
92,aviator-neural/bert-base-uncased-sst2,0.8170123
93,Alassea/glue_sst_classifier,0.8649856
94,ChrisUPM/BioBERT_Re_trained,0.7576596
95,gchhablani/bert-base-cased-finetuned-wnli,0.80529773
96,gchhablani/bert-base-cased-finetuned-wnli,0.86317235
97,Hate-speech-CNERG/bert-base-uncased-hatexplain-rationale-two,0.8260023
98,Hate-speech-CNERG/bert-base-uncased-hatexplain-rationale-two,0.8919442
99,heranm/finetuning-sentiment-model-3000-samples,0.88451135
100,PrasunMishra/finetuning-sentiment-model-3000-samples,0.87441796
101,yukta10/finetuning-sentiment-model-3000-samples,0.86992013
102,ncduy/roberta-imdb-sentiment-analysis,0.9013653
103,markt23917/finetuning-sentiment-model-3000-samples,0.85402316
104,juliensimon/autonlp-imdb-demo-hf-16622767,0.868329
105,XSY/albert-base-v2-imdb-calssification,0.7774759
106,heranm/finetuning-sentiment-model-3000-samples,0.8905402
107,PrasunMishra/finetuning-sentiment-model-3000-samples,0.9043284
108,yukta10/finetuning-sentiment-model-3000-samples,0.86399245
109,ncduy/roberta-imdb-sentiment-analysis,0.8858591
110,markt23917/finetuning-sentiment-model-3000-samples,0.8805638
111,juliensimon/autonlp-imdb-demo-hf-16622767,0.8220699
112,XSY/albert-base-v2-imdb-calssification,0.72267944
113,fabriceyhc/bert-base-uncased-imdb,0.81874216
114,Anthos23/FS-distilroberta-fine-tuned,0.8946255
115,Anthos23/FS-distilroberta-fine-tuned,0.89468014
116,oferweintraub/bert-base-finance-sentiment-noisy-search,0.85934997
117,emrecan/bert-base-multilingual-cased-snli_tr,0.7878329
118,nurkayevaa/autonlp-bert-covid-407910458,0.87661123
119,nurkayevaa/autonlp-bert-covid-407910458,0.8923159
120,w11wo/sundanese-bert-base-emotion-classifier,0.578426
121,aychang/bert-base-cased-trec-coarse,0.890364
122,aychang/bert-base-cased-trec-coarse,0.8774037
123,JNK789/distilbert-base-uncased-finetuned-tweets-emoji-dataset,0.07138563
124,JNK789/distilbert-base-uncased-finetuned-tweets-emoji-dataset,0.035484336
125,pietrotrope/emotion_final,0.8586859
126,aXhyra/emotion_trained_31415,0.871063
127,aXhyra/presentation_emotion_31415,0.8890157
128,pietrotrope/emotion_final,0.8709637
129,aXhyra/emotion_trained_31415,0.89024043
130,aXhyra/presentation_emotion_31415,0.850553
131,elozano/tweet_offensive_eval,0.5713475
132,aXhyra/demo_sentiment_31415,0.8893832
133,aXhyra/presentation_sentiment_1234567,0.8893352
134,aXhyra/demo_sentiment_31415,0.87337774
135,aXhyra/presentation_sentiment_1234567,0.84210354
136,nickmuchi/facebook-data2vec-finetuned-finance-classification,0.84284186
137,manueltonneau/bert-twitter-en-is-hired,0.8968142
138,distilbert-base-uncased,0.88142097
139,albert-base-v2,0.8564992
140,bert-base-cased,0.8425705
141,dhimskyy/wiki-bert,0.6271492
142,bert-base-uncased,0.8683175
143,distilbert-base-uncased,0.87652683
144,roberta-base,0.884329
145,albert-base-v2,0.83711255
146,bert-base-cased,0.90198684
147,michiyasunaga/LinkBERT-base,0.8585584
148,roberta-large,0.8281735
149,bert-large-uncased,0.5023271
150,Recognai/bert-base-spanish-wwm-cased-xnli,0.6374905
151,Recognai/bert-base-spanish-wwm-cased-xnli,0.6481179
152,mrm8488/electricidad-base-finetuned-pawsx-es,0.60110176
153,dapang/distilroberta-base-mic-sym,0.88776267
154,Capreolus/bert-base-msmarco,0.8680743
155,Splend1dchan/bert-base-uncased-slue-goldtrascription-e3-lr1e-4,0.84997356
156,cambridgeltl/guardian_news_distilbert-base-uncased,0.8270477
157,JonatanGk/roberta-base-bne-finetuned-cyberbullying-spanish,0.36569166
158,phailyoor/distilbert-base-uncased-finetuned-yahd,0.78109294
159,arianpasquali/distilbert-base-multilingual-cased-toxicity,0.6858074
160,amyma21/sincere_question_classification,0.79030246
161,liangyuant/distilbert-base-uncased-finetuned-num200-450-405cls,0.84693676
162,Giyaseddin/distilroberta-base-finetuned-short-answer-assessment,0.8570688
163,DoyyingFace/bert-asian-hate-tweets-asian-unclean-freeze-4,0.8126203
164,viviastaari/finetuning-sentiment-analysis-en-id,0.67396015
165,Aureliano/distilbert-base-uncased-if,0.86222297
166,rmihaylov/roberta-base-sentiment-bg,0.6697489
167,korca/bae-roberta-base-boolq,0.86034095
168,matthewburke/korean_sentiment,0.63014984
169,IMSyPP/hate_speech_nl,0.51677126
170,cointegrated/roberta-base-formality,0.87758213
171,dapang/distilroberta-base-mic-sym,0.8836278
172,Splend1dchan/bert-base-uncased-slue-goldtrascription-e3-lr1e-4,0.8440881
173,Jeevesh8/feather_berts_46,0.8822922
174,Capreolus/bert-base-msmarco,0.8768129
175,cambridgeltl/guardian_news_distilbert-base-uncased,0.79145205
176,JonatanGk/roberta-base-bne-finetuned-cyberbullying-spanish,0.49826187
177,phailyoor/distilbert-base-uncased-finetuned-yahd,0.7389198
178,amyma21/sincere_question_classification,0.8278174
179,arianpasquali/distilbert-base-multilingual-cased-toxicity,0.70902205
180,connectivity/feather_berts_28,0.8656066
181,chiragasarpota/scotus-bert,0.48937008
182,IMSyPP/hate_speech_it,0.6089415
183,liangyuant/distilbert-base-uncased-finetuned-num200-450-405cls,0.7925834
184,DoyyingFace/bert-asian-hate-tweets-asian-unclean-freeze-4,0.87239766
185,Giyaseddin/distilroberta-base-finetuned-short-answer-assessment,0.8572683
186,Jeevesh8/lecun_feather_berts-3,0.83810306
187,Jeevesh8/feather_berts_96,0.8542675
188,Jeevesh8/lecun_feather_berts-51,0.8652097
189,viviastaari/finetuning-sentiment-analysis-en-id,0.64303225
190,AnonymousSub/dummy_2,0.65956855
191,finiteautomata/betonews-tweetcontext,0.6385959
192,Aureliano/distilbert-base-uncased-if,0.8289443
193,rmihaylov/roberta-base-sentiment-bg,0.63867307
194,cardiffnlp/twitter-roberta-base-2021-124m,0.86233205
195,warwickai/fin-perceiver,0.81444
196,Jeevesh8/lecun_feather_berts-8,0.8552588
197,Jeevesh8/lecun_feather_berts-7,0.8663337
198,IMSyPP/hate_speech_nl,0.5041906
199,anferico/bert-for-patents,0.7003238
200,korca/bae-roberta-base-boolq,0.88486636
201,matthewburke/korean_sentiment,0.6095962
202,waboucay/camembert-base-finetuned-xnli_fr-finetuned-nli-rua_wl,0.44434202
203,aditeyabaral/finetuned-sail2017-xlm-roberta-base,0.81785077
204,mrm8488/codebert-base-finetuned-detect-insecure-code,0.7704319
205,socialmediaie/TRAC2020_IBEN_B_bert-base-multilingual-uncased,0.79836035
206,zenkri/autotrain-Arabic_Poetry_by_Subject-920730230,0.82184505
207,M47Labs/spanish_news_classification_headlines_untrained,0.6773024
208,cointegrated/roberta-base-formality,0.8617838
209,bondi/bert-semaphore-prediction-w4,0.6292165
210,JonatanGk/roberta-base-ca-finetuned-hate-speech-offensive-catalan,0.6147155
211,Raychanan/COVID_RandomOver,0.000949573
212,CAMeL-Lab/bert-base-arabic-camelbert-da-sentiment,0.49140677
213,classla/bcms-bertic-parlasent-bcs-ter,0.6621736
214,ali2066/DistilBERTFINAL_ctxSentence_TRAIN_editorials_TEST_NULL_second_train_set_null_False,0.8954257
215,anvay/finetuning-cardiffnlp-sentiment-model,0.8876871
216,joebobby/finetuning-sentiment-model-5000-samples3,0.87471163
217,YeRyeongLee/electra-base-discriminator-finetuned-filtered-0602,0.1145387
218,Jeevesh8/feather_berts_92,0.87072325
219,Monsia/camembert-fr-covid-tweet-classification,0.6923485
220,CAMeL-Lab/bert-base-arabic-camelbert-mix-did-nadi,0.49416032
221,ASCCCCCCCC/distilbert-base-chinese-amazon_zh_20000,0.5514397
222,kyleinincubated/autonlp-cat333-624217911,0.661684
223,fgaim/tiroberta-geezswitch,0.5056017
