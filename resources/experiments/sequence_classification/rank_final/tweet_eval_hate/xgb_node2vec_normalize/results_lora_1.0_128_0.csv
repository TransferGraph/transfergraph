,model,score
0,Jeevesh8/init_bert_ft_qqp-33,0.79682827
1,Jeevesh8/init_bert_ft_qqp-33,0.7987498
2,ali2066/finetuned_sentence_itr1_2e-05_all_26_02_2022-04_03_26,0.8266323
3,ali2066/finetuned_sentence_itr1_2e-05_all_26_02_2022-04_03_26,0.81690824
4,ali2066/finetuned_sentence_itr1_2e-05_all_26_02_2022-04_03_26,0.8080628
5,vaariis/distilbert-base-uncased-finetuned-emotion,0.812822
6,vaariis/distilbert-base-uncased-finetuned-emotion,0.8117569
7,vaariis/distilbert-base-uncased-finetuned-emotion,0.7974723
8,heranm/finetuning-sentiment-model-3000-samples,0.8293125
9,heranm/finetuning-sentiment-model-3000-samples,0.8143779
10,heranm/finetuning-sentiment-model-3000-samples,0.8068941
11,marcelcastrobr/sagemaker-distilbert-emotion,0.83053195
12,marcelcastrobr/sagemaker-distilbert-emotion,0.8016035
13,marcelcastrobr/sagemaker-distilbert-emotion,0.7999444
14,jasonyim2/distilbert-base-uncased-finetuned-emotion,0.80799884
15,jasonyim2/distilbert-base-uncased-finetuned-emotion,0.81173974
16,jasonyim2/distilbert-base-uncased-finetuned-emotion,0.8170027
17,riyadhctg/distilbert-base-uncased-finetuned-cola,0.8243411
18,riyadhctg/distilbert-base-uncased-finetuned-cola,0.8003164
19,riyadhctg/distilbert-base-uncased-finetuned-cola,0.7960619
20,dapang/distilroberta-base-mic-sym,0.8477983
21,dapang/distilroberta-base-mic-sym,0.81605685
22,dapang/distilroberta-base-mic-sym,0.80935454
23,PrasunMishra/finetuning-sentiment-model-3000-samples,0.8103656
24,PrasunMishra/finetuning-sentiment-model-3000-samples,0.80670816
25,PrasunMishra/finetuning-sentiment-model-3000-samples,0.8109652
26,nurkayevaa/autonlp-bert-covid-407910458,0.8134416
27,nurkayevaa/autonlp-bert-covid-407910458,0.80770934
28,nurkayevaa/autonlp-bert-covid-407910458,0.8191952
29,SetFit/distilbert-base-uncased__sst2__train-16-0,0.7953423
30,SetFit/distilbert-base-uncased__sst2__train-16-0,0.80916345
31,SetFit/distilbert-base-uncased__sst2__train-16-0,0.8041324
32,abdelkader/distilbert-base-uncased-finetuned-emotion,0.8275883
33,abdelkader/distilbert-base-uncased-finetuned-emotion,0.8120607
34,abdelkader/distilbert-base-uncased-finetuned-emotion,0.79917127
35,SetFit/distilbert-base-uncased__hate_speech_offensive__train-16-1,0.81597215
36,SetFit/distilbert-base-uncased__hate_speech_offensive__train-16-1,0.807166
37,SetFit/distilbert-base-uncased__hate_speech_offensive__train-16-1,0.80559206
38,Capreolus/bert-base-msmarco,0.7995024
39,Capreolus/bert-base-msmarco,0.80318403
40,Capreolus/bert-base-msmarco,0.8022752
41,Splend1dchan/bert-base-uncased-slue-goldtrascription-e3-lr1e-4,0.80652505
42,Splend1dchan/bert-base-uncased-slue-goldtrascription-e3-lr1e-4,0.8046225
43,Splend1dchan/bert-base-uncased-slue-goldtrascription-e3-lr1e-4,0.80595064
44,crcb/isear_bert,0.8213917
45,crcb/isear_bert,0.8165563
46,connectivity/cola_6ep_ft-33,0.7967409
47,connectivity/cola_6ep_ft-33,0.8100534
48,connectivity/cola_6ep_ft-33,0.81252074
49,Jeevesh8/init_bert_ft_qqp-49,0.79729265
50,Jeevesh8/init_bert_ft_qqp-49,0.80707526
51,Jeevesh8/init_bert_ft_qqp-49,0.7990414
52,Jeevesh8/feather_berts_46,0.81656337
53,Jeevesh8/feather_berts_46,0.8100426
54,yukta10/finetuning-sentiment-model-3000-samples,0.8307385
55,yukta10/finetuning-sentiment-model-3000-samples,0.80795556
56,yukta10/finetuning-sentiment-model-3000-samples,0.80461484
57,connectivity/cola_6ep_ft-22,0.8257879
58,connectivity/cola_6ep_ft-22,0.8050008
59,connectivity/cola_6ep_ft-22,0.80331695
60,JonatanGk/roberta-base-bne-finetuned-cyberbullying-spanish,0.65606576
61,JonatanGk/roberta-base-bne-finetuned-cyberbullying-spanish,0.70001423
62,JonatanGk/roberta-base-bne-finetuned-cyberbullying-spanish,0.6446949
63,cambridgeltl/guardian_news_distilbert-base-uncased,0.81829333
64,cambridgeltl/guardian_news_distilbert-base-uncased,0.7916745
65,cambridgeltl/guardian_news_distilbert-base-uncased,0.78259075
66,ncduy/roberta-imdb-sentiment-analysis,0.82867336
67,ncduy/roberta-imdb-sentiment-analysis,0.82856226
68,ncduy/roberta-imdb-sentiment-analysis,0.81537044
69,isakbos/Q8BERT_COLA_L_512,0.70788056
70,isakbos/Q8BERT_COLA_L_512,0.6628112
71,connectivity/bert_ft_qqp-7,0.79571885
72,connectivity/bert_ft_qqp-7,0.7866127
73,moghis/distilbert-base-uncased-finetuned-emotion,0.83136076
74,moghis/distilbert-base-uncased-finetuned-emotion,0.8028408
75,moghis/distilbert-base-uncased-finetuned-emotion,0.8106678
76,uygarkurt/distilbert-base-uncased-finetuned-emotion,0.8065902
77,uygarkurt/distilbert-base-uncased-finetuned-emotion,0.8098667
78,uygarkurt/distilbert-base-uncased-finetuned-emotion,0.8124583
79,amyma21/sincere_question_classification,0.80647844
80,amyma21/sincere_question_classification,0.7963056
81,amyma21/sincere_question_classification,0.7964739
82,phailyoor/distilbert-base-uncased-finetuned-yahd,0.8115662
83,phailyoor/distilbert-base-uncased-finetuned-yahd,0.7736218
84,phailyoor/distilbert-base-uncased-finetuned-yahd,0.80096877
85,arianpasquali/distilbert-base-multilingual-cased-toxicity,0.7981302
86,arianpasquali/distilbert-base-multilingual-cased-toxicity,0.74530005
87,arianpasquali/distilbert-base-multilingual-cased-toxicity,0.7426665
88,neibla/distilbert-base-uncased-finetuned-emotion,0.7790476
89,neibla/distilbert-base-uncased-finetuned-emotion,0.8081098
90,neibla/distilbert-base-uncased-finetuned-emotion,0.8099626
91,robertou2/roberta-base-bne-finetuned-amazon_reviews_multi,0.79863137
92,robertou2/roberta-base-bne-finetuned-amazon_reviews_multi,0.7386995
93,robertou2/roberta-base-bne-finetuned-amazon_reviews_multi,0.73169446
94,Anthos23/FS-distilroberta-fine-tuned,0.8222041
95,Anthos23/FS-distilroberta-fine-tuned,0.8189883
96,Anthos23/FS-distilroberta-fine-tuned,0.81431246
97,pietrotrope/emotion_final,0.83882993
98,pietrotrope/emotion_final,0.81336224
99,pietrotrope/emotion_final,0.7941325
100,aviator-neural/bert-base-uncased-sst2,0.77240145
101,aviator-neural/bert-base-uncased-sst2,0.79786736
102,aviator-neural/bert-base-uncased-sst2,0.80057156
103,Jeevesh8/bert_ft_qqp-40,0.7838616
104,Jeevesh8/bert_ft_qqp-40,0.8050882
105,Jeevesh8/bert_ft_qqp-40,0.79961896
106,jaesun/distilbert-base-uncased-finetuned-cola,0.82393116
107,jaesun/distilbert-base-uncased-finetuned-cola,0.7994673
108,jaesun/distilbert-base-uncased-finetuned-cola,0.81153387
109,SetFit/distilbert-base-uncased__sst2__train-32-9,0.8242172
110,SetFit/distilbert-base-uncased__sst2__train-32-9,0.8023949
111,SetFit/distilbert-base-uncased__sst2__train-32-9,0.81729674
112,usami/distilbert-base-uncased-finetuned-cola,0.80248827
113,usami/distilbert-base-uncased-finetuned-cola,0.8014702
114,usami/distilbert-base-uncased-finetuned-cola,0.82015526
115,connectivity/feather_berts_28,0.7996018
116,connectivity/feather_berts_28,0.8028236
117,Jeevesh8/512seq_len_6ep_bert_ft_cola-91,0.807094
118,Jeevesh8/512seq_len_6ep_bert_ft_cola-91,0.80648094
119,Jeevesh8/512seq_len_6ep_bert_ft_cola-91,0.78416896
120,Jeevesh8/bert_ft_qqp-9,0.8069292
121,Jeevesh8/bert_ft_qqp-9,0.8022016
122,Jeevesh8/bert_ft_qqp-88,0.7875795
123,Jeevesh8/bert_ft_qqp-88,0.8123767
124,Jeevesh8/bert_ft_qqp-88,0.80884343
125,Recognai/bert-base-spanish-wwm-cased-xnli,0.7424477
126,Recognai/bert-base-spanish-wwm-cased-xnli,0.75224084
127,Recognai/bert-base-spanish-wwm-cased-xnli,0.7505656
128,markt23917/finetuning-sentiment-model-3000-samples,0.8122858
129,markt23917/finetuning-sentiment-model-3000-samples,0.8121884
130,markt23917/finetuning-sentiment-model-3000-samples,0.8270024
131,anirudh21/bert-base-uncased-finetuned-qnli,0.8140841
132,anirudh21/bert-base-uncased-finetuned-qnli,0.8167144
133,Jeevesh8/6ep_bert_ft_cola-47,0.7863193
134,Jeevesh8/6ep_bert_ft_cola-47,0.80930674
135,Jeevesh8/6ep_bert_ft_cola-47,0.8003286
136,oferweintraub/bert-base-finance-sentiment-noisy-search,0.81815195
137,oferweintraub/bert-base-finance-sentiment-noisy-search,0.7884645
138,aXhyra/demo_sentiment_31415,0.8393906
139,aXhyra/demo_sentiment_31415,0.81354123
140,aXhyra/demo_sentiment_31415,0.8238317
141,milyiyo/selectra-small-finetuned-amazon-review,0.71939576
142,milyiyo/selectra-small-finetuned-amazon-review,0.68237454
143,milyiyo/selectra-small-finetuned-amazon-review,0.65743124
144,aXhyra/presentation_sentiment_1234567,0.82364345
145,aXhyra/presentation_sentiment_1234567,0.81502414
146,aXhyra/presentation_sentiment_1234567,0.814111
147,liangyuant/distilbert-base-uncased-finetuned-num200-450-405cls,0.81323284
148,liangyuant/distilbert-base-uncased-finetuned-num200-450-405cls,0.7883018
149,liangyuant/distilbert-base-uncased-finetuned-num200-450-405cls,0.8319426
150,DoyyingFace/bert-asian-hate-tweets-asian-unclean-freeze-4,0.8123445
151,DoyyingFace/bert-asian-hate-tweets-asian-unclean-freeze-4,0.8116357
152,DoyyingFace/bert-asian-hate-tweets-asian-unclean-freeze-4,0.8057704
153,connectivity/cola_6ep_ft-10,0.7968834
154,connectivity/cola_6ep_ft-10,0.80450475
155,connectivity/cola_6ep_ft-10,0.80612284
156,Jeevesh8/lecun_feather_berts-3,0.8122976
157,Jeevesh8/lecun_feather_berts-3,0.8073051
158,jb2k/bert-base-multilingual-cased-language-detection,0.7298793
159,jb2k/bert-base-multilingual-cased-language-detection,0.7171612
160,Giyaseddin/distilroberta-base-finetuned-short-answer-assessment,0.84190184
161,Giyaseddin/distilroberta-base-finetuned-short-answer-assessment,0.8143978
162,Giyaseddin/distilroberta-base-finetuned-short-answer-assessment,0.80478275
163,connectivity/bert_ft_qqp-25,0.77012354
164,connectivity/bert_ft_qqp-25,0.79905933
165,connectivity/bert_ft_qqp-25,0.80127007
166,Jeevesh8/6ep_bert_ft_cola-12,0.80979973
167,Jeevesh8/6ep_bert_ft_cola-12,0.803721
168,JB173/distilbert-base-uncased-finetuned-emotion,0.81215495
169,JB173/distilbert-base-uncased-finetuned-emotion,0.8061655
170,JB173/distilbert-base-uncased-finetuned-emotion,0.81761646
171,aXhyra/emotion_trained_31415,0.8286003
172,aXhyra/emotion_trained_31415,0.8081757
173,aXhyra/emotion_trained_31415,0.80628425
174,aXhyra/presentation_emotion_31415,0.7931525
175,aXhyra/presentation_emotion_31415,0.80323374
176,aXhyra/presentation_emotion_31415,0.80483097
177,AnonymousSub/dummy_2,0.76232785
178,AnonymousSub/dummy_2,0.7292405
179,Jeevesh8/bert_ft_qqp-55,0.7981766
180,Jeevesh8/bert_ft_qqp-55,0.81035095
181,Jeevesh8/bert_ft_qqp-55,0.7900479
182,Jeevesh8/lecun_feather_berts-51,0.80710614
183,Jeevesh8/lecun_feather_berts-51,0.80032873
184,viviastaari/finetuning-sentiment-analysis-en-id,0.7466281
185,viviastaari/finetuning-sentiment-analysis-en-id,0.7026047
186,viviastaari/finetuning-sentiment-analysis-en-id,0.7103593
187,vinai/bertweet-base,0.8479272
188,vinai/bertweet-base,0.82334554
189,vinai/bertweet-base,0.80978787
190,distilbert-base-uncased,0.8071209
191,distilbert-base-uncased,0.82119524
192,distilbert-base-uncased,0.80414677
193,bert-base-uncased,0.8082641
194,bert-base-uncased,0.8114652
195,roberta-base,0.8343572
196,roberta-base,0.82683897
197,Aureliano/distilbert-base-uncased-if,0.8241468
198,Aureliano/distilbert-base-uncased-if,0.79958516
199,Aureliano/distilbert-base-uncased-if,0.8202479
200,rmihaylov/roberta-base-sentiment-bg,0.7703303
201,rmihaylov/roberta-base-sentiment-bg,0.77245986
202,rmihaylov/roberta-base-sentiment-bg,0.72759354
203,cardiffnlp/twitter-roberta-base-2021-124m,0.81967914
204,cardiffnlp/twitter-roberta-base-2021-124m,0.8149179
205,Alassea/glue_sst_classifier,0.8275993
206,Alassea/glue_sst_classifier,0.80074495
207,Alassea/glue_sst_classifier,0.80710536
208,Nanatan/distilbert-base-uncased-finetuned-emotion,0.81027204
209,Nanatan/distilbert-base-uncased-finetuned-emotion,0.80222476
210,Nanatan/distilbert-base-uncased-finetuned-emotion,0.7820769
211,connectivity/bert_ft_qqp-1,0.8112376
212,connectivity/bert_ft_qqp-1,0.8178778
213,juliensimon/autonlp-imdb-demo-hf-16622767,0.82865757
214,juliensimon/autonlp-imdb-demo-hf-16622767,0.78768176
215,juliensimon/autonlp-imdb-demo-hf-16622767,0.79606724
216,Jeevesh8/bert_ft_qqp-39,0.80509484
217,Jeevesh8/bert_ft_qqp-39,0.8081051
218,Jeevesh8/bert_ft_qqp-39,0.78973305
219,Jeevesh8/lecun_feather_berts-8,0.81489575
220,Jeevesh8/lecun_feather_berts-8,0.82262695
221,connectivity/bert_ft_qqp-94,0.81555086
222,connectivity/bert_ft_qqp-94,0.7914615
223,korca/bae-roberta-base-boolq,0.84580606
224,korca/bae-roberta-base-boolq,0.82304335
225,korca/bae-roberta-base-boolq,0.80838525
226,Jeevesh8/bert_ft_cola-88,0.8064404
227,Jeevesh8/bert_ft_cola-88,0.79869753
228,aditeyabaral/finetuned-sail2017-xlm-roberta-base,0.8170135
229,aditeyabaral/finetuned-sail2017-xlm-roberta-base,0.7841508
230,connectivity/bert_ft_qqp-96,0.7994395
231,connectivity/bert_ft_qqp-96,0.8085552
232,boychaboy/MNLI_roberta-base,0.828321
233,boychaboy/MNLI_roberta-base,0.8226573
234,fabriceyhc/bert-base-uncased-imdb,0.80117244
235,fabriceyhc/bert-base-uncased-imdb,0.80106604
236,emrecan/bert-base-multilingual-cased-snli_tr,0.7653417
237,emrecan/bert-base-multilingual-cased-snli_tr,0.7439052
238,elozano/tweet_offensive_eval,0.69638616
239,elozano/tweet_offensive_eval,0.7039323
240,joebobby/finetuning-sentiment-model-5000-samples3,0.81340456
241,joebobby/finetuning-sentiment-model-5000-samples3,0.80104196
242,Jeevesh8/feather_berts_92,0.8008188
243,Jeevesh8/feather_berts_92,0.78589416
244,ASCCCCCCCC/distilbert-base-chinese-amazon_zh_20000,0.71403575
245,ASCCCCCCCC/distilbert-base-chinese-amazon_zh_20000,0.6787743
246,Jeevesh8/6ep_bert_ft_cola-29,0.8132031
247,Jeevesh8/6ep_bert_ft_cola-29,0.8141822
248,Jeevesh8/6ep_bert_ft_cola-29,0.81103
249,bert-base-cased,0.7759738
250,bert-base-cased,0.80822515
251,bert-base-cased,0.8050886
252,Hate-speech-CNERG/bert-base-uncased-hatexplain-rationale-two,0.79151917
253,Hate-speech-CNERG/bert-base-uncased-hatexplain-rationale-two,0.8163136
254,Hate-speech-CNERG/bert-base-uncased-hatexplain-rationale-two,0.8101167
255,matthewburke/korean_sentiment,0.7922762
256,matthewburke/korean_sentiment,0.7537411
257,matthewburke/korean_sentiment,0.6322508
258,aychang/bert-base-cased-trec-coarse,0.79417735
259,aychang/bert-base-cased-trec-coarse,0.8186423
260,aychang/bert-base-cased-trec-coarse,0.8168224
261,IMSyPP/hate_speech_nl,0.7194674
262,IMSyPP/hate_speech_nl,0.7037693
263,IMSyPP/hate_speech_nl,0.68422884
264,cointegrated/roberta-base-formality,0.83099186
265,cointegrated/roberta-base-formality,0.82232994
266,cointegrated/roberta-base-formality,0.81633884
267,philschmid/tiny-distilbert-classification,0.49367613
268,philschmid/tiny-distilbert-classification,0.4905626
269,gchhablani/bert-base-cased-finetuned-wnli,0.7932966
270,gchhablani/bert-base-cased-finetuned-wnli,0.80438465
271,gchhablani/bert-base-cased-finetuned-wnli,0.7972242
272,moshew/bert-mini-sst2-distilled,0.7582341
273,moshew/bert-mini-sst2-distilled,0.77616054
274,vesteinn/XLMR-ENIS-finetuned-cola,0.8186962
275,vesteinn/XLMR-ENIS-finetuned-cola,0.80684686
276,IMSyPP/hate_speech_it,0.71278936
277,IMSyPP/hate_speech_it,0.6913274
278,Jeevesh8/init_bert_ft_qqp-24,0.8107562
279,Jeevesh8/init_bert_ft_qqp-24,0.7889729
280,Jeevesh8/bert_ft_qqp-68,0.79543084
281,Jeevesh8/bert_ft_qqp-68,0.7918244
282,Jeevesh8/init_bert_ft_qqp-28,0.7968532
283,Jeevesh8/init_bert_ft_qqp-28,0.7957985
284,connectivity/bert_ft_qqp-17,0.8059959
285,connectivity/bert_ft_qqp-17,0.79423165
286,dhimskyy/wiki-bert,0.7005598
287,dhimskyy/wiki-bert,0.69202816
288,18811449050/bert_finetuning_test,0.7835614
289,18811449050/bert_finetuning_test,0.7851911
290,finiteautomata/betonews-tweetcontext,0.734431
291,finiteautomata/betonews-tweetcontext,0.6965199
292,Jeevesh8/feather_berts_96,0.81186956
293,Jeevesh8/feather_berts_96,0.79473674
294,michiyasunaga/LinkBERT-base,0.81267035
295,michiyasunaga/LinkBERT-base,0.8037684
296,navsad/navid_test_bert,0.8051066
297,navsad/navid_test_bert,0.80338037
298,Jeevesh8/bert_ft_cola-60,0.79924726
299,Jeevesh8/bert_ft_cola-60,0.8028016
300,Jeevesh8/lecun_feather_berts-7,0.80200416
301,Jeevesh8/lecun_feather_berts-7,0.80424947
302,w11wo/sundanese-bert-base-emotion-classifier,0.6583867
303,w11wo/sundanese-bert-base-emotion-classifier,0.6216571
304,mrm8488/codebert-base-finetuned-detect-insecure-code,0.78617895
305,mrm8488/codebert-base-finetuned-detect-insecure-code,0.7583435
306,socialmediaie/TRAC2020_IBEN_B_bert-base-multilingual-uncased,0.76427174
307,socialmediaie/TRAC2020_IBEN_B_bert-base-multilingual-uncased,0.7077383
308,ishan/bert-base-uncased-mnli,0.8153807
309,ishan/bert-base-uncased-mnli,0.80410975
310,zenkri/autotrain-Arabic_Poetry_by_Subject-920730230,0.7886104
311,zenkri/autotrain-Arabic_Poetry_by_Subject-920730230,0.76768035
312,M47Labs/spanish_news_classification_headlines_untrained,0.7593336
313,M47Labs/spanish_news_classification_headlines_untrained,0.75359166
314,bondi/bert-semaphore-prediction-w4,0.72227323
315,bondi/bert-semaphore-prediction-w4,0.70665205
316,gchhablani/bert-base-cased-finetuned-rte,0.8085946
317,gchhablani/bert-base-cased-finetuned-rte,0.8164033
318,classla/bcms-bertic-parlasent-bcs-ter,0.74650097
319,classla/bcms-bertic-parlasent-bcs-ter,0.723795
320,anferico/bert-for-patents,0.7429862
321,anferico/bert-for-patents,0.7629155
322,ali2066/DistilBERTFINAL_ctxSentence_TRAIN_editorials_TEST_NULL_second_train_set_null_False,0.8170869
323,ali2066/DistilBERTFINAL_ctxSentence_TRAIN_editorials_TEST_NULL_second_train_set_null_False,0.8181764
324,anvay/finetuning-cardiffnlp-sentiment-model,0.8228511
325,anvay/finetuning-cardiffnlp-sentiment-model,0.82950515
326,JonatanGk/roberta-base-ca-finetuned-hate-speech-offensive-catalan,0.735691
327,JonatanGk/roberta-base-ca-finetuned-hate-speech-offensive-catalan,0.71864545
328,mrm8488/electricidad-base-finetuned-pawsx-es,0.6979519
329,mrm8488/electricidad-base-finetuned-pawsx-es,0.70391166
330,Raychanan/COVID_RandomOver,0.51453143
331,Raychanan/COVID_RandomOver,0.51457727
332,manueltonneau/bert-twitter-en-is-hired,0.8270785
333,manueltonneau/bert-twitter-en-is-hired,0.80990416
334,kyleinincubated/autonlp-cat333-624217911,0.6994201
335,kyleinincubated/autonlp-cat333-624217911,0.67303604
336,Guscode/DKbert-hatespeech-detection,0.6906903
337,Guscode/DKbert-hatespeech-detection,0.69110084
338,bert-large-uncased,0.75182694
339,bert-large-uncased,0.79708445
340,ChrisUPM/BioBERT_Re_trained,0.7785552
341,ChrisUPM/BioBERT_Re_trained,0.7679543
342,roberta-large,0.8137811
343,roberta-large,0.8141296
344,justinqbui/bertweet-covid19-base-uncased-pretraining-covid-vaccine-tweets,0.81389785
345,justinqbui/bertweet-covid19-base-uncased-pretraining-covid-vaccine-tweets,0.789496
