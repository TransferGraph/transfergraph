,model,score
0,Guscode/DKbert-hatespeech-detection,0.5278672900220356
1,milyiyo/selectra-small-finetuned-amazon-review,0.46791418301965554
2,robertou2/roberta-base-bne-finetuned-amazon_reviews_multi,0.6062105363319577
3,vinai/bertweet-covid19-base-cased,0.706713744070335
4,vinai/bertweet-base,0.8374119717107409
5,vinai/bertweet-covid19-base-uncased,0.9035720954799198
6,justinqbui/bertweet-covid19-base-uncased-pretraining-covid-vaccine-tweets,0.9091354027403289
7,jb2k/bert-base-multilingual-cased-language-detection,0.6245865096436567
8,crcb/isear_bert,0.7985761378396703
9,marcelcastrobr/sagemaker-distilbert-emotion,0.7917786603099456
10,abdelkader/distilbert-base-uncased-finetuned-emotion,0.8129506332409239
11,moghis/distilbert-base-uncased-finetuned-emotion,0.7701436919033954
12,neibla/distilbert-base-uncased-finetuned-emotion,0.8058828476865797
13,uygarkurt/distilbert-base-uncased-finetuned-emotion,0.8199358989420581
14,JB173/distilbert-base-uncased-finetuned-emotion,0.8210055794160699
15,vaariis/distilbert-base-uncased-finetuned-emotion,0.8794089759631869
16,Nanatan/distilbert-base-uncased-finetuned-emotion,0.7792206890897826
17,riyadhctg/distilbert-base-uncased-finetuned-cola,0.7475926738133113
18,connectivity/cola_6ep_ft-33,0.8166181103646926
19,vesteinn/XLMR-ENIS-finetuned-cola,0.7647363505291099
20,Jeevesh8/6ep_bert_ft_cola-47,0.8141203277068019
21,Jeevesh8/512seq_len_6ep_bert_ft_cola-91,0.8050235563303806
22,jaesun/distilbert-base-uncased-finetuned-cola,0.7910813985755553
23,Jeevesh8/6ep_bert_ft_cola-12,0.8382176235656048
24,connectivity/cola_6ep_ft-10,0.8202779071041606
25,Jeevesh8/bert_ft_cola-60,0.800388767137519
26,navsad/navid_test_bert,0.771151368461752
27,Jeevesh8/bert_ft_cola-88,0.750041704574714
28,usami/distilbert-base-uncased-finetuned-cola,0.7487265019862188
29,isakbos/Q8BERT_COLA_L_512,0.5489036002380163
30,ishan/bert-base-uncased-mnli,0.8393539210909273
31,boychaboy/MNLI_roberta-base,0.8324568557775243
32,anirudh21/bert-base-uncased-finetuned-qnli,0.877334696485618
33,Alireza1044/albert-base-v2-qnli,0.7451546564615452
34,Jeevesh8/init_bert_ft_qqp-49,0.827214002260001
35,connectivity/bert_ft_qqp-7,0.8241389873311915
36,Jeevesh8/bert_ft_qqp-88,0.8249895188445144
37,Jeevesh8/bert_ft_qqp-9,0.7509481778214642
38,connectivity/bert_ft_qqp-17,0.861440765667923
39,Jeevesh8/init_bert_ft_qqp-28,0.847442035070696
40,Jeevesh8/bert_ft_qqp-55,0.8189607112912296
41,Jeevesh8/bert_ft_qqp-40,0.834850515615276
42,Jeevesh8/bert_ft_qqp-39,0.8574957880642756
43,connectivity/bert_ft_qqp-1,0.8168301445273004
44,connectivity/bert_ft_qqp-96,0.81210230173948
45,connectivity/bert_ft_qqp-25,0.8331477483820219
46,Jeevesh8/bert_ft_qqp-68,0.7670353917750861
47,Jeevesh8/init_bert_ft_qqp-24,0.8256200393212457
48,gchhablani/bert-base-cased-finetuned-rte,0.8896177099636502
49,philschmid/tiny-distilbert-classification,0.06968387092553252
50,ali2066/finetuned_sentence_itr1_2e-05_all_26_02_2022-04_03_26,0.7656176375124896
51,SetFit/distilbert-base-uncased__sst2__train-16-0,0.8306394980403264
52,gchhablani/fnet-base-finetuned-sst2,0.7070573610097771
53,SetFit/distilbert-base-uncased__sst2__train-32-9,0.8736495850218607
54,Alassea/glue_sst_classifier,0.8735534711370494
55,ChrisUPM/BioBERT_Re_trained,0.6793389739822893
56,moshew/bert-mini-sst2-distilled,0.6943513572104484
57,gchhablani/bert-base-cased-finetuned-wnli,0.7653417943982835
58,Hate-speech-CNERG/bert-base-uncased-hatexplain-rationale-two,0.8635544323060904
59,PrasunMishra/finetuning-sentiment-model-3000-samples,0.8308098989464514
60,heranm/finetuning-sentiment-model-3000-samples,0.8511209074030663
61,yukta10/finetuning-sentiment-model-3000-samples,0.826908650837216
62,markt23917/finetuning-sentiment-model-3000-samples,0.7814673471134672
63,juliensimon/autonlp-imdb-demo-hf-16622767,0.8934458484441697
64,XSY/albert-base-v2-imdb-calssification,0.7288532942130512
65,fabriceyhc/bert-base-uncased-imdb,0.8001930197961581
66,ncduy/roberta-imdb-sentiment-analysis,0.904017976594706
67,Anthos23/FS-distilroberta-fine-tuned,0.841431425308074
68,oferweintraub/bert-base-finance-sentiment-noisy-search,0.8234106840949794
69,emrecan/bert-base-multilingual-cased-snli_tr,0.7013964148870423
70,nurkayevaa/autonlp-bert-covid-407910458,0.8315681163361414
71,w11wo/sundanese-bert-base-emotion-classifier,0.5335997875244999
72,aychang/bert-base-cased-trec-coarse,0.8244557862880305
73,JNK789/distilbert-base-uncased-finetuned-tweets-emoji-dataset,-0.031400425261189135
74,aXhyra/presentation_emotion_31415,0.7623878685765658
75,aXhyra/emotion_trained_31415,0.7745717857963623
76,elozano/tweet_offensive_eval,0.5672504721520537
77,aXhyra/presentation_sentiment_1234567,0.8062702411775508
78,nickmuchi/facebook-data2vec-finetuned-finance-classification,0.7450358590264777
79,distilbert-base-uncased,0.867301493845011
80,bert-base-uncased,0.797497207013633
81,albert-base-v2,0.7634050212132626
82,dhimskyy/wiki-bert,0.5028762772230628
83,michiyasunaga/LinkBERT-base,0.8817120342673426
84,bert-base-cased,0.8615981348414683
85,roberta-base,0.8926689758597768
86,bert-large-uncased,0.7076849227455076
87,roberta-large,0.5562802411051213
88,Recognai/bert-base-spanish-wwm-cased-xnli,0.5822161352881069
89,mrm8488/electricidad-base-finetuned-pawsx-es,0.5825907068681537
90,dapang/distilroberta-base-mic-sym,0.8547608669440094
91,cambridgeltl/guardian_news_distilbert-base-uncased,0.7550644419507728
92,Capreolus/bert-base-msmarco,0.8454279179040967
93,Jeevesh8/feather_berts_46,0.8103526977673274
94,phailyoor/distilbert-base-uncased-finetuned-yahd,0.7641844293632839
95,amyma21/sincere_question_classification,0.805095245314714
96,arianpasquali/distilbert-base-multilingual-cased-toxicity,0.6766514856967282
97,JonatanGk/roberta-base-bne-finetuned-cyberbullying-spanish,0.4186153627008181
98,chiragasarpota/scotus-bert,0.4454200465324743
99,connectivity/feather_berts_28,0.7845302735598082
100,Giyaseddin/distilroberta-base-finetuned-short-answer-assessment,0.7957551370090037
101,IMSyPP/hate_speech_it,0.6650650579702392
102,Jeevesh8/feather_berts_96,0.8513471050381795
103,18811449050/bert_finetuning_test,0.6722122952750207
104,viviastaari/finetuning-sentiment-analysis-en-id,0.6057301142180086
105,Jeevesh8/lecun_feather_berts-3,0.8523504093818797
106,Jeevesh8/lecun_feather_berts-51,0.8608500589582581
107,rmihaylov/roberta-base-sentiment-bg,0.6605369281245088
108,finiteautomata/betonews-tweetcontext,0.5682459265963914
109,Jeevesh8/lecun_feather_berts-8,0.7964146011109947
110,Jeevesh8/lecun_feather_berts-7,0.8346075745573955
111,korca/bae-roberta-base-boolq,0.8447826963477595
112,IMSyPP/hate_speech_nl,0.48356649119218864
113,cardiffnlp/bertweet-base-stance-climate,0.8456339405059571
114,waboucay/camembert-base-finetuned-xnli_fr-finetuned-nli-rua_wl,0.44078912433128736
115,aditeyabaral/finetuned-sail2017-xlm-roberta-base,0.8570651001862316
116,M47Labs/spanish_news_classification_headlines_untrained,0.6313740669831727
117,mrm8488/codebert-base-finetuned-detect-insecure-code,0.8148075206282269
118,socialmediaie/TRAC2020_IBEN_B_bert-base-multilingual-uncased,0.7562436673688192
119,JonatanGk/roberta-base-ca-finetuned-hate-speech-offensive-catalan,0.6277863967908276
120,cointegrated/roberta-base-formality,0.8274208146687873
121,YeRyeongLee/electra-base-discriminator-finetuned-filtered-0602,0.21606736024847006
122,joebobby/finetuning-sentiment-model-5000-samples3,0.769954617943039
123,Jeevesh8/feather_berts_92,0.8327264405862702
124,Raychanan/COVID_RandomOver,0.022844405751517805
125,anvay/finetuning-cardiffnlp-sentiment-model,0.8388821685500498
126,bondi/bert-semaphore-prediction-w4,0.6171666351136096
127,zenkri/autotrain-Arabic_Poetry_by_Subject-920730230,0.8414002807405172
128,ASCCCCCCCC/distilbert-base-chinese-amazon_zh_20000,0.5680301576701526
129,Monsia/camembert-fr-covid-tweet-classification,0.7056059246251476
130,anferico/bert-for-patents,0.6497393172279494
131,CAMeL-Lab/bert-base-arabic-camelbert-da-sentiment,0.47777823087145377
132,warwickai/fin-perceiver,0.8538566143265284
133,liangyuant/distilbert-base-uncased-finetuned-num200-450-405cls,0.7945715747836577
134,DoyyingFace/bert-asian-hate-tweets-asian-unclean-freeze-4,0.8612938608964149
135,Aureliano/distilbert-base-uncased-if,0.7895299295425481
136,matthewburke/korean_sentiment,0.581241824790222
137,ali2066/DistilBERTFINAL_ctxSentence_TRAIN_editorials_TEST_NULL_second_train_set_null_False,0.8927950569119611
138,classla/bcms-bertic-parlasent-bcs-ter,0.7031274284218925
139,fgaim/tiroberta-geezswitch,0.4913571189769461
