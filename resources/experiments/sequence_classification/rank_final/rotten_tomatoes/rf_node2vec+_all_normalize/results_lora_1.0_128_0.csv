,model,score
0,Jeevesh8/init_bert_ft_qqp-33,0.7978613793211033
1,Jeevesh8/init_bert_ft_qqp-33,0.7978613793211033
2,Jeevesh8/init_bert_ft_qqp-49,0.7943889739967761
3,Jeevesh8/init_bert_ft_qqp-49,0.7939760709704712
4,connectivity/bert_ft_qqp-7,0.7963738088170453
5,connectivity/bert_ft_qqp-7,0.7959609057907404
6,Jeevesh8/bert_ft_qqp-40,0.7986994739650286
7,Jeevesh8/bert_ft_qqp-40,0.7982865709387238
8,Jeevesh8/bert_ft_qqp-9,0.7956870362771095
9,Jeevesh8/bert_ft_qqp-9,0.7952741332508044
10,Jeevesh8/bert_ft_qqp-88,0.7986239765970169
11,Jeevesh8/bert_ft_qqp-88,0.798211073570712
12,connectivity/bert_ft_qqp-25,0.797130211834401
13,connectivity/bert_ft_qqp-25,0.7929673088080961
14,Jeevesh8/bert_ft_qqp-55,0.800381746453181
15,Jeevesh8/bert_ft_qqp-55,0.8001634373178862
16,connectivity/bert_ft_qqp-1,0.7978223306768669
17,connectivity/bert_ft_qqp-1,0.7974094276505619
18,Jeevesh8/bert_ft_qqp-39,0.7981889569661749
19,Jeevesh8/bert_ft_qqp-39,0.7981889569661749
20,connectivity/bert_ft_qqp-94,0.7989993509625093
21,connectivity/bert_ft_qqp-94,0.7950310418272144
22,connectivity/bert_ft_qqp-96,0.7989299478671046
23,connectivity/bert_ft_qqp-96,0.7989299478671046
24,Jeevesh8/init_bert_ft_qqp-24,0.7980113772788406
25,Jeevesh8/init_bert_ft_qqp-24,0.7975984742525357
26,Jeevesh8/bert_ft_qqp-68,0.7973379848585184
27,Jeevesh8/bert_ft_qqp-68,0.7969250818322133
28,Jeevesh8/init_bert_ft_qqp-28,0.7949352728462711
29,Jeevesh8/init_bert_ft_qqp-28,0.7949352728462711
30,connectivity/bert_ft_qqp-17,0.7966813929147637
31,connectivity/bert_ft_qqp-17,0.7966813929147637
32,ali2066/finetuned_sentence_itr1_2e-05_all_26_02_2022-04_03_26,0.7961468828254061
33,ali2066/finetuned_sentence_itr1_2e-05_all_26_02_2022-04_03_26,0.7961468828254061
34,SetFit/distilbert-base-uncased__sst2__train-16-0,0.7916291624510664
35,SetFit/distilbert-base-uncased__sst2__train-16-0,0.7916291624510664
36,aviator-neural/bert-base-uncased-sst2,0.7908750202918924
37,aviator-neural/bert-base-uncased-sst2,0.7908750202918924
38,SetFit/distilbert-base-uncased__sst2__train-32-9,0.7989884294211784
39,SetFit/distilbert-base-uncased__sst2__train-32-9,0.7989884294211784
40,Alassea/glue_sst_classifier,0.7980837835414687
41,Alassea/glue_sst_classifier,0.7976708805151637
42,philschmid/tiny-distilbert-classification,0.6175249990968393
43,philschmid/tiny-distilbert-classification,0.6175249990968393
44,moshew/bert-mini-sst2-distilled,0.7911712542565748
45,moshew/bert-mini-sst2-distilled,0.7911712542565748
46,ChrisUPM/BioBERT_Re_trained,0.7873476422958625
47,ChrisUPM/BioBERT_Re_trained,0.7873476422958625
48,vaariis/distilbert-base-uncased-finetuned-emotion,0.7926769165409121
49,vaariis/distilbert-base-uncased-finetuned-emotion,0.7926769165409121
50,marcelcastrobr/sagemaker-distilbert-emotion,0.7939440013362591
51,marcelcastrobr/sagemaker-distilbert-emotion,0.7939440013362591
52,jasonyim2/distilbert-base-uncased-finetuned-emotion,0.8001123049273705
53,jasonyim2/distilbert-base-uncased-finetuned-emotion,0.8001123049273705
54,abdelkader/distilbert-base-uncased-finetuned-emotion,0.8001546691582588
55,abdelkader/distilbert-base-uncased-finetuned-emotion,0.8001546691582588
56,moghis/distilbert-base-uncased-finetuned-emotion,0.7992718446649022
57,moghis/distilbert-base-uncased-finetuned-emotion,0.7992718446649022
58,uygarkurt/distilbert-base-uncased-finetuned-emotion,0.7986324653803516
59,uygarkurt/distilbert-base-uncased-finetuned-emotion,0.7986324653803516
60,neibla/distilbert-base-uncased-finetuned-emotion,0.795976370640294
61,neibla/distilbert-base-uncased-finetuned-emotion,0.795976370640294
62,JB173/distilbert-base-uncased-finetuned-emotion,0.7993742979965381
63,JB173/distilbert-base-uncased-finetuned-emotion,0.7993742979965381
64,Nanatan/distilbert-base-uncased-finetuned-emotion,0.7940687392290974
65,Nanatan/distilbert-base-uncased-finetuned-emotion,0.7940687392290974
66,heranm/finetuning-sentiment-model-3000-samples,0.7989091990941403
67,heranm/finetuning-sentiment-model-3000-samples,0.7989091990941403
68,PrasunMishra/finetuning-sentiment-model-3000-samples,0.7972596688282948
69,PrasunMishra/finetuning-sentiment-model-3000-samples,0.7972596688282948
70,yukta10/finetuning-sentiment-model-3000-samples,0.8008476078388466
71,yukta10/finetuning-sentiment-model-3000-samples,0.8008476078388466
72,ncduy/roberta-imdb-sentiment-analysis,0.7995821098661722
73,ncduy/roberta-imdb-sentiment-analysis,0.7991692068398671
74,markt23917/finetuning-sentiment-model-3000-samples,0.7989629199581073
75,markt23917/finetuning-sentiment-model-3000-samples,0.7989629199581073
76,juliensimon/autonlp-imdb-demo-hf-16622767,0.7958312482257576
77,juliensimon/autonlp-imdb-demo-hf-16622767,0.795047451485585
78,fabriceyhc/bert-base-uncased-imdb,0.7910537563313496
79,fabriceyhc/bert-base-uncased-imdb,0.7910537563313496
80,riyadhctg/distilbert-base-uncased-finetuned-cola,0.7981750575963338
81,riyadhctg/distilbert-base-uncased-finetuned-cola,0.7981750575963338
82,connectivity/cola_6ep_ft-33,0.7939118452131062
83,connectivity/cola_6ep_ft-33,0.7939118452131062
84,connectivity/cola_6ep_ft-22,0.7985449226568387
85,connectivity/cola_6ep_ft-22,0.7983266135215438
86,isakbos/Q8BERT_COLA_L_512,0.7736735270820896
87,isakbos/Q8BERT_COLA_L_512,0.7695106240557847
88,jaesun/distilbert-base-uncased-finetuned-cola,0.7972840224736043
89,jaesun/distilbert-base-uncased-finetuned-cola,0.7972840224736043
90,usami/distilbert-base-uncased-finetuned-cola,0.7979565246716764
91,usami/distilbert-base-uncased-finetuned-cola,0.7937936216453716
92,Jeevesh8/512seq_len_6ep_bert_ft_cola-91,0.7970129620436999
93,Jeevesh8/512seq_len_6ep_bert_ft_cola-91,0.7928500590173949
94,Jeevesh8/6ep_bert_ft_cola-47,0.7996745054957737
95,Jeevesh8/6ep_bert_ft_cola-47,0.7996745054957737
96,connectivity/cola_6ep_ft-10,0.7969029860762318
97,connectivity/cola_6ep_ft-10,0.7966846769409369
98,Jeevesh8/6ep_bert_ft_cola-12,0.7986718668074563
99,Jeevesh8/6ep_bert_ft_cola-12,0.7986718668074563
100,Jeevesh8/bert_ft_cola-88,0.7962364649890233
101,Jeevesh8/bert_ft_cola-88,0.7962364649890233
102,Jeevesh8/6ep_bert_ft_cola-29,0.7970700203442281
103,Jeevesh8/6ep_bert_ft_cola-29,0.7970700203442281
104,vesteinn/XLMR-ENIS-finetuned-cola,0.797760186427682
105,vesteinn/XLMR-ENIS-finetuned-cola,0.797760186427682
106,navsad/navid_test_bert,0.7982541143247123
107,navsad/navid_test_bert,0.7982541143247123
108,Jeevesh8/bert_ft_cola-60,0.7956984526307603
109,Jeevesh8/bert_ft_cola-60,0.7956984526307603
110,dapang/distilroberta-base-mic-sym,0.7926622732340155
111,dapang/distilroberta-base-mic-sym,0.7926622732340155
112,Capreolus/bert-base-msmarco,0.7952776548295566
113,Capreolus/bert-base-msmarco,0.7952776548295566
114,Splend1dchan/bert-base-uncased-slue-goldtrascription-e3-lr1e-4,0.7990627938072783
115,Splend1dchan/bert-base-uncased-slue-goldtrascription-e3-lr1e-4,0.7990627938072783
116,Jeevesh8/feather_berts_46,0.7947108668945895
117,Jeevesh8/feather_berts_46,0.7942979638682844
118,JonatanGk/roberta-base-bne-finetuned-cyberbullying-spanish,0.7565493941521221
119,JonatanGk/roberta-base-bne-finetuned-cyberbullying-spanish,0.7565493941521221
120,cambridgeltl/guardian_news_distilbert-base-uncased,0.7956537141593527
121,cambridgeltl/guardian_news_distilbert-base-uncased,0.7956537141593527
122,amyma21/sincere_question_classification,0.7965754001646174
123,amyma21/sincere_question_classification,0.7965754001646174
124,phailyoor/distilbert-base-uncased-finetuned-yahd,0.7954845595452918
125,phailyoor/distilbert-base-uncased-finetuned-yahd,0.7954845595452918
126,arianpasquali/distilbert-base-multilingual-cased-toxicity,0.7937302261588784
127,arianpasquali/distilbert-base-multilingual-cased-toxicity,0.7937302261588784
128,connectivity/feather_berts_28,0.7984315758282492
129,connectivity/feather_berts_28,0.7980186728019442
130,liangyuant/distilbert-base-uncased-finetuned-num200-450-405cls,0.7990727664811295
131,liangyuant/distilbert-base-uncased-finetuned-num200-450-405cls,0.7990727664811295
132,DoyyingFace/bert-asian-hate-tweets-asian-unclean-freeze-4,0.7953446702749228
133,DoyyingFace/bert-asian-hate-tweets-asian-unclean-freeze-4,0.7953446702749228
134,Jeevesh8/lecun_feather_berts-3,0.7980952745160873
135,Jeevesh8/lecun_feather_berts-3,0.7976823714897825
136,Giyaseddin/distilroberta-base-finetuned-short-answer-assessment,0.7969946172696837
137,Giyaseddin/distilroberta-base-finetuned-short-answer-assessment,0.7969946172696837
138,AnonymousSub/dummy_2,0.7921954176430576
139,AnonymousSub/dummy_2,0.7917825146167526
140,Jeevesh8/lecun_feather_berts-51,0.7993656432346106
141,Jeevesh8/lecun_feather_berts-51,0.7993656432346106
142,viviastaari/finetuning-sentiment-analysis-en-id,0.7836790212137469
143,viviastaari/finetuning-sentiment-analysis-en-id,0.7836790212137469
144,Aureliano/distilbert-base-uncased-if,0.7972569129682731
145,Aureliano/distilbert-base-uncased-if,0.7972569129682731
146,rmihaylov/roberta-base-sentiment-bg,0.7875096544098248
147,rmihaylov/roberta-base-sentiment-bg,0.7875096544098248
148,cardiffnlp/twitter-roberta-base-2021-124m,0.7982660251643944
149,cardiffnlp/twitter-roberta-base-2021-124m,0.7982660251643944
150,Jeevesh8/lecun_feather_berts-8,0.7945078877276621
151,Jeevesh8/lecun_feather_berts-8,0.7945078877276621
152,korca/bae-roberta-base-boolq,0.7967145614044049
153,korca/bae-roberta-base-boolq,0.7967145614044049
154,aditeyabaral/finetuned-sail2017-xlm-roberta-base,0.7935154542149179
155,aditeyabaral/finetuned-sail2017-xlm-roberta-base,0.793102551188613
156,joebobby/finetuning-sentiment-model-5000-samples3,0.795791033114033
157,joebobby/finetuning-sentiment-model-5000-samples3,0.795791033114033
158,Jeevesh8/feather_berts_92,0.7987070298530848
159,Jeevesh8/feather_berts_92,0.7987070298530848
160,ASCCCCCCCC/distilbert-base-chinese-amazon_zh_20000,0.7918511156071006
161,ASCCCCCCCC/distilbert-base-chinese-amazon_zh_20000,0.7918511156071006
162,matthewburke/korean_sentiment,0.7842950202307954
163,matthewburke/korean_sentiment,0.7842950202307954
164,IMSyPP/hate_speech_nl,0.7836938697485388
165,IMSyPP/hate_speech_nl,0.7803193921365985
166,cointegrated/roberta-base-formality,0.796460811608633
167,cointegrated/roberta-base-formality,0.7960479085823282
168,IMSyPP/hate_speech_it,0.791388372636625
169,IMSyPP/hate_speech_it,0.7872254696103201
170,18811449050/bert_finetuning_test,0.7917900416285145
171,18811449050/bert_finetuning_test,0.7917900416285145
172,finiteautomata/betonews-tweetcontext,0.7920343591641674
173,finiteautomata/betonews-tweetcontext,0.7916214561378625
174,Jeevesh8/feather_berts_96,0.7926735375341497
175,Jeevesh8/feather_berts_96,0.7926735375341497
176,Jeevesh8/lecun_feather_berts-7,0.7983380481152822
177,Jeevesh8/lecun_feather_berts-7,0.7983380481152822
178,mrm8488/codebert-base-finetuned-detect-insecure-code,0.7936700149826796
179,mrm8488/codebert-base-finetuned-detect-insecure-code,0.7895071119563747
180,socialmediaie/TRAC2020_IBEN_B_bert-base-multilingual-uncased,0.7937389933745908
181,socialmediaie/TRAC2020_IBEN_B_bert-base-multilingual-uncased,0.7895760903482858
182,zenkri/autotrain-Arabic_Poetry_by_Subject-920730230,0.7962580520152518
183,zenkri/autotrain-Arabic_Poetry_by_Subject-920730230,0.7960397428799569
184,M47Labs/spanish_news_classification_headlines_untrained,0.7871239013835317
185,M47Labs/spanish_news_classification_headlines_untrained,0.7867109983572269
186,bondi/bert-semaphore-prediction-w4,0.791758458806641
187,bondi/bert-semaphore-prediction-w4,0.7915401496713461
188,classla/bcms-bertic-parlasent-bcs-ter,0.7913579394460499
189,classla/bcms-bertic-parlasent-bcs-ter,0.7873896303107552
190,anferico/bert-for-patents,0.7940510925918101
191,anferico/bert-for-patents,0.7940510925918101
192,ali2066/DistilBERTFINAL_ctxSentence_TRAIN_editorials_TEST_NULL_second_train_set_null_False,0.7979415921226977
193,ali2066/DistilBERTFINAL_ctxSentence_TRAIN_editorials_TEST_NULL_second_train_set_null_False,0.7979415921226977
194,anvay/finetuning-cardiffnlp-sentiment-model,0.7950271922805661
195,anvay/finetuning-cardiffnlp-sentiment-model,0.7950271922805661
196,JonatanGk/roberta-base-ca-finetuned-hate-speech-offensive-catalan,0.7931813593739732
197,JonatanGk/roberta-base-ca-finetuned-hate-speech-offensive-catalan,0.7927684563476681
198,Raychanan/COVID_RandomOver,0.7014305437163987
199,Raychanan/COVID_RandomOver,0.7010176406900936
200,kyleinincubated/autonlp-cat333-624217911,0.794011903160854
201,kyleinincubated/autonlp-cat333-624217911,0.7935990001345492
202,cardiffnlp/bertweet-base-stance-climate,0.7934724408374302
203,cardiffnlp/bertweet-base-stance-climate,0.7934724408374302
204,nurkayevaa/autonlp-bert-covid-407910458,0.7990471085306237
205,nurkayevaa/autonlp-bert-covid-407910458,0.7990471085306237
206,SetFit/distilbert-base-uncased__hate_speech_offensive__train-16-1,0.7982778619371955
207,SetFit/distilbert-base-uncased__hate_speech_offensive__train-16-1,0.7982778619371955
208,crcb/isear_bert,0.798858868433898
209,crcb/isear_bert,0.798858868433898
210,robertou2/roberta-base-bne-finetuned-amazon_reviews_multi,0.7872775267013157
211,robertou2/roberta-base-bne-finetuned-amazon_reviews_multi,0.7872775267013157
212,milyiyo/selectra-small-finetuned-amazon-review,0.7542281427454696
213,milyiyo/selectra-small-finetuned-amazon-review,0.7542281427454696
214,Anthos23/FS-distilroberta-fine-tuned,0.7972040077408462
215,Anthos23/FS-distilroberta-fine-tuned,0.7972040077408462
216,oferweintraub/bert-base-finance-sentiment-noisy-search,0.7970651724076593
217,oferweintraub/bert-base-finance-sentiment-noisy-search,0.7970651724076593
218,pietrotrope/emotion_final,0.7955333487029635
219,pietrotrope/emotion_final,0.7955333487029635
220,aXhyra/emotion_trained_31415,0.7953305324743118
221,aXhyra/emotion_trained_31415,0.7953305324743118
222,aXhyra/presentation_emotion_31415,0.7896289536198696
223,aXhyra/presentation_emotion_31415,0.7896289536198696
224,Recognai/bert-base-spanish-wwm-cased-xnli,0.7914437683898876
225,Recognai/bert-base-spanish-wwm-cased-xnli,0.7910308653635826
226,anirudh21/bert-base-uncased-finetuned-qnli,0.7956354351461041
227,anirudh21/bert-base-uncased-finetuned-qnli,0.7956354351461041
228,aXhyra/demo_sentiment_31415,0.7943550771112363
229,aXhyra/demo_sentiment_31415,0.7943550771112363
230,aXhyra/presentation_sentiment_1234567,0.7949062750484938
231,aXhyra/presentation_sentiment_1234567,0.7949062750484938
232,jb2k/bert-base-multilingual-cased-language-detection,0.7906999034810748
233,jb2k/bert-base-multilingual-cased-language-detection,0.7904815943457799
234,vinai/bertweet-base,0.7994763740931061
235,vinai/bertweet-base,0.7990634710668013
236,justinqbui/bertweet-covid19-base-uncased-pretraining-covid-vaccine-tweets,0.7920604828801919
237,justinqbui/bertweet-covid19-base-uncased-pretraining-covid-vaccine-tweets,0.7918421737448971
238,vinai/bertweet-covid19-base-cased,0.7964125870794028
239,vinai/bertweet-covid19-base-cased,0.7964125870794028
240,vinai/bertweet-covid19-base-uncased,0.7945792891391786
241,vinai/bertweet-covid19-base-uncased,0.7904163861128738
242,distilbert-base-uncased,0.7932324371135369
243,distilbert-base-uncased,0.7932324371135369
244,bert-base-uncased,0.7992804118346752
245,bert-base-uncased,0.7992804118346752
246,roberta-base,0.8018941209602791
247,roberta-base,0.7979258118249842
248,bert-base-cased,0.7970113465779604
249,bert-base-cased,0.7965984435516554
250,dhimskyy/wiki-bert,0.7868830079480033
251,dhimskyy/wiki-bert,0.7866646988127084
252,michiyasunaga/LinkBERT-base,0.7986737647222156
253,michiyasunaga/LinkBERT-base,0.7986737647222156
254,bert-large-uncased,0.7953253394396907
255,bert-large-uncased,0.7953253394396907
256,roberta-large,0.7900731984690146
257,roberta-large,0.7900731984690146
258,boychaboy/MNLI_roberta-base,0.8015497880443783
259,boychaboy/MNLI_roberta-base,0.8011368850180735
260,ishan/bert-base-uncased-mnli,0.7993864952385958
261,ishan/bert-base-uncased-mnli,0.799168186103301
262,emrecan/bert-base-multilingual-cased-snli_tr,0.7946400326944091
263,emrecan/bert-base-multilingual-cased-snli_tr,0.794227129668104
264,elozano/tweet_offensive_eval,0.7858678719615538
265,elozano/tweet_offensive_eval,0.7858678719615538
266,Hate-speech-CNERG/bert-base-uncased-hatexplain-rationale-two,0.8004634248407221
267,Hate-speech-CNERG/bert-base-uncased-hatexplain-rationale-two,0.8004634248407221
268,aychang/bert-base-cased-trec-coarse,0.7945581395015409
269,aychang/bert-base-cased-trec-coarse,0.7945581395015409
270,gchhablani/bert-base-cased-finetuned-wnli,0.7968898763518979
271,gchhablani/bert-base-cased-finetuned-wnli,0.7968898763518979
272,w11wo/sundanese-bert-base-emotion-classifier,0.7749430043935142
273,w11wo/sundanese-bert-base-emotion-classifier,0.7745301013672093
274,gchhablani/bert-base-cased-finetuned-rte,0.7988843967975299
275,gchhablani/bert-base-cased-finetuned-rte,0.7984714937712251
276,mrm8488/electricidad-base-finetuned-pawsx-es,0.7917350102609518
277,mrm8488/electricidad-base-finetuned-pawsx-es,0.7917350102609518
278,manueltonneau/bert-twitter-en-is-hired,0.7986618497903186
279,manueltonneau/bert-twitter-en-is-hired,0.7986618497903186
280,Guscode/DKbert-hatespeech-detection,0.7841250438094437
281,Guscode/DKbert-hatespeech-detection,0.7841250438094437
