,model,score
0,milyiyo/selectra-small-finetuned-amazon-review,0.4469044805797463
1,robertou2/roberta-base-bne-finetuned-amazon_reviews_multi,0.6105832240501645
2,SetFit/distilbert-base-uncased__hate_speech_offensive__train-16-1,0.7762795323900605
3,vinai/bertweet-covid19-base-cased,0.6587668744119557
4,vinai/bertweet-covid19-base-uncased,0.8422149067650184
5,justinqbui/bertweet-covid19-base-uncased-pretraining-covid-vaccine-tweets,0.8101860597876184
6,jb2k/bert-base-multilingual-cased-language-detection,0.5954352542996958
7,jasonyim2/distilbert-base-uncased-finetuned-emotion,0.8016919236691001
8,marcelcastrobr/sagemaker-distilbert-emotion,0.7974554317807592
9,vaariis/distilbert-base-uncased-finetuned-emotion,0.807926235035886
10,Nanatan/distilbert-base-uncased-finetuned-emotion,0.7857701530781415
11,riyadhctg/distilbert-base-uncased-finetuned-cola,0.7228082383276184
12,connectivity/cola_6ep_ft-33,0.7850576370023509
13,connectivity/cola_6ep_ft-22,0.7950917604152049
14,vesteinn/XLMR-ENIS-finetuned-cola,0.7622089091243917
15,Jeevesh8/512seq_len_6ep_bert_ft_cola-91,0.7509439414173434
16,jaesun/distilbert-base-uncased-finetuned-cola,0.6952398587650382
17,Jeevesh8/6ep_bert_ft_cola-29,0.7610134153358414
18,Jeevesh8/bert_ft_cola-60,0.756472220696445
19,navsad/navid_test_bert,0.7404660077497316
20,isakbos/Q8BERT_COLA_L_512,0.496493873376726
21,ishan/bert-base-uncased-mnli,0.7945728693540458
22,boychaboy/MNLI_roberta-base,0.8562092764441369
23,Alireza1044/albert-base-v2-qnli,0.746394575622089
24,Jeevesh8/init_bert_ft_qqp-33,0.7533641650020932
25,Jeevesh8/init_bert_ft_qqp-49,0.7726013324939943
26,Jeevesh8/bert_ft_qqp-88,0.8047381882776328
27,Jeevesh8/bert_ft_qqp-9,0.775814470032324
28,connectivity/bert_ft_qqp-17,0.7850977554181087
29,Jeevesh8/bert_ft_qqp-55,0.7973148782242272
30,Jeevesh8/bert_ft_qqp-40,0.7977812578434296
31,connectivity/bert_ft_qqp-96,0.7819285428755953
32,connectivity/bert_ft_qqp-25,0.7904848920226498
33,Jeevesh8/bert_ft_qqp-68,0.7699156865815571
34,Jeevesh8/init_bert_ft_qqp-24,0.7807234770251712
35,philschmid/tiny-distilbert-classification,-0.04527845902035843
36,ali2066/finetuned_sentence_itr1_2e-05_all_26_02_2022-04_03_26,0.7478242890410195
37,SetFit/distilbert-base-uncased__sst2__train-16-0,0.8069000098966201
38,gchhablani/fnet-base-finetuned-sst2,0.6560006724479392
39,SetFit/distilbert-base-uncased__sst2__train-32-9,0.8070681399514108
40,Alassea/glue_sst_classifier,0.8112809582737148
41,ChrisUPM/BioBERT_Re_trained,0.6930034598120673
42,moshew/bert-mini-sst2-distilled,0.6690749914118853
43,Hate-speech-CNERG/bert-base-uncased-hatexplain-rationale-two,0.8042305246324972
44,PrasunMishra/finetuning-sentiment-model-3000-samples,0.838358979590519
45,heranm/finetuning-sentiment-model-3000-samples,0.8406135206531629
46,yukta10/finetuning-sentiment-model-3000-samples,0.8094836481513231
47,markt23917/finetuning-sentiment-model-3000-samples,0.8291519370648952
48,juliensimon/autonlp-imdb-demo-hf-16622767,0.8067931967622547
49,XSY/albert-base-v2-imdb-calssification,0.7190874294990951
50,fabriceyhc/bert-base-uncased-imdb,0.7884976769194675
51,ncduy/roberta-imdb-sentiment-analysis,0.9034668736183109
52,emrecan/bert-base-multilingual-cased-snli_tr,0.7002571820621748
53,nurkayevaa/autonlp-bert-covid-407910458,0.7854077693956796
54,w11wo/sundanese-bert-base-emotion-classifier,0.48334207972612664
55,JNK789/distilbert-base-uncased-finetuned-tweets-emoji-dataset,-0.08321426114927188
56,pietrotrope/emotion_final,0.7573923140056494
57,aXhyra/presentation_emotion_31415,0.7554165986845607
58,aXhyra/emotion_trained_31415,0.7557950153209739
59,elozano/tweet_offensive_eval,0.43235013758397767
60,aXhyra/demo_sentiment_31415,0.7645865989537668
61,nickmuchi/facebook-data2vec-finetuned-finance-classification,0.726361913566701
62,bert-base-uncased,0.8168499197803449
63,albert-base-v2,0.7008679726803684
64,dhimskyy/wiki-bert,0.5052825327173593
65,michiyasunaga/LinkBERT-base,0.7858106428460179
66,bert-base-cased,0.7921971758990172
67,roberta-base,0.8835009768678057
68,bert-large-uncased,0.7390591924453788
69,roberta-large,0.4403721965027184
70,dapang/distilroberta-base-mic-sym,0.8011923279733763
71,cambridgeltl/guardian_news_distilbert-base-uncased,0.7385564897486023
72,Capreolus/bert-base-msmarco,0.8079122962652359
73,Splend1dchan/bert-base-uncased-slue-goldtrascription-e3-lr1e-4,0.7910153860311464
74,Jeevesh8/feather_berts_46,0.8061216355434323
75,amyma21/sincere_question_classification,0.7698527046289159
76,arianpasquali/distilbert-base-multilingual-cased-toxicity,0.6197753308463063
77,chiragasarpota/scotus-bert,0.3951567643338135
78,Giyaseddin/distilroberta-base-finetuned-short-answer-assessment,0.7703584874015396
79,IMSyPP/hate_speech_it,0.6124980921663283
80,Jeevesh8/feather_berts_96,0.8074546001565359
81,18811449050/bert_finetuning_test,0.6896422350287547
82,viviastaari/finetuning-sentiment-analysis-en-id,0.5716649820916203
83,AnonymousSub/dummy_2,0.6529532545393901
84,Jeevesh8/lecun_feather_berts-3,0.7838133923333853
85,rmihaylov/roberta-base-sentiment-bg,0.6101006220732612
86,finiteautomata/betonews-tweetcontext,0.5431442545623028
87,Jeevesh8/lecun_feather_berts-8,0.8050681461804873
88,Jeevesh8/lecun_feather_berts-7,0.7996862735474415
89,IMSyPP/hate_speech_nl,0.38287707309363916
90,cardiffnlp/bertweet-base-stance-climate,0.7543748386117282
91,waboucay/camembert-base-finetuned-xnli_fr-finetuned-nli-rua_wl,0.43336074678569875
92,aditeyabaral/finetuned-sail2017-xlm-roberta-base,0.7919098185770534
93,M47Labs/spanish_news_classification_headlines_untrained,0.5891581194805264
94,JonatanGk/roberta-base-ca-finetuned-hate-speech-offensive-catalan,0.5847089852909955
95,cointegrated/roberta-base-formality,0.8360986838201234
96,joebobby/finetuning-sentiment-model-5000-samples3,0.7905958988406956
97,Raychanan/COVID_RandomOver,-0.0530777691408334
98,anvay/finetuning-cardiffnlp-sentiment-model,0.8539715115874725
99,bondi/bert-semaphore-prediction-w4,0.5111168741852756
100,zenkri/autotrain-Arabic_Poetry_by_Subject-920730230,0.7861554517532517
101,ASCCCCCCCC/distilbert-base-chinese-amazon_zh_20000,0.5414003044626088
102,warwickai/fin-perceiver,0.7290149787712489
103,liangyuant/distilbert-base-uncased-finetuned-num200-450-405cls,0.7673456211953379
104,Aureliano/distilbert-base-uncased-if,0.7689147976533359
105,matthewburke/korean_sentiment,0.5051126229740932
106,ali2066/DistilBERTFINAL_ctxSentence_TRAIN_editorials_TEST_NULL_second_train_set_null_False,0.8589384096630399
107,classla/bcms-bertic-parlasent-bcs-ter,0.6423810584634384
108,fgaim/tiroberta-geezswitch,0.47233276574955163
