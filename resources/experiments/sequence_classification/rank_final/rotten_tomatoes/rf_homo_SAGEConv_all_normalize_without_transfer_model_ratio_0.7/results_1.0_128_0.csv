,model,score
0,milyiyo/selectra-small-finetuned-amazon-review,0.7838660369654691
1,robertou2/roberta-base-bne-finetuned-amazon_reviews_multi,0.9032258319424912
2,SetFit/distilbert-base-uncased__hate_speech_offensive__train-16-1,0.982563319368553
3,vinai/bertweet-covid19-base-cased,0.9769253647729091
4,vinai/bertweet-covid19-base-uncased,0.9822048689085824
5,justinqbui/bertweet-covid19-base-uncased-pretraining-covid-vaccine-tweets,0.9831412749533338
6,jb2k/bert-base-multilingual-cased-language-detection,0.8810276289836504
7,jasonyim2/distilbert-base-uncased-finetuned-emotion,0.9830771377710914
8,marcelcastrobr/sagemaker-distilbert-emotion,0.9771637962644685
9,vaariis/distilbert-base-uncased-finetuned-emotion,0.9760170305379051
10,Nanatan/distilbert-base-uncased-finetuned-emotion,0.9830771377710914
11,riyadhctg/distilbert-base-uncased-finetuned-cola,0.974907071084932
12,connectivity/cola_6ep_ft-33,0.9773445499876344
13,connectivity/cola_6ep_ft-22,0.9825467796916866
14,vesteinn/XLMR-ENIS-finetuned-cola,0.9823453552029789
15,Jeevesh8/512seq_len_6ep_bert_ft_cola-91,0.9824477925524444
16,jaesun/distilbert-base-uncased-finetuned-cola,0.8005952210366593
17,Jeevesh8/6ep_bert_ft_cola-29,0.9816688371879861
18,Jeevesh8/bert_ft_cola-60,0.982553363144413
19,navsad/navid_test_bert,0.9748096764417443
20,isakbos/Q8BERT_COLA_L_512,0.8187950172551065
21,ishan/bert-base-uncased-mnli,0.982585233025995
22,boychaboy/MNLI_roberta-base,0.9831844535039842
23,Alireza1044/albert-base-v2-qnli,0.9826141688476595
24,Jeevesh8/init_bert_ft_qqp-33,0.9824477925524444
25,Jeevesh8/init_bert_ft_qqp-49,0.9825467796916866
26,Jeevesh8/bert_ft_qqp-88,0.9816688371879861
27,Jeevesh8/bert_ft_qqp-9,0.9825467796916866
28,connectivity/bert_ft_qqp-17,0.9826141688476595
29,Jeevesh8/bert_ft_qqp-55,0.9826198947244309
30,Jeevesh8/bert_ft_qqp-40,0.9825467796916866
31,connectivity/bert_ft_qqp-96,0.9824477925524444
32,connectivity/bert_ft_qqp-25,0.9772028419954766
33,Jeevesh8/bert_ft_qqp-68,0.9816688371879861
34,Jeevesh8/init_bert_ft_qqp-24,0.982585233025995
35,philschmid/tiny-distilbert-classification,0.6469180361681053
36,ali2066/finetuned_sentence_itr1_2e-05_all_26_02_2022-04_03_26,0.982209156173161
37,SetFit/distilbert-base-uncased__sst2__train-16-0,0.9823767887249677
38,gchhablani/fnet-base-finetuned-sst2,0.9830537847417237
39,SetFit/distilbert-base-uncased__sst2__train-32-9,0.9832169623559415
40,Alassea/glue_sst_classifier,0.9821007295573025
41,ChrisUPM/BioBERT_Re_trained,0.9829629735512624
42,moshew/bert-mini-sst2-distilled,0.9481818591234185
43,Hate-speech-CNERG/bert-base-uncased-hatexplain-rationale-two,0.9814451774191306
44,PrasunMishra/finetuning-sentiment-model-3000-samples,0.9771404432351009
45,heranm/finetuning-sentiment-model-3000-samples,0.9832169623559415
46,yukta10/finetuning-sentiment-model-3000-samples,0.9830922380760322
47,markt23917/finetuning-sentiment-model-3000-samples,0.9830537847417237
48,juliensimon/autonlp-imdb-demo-hf-16622767,0.9830936821295877
49,XSY/albert-base-v2-imdb-calssification,0.8018751615317583
50,fabriceyhc/bert-base-uncased-imdb,0.982956390098536
51,ncduy/roberta-imdb-sentiment-analysis,0.9836508125571691
52,emrecan/bert-base-multilingual-cased-snli_tr,0.9826423503959176
53,nurkayevaa/autonlp-bert-covid-407910458,0.9792422019962703
54,w11wo/sundanese-bert-base-emotion-classifier,0.8987629523363679
55,JNK789/distilbert-base-uncased-finetuned-tweets-emoji-dataset,0.0
56,pietrotrope/emotion_final,0.9830936821295877
57,aXhyra/presentation_emotion_31415,0.9830936821295877
58,aXhyra/emotion_trained_31415,0.9830936821295877
59,elozano/tweet_offensive_eval,0.7848942374408613
60,aXhyra/demo_sentiment_31415,0.9830726079620831
61,nickmuchi/facebook-data2vec-finetuned-finance-classification,0.9810663077654566
62,bert-base-uncased,0.9820784475948355
63,albert-base-v2,0.9758962828653498
64,dhimskyy/wiki-bert,0.8225792194794752
65,michiyasunaga/LinkBERT-base,0.9829418993837578
66,bert-base-cased,0.982956390098536
67,roberta-base,0.9836508125571691
68,bert-large-uncased,0.9558904205380871
69,roberta-large,0.8518961014405203
70,dapang/distilroberta-base-mic-sym,0.9772394044755275
71,cambridgeltl/guardian_news_distilbert-base-uncased,0.9822325092025287
72,Capreolus/bert-base-msmarco,0.9830181964622122
73,Splend1dchan/bert-base-uncased-slue-goldtrascription-e3-lr1e-4,0.9822895285919574
74,Jeevesh8/feather_berts_46,0.9821240825866703
75,amyma21/sincere_question_classification,0.9831445269270644
76,arianpasquali/distilbert-base-multilingual-cased-toxicity,0.9122510586558903
77,chiragasarpota/scotus-bert,0.7969588757553455
78,Giyaseddin/distilroberta-base-finetuned-short-answer-assessment,0.9833490754390026
79,IMSyPP/hate_speech_it,0.9774563921391592
80,Jeevesh8/feather_berts_96,0.9829797431279037
81,18811449050/bert_finetuning_test,0.9803182283951662
82,viviastaari/finetuning-sentiment-analysis-en-id,0.7887193606448952
83,AnonymousSub/dummy_2,0.9344497175028829
84,Jeevesh8/lecun_feather_berts-3,0.9829652524131255
85,rmihaylov/roberta-base-sentiment-bg,0.9236208438429838
86,finiteautomata/betonews-tweetcontext,0.8269721557499133
87,Jeevesh8/lecun_feather_berts-8,0.9777775134238514
88,Jeevesh8/lecun_feather_berts-7,0.9830181964622122
89,IMSyPP/hate_speech_nl,0.8269721557499133
90,cardiffnlp/bertweet-base-stance-climate,0.9836174169402012
91,waboucay/camembert-base-finetuned-xnli_fr-finetuned-nli-rua_wl,0.9637249810268642
92,aditeyabaral/finetuned-sail2017-xlm-roberta-base,0.9772075424073807
93,M47Labs/spanish_news_classification_headlines_untrained,0.9446163517624352
94,JonatanGk/roberta-base-ca-finetuned-hate-speech-offensive-catalan,0.9266188006698854
95,cointegrated/roberta-base-formality,0.9836116910634298
96,joebobby/finetuning-sentiment-model-5000-samples3,0.9821018006242032
97,Raychanan/COVID_RandomOver,0.0
98,anvay/finetuning-cardiffnlp-sentiment-model,0.9836174169402012
99,bondi/bert-semaphore-prediction-w4,0.8269721557499133
100,zenkri/autotrain-Arabic_Poetry_by_Subject-920730230,0.9832051775112148
101,ASCCCCCCCC/distilbert-base-chinese-amazon_zh_20000,0.9087595672667308
102,warwickai/fin-perceiver,0.9831144312344218
103,liangyuant/distilbert-base-uncased-finetuned-num200-450-405cls,0.9831835667389736
104,Aureliano/distilbert-base-uncased-if,0.9778749080670391
105,matthewburke/korean_sentiment,0.9293074012479678
106,ali2066/DistilBERTFINAL_ctxSentence_TRAIN_editorials_TEST_NULL_second_train_set_null_False,0.9774351929277966
107,classla/bcms-bertic-parlasent-bcs-ter,0.9071776638702648
108,fgaim/tiroberta-geezswitch,0.9779704809523948
