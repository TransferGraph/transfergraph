,model,score
0,Guscode/DKbert-hatespeech-detection,0.7581080684239236
1,milyiyo/selectra-small-finetuned-amazon-review,0.7374700588608948
2,robertou2/roberta-base-bne-finetuned-amazon_reviews_multi,0.7739865556192226
3,vinai/bertweet-covid19-base-cased,0.8097681051904437
4,vinai/bertweet-base,0.8062395840705111
5,vinai/bertweet-covid19-base-uncased,0.816236180371994
6,justinqbui/bertweet-covid19-base-uncased-pretraining-covid-vaccine-tweets,0.8149805564475588
7,jb2k/bert-base-multilingual-cased-language-detection,0.7460117575824348
8,crcb/isear_bert,0.8310706625106681
9,marcelcastrobr/sagemaker-distilbert-emotion,0.8122693561481448
10,abdelkader/distilbert-base-uncased-finetuned-emotion,0.8064315930024861
11,moghis/distilbert-base-uncased-finetuned-emotion,0.8000850268175913
12,neibla/distilbert-base-uncased-finetuned-emotion,0.8030189893970012
13,uygarkurt/distilbert-base-uncased-finetuned-emotion,0.8070705969918592
14,JB173/distilbert-base-uncased-finetuned-emotion,0.8085416220133869
15,vaariis/distilbert-base-uncased-finetuned-emotion,0.8178693010429615
16,Nanatan/distilbert-base-uncased-finetuned-emotion,0.8074928590253236
17,riyadhctg/distilbert-base-uncased-finetuned-cola,0.8050333824490147
18,connectivity/cola_6ep_ft-33,0.8129802578500128
19,vesteinn/XLMR-ENIS-finetuned-cola,0.8076145608096656
20,Jeevesh8/6ep_bert_ft_cola-47,0.8094067730495392
21,Jeevesh8/512seq_len_6ep_bert_ft_cola-91,0.8125781111549437
22,jaesun/distilbert-base-uncased-finetuned-cola,0.7862927330381656
23,Jeevesh8/6ep_bert_ft_cola-12,0.8249541545087513
24,connectivity/cola_6ep_ft-10,0.8081620089836352
25,Jeevesh8/bert_ft_cola-60,0.7930471111128499
26,navsad/navid_test_bert,0.8134624435485576
27,Jeevesh8/bert_ft_cola-88,0.8127818912972118
28,usami/distilbert-base-uncased-finetuned-cola,0.8133492806664435
29,isakbos/Q8BERT_COLA_L_512,0.7726703799336717
30,ishan/bert-base-uncased-mnli,0.8163006696348925
31,boychaboy/MNLI_roberta-base,0.8322536343194048
32,anirudh21/bert-base-uncased-finetuned-qnli,0.8225428498843406
33,Alireza1044/albert-base-v2-qnli,0.8119196719669769
34,Jeevesh8/init_bert_ft_qqp-49,0.8133317340383005
35,connectivity/bert_ft_qqp-7,0.8145940835858022
36,Jeevesh8/bert_ft_qqp-88,0.8167596437640096
37,Jeevesh8/bert_ft_qqp-9,0.8227589685241192
38,connectivity/bert_ft_qqp-17,0.8209392925207686
39,Jeevesh8/init_bert_ft_qqp-28,0.81120771895026
40,Jeevesh8/bert_ft_qqp-55,0.8241440382506169
41,Jeevesh8/bert_ft_qqp-40,0.8215749240522241
42,Jeevesh8/bert_ft_qqp-39,0.8268712864593887
43,connectivity/bert_ft_qqp-1,0.822194824112574
44,connectivity/bert_ft_qqp-96,0.8058485714582511
45,connectivity/bert_ft_qqp-25,0.8138978822791816
46,Jeevesh8/bert_ft_qqp-68,0.812344903605313
47,Jeevesh8/init_bert_ft_qqp-24,0.8252338608763872
48,gchhablani/bert-base-cased-finetuned-rte,0.7994339713084202
49,philschmid/tiny-distilbert-classification,0.29458267059668686
50,ali2066/finetuned_sentence_itr1_2e-05_all_26_02_2022-04_03_26,0.7938875844807511
51,SetFit/distilbert-base-uncased__sst2__train-16-0,0.8099769643339146
52,gchhablani/fnet-base-finetuned-sst2,0.7895612397476208
53,SetFit/distilbert-base-uncased__sst2__train-32-9,0.8198140282506625
54,Alassea/glue_sst_classifier,0.8116815151443544
55,ChrisUPM/BioBERT_Re_trained,0.7931222896258167
56,moshew/bert-mini-sst2-distilled,0.8021176805405947
57,gchhablani/bert-base-cased-finetuned-wnli,0.8066468659145656
58,Hate-speech-CNERG/bert-base-uncased-hatexplain-rationale-two,0.8144533261181135
59,PrasunMishra/finetuning-sentiment-model-3000-samples,0.8069670044164974
60,heranm/finetuning-sentiment-model-3000-samples,0.803981791904403
61,yukta10/finetuning-sentiment-model-3000-samples,0.8245221953753398
62,markt23917/finetuning-sentiment-model-3000-samples,0.818065902710601
63,juliensimon/autonlp-imdb-demo-hf-16622767,0.7996390237036889
64,XSY/albert-base-v2-imdb-calssification,0.7941685592076162
65,fabriceyhc/bert-base-uncased-imdb,0.8175638238560528
66,ncduy/roberta-imdb-sentiment-analysis,0.829945013623647
67,Anthos23/FS-distilroberta-fine-tuned,0.8247831417936947
68,oferweintraub/bert-base-finance-sentiment-noisy-search,0.8179262656097415
69,emrecan/bert-base-multilingual-cased-snli_tr,0.7935062075324981
70,nurkayevaa/autonlp-bert-covid-407910458,0.8069554053519694
71,w11wo/sundanese-bert-base-emotion-classifier,0.7421650912424248
72,aychang/bert-base-cased-trec-coarse,0.8014968908645281
73,JNK789/distilbert-base-uncased-finetuned-tweets-emoji-dataset,0.34817242050966685
74,aXhyra/presentation_emotion_31415,0.8037917144200288
75,aXhyra/emotion_trained_31415,0.8090314896798195
76,elozano/tweet_offensive_eval,0.7476398534064973
77,aXhyra/presentation_sentiment_1234567,0.8148417127723901
78,nickmuchi/facebook-data2vec-finetuned-finance-classification,0.8067824265879381
79,distilbert-base-uncased,0.8082090962432197
80,bert-base-uncased,0.8147414492407837
81,albert-base-v2,0.8030355548214643
82,dhimskyy/wiki-bert,0.7411893640281627
83,michiyasunaga/LinkBERT-base,0.8149693114628139
84,bert-base-cased,0.8008755903950854
85,roberta-base,0.8335986993863539
86,bert-large-uncased,0.8152630150142828
87,roberta-large,0.7140793939664484
88,Recognai/bert-base-spanish-wwm-cased-xnli,0.7546611348332007
89,mrm8488/electricidad-base-finetuned-pawsx-es,0.7936208039999454
90,dapang/distilroberta-base-mic-sym,0.8263804766034094
91,cambridgeltl/guardian_news_distilbert-base-uncased,0.8134263470836534
92,Capreolus/bert-base-msmarco,0.8172567932154503
93,Jeevesh8/feather_berts_46,0.8111171967797653
94,phailyoor/distilbert-base-uncased-finetuned-yahd,0.8119574612583464
95,amyma21/sincere_question_classification,0.8173873516723988
96,arianpasquali/distilbert-base-multilingual-cased-toxicity,0.7839589773026624
97,JonatanGk/roberta-base-bne-finetuned-cyberbullying-spanish,0.6636173767872299
98,chiragasarpota/scotus-bert,0.7001675158211481
99,connectivity/feather_berts_28,0.8213601580474171
100,Giyaseddin/distilroberta-base-finetuned-short-answer-assessment,0.814164261936972
101,IMSyPP/hate_speech_it,0.7587661047134974
102,Jeevesh8/feather_berts_96,0.8144368929242547
103,18811449050/bert_finetuning_test,0.7988683936603597
104,viviastaari/finetuning-sentiment-analysis-en-id,0.7653393138049865
105,Jeevesh8/lecun_feather_berts-3,0.8142176198445551
106,Jeevesh8/lecun_feather_berts-51,0.8225191079891532
107,rmihaylov/roberta-base-sentiment-bg,0.7914215554373886
108,finiteautomata/betonews-tweetcontext,0.7717823991312908
109,Jeevesh8/lecun_feather_berts-8,0.8193395776249726
110,Jeevesh8/lecun_feather_berts-7,0.8181055607277399
111,korca/bae-roberta-base-boolq,0.830599696464923
112,IMSyPP/hate_speech_nl,0.7220570114013927
113,cardiffnlp/bertweet-base-stance-climate,0.8117493997754578
114,waboucay/camembert-base-finetuned-xnli_fr-finetuned-nli-rua_wl,0.7315368927562206
115,aditeyabaral/finetuned-sail2017-xlm-roberta-base,0.8268099916233494
116,M47Labs/spanish_news_classification_headlines_untrained,0.7573325094091794
117,mrm8488/codebert-base-finetuned-detect-insecure-code,0.8102317996986627
118,socialmediaie/TRAC2020_IBEN_B_bert-base-multilingual-uncased,0.7854517101292129
119,JonatanGk/roberta-base-ca-finetuned-hate-speech-offensive-catalan,0.7668742508955013
120,cointegrated/roberta-base-formality,0.8149677789453726
121,YeRyeongLee/electra-base-discriminator-finetuned-filtered-0602,0.4661564266200671
122,joebobby/finetuning-sentiment-model-5000-samples3,0.8109926704382133
123,Jeevesh8/feather_berts_92,0.8197127761382765
124,Raychanan/COVID_RandomOver,0.396053005369998
125,anvay/finetuning-cardiffnlp-sentiment-model,0.8340056385858295
126,bondi/bert-semaphore-prediction-w4,0.7800275768257007
127,zenkri/autotrain-Arabic_Poetry_by_Subject-920730230,0.8192942302905339
128,ASCCCCCCCC/distilbert-base-chinese-amazon_zh_20000,0.7912262385751844
129,Monsia/camembert-fr-covid-tweet-classification,0.7935401990895286
130,anferico/bert-for-patents,0.7965485791213369
131,CAMeL-Lab/bert-base-arabic-camelbert-da-sentiment,0.737212798798584
132,warwickai/fin-perceiver,0.8168068801131628
133,liangyuant/distilbert-base-uncased-finetuned-num200-450-405cls,0.8090580413373379
134,DoyyingFace/bert-asian-hate-tweets-asian-unclean-freeze-4,0.808239454102956
135,Aureliano/distilbert-base-uncased-if,0.8108933217819628
136,matthewburke/korean_sentiment,0.7337276635619386
137,ali2066/DistilBERTFINAL_ctxSentence_TRAIN_editorials_TEST_NULL_second_train_set_null_False,0.8306261714065163
138,classla/bcms-bertic-parlasent-bcs-ter,0.7655718218549061
139,fgaim/tiroberta-geezswitch,0.7789840420903313
