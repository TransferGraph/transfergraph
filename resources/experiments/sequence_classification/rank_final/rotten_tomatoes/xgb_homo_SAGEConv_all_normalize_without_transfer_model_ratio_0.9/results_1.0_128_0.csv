,model,score
0,Guscode/DKbert-hatespeech-detection,0.017309412
1,milyiyo/selectra-small-finetuned-amazon-review,0.3659234
2,robertou2/roberta-base-bne-finetuned-amazon_reviews_multi,0.2979997
3,vinai/bertweet-covid19-base-cased,0.6401787
4,vinai/bertweet-base,0.5354312
5,vinai/bertweet-covid19-base-uncased,0.8359822
6,justinqbui/bertweet-covid19-base-uncased-pretraining-covid-vaccine-tweets,0.7929526
7,jb2k/bert-base-multilingual-cased-language-detection,0.38467228
8,crcb/isear_bert,0.78386295
9,marcelcastrobr/sagemaker-distilbert-emotion,0.7838683
10,abdelkader/distilbert-base-uncased-finetuned-emotion,0.77626634
11,moghis/distilbert-base-uncased-finetuned-emotion,0.8010595
12,neibla/distilbert-base-uncased-finetuned-emotion,0.7838838
13,uygarkurt/distilbert-base-uncased-finetuned-emotion,0.8069528
14,JB173/distilbert-base-uncased-finetuned-emotion,0.7522558
15,vaariis/distilbert-base-uncased-finetuned-emotion,0.7934345
16,Nanatan/distilbert-base-uncased-finetuned-emotion,0.779374
17,riyadhctg/distilbert-base-uncased-finetuned-cola,0.6870863
18,connectivity/cola_6ep_ft-33,0.74018097
19,vesteinn/XLMR-ENIS-finetuned-cola,0.48162583
20,Jeevesh8/6ep_bert_ft_cola-47,0.78291106
21,Jeevesh8/512seq_len_6ep_bert_ft_cola-91,0.5432474
22,jaesun/distilbert-base-uncased-finetuned-cola,0.6110459
23,Jeevesh8/6ep_bert_ft_cola-12,0.71600664
24,connectivity/cola_6ep_ft-10,0.8139849
25,Jeevesh8/bert_ft_cola-60,0.78946656
26,navsad/navid_test_bert,0.6088569
27,Jeevesh8/bert_ft_cola-88,0.7746964
28,usami/distilbert-base-uncased-finetuned-cola,0.5912395
29,isakbos/Q8BERT_COLA_L_512,0.4318657
30,ishan/bert-base-uncased-mnli,0.7393648
31,boychaboy/MNLI_roberta-base,0.8371235
32,anirudh21/bert-base-uncased-finetuned-qnli,0.81457174
33,Alireza1044/albert-base-v2-qnli,0.6411548
34,Jeevesh8/init_bert_ft_qqp-49,0.77222854
35,connectivity/bert_ft_qqp-7,0.8143386
36,Jeevesh8/bert_ft_qqp-88,0.82602555
37,Jeevesh8/bert_ft_qqp-9,0.7982924
38,connectivity/bert_ft_qqp-17,0.72167283
39,Jeevesh8/init_bert_ft_qqp-28,0.71875197
40,Jeevesh8/bert_ft_qqp-55,0.82692033
41,Jeevesh8/bert_ft_qqp-40,0.800031
42,Jeevesh8/bert_ft_qqp-39,0.7865753
43,connectivity/bert_ft_qqp-1,0.8211475
44,connectivity/bert_ft_qqp-96,0.78021264
45,connectivity/bert_ft_qqp-25,0.70917404
46,Jeevesh8/bert_ft_qqp-68,0.79889524
47,Jeevesh8/init_bert_ft_qqp-24,0.80084854
48,gchhablani/bert-base-cased-finetuned-rte,0.80433863
49,philschmid/tiny-distilbert-classification,0.15588114
50,ali2066/finetuned_sentence_itr1_2e-05_all_26_02_2022-04_03_26,0.7036902
51,SetFit/distilbert-base-uncased__sst2__train-16-0,0.8070634
52,gchhablani/fnet-base-finetuned-sst2,0.5517197
53,SetFit/distilbert-base-uncased__sst2__train-32-9,0.7762017
54,Alassea/glue_sst_classifier,0.8113063
55,ChrisUPM/BioBERT_Re_trained,0.7210214
56,moshew/bert-mini-sst2-distilled,0.58561444
57,gchhablani/bert-base-cased-finetuned-wnli,0.7236864
58,Hate-speech-CNERG/bert-base-uncased-hatexplain-rationale-two,0.68928576
59,PrasunMishra/finetuning-sentiment-model-3000-samples,0.8187716
60,heranm/finetuning-sentiment-model-3000-samples,0.80255973
61,yukta10/finetuning-sentiment-model-3000-samples,0.8356642
62,markt23917/finetuning-sentiment-model-3000-samples,0.6867671
63,juliensimon/autonlp-imdb-demo-hf-16622767,0.7608121
64,XSY/albert-base-v2-imdb-calssification,0.5808479
65,fabriceyhc/bert-base-uncased-imdb,0.75679743
66,ncduy/roberta-imdb-sentiment-analysis,0.88845277
67,Anthos23/FS-distilroberta-fine-tuned,0.8485121
68,oferweintraub/bert-base-finance-sentiment-noisy-search,0.8352184
69,emrecan/bert-base-multilingual-cased-snli_tr,0.6971547
70,nurkayevaa/autonlp-bert-covid-407910458,0.7360444
71,w11wo/sundanese-bert-base-emotion-classifier,0.2417593
72,aychang/bert-base-cased-trec-coarse,0.79574347
73,JNK789/distilbert-base-uncased-finetuned-tweets-emoji-dataset,0.09296803
74,aXhyra/presentation_emotion_31415,0.7871324
75,aXhyra/emotion_trained_31415,0.7871324
76,elozano/tweet_offensive_eval,0.19360009
77,aXhyra/presentation_sentiment_1234567,0.83381265
78,nickmuchi/facebook-data2vec-finetuned-finance-classification,0.75264335
79,distilbert-base-uncased,0.8139823
80,bert-base-uncased,0.86320615
81,albert-base-v2,0.59506404
82,dhimskyy/wiki-bert,0.20985132
83,michiyasunaga/LinkBERT-base,0.7565564
84,bert-base-cased,0.82738096
85,roberta-base,0.88119906
86,bert-large-uncased,0.5989718
87,roberta-large,0.40048277
88,Recognai/bert-base-spanish-wwm-cased-xnli,0.3633119
89,mrm8488/electricidad-base-finetuned-pawsx-es,0.40364388
90,dapang/distilroberta-base-mic-sym,0.8005447
91,cambridgeltl/guardian_news_distilbert-base-uncased,0.55260634
92,Capreolus/bert-base-msmarco,0.81210756
93,Jeevesh8/feather_berts_46,0.8005101
94,phailyoor/distilbert-base-uncased-finetuned-yahd,0.6368031
95,amyma21/sincere_question_classification,0.80536896
96,arianpasquali/distilbert-base-multilingual-cased-toxicity,0.40036222
97,JonatanGk/roberta-base-bne-finetuned-cyberbullying-spanish,0.31807953
98,chiragasarpota/scotus-bert,0.27586994
99,connectivity/feather_berts_28,0.8229376
100,Giyaseddin/distilroberta-base-finetuned-short-answer-assessment,0.8120962
101,IMSyPP/hate_speech_it,0.35588118
102,Jeevesh8/feather_berts_96,0.84092784
103,18811449050/bert_finetuning_test,0.67948365
104,viviastaari/finetuning-sentiment-analysis-en-id,0.3990264
105,Jeevesh8/lecun_feather_berts-3,0.8316719
106,Jeevesh8/lecun_feather_berts-51,0.82696205
107,rmihaylov/roberta-base-sentiment-bg,0.3954318
108,finiteautomata/betonews-tweetcontext,0.23125109
109,Jeevesh8/lecun_feather_berts-8,0.8452013
110,Jeevesh8/lecun_feather_berts-7,0.81690544
111,korca/bae-roberta-base-boolq,0.8306247
112,IMSyPP/hate_speech_nl,0.23965512
113,cardiffnlp/bertweet-base-stance-climate,0.7588411
114,waboucay/camembert-base-finetuned-xnli_fr-finetuned-nli-rua_wl,0.29747894
115,aditeyabaral/finetuned-sail2017-xlm-roberta-base,0.815892
116,M47Labs/spanish_news_classification_headlines_untrained,0.433153
117,mrm8488/codebert-base-finetuned-detect-insecure-code,0.6904102
118,socialmediaie/TRAC2020_IBEN_B_bert-base-multilingual-uncased,0.45524994
119,JonatanGk/roberta-base-ca-finetuned-hate-speech-offensive-catalan,0.4149108
120,cointegrated/roberta-base-formality,0.8187061
121,YeRyeongLee/electra-base-discriminator-finetuned-filtered-0602,-0.031735417
122,joebobby/finetuning-sentiment-model-5000-samples3,0.8268666
123,Jeevesh8/feather_berts_92,0.8328332
124,Raychanan/COVID_RandomOver,0.09092738
125,anvay/finetuning-cardiffnlp-sentiment-model,0.8477158
126,bondi/bert-semaphore-prediction-w4,0.31155667
127,zenkri/autotrain-Arabic_Poetry_by_Subject-920730230,0.8401676
128,ASCCCCCCCC/distilbert-base-chinese-amazon_zh_20000,0.508697
129,Monsia/camembert-fr-covid-tweet-classification,0.46864986
130,anferico/bert-for-patents,0.4708318
131,CAMeL-Lab/bert-base-arabic-camelbert-da-sentiment,0.17907155
132,warwickai/fin-perceiver,0.7348891
133,liangyuant/distilbert-base-uncased-finetuned-num200-450-405cls,0.6181499
134,DoyyingFace/bert-asian-hate-tweets-asian-unclean-freeze-4,0.8136546
135,Aureliano/distilbert-base-uncased-if,0.6592826
136,matthewburke/korean_sentiment,0.3083723
137,ali2066/DistilBERTFINAL_ctxSentence_TRAIN_editorials_TEST_NULL_second_train_set_null_False,0.8682696
138,classla/bcms-bertic-parlasent-bcs-ter,0.4568158
139,fgaim/tiroberta-geezswitch,0.5097216
