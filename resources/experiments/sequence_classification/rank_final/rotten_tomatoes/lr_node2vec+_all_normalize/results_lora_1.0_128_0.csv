,model,score
0,Jeevesh8/init_bert_ft_qqp-33,0.7216857191852428
1,Jeevesh8/init_bert_ft_qqp-33,0.7212215835307212
2,Jeevesh8/init_bert_ft_qqp-49,0.7384079366656404
3,Jeevesh8/init_bert_ft_qqp-49,0.7376211920413622
4,connectivity/bert_ft_qqp-7,0.7286423566388465
5,connectivity/bert_ft_qqp-7,0.7278787991934164
6,Jeevesh8/bert_ft_qqp-40,0.7475026876337139
7,Jeevesh8/bert_ft_qqp-40,0.7461260057144443
8,Jeevesh8/bert_ft_qqp-9,0.7164379139755219
9,Jeevesh8/bert_ft_qqp-9,0.7156753559217892
10,Jeevesh8/bert_ft_qqp-88,0.7510216993506595
11,Jeevesh8/bert_ft_qqp-88,0.7507128277927735
12,connectivity/bert_ft_qqp-25,0.7489963263684556
13,connectivity/bert_ft_qqp-25,0.748312785344248
14,Jeevesh8/bert_ft_qqp-55,0.7394905281876252
15,Jeevesh8/bert_ft_qqp-55,0.7387416739919821
16,connectivity/bert_ft_qqp-1,0.7204416289336638
17,connectivity/bert_ft_qqp-1,0.7195874559415804
18,Jeevesh8/bert_ft_qqp-39,0.7398778754665439
19,Jeevesh8/bert_ft_qqp-39,0.7398317500709992
20,connectivity/bert_ft_qqp-94,0.7281971393904348
21,connectivity/bert_ft_qqp-94,0.727801428671029
22,connectivity/bert_ft_qqp-96,0.7404757421061847
23,connectivity/bert_ft_qqp-96,0.7400283402213728
24,Jeevesh8/init_bert_ft_qqp-24,0.7296129643382012
25,Jeevesh8/init_bert_ft_qqp-24,0.728804825048379
26,Jeevesh8/bert_ft_qqp-68,0.7251964363290615
27,Jeevesh8/bert_ft_qqp-68,0.7243874156823321
28,Jeevesh8/init_bert_ft_qqp-28,0.7216508832758735
29,Jeevesh8/init_bert_ft_qqp-28,0.7214935290902819
30,connectivity/bert_ft_qqp-17,0.7197882456527158
31,connectivity/bert_ft_qqp-17,0.719624330518504
32,ali2066/finetuned_sentence_itr1_2e-05_all_26_02_2022-04_03_26,0.7855087212047014
33,ali2066/finetuned_sentence_itr1_2e-05_all_26_02_2022-04_03_26,0.7852317095725625
34,SetFit/distilbert-base-uncased__sst2__train-16-0,0.7888323997890976
35,SetFit/distilbert-base-uncased__sst2__train-16-0,0.7885647059957464
36,aviator-neural/bert-base-uncased-sst2,0.7170932454265526
37,aviator-neural/bert-base-uncased-sst2,0.7165209801856529
38,SetFit/distilbert-base-uncased__sst2__train-32-9,0.794513007098214
39,SetFit/distilbert-base-uncased__sst2__train-32-9,0.7937198726103535
40,Alassea/glue_sst_classifier,0.7429500792578891
41,Alassea/glue_sst_classifier,0.7420784448696922
42,philschmid/tiny-distilbert-classification,0.5363783024233104
43,philschmid/tiny-distilbert-classification,0.5362549358394653
44,moshew/bert-mini-sst2-distilled,0.6897103982920076
45,moshew/bert-mini-sst2-distilled,0.6895980215194506
46,ChrisUPM/BioBERT_Re_trained,0.69895560078355
47,ChrisUPM/BioBERT_Re_trained,0.6984136554035976
48,vaariis/distilbert-base-uncased-finetuned-emotion,0.7907438203166434
49,vaariis/distilbert-base-uncased-finetuned-emotion,0.7904618911319555
50,marcelcastrobr/sagemaker-distilbert-emotion,0.7770251781140692
51,marcelcastrobr/sagemaker-distilbert-emotion,0.77693927397281
52,jasonyim2/distilbert-base-uncased-finetuned-emotion,0.7793215199660656
53,jasonyim2/distilbert-base-uncased-finetuned-emotion,0.7792538460546891
54,abdelkader/distilbert-base-uncased-finetuned-emotion,0.7932597784201595
55,abdelkader/distilbert-base-uncased-finetuned-emotion,0.792906219481634
56,moghis/distilbert-base-uncased-finetuned-emotion,0.7899079897215691
57,moghis/distilbert-base-uncased-finetuned-emotion,0.789607575388732
58,uygarkurt/distilbert-base-uncased-finetuned-emotion,0.7678518607881211
59,uygarkurt/distilbert-base-uncased-finetuned-emotion,0.7674621558140857
60,neibla/distilbert-base-uncased-finetuned-emotion,0.7899244636826562
61,neibla/distilbert-base-uncased-finetuned-emotion,0.7897936081089404
62,JB173/distilbert-base-uncased-finetuned-emotion,0.7834505440060099
63,JB173/distilbert-base-uncased-finetuned-emotion,0.7831097812303119
64,Nanatan/distilbert-base-uncased-finetuned-emotion,0.7835627765584332
65,Nanatan/distilbert-base-uncased-finetuned-emotion,0.7834437836119789
66,heranm/finetuning-sentiment-model-3000-samples,0.789582364179941
67,heranm/finetuning-sentiment-model-3000-samples,0.7892477992095075
68,PrasunMishra/finetuning-sentiment-model-3000-samples,0.7924370750745287
69,PrasunMishra/finetuning-sentiment-model-3000-samples,0.7921464417342449
70,yukta10/finetuning-sentiment-model-3000-samples,0.7800718053156058
71,yukta10/finetuning-sentiment-model-3000-samples,0.7798882428090154
72,ncduy/roberta-imdb-sentiment-analysis,0.8056278405248843
73,ncduy/roberta-imdb-sentiment-analysis,0.8052025528150597
74,markt23917/finetuning-sentiment-model-3000-samples,0.8013345754397152
75,markt23917/finetuning-sentiment-model-3000-samples,0.8005410095740194
76,juliensimon/autonlp-imdb-demo-hf-16622767,0.7789662361681967
77,juliensimon/autonlp-imdb-demo-hf-16622767,0.7785510988120303
78,fabriceyhc/bert-base-uncased-imdb,0.731527545587275
79,fabriceyhc/bert-base-uncased-imdb,0.731044536232798
80,riyadhctg/distilbert-base-uncased-finetuned-cola,0.797028857149148
81,riyadhctg/distilbert-base-uncased-finetuned-cola,0.7966800936604439
82,connectivity/cola_6ep_ft-33,0.7391786876719122
83,connectivity/cola_6ep_ft-33,0.7385993171290761
84,connectivity/cola_6ep_ft-22,0.7526540189799479
85,connectivity/cola_6ep_ft-22,0.7522719238139818
86,isakbos/Q8BERT_COLA_L_512,0.5897537958527417
87,isakbos/Q8BERT_COLA_L_512,0.5890196173107961
88,jaesun/distilbert-base-uncased-finetuned-cola,0.7837481738932626
89,jaesun/distilbert-base-uncased-finetuned-cola,0.7831847497670881
90,usami/distilbert-base-uncased-finetuned-cola,0.7847497788566278
91,usami/distilbert-base-uncased-finetuned-cola,0.7793774295062372
92,Jeevesh8/512seq_len_6ep_bert_ft_cola-91,0.709845080480448
93,Jeevesh8/512seq_len_6ep_bert_ft_cola-91,0.7090538988639324
94,Jeevesh8/6ep_bert_ft_cola-47,0.724530875322787
95,Jeevesh8/6ep_bert_ft_cola-47,0.7239602845540964
96,connectivity/cola_6ep_ft-10,0.7539184151380954
97,connectivity/cola_6ep_ft-10,0.7535150425296798
98,Jeevesh8/6ep_bert_ft_cola-12,0.7442109805021947
99,Jeevesh8/6ep_bert_ft_cola-12,0.7437276045069765
100,Jeevesh8/bert_ft_cola-88,0.7456673327502371
101,Jeevesh8/bert_ft_cola-88,0.7450429149128528
102,Jeevesh8/6ep_bert_ft_cola-29,0.7357477896958393
103,Jeevesh8/6ep_bert_ft_cola-29,0.7355677641492657
104,vesteinn/XLMR-ENIS-finetuned-cola,0.7883754721848601
105,vesteinn/XLMR-ENIS-finetuned-cola,0.7883132701892162
106,navsad/navid_test_bert,0.7381477701665884
107,navsad/navid_test_bert,0.7377532173639065
108,Jeevesh8/bert_ft_cola-60,0.7252533489251412
109,Jeevesh8/bert_ft_cola-60,0.724679361315661
110,dapang/distilroberta-base-mic-sym,0.785524290111382
111,dapang/distilroberta-base-mic-sym,0.7851526588611982
112,Capreolus/bert-base-msmarco,0.742808037377214
113,Capreolus/bert-base-msmarco,0.7422192600069093
114,Splend1dchan/bert-base-uncased-slue-goldtrascription-e3-lr1e-4,0.7464218433636348
115,Splend1dchan/bert-base-uncased-slue-goldtrascription-e3-lr1e-4,0.745840625282383
116,Jeevesh8/feather_berts_46,0.7377980218785524
117,Jeevesh8/feather_berts_46,0.7374052587395696
118,JonatanGk/roberta-base-bne-finetuned-cyberbullying-spanish,0.6738102762339666
119,JonatanGk/roberta-base-bne-finetuned-cyberbullying-spanish,0.673513236758353
120,cambridgeltl/guardian_news_distilbert-base-uncased,0.7756683392954992
121,cambridgeltl/guardian_news_distilbert-base-uncased,0.7752851278094735
122,amyma21/sincere_question_classification,0.7808724962856383
123,amyma21/sincere_question_classification,0.780766066148066
124,phailyoor/distilbert-base-uncased-finetuned-yahd,0.7515387915443108
125,phailyoor/distilbert-base-uncased-finetuned-yahd,0.7512582215233794
126,arianpasquali/distilbert-base-multilingual-cased-toxicity,0.7478588852928356
127,arianpasquali/distilbert-base-multilingual-cased-toxicity,0.7473527479613105
128,connectivity/feather_berts_28,0.741798137514672
129,connectivity/feather_berts_28,0.7414137930491166
130,liangyuant/distilbert-base-uncased-finetuned-num200-450-405cls,0.8247431554490826
131,liangyuant/distilbert-base-uncased-finetuned-num200-450-405cls,0.8245672111196996
132,DoyyingFace/bert-asian-hate-tweets-asian-unclean-freeze-4,0.7531256496930229
133,DoyyingFace/bert-asian-hate-tweets-asian-unclean-freeze-4,0.7529629025846971
134,Jeevesh8/lecun_feather_berts-3,0.7349944940043125
135,Jeevesh8/lecun_feather_berts-3,0.7346586976468417
136,Giyaseddin/distilroberta-base-finetuned-short-answer-assessment,0.7827948617068506
137,Giyaseddin/distilroberta-base-finetuned-short-answer-assessment,0.7823625555292295
138,AnonymousSub/dummy_2,0.7062142090145205
139,AnonymousSub/dummy_2,0.705449098580198
140,Jeevesh8/lecun_feather_berts-51,0.7504717436354832
141,Jeevesh8/lecun_feather_berts-51,0.7498758687035124
142,viviastaari/finetuning-sentiment-analysis-en-id,0.7152501891145836
143,viviastaari/finetuning-sentiment-analysis-en-id,0.7147191816415032
144,Aureliano/distilbert-base-uncased-if,0.7883803358964359
145,Aureliano/distilbert-base-uncased-if,0.7883356636338322
146,rmihaylov/roberta-base-sentiment-bg,0.7280497890548911
147,rmihaylov/roberta-base-sentiment-bg,0.7275560015668465
148,cardiffnlp/twitter-roberta-base-2021-124m,0.8072170408766489
149,cardiffnlp/twitter-roberta-base-2021-124m,0.8070236121352351
150,Jeevesh8/lecun_feather_berts-8,0.7572793499707617
151,Jeevesh8/lecun_feather_berts-8,0.7568802561053762
152,korca/bae-roberta-base-boolq,0.7986201713508618
153,korca/bae-roberta-base-boolq,0.7979958642162097
154,aditeyabaral/finetuned-sail2017-xlm-roberta-base,0.7923402629326491
155,aditeyabaral/finetuned-sail2017-xlm-roberta-base,0.7918759020033158
156,joebobby/finetuning-sentiment-model-5000-samples3,0.7488309541773642
157,joebobby/finetuning-sentiment-model-5000-samples3,0.748356206046194
158,Jeevesh8/feather_berts_92,0.7468859680792714
159,Jeevesh8/feather_berts_92,0.7463276455399939
160,ASCCCCCCCC/distilbert-base-chinese-amazon_zh_20000,0.6632540810599963
161,ASCCCCCCCC/distilbert-base-chinese-amazon_zh_20000,0.6631392368181366
162,matthewburke/korean_sentiment,0.6979947232371588
163,matthewburke/korean_sentiment,0.6977052904867457
164,IMSyPP/hate_speech_nl,0.6579458069595129
165,IMSyPP/hate_speech_nl,0.6572867252420278
166,cointegrated/roberta-base-formality,0.7841822600303288
167,cointegrated/roberta-base-formality,0.7832514863206825
168,IMSyPP/hate_speech_it,0.6861770257347677
169,IMSyPP/hate_speech_it,0.6855819001668937
170,18811449050/bert_finetuning_test,0.7088542475183546
171,18811449050/bert_finetuning_test,0.708349560805877
172,finiteautomata/betonews-tweetcontext,0.6668523131933922
173,finiteautomata/betonews-tweetcontext,0.6661948249361221
174,Jeevesh8/feather_berts_96,0.7326865339931083
175,Jeevesh8/feather_berts_96,0.7326443838435007
176,Jeevesh8/lecun_feather_berts-7,0.7194822485710407
177,Jeevesh8/lecun_feather_berts-7,0.7190005938821055
178,mrm8488/codebert-base-finetuned-detect-insecure-code,0.7502866412151971
179,mrm8488/codebert-base-finetuned-detect-insecure-code,0.7494952405810219
180,socialmediaie/TRAC2020_IBEN_B_bert-base-multilingual-uncased,0.7164735869427366
181,socialmediaie/TRAC2020_IBEN_B_bert-base-multilingual-uncased,0.7155612837344603
182,zenkri/autotrain-Arabic_Poetry_by_Subject-920730230,0.7399258245869723
183,zenkri/autotrain-Arabic_Poetry_by_Subject-920730230,0.7389104162003175
184,M47Labs/spanish_news_classification_headlines_untrained,0.6613141479822671
185,M47Labs/spanish_news_classification_headlines_untrained,0.6607645280508465
186,bondi/bert-semaphore-prediction-w4,0.6587302113659982
187,bondi/bert-semaphore-prediction-w4,0.6576307403967427
188,classla/bcms-bertic-parlasent-bcs-ter,0.7310860851871991
189,classla/bcms-bertic-parlasent-bcs-ter,0.7303104310686502
190,anferico/bert-for-patents,0.6980808182220111
191,anferico/bert-for-patents,0.6955354643696642
192,ali2066/DistilBERTFINAL_ctxSentence_TRAIN_editorials_TEST_NULL_second_train_set_null_False,0.8068437789972218
193,ali2066/DistilBERTFINAL_ctxSentence_TRAIN_editorials_TEST_NULL_second_train_set_null_False,0.8062273364580886
194,anvay/finetuning-cardiffnlp-sentiment-model,0.8036572952977724
195,anvay/finetuning-cardiffnlp-sentiment-model,0.8031030005093455
196,JonatanGk/roberta-base-ca-finetuned-hate-speech-offensive-catalan,0.7251837286944618
197,JonatanGk/roberta-base-ca-finetuned-hate-speech-offensive-catalan,0.724747725432047
198,Raychanan/COVID_RandomOver,0.5167335636455282
199,Raychanan/COVID_RandomOver,0.5161585345133854
200,kyleinincubated/autonlp-cat333-624217911,0.6767183345516176
201,kyleinincubated/autonlp-cat333-624217911,0.6761667759921477
202,cardiffnlp/bertweet-base-stance-climate,0.8132354088342378
203,cardiffnlp/bertweet-base-stance-climate,0.8126819472951481
204,nurkayevaa/autonlp-bert-covid-407910458,0.7996935949105368
205,nurkayevaa/autonlp-bert-covid-407910458,0.7993346283552146
206,SetFit/distilbert-base-uncased__hate_speech_offensive__train-16-1,0.7957423755500938
207,SetFit/distilbert-base-uncased__hate_speech_offensive__train-16-1,0.7953321300243802
208,crcb/isear_bert,0.8111590625425631
209,crcb/isear_bert,0.8106194853528179
210,robertou2/roberta-base-bne-finetuned-amazon_reviews_multi,0.7209360028401535
211,robertou2/roberta-base-bne-finetuned-amazon_reviews_multi,0.7209858844103882
212,milyiyo/selectra-small-finetuned-amazon-review,0.696549344650572
213,milyiyo/selectra-small-finetuned-amazon-review,0.6963224730058959
214,Anthos23/FS-distilroberta-fine-tuned,0.8080474826194171
215,Anthos23/FS-distilroberta-fine-tuned,0.8077084209663524
216,oferweintraub/bert-base-finance-sentiment-noisy-search,0.71895464496907
217,oferweintraub/bert-base-finance-sentiment-noisy-search,0.7184961579499076
218,pietrotrope/emotion_final,0.7712745629321436
219,pietrotrope/emotion_final,0.7709321048149795
220,aXhyra/emotion_trained_31415,0.8071437134524163
221,aXhyra/emotion_trained_31415,0.8070650681434312
222,aXhyra/presentation_emotion_31415,0.7933546911691489
223,aXhyra/presentation_emotion_31415,0.7930555853013754
224,Recognai/bert-base-spanish-wwm-cased-xnli,0.6713811416437961
225,Recognai/bert-base-spanish-wwm-cased-xnli,0.6704261128296639
226,anirudh21/bert-base-uncased-finetuned-qnli,0.7498057053104887
227,anirudh21/bert-base-uncased-finetuned-qnli,0.7498133625830758
228,aXhyra/demo_sentiment_31415,0.7822742691775459
229,aXhyra/demo_sentiment_31415,0.7819600946533376
230,aXhyra/presentation_sentiment_1234567,0.7993410580144726
231,aXhyra/presentation_sentiment_1234567,0.7990171176378125
232,jb2k/bert-base-multilingual-cased-language-detection,0.6857684645444951
233,jb2k/bert-base-multilingual-cased-language-detection,0.6847029302938887
234,vinai/bertweet-base,0.8006022177793923
235,vinai/bertweet-base,0.8001609618962997
236,justinqbui/bertweet-covid19-base-uncased-pretraining-covid-vaccine-tweets,0.7939355008432765
237,justinqbui/bertweet-covid19-base-uncased-pretraining-covid-vaccine-tweets,0.7931157929508715
238,vinai/bertweet-covid19-base-cased,0.8181088260402631
239,vinai/bertweet-covid19-base-cased,0.8175690386637963
240,vinai/bertweet-covid19-base-uncased,0.7877075219845524
241,vinai/bertweet-covid19-base-uncased,0.7861495180825082
242,distilbert-base-uncased,0.7758861438580553
243,distilbert-base-uncased,0.7755861756018446
244,bert-base-uncased,0.7333012112087933
245,bert-base-uncased,0.7328140430815383
246,roberta-base,0.8131483331296971
247,roberta-base,0.8127259409619103
248,bert-base-cased,0.7557002671846516
249,bert-base-cased,0.7549629745290474
250,dhimskyy/wiki-bert,0.6741707865134663
251,dhimskyy/wiki-bert,0.6731636306515736
252,michiyasunaga/LinkBERT-base,0.7352972552899166
253,michiyasunaga/LinkBERT-base,0.7352662406013903
254,bert-large-uncased,0.7296148862597156
255,bert-large-uncased,0.7254128319586812
256,roberta-large,0.7546998632465568
257,roberta-large,0.7516851289900978
258,boychaboy/MNLI_roberta-base,0.8128654203020236
259,boychaboy/MNLI_roberta-base,0.812040651054476
260,ishan/bert-base-uncased-mnli,0.7362550158083251
261,ishan/bert-base-uncased-mnli,0.7353919156018431
262,emrecan/bert-base-multilingual-cased-snli_tr,0.6863214223930476
263,emrecan/bert-base-multilingual-cased-snli_tr,0.6857802963138692
264,elozano/tweet_offensive_eval,0.7067289014859598
265,elozano/tweet_offensive_eval,0.7066061418742351
266,Hate-speech-CNERG/bert-base-uncased-hatexplain-rationale-two,0.7410537244591864
267,Hate-speech-CNERG/bert-base-uncased-hatexplain-rationale-two,0.7403526156767368
268,aychang/bert-base-cased-trec-coarse,0.7673470643170125
269,aychang/bert-base-cased-trec-coarse,0.7666771784380988
270,gchhablani/bert-base-cased-finetuned-wnli,0.7375114603292178
271,gchhablani/bert-base-cased-finetuned-wnli,0.737089704961411
272,w11wo/sundanese-bert-base-emotion-classifier,0.6405445179828089
273,w11wo/sundanese-bert-base-emotion-classifier,0.6402652895646292
274,gchhablani/bert-base-cased-finetuned-rte,0.7421119094741443
275,gchhablani/bert-base-cased-finetuned-rte,0.7417757058659122
276,mrm8488/electricidad-base-finetuned-pawsx-es,0.6985872443934676
277,mrm8488/electricidad-base-finetuned-pawsx-es,0.6982662159992364
278,manueltonneau/bert-twitter-en-is-hired,0.7453022684075882
279,manueltonneau/bert-twitter-en-is-hired,0.7446717138990488
280,Guscode/DKbert-hatespeech-detection,0.6408576543366926
281,Guscode/DKbert-hatespeech-detection,0.6405399990375951
