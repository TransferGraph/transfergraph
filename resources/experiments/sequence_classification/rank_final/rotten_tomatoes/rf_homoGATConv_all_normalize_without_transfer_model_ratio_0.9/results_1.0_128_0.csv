,model,score
0,Guscode/DKbert-hatespeech-detection,0.8564344887101408
1,milyiyo/selectra-small-finetuned-amazon-review,0.8460218464182251
2,robertou2/roberta-base-bne-finetuned-amazon_reviews_multi,0.8809736847894082
3,vinai/bertweet-covid19-base-cased,0.965836824109768
4,vinai/bertweet-base,0.8984292292265728
5,vinai/bertweet-covid19-base-uncased,0.9666305389213025
6,justinqbui/bertweet-covid19-base-uncased-pretraining-covid-vaccine-tweets,0.9682619042812054
7,jb2k/bert-base-multilingual-cased-language-detection,0.8568526352926277
8,crcb/isear_bert,0.9695971382371976
9,marcelcastrobr/sagemaker-distilbert-emotion,0.9661486454213764
10,abdelkader/distilbert-base-uncased-finetuned-emotion,0.9662949033043889
11,moghis/distilbert-base-uncased-finetuned-emotion,0.9662949033043889
12,neibla/distilbert-base-uncased-finetuned-emotion,0.9661531530018266
13,uygarkurt/distilbert-base-uncased-finetuned-emotion,0.9658179795925799
14,JB173/distilbert-base-uncased-finetuned-emotion,0.9682684061885061
15,vaariis/distilbert-base-uncased-finetuned-emotion,0.9664487593112296
16,Nanatan/distilbert-base-uncased-finetuned-emotion,0.96594875643377
17,riyadhctg/distilbert-base-uncased-finetuned-cola,0.9602625968664061
18,connectivity/cola_6ep_ft-33,0.9671316390303847
19,vesteinn/XLMR-ENIS-finetuned-cola,0.968690413749018
20,Jeevesh8/6ep_bert_ft_cola-47,0.9682714412552491
21,Jeevesh8/512seq_len_6ep_bert_ft_cola-91,0.9646896145377781
22,jaesun/distilbert-base-uncased-finetuned-cola,0.9588125955811748
23,Jeevesh8/6ep_bert_ft_cola-12,0.9667886416262376
24,connectivity/cola_6ep_ft-10,0.9669448139872563
25,Jeevesh8/bert_ft_cola-60,0.967205928420896
26,navsad/navid_test_bert,0.9676117056918072
27,Jeevesh8/bert_ft_cola-88,0.9678192997970253
28,usami/distilbert-base-uncased-finetuned-cola,0.9676464989844373
29,isakbos/Q8BERT_COLA_L_512,0.9084920344653071
30,ishan/bert-base-uncased-mnli,0.9664487593112296
31,boychaboy/MNLI_roberta-base,0.9698303608977991
32,anirudh21/bert-base-uncased-finetuned-qnli,0.9683877503191664
33,Alireza1044/albert-base-v2-qnli,0.9669010154047869
34,Jeevesh8/init_bert_ft_qqp-49,0.9671088305328022
35,connectivity/bert_ft_qqp-7,0.9679393375845465
36,Jeevesh8/bert_ft_qqp-88,0.9662165157893746
37,Jeevesh8/bert_ft_qqp-9,0.9662389103124259
38,connectivity/bert_ft_qqp-17,0.9680994907990393
39,Jeevesh8/init_bert_ft_qqp-28,0.9671309817461261
40,Jeevesh8/bert_ft_qqp-55,0.9681334277277105
41,Jeevesh8/bert_ft_qqp-40,0.9681334277277105
42,Jeevesh8/bert_ft_qqp-39,0.968184520285985
43,connectivity/bert_ft_qqp-1,0.9666924495479915
44,connectivity/bert_ft_qqp-96,0.9664776766947906
45,connectivity/bert_ft_qqp-25,0.9685544598766007
46,Jeevesh8/bert_ft_qqp-68,0.9656159180151525
47,Jeevesh8/init_bert_ft_qqp-24,0.9667886416262376
48,gchhablani/bert-base-cased-finetuned-rte,0.966706502824572
49,philschmid/tiny-distilbert-classification,0.022336262050928663
50,ali2066/finetuned_sentence_itr1_2e-05_all_26_02_2022-04_03_26,0.9678309400791999
51,SetFit/distilbert-base-uncased__sst2__train-16-0,0.9676818403305204
52,gchhablani/fnet-base-finetuned-sst2,0.8926952474219011
53,SetFit/distilbert-base-uncased__sst2__train-32-9,0.9681334277277105
54,Alassea/glue_sst_classifier,0.9682150818906458
55,ChrisUPM/BioBERT_Re_trained,0.9657873129854828
56,moshew/bert-mini-sst2-distilled,0.9000715689592195
57,gchhablani/bert-base-cased-finetuned-wnli,0.9663290405626228
58,Hate-speech-CNERG/bert-base-uncased-hatexplain-rationale-two,0.9681090420546934
59,PrasunMishra/finetuning-sentiment-model-3000-samples,0.9664776766947906
60,heranm/finetuning-sentiment-model-3000-samples,0.9664487593112296
61,yukta10/finetuning-sentiment-model-3000-samples,0.9677928530333035
62,markt23917/finetuning-sentiment-model-3000-samples,0.967368907261834
63,juliensimon/autonlp-imdb-demo-hf-16622767,0.9669010154047869
64,XSY/albert-base-v2-imdb-calssification,0.9022674279951239
65,fabriceyhc/bert-base-uncased-imdb,0.9663771548454123
66,ncduy/roberta-imdb-sentiment-analysis,0.9677222482483887
67,Anthos23/FS-distilroberta-fine-tuned,0.9692927403821264
68,oferweintraub/bert-base-finance-sentiment-noisy-search,0.9681334277277105
69,emrecan/bert-base-multilingual-cased-snli_tr,0.9682303615310714
70,nurkayevaa/autonlp-bert-covid-407910458,0.9677571637985776
71,w11wo/sundanese-bert-base-emotion-classifier,0.824640677248531
72,aychang/bert-base-cased-trec-coarse,0.9681334277277105
73,JNK789/distilbert-base-uncased-finetuned-tweets-emoji-dataset,0.025557813482435736
74,aXhyra/presentation_emotion_31415,0.9671654271501133
75,aXhyra/emotion_trained_31415,0.9677571637985776
76,elozano/tweet_offensive_eval,0.8248158955100818
77,aXhyra/presentation_sentiment_1234567,0.9647956848578813
78,nickmuchi/facebook-data2vec-finetuned-finance-classification,0.9682059758580543
79,distilbert-base-uncased,0.9666662667998333
80,bert-base-uncased,0.9682359069169624
81,albert-base-v2,0.961696784026894
82,dhimskyy/wiki-bert,0.873562510037463
83,michiyasunaga/LinkBERT-base,0.9662923569735229
84,bert-base-cased,0.9681334277277105
85,roberta-base,0.9679514577551731
86,bert-large-uncased,0.8929863023892447
87,roberta-large,0.8967399730717173
88,Recognai/bert-base-spanish-wwm-cased-xnli,0.8479604391459443
89,mrm8488/electricidad-base-finetuned-pawsx-es,0.8972149383545824
90,dapang/distilroberta-base-mic-sym,0.9691045236419673
91,cambridgeltl/guardian_news_distilbert-base-uncased,0.9681334277277105
92,Capreolus/bert-base-msmarco,0.9681500748819978
93,Jeevesh8/feather_berts_46,0.9682359069169624
94,phailyoor/distilbert-base-uncased-finetuned-yahd,0.9502709915752754
95,amyma21/sincere_question_classification,0.9669448139872563
96,arianpasquali/distilbert-base-multilingual-cased-toxicity,0.9001084795145059
97,JonatanGk/roberta-base-bne-finetuned-cyberbullying-spanish,0.8410250398018911
98,chiragasarpota/scotus-bert,0.8164202394544823
99,connectivity/feather_berts_28,0.9676995277528497
100,Giyaseddin/distilroberta-base-finetuned-short-answer-assessment,0.9700503141843899
101,IMSyPP/hate_speech_it,0.9073959660479458
102,Jeevesh8/feather_berts_96,0.9681334277277105
103,18811449050/bert_finetuning_test,0.966024632528798
104,viviastaari/finetuning-sentiment-analysis-en-id,0.865938838663834
105,Jeevesh8/lecun_feather_berts-3,0.9681334277277105
106,Jeevesh8/lecun_feather_berts-51,0.9661384640640484
107,rmihaylov/roberta-base-sentiment-bg,0.8779750574614574
108,finiteautomata/betonews-tweetcontext,0.8722503358797721
109,Jeevesh8/lecun_feather_berts-8,0.9663591424698051
110,Jeevesh8/lecun_feather_berts-7,0.9683371662362079
111,korca/bae-roberta-base-boolq,0.96973244729794
112,IMSyPP/hate_speech_nl,0.8209803813552436
113,cardiffnlp/bertweet-base-stance-climate,0.9695971382371976
114,waboucay/camembert-base-finetuned-xnli_fr-finetuned-nli-rua_wl,0.7831557834259972
115,aditeyabaral/finetuned-sail2017-xlm-roberta-base,0.9697283901838629
116,M47Labs/spanish_news_classification_headlines_untrained,0.8739513204786789
117,mrm8488/codebert-base-finetuned-detect-insecure-code,0.9695971382371976
118,socialmediaie/TRAC2020_IBEN_B_bert-base-multilingual-uncased,0.968365339991867
119,JonatanGk/roberta-base-ca-finetuned-hate-speech-offensive-catalan,0.8977437669719357
120,cointegrated/roberta-base-formality,0.9694104992118039
121,YeRyeongLee/electra-base-discriminator-finetuned-filtered-0602,0.79211507535361
122,joebobby/finetuning-sentiment-model-5000-samples3,0.9683371662362079
123,Jeevesh8/feather_berts_92,0.9682714412552491
124,Raychanan/COVID_RandomOver,0.026918107600082793
125,anvay/finetuning-cardiffnlp-sentiment-model,0.9697797768148405
126,bondi/bert-semaphore-prediction-w4,0.8714685918738287
127,zenkri/autotrain-Arabic_Poetry_by_Subject-920730230,0.9681868025813796
128,ASCCCCCCCC/distilbert-base-chinese-amazon_zh_20000,0.8664409791063289
129,Monsia/camembert-fr-covid-tweet-classification,0.8904082094330419
130,anferico/bert-for-patents,0.8883713039169548
131,CAMeL-Lab/bert-base-arabic-camelbert-da-sentiment,0.851502353157618
132,warwickai/fin-perceiver,0.967895529332022
133,liangyuant/distilbert-base-uncased-finetuned-num200-450-405cls,0.9681334277277105
134,DoyyingFace/bert-asian-hate-tweets-asian-unclean-freeze-4,0.9678309400791999
135,Aureliano/distilbert-base-uncased-if,0.9672312053592065
136,matthewburke/korean_sentiment,0.8743015346894205
137,ali2066/DistilBERTFINAL_ctxSentence_TRAIN_editorials_TEST_NULL_second_train_set_null_False,0.9695971382371976
138,classla/bcms-bertic-parlasent-bcs-ter,0.890284328365876
139,fgaim/tiroberta-geezswitch,0.8783137603309825
