,model,score
0,Jeevesh8/init_bert_ft_qqp-33,0.76862156
1,Jeevesh8/init_bert_ft_qqp-33,0.7589307
2,Jeevesh8/init_bert_ft_qqp-49,0.78175205
3,Jeevesh8/init_bert_ft_qqp-49,0.7698873
4,connectivity/bert_ft_qqp-7,0.78451556
5,connectivity/bert_ft_qqp-7,0.6939096
6,Jeevesh8/bert_ft_qqp-40,0.7832809
7,Jeevesh8/bert_ft_qqp-40,0.77147
8,Jeevesh8/bert_ft_qqp-9,0.79518133
9,Jeevesh8/bert_ft_qqp-9,0.7678096
10,Jeevesh8/bert_ft_qqp-88,0.7898669
11,Jeevesh8/bert_ft_qqp-88,0.7761614
12,connectivity/bert_ft_qqp-25,0.78744364
13,connectivity/bert_ft_qqp-25,0.7392647
14,Jeevesh8/bert_ft_qqp-55,0.7905375
15,Jeevesh8/bert_ft_qqp-55,0.77458376
16,connectivity/bert_ft_qqp-1,0.782431
17,connectivity/bert_ft_qqp-1,0.7626513
18,Jeevesh8/bert_ft_qqp-39,0.78212273
19,Jeevesh8/bert_ft_qqp-39,0.782323
20,connectivity/bert_ft_qqp-94,0.78727114
21,connectivity/bert_ft_qqp-94,0.7788203
22,connectivity/bert_ft_qqp-96,0.7672907
23,connectivity/bert_ft_qqp-96,0.7534324
24,Jeevesh8/init_bert_ft_qqp-24,0.7912501
25,Jeevesh8/init_bert_ft_qqp-24,0.76261836
26,Jeevesh8/bert_ft_qqp-68,0.7826657
27,Jeevesh8/bert_ft_qqp-68,0.7494662
28,Jeevesh8/init_bert_ft_qqp-28,0.7606921
29,Jeevesh8/init_bert_ft_qqp-28,0.7700266
30,connectivity/bert_ft_qqp-17,0.7630612
31,connectivity/bert_ft_qqp-17,0.7669532
32,ali2066/finetuned_sentence_itr1_2e-05_all_26_02_2022-04_03_26,0.777316
33,ali2066/finetuned_sentence_itr1_2e-05_all_26_02_2022-04_03_26,0.75503004
34,SetFit/distilbert-base-uncased__sst2__train-16-0,0.78441906
35,SetFit/distilbert-base-uncased__sst2__train-16-0,0.78622127
36,aviator-neural/bert-base-uncased-sst2,0.75331044
37,aviator-neural/bert-base-uncased-sst2,0.7415106
38,SetFit/distilbert-base-uncased__sst2__train-32-9,0.7875936
39,SetFit/distilbert-base-uncased__sst2__train-32-9,0.7712139
40,Alassea/glue_sst_classifier,0.7972867
41,Alassea/glue_sst_classifier,0.7745723
42,philschmid/tiny-distilbert-classification,0.6208369
43,philschmid/tiny-distilbert-classification,0.6314696
44,moshew/bert-mini-sst2-distilled,0.7290641
45,moshew/bert-mini-sst2-distilled,0.7438233
46,ChrisUPM/BioBERT_Re_trained,0.7452836
47,ChrisUPM/BioBERT_Re_trained,0.73521024
48,vaariis/distilbert-base-uncased-finetuned-emotion,0.7700378
49,vaariis/distilbert-base-uncased-finetuned-emotion,0.7592561
50,marcelcastrobr/sagemaker-distilbert-emotion,0.77059555
51,marcelcastrobr/sagemaker-distilbert-emotion,0.783485
52,jasonyim2/distilbert-base-uncased-finetuned-emotion,0.77028364
53,jasonyim2/distilbert-base-uncased-finetuned-emotion,0.76612025
54,abdelkader/distilbert-base-uncased-finetuned-emotion,0.7879027
55,abdelkader/distilbert-base-uncased-finetuned-emotion,0.7662973
56,moghis/distilbert-base-uncased-finetuned-emotion,0.769285
57,moghis/distilbert-base-uncased-finetuned-emotion,0.76125115
58,uygarkurt/distilbert-base-uncased-finetuned-emotion,0.79877824
59,uygarkurt/distilbert-base-uncased-finetuned-emotion,0.7600978
60,neibla/distilbert-base-uncased-finetuned-emotion,0.76237327
61,neibla/distilbert-base-uncased-finetuned-emotion,0.7705926
62,JB173/distilbert-base-uncased-finetuned-emotion,0.7789441
63,JB173/distilbert-base-uncased-finetuned-emotion,0.7522762
64,Nanatan/distilbert-base-uncased-finetuned-emotion,0.77534735
65,Nanatan/distilbert-base-uncased-finetuned-emotion,0.7889733
66,heranm/finetuning-sentiment-model-3000-samples,0.77892417
67,heranm/finetuning-sentiment-model-3000-samples,0.7421978
68,PrasunMishra/finetuning-sentiment-model-3000-samples,0.77436733
69,PrasunMishra/finetuning-sentiment-model-3000-samples,0.77508724
70,yukta10/finetuning-sentiment-model-3000-samples,0.79730743
71,yukta10/finetuning-sentiment-model-3000-samples,0.78046066
72,ncduy/roberta-imdb-sentiment-analysis,0.8006933
73,ncduy/roberta-imdb-sentiment-analysis,0.7913549
74,markt23917/finetuning-sentiment-model-3000-samples,0.7771309
75,markt23917/finetuning-sentiment-model-3000-samples,0.76679194
76,juliensimon/autonlp-imdb-demo-hf-16622767,0.7846019
77,juliensimon/autonlp-imdb-demo-hf-16622767,0.7526699
78,fabriceyhc/bert-base-uncased-imdb,0.76801884
79,fabriceyhc/bert-base-uncased-imdb,0.7567189
80,riyadhctg/distilbert-base-uncased-finetuned-cola,0.76875526
81,riyadhctg/distilbert-base-uncased-finetuned-cola,0.75035036
82,connectivity/cola_6ep_ft-33,0.7676925
83,connectivity/cola_6ep_ft-33,0.77880436
84,connectivity/cola_6ep_ft-22,0.79738677
85,connectivity/cola_6ep_ft-22,0.7817686
86,isakbos/Q8BERT_COLA_L_512,0.72150195
87,isakbos/Q8BERT_COLA_L_512,0.62501144
88,jaesun/distilbert-base-uncased-finetuned-cola,0.7652864
89,jaesun/distilbert-base-uncased-finetuned-cola,0.76374286
90,usami/distilbert-base-uncased-finetuned-cola,0.79141855
91,usami/distilbert-base-uncased-finetuned-cola,0.78077495
92,Jeevesh8/512seq_len_6ep_bert_ft_cola-91,0.7869532
93,Jeevesh8/512seq_len_6ep_bert_ft_cola-91,0.77254176
94,Jeevesh8/6ep_bert_ft_cola-47,0.7720089
95,Jeevesh8/6ep_bert_ft_cola-47,0.7771506
96,connectivity/cola_6ep_ft-10,0.7964363
97,connectivity/cola_6ep_ft-10,0.7832808
98,Jeevesh8/6ep_bert_ft_cola-12,0.77437526
99,Jeevesh8/6ep_bert_ft_cola-12,0.78040093
100,Jeevesh8/bert_ft_cola-88,0.77787715
101,Jeevesh8/bert_ft_cola-88,0.7775418
102,Jeevesh8/6ep_bert_ft_cola-29,0.7703584
103,Jeevesh8/6ep_bert_ft_cola-29,0.7741288
104,vesteinn/XLMR-ENIS-finetuned-cola,0.76222956
105,vesteinn/XLMR-ENIS-finetuned-cola,0.7636989
106,navsad/navid_test_bert,0.7631124
107,navsad/navid_test_bert,0.77371156
108,Jeevesh8/bert_ft_cola-60,0.7734834
109,Jeevesh8/bert_ft_cola-60,0.76812965
110,dapang/distilroberta-base-mic-sym,0.7966623
111,dapang/distilroberta-base-mic-sym,0.7645588
112,Capreolus/bert-base-msmarco,0.7826197
113,Capreolus/bert-base-msmarco,0.7609446
114,Splend1dchan/bert-base-uncased-slue-goldtrascription-e3-lr1e-4,0.7849731
115,Splend1dchan/bert-base-uncased-slue-goldtrascription-e3-lr1e-4,0.7904186
116,Jeevesh8/feather_berts_46,0.7926615
117,Jeevesh8/feather_berts_46,0.78206193
118,JonatanGk/roberta-base-bne-finetuned-cyberbullying-spanish,0.69089335
119,JonatanGk/roberta-base-bne-finetuned-cyberbullying-spanish,0.69199234
120,cambridgeltl/guardian_news_distilbert-base-uncased,0.77172774
121,cambridgeltl/guardian_news_distilbert-base-uncased,0.7313943
122,amyma21/sincere_question_classification,0.78148586
123,amyma21/sincere_question_classification,0.77760935
124,phailyoor/distilbert-base-uncased-finetuned-yahd,0.7637437
125,phailyoor/distilbert-base-uncased-finetuned-yahd,0.7268382
126,arianpasquali/distilbert-base-multilingual-cased-toxicity,0.73356324
127,arianpasquali/distilbert-base-multilingual-cased-toxicity,0.71997887
128,connectivity/feather_berts_28,0.7981155
129,connectivity/feather_berts_28,0.792392
130,liangyuant/distilbert-base-uncased-finetuned-num200-450-405cls,0.7929402
131,liangyuant/distilbert-base-uncased-finetuned-num200-450-405cls,0.7758459
132,DoyyingFace/bert-asian-hate-tweets-asian-unclean-freeze-4,0.78439724
133,DoyyingFace/bert-asian-hate-tweets-asian-unclean-freeze-4,0.7836631
134,Jeevesh8/lecun_feather_berts-3,0.7915384
135,Jeevesh8/lecun_feather_berts-3,0.78183675
136,Giyaseddin/distilroberta-base-finetuned-short-answer-assessment,0.79646295
137,Giyaseddin/distilroberta-base-finetuned-short-answer-assessment,0.7559994
138,AnonymousSub/dummy_2,0.732944
139,AnonymousSub/dummy_2,0.69533384
140,Jeevesh8/lecun_feather_berts-51,0.7832982
141,Jeevesh8/lecun_feather_berts-51,0.7709361
142,viviastaari/finetuning-sentiment-analysis-en-id,0.733497
143,viviastaari/finetuning-sentiment-analysis-en-id,0.721352
144,Aureliano/distilbert-base-uncased-if,0.77061206
145,Aureliano/distilbert-base-uncased-if,0.77898407
146,rmihaylov/roberta-base-sentiment-bg,0.73845303
147,rmihaylov/roberta-base-sentiment-bg,0.71732825
148,cardiffnlp/twitter-roberta-base-2021-124m,0.78014636
149,cardiffnlp/twitter-roberta-base-2021-124m,0.78847116
150,Jeevesh8/lecun_feather_berts-8,0.7874989
151,Jeevesh8/lecun_feather_berts-8,0.7650699
152,korca/bae-roberta-base-boolq,0.76923174
153,korca/bae-roberta-base-boolq,0.7485288
154,aditeyabaral/finetuned-sail2017-xlm-roberta-base,0.78523314
155,aditeyabaral/finetuned-sail2017-xlm-roberta-base,0.7659852
156,joebobby/finetuning-sentiment-model-5000-samples3,0.77637017
157,joebobby/finetuning-sentiment-model-5000-samples3,0.7605263
158,Jeevesh8/feather_berts_92,0.7906542
159,Jeevesh8/feather_berts_92,0.7842686
160,ASCCCCCCCC/distilbert-base-chinese-amazon_zh_20000,0.70063865
161,ASCCCCCCCC/distilbert-base-chinese-amazon_zh_20000,0.7001913
162,matthewburke/korean_sentiment,0.6952865
163,matthewburke/korean_sentiment,0.69444686
164,IMSyPP/hate_speech_nl,0.69477475
165,IMSyPP/hate_speech_nl,0.6857369
166,cointegrated/roberta-base-formality,0.7972457
167,cointegrated/roberta-base-formality,0.78472996
168,IMSyPP/hate_speech_it,0.70966816
169,IMSyPP/hate_speech_it,0.6921281
170,18811449050/bert_finetuning_test,0.75354564
171,18811449050/bert_finetuning_test,0.7564012
172,finiteautomata/betonews-tweetcontext,0.68569875
173,finiteautomata/betonews-tweetcontext,0.6820851
174,Jeevesh8/feather_berts_96,0.7894331
175,Jeevesh8/feather_berts_96,0.7942258
176,Jeevesh8/lecun_feather_berts-7,0.786291
177,Jeevesh8/lecun_feather_berts-7,0.7856157
178,mrm8488/codebert-base-finetuned-detect-insecure-code,0.76310533
179,mrm8488/codebert-base-finetuned-detect-insecure-code,0.7147526
180,socialmediaie/TRAC2020_IBEN_B_bert-base-multilingual-uncased,0.7505775
181,socialmediaie/TRAC2020_IBEN_B_bert-base-multilingual-uncased,0.7242138
182,zenkri/autotrain-Arabic_Poetry_by_Subject-920730230,0.7741942
183,zenkri/autotrain-Arabic_Poetry_by_Subject-920730230,0.7713792
184,M47Labs/spanish_news_classification_headlines_untrained,0.708987
185,M47Labs/spanish_news_classification_headlines_untrained,0.70478845
186,bondi/bert-semaphore-prediction-w4,0.6878601
187,bondi/bert-semaphore-prediction-w4,0.67918056
188,classla/bcms-bertic-parlasent-bcs-ter,0.7174822
189,classla/bcms-bertic-parlasent-bcs-ter,0.6977837
190,anferico/bert-for-patents,0.72318816
191,anferico/bert-for-patents,0.7114821
192,ali2066/DistilBERTFINAL_ctxSentence_TRAIN_editorials_TEST_NULL_second_train_set_null_False,0.7951966
193,ali2066/DistilBERTFINAL_ctxSentence_TRAIN_editorials_TEST_NULL_second_train_set_null_False,0.80671185
194,anvay/finetuning-cardiffnlp-sentiment-model,0.8076987
195,anvay/finetuning-cardiffnlp-sentiment-model,0.79132396
196,JonatanGk/roberta-base-ca-finetuned-hate-speech-offensive-catalan,0.70452726
197,JonatanGk/roberta-base-ca-finetuned-hate-speech-offensive-catalan,0.6935133
198,Raychanan/COVID_RandomOver,0.6466048
199,Raychanan/COVID_RandomOver,0.65139014
200,kyleinincubated/autonlp-cat333-624217911,0.7092043
201,kyleinincubated/autonlp-cat333-624217911,0.7090077
202,cardiffnlp/bertweet-base-stance-climate,0.76950765
203,cardiffnlp/bertweet-base-stance-climate,0.7445922
204,nurkayevaa/autonlp-bert-covid-407910458,0.77207446
205,nurkayevaa/autonlp-bert-covid-407910458,0.7479021
206,SetFit/distilbert-base-uncased__hate_speech_offensive__train-16-1,0.789704
207,SetFit/distilbert-base-uncased__hate_speech_offensive__train-16-1,0.76618767
208,crcb/isear_bert,0.7790389
209,crcb/isear_bert,0.76860994
210,robertou2/roberta-base-bne-finetuned-amazon_reviews_multi,0.7071835
211,robertou2/roberta-base-bne-finetuned-amazon_reviews_multi,0.7056332
212,milyiyo/selectra-small-finetuned-amazon-review,0.694839
213,milyiyo/selectra-small-finetuned-amazon-review,0.67289174
214,Anthos23/FS-distilroberta-fine-tuned,0.79727614
215,Anthos23/FS-distilroberta-fine-tuned,0.7766659
216,oferweintraub/bert-base-finance-sentiment-noisy-search,0.7807767
217,oferweintraub/bert-base-finance-sentiment-noisy-search,0.7654335
218,pietrotrope/emotion_final,0.78806776
219,pietrotrope/emotion_final,0.76680505
220,aXhyra/emotion_trained_31415,0.7866634
221,aXhyra/emotion_trained_31415,0.77733743
222,aXhyra/presentation_emotion_31415,0.7726164
223,aXhyra/presentation_emotion_31415,0.7656403
224,Recognai/bert-base-spanish-wwm-cased-xnli,0.7046057
225,Recognai/bert-base-spanish-wwm-cased-xnli,0.7037197
226,anirudh21/bert-base-uncased-finetuned-qnli,0.7869766
227,anirudh21/bert-base-uncased-finetuned-qnli,0.7869766
228,aXhyra/demo_sentiment_31415,0.7813897
229,aXhyra/demo_sentiment_31415,0.7700292
230,aXhyra/presentation_sentiment_1234567,0.79805815
231,aXhyra/presentation_sentiment_1234567,0.7854438
232,jb2k/bert-base-multilingual-cased-language-detection,0.7249139
233,jb2k/bert-base-multilingual-cased-language-detection,0.7025468
234,vinai/bertweet-base,0.7739607
235,vinai/bertweet-base,0.768682
236,justinqbui/bertweet-covid19-base-uncased-pretraining-covid-vaccine-tweets,0.7877128
237,justinqbui/bertweet-covid19-base-uncased-pretraining-covid-vaccine-tweets,0.7716128
238,vinai/bertweet-covid19-base-cased,0.76592904
239,vinai/bertweet-covid19-base-cased,0.76286
240,vinai/bertweet-covid19-base-uncased,0.78646934
241,vinai/bertweet-covid19-base-uncased,0.7723331
242,distilbert-base-uncased,0.7746228
243,distilbert-base-uncased,0.7697005
244,bert-base-uncased,0.7889357
245,bert-base-uncased,0.784392
246,roberta-base,0.80383706
247,roberta-base,0.7938219
248,bert-base-cased,0.7953643
249,bert-base-cased,0.76388085
250,dhimskyy/wiki-bert,0.6965133
251,dhimskyy/wiki-bert,0.6657376
252,michiyasunaga/LinkBERT-base,0.77403027
253,michiyasunaga/LinkBERT-base,0.7783201
254,bert-large-uncased,0.7787826
255,bert-large-uncased,0.7413137
256,roberta-large,0.81168926
257,roberta-large,0.7340432
258,boychaboy/MNLI_roberta-base,0.8030508
259,boychaboy/MNLI_roberta-base,0.79365134
260,ishan/bert-base-uncased-mnli,0.7931563
261,ishan/bert-base-uncased-mnli,0.7792809
262,emrecan/bert-base-multilingual-cased-snli_tr,0.74960625
263,emrecan/bert-base-multilingual-cased-snli_tr,0.7398271
264,elozano/tweet_offensive_eval,0.68502444
265,elozano/tweet_offensive_eval,0.67955774
266,Hate-speech-CNERG/bert-base-uncased-hatexplain-rationale-two,0.7837188
267,Hate-speech-CNERG/bert-base-uncased-hatexplain-rationale-two,0.7811548
268,aychang/bert-base-cased-trec-coarse,0.78705454
269,aychang/bert-base-cased-trec-coarse,0.76386464
270,gchhablani/bert-base-cased-finetuned-wnli,0.77306336
271,gchhablani/bert-base-cased-finetuned-wnli,0.77427554
272,w11wo/sundanese-bert-base-emotion-classifier,0.68842006
273,w11wo/sundanese-bert-base-emotion-classifier,0.6646651
274,gchhablani/bert-base-cased-finetuned-rte,0.79209083
275,gchhablani/bert-base-cased-finetuned-rte,0.77753454
276,mrm8488/electricidad-base-finetuned-pawsx-es,0.70746624
277,mrm8488/electricidad-base-finetuned-pawsx-es,0.71011674
278,manueltonneau/bert-twitter-en-is-hired,0.7871118
279,manueltonneau/bert-twitter-en-is-hired,0.7900461
280,Guscode/DKbert-hatespeech-detection,0.65454483
281,Guscode/DKbert-hatespeech-detection,0.6490697
