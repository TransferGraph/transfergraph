,model,score
0,Jeevesh8/init_bert_ft_qqp-33,0.75401783
1,Jeevesh8/init_bert_ft_qqp-33,0.7272693
2,Jeevesh8/init_bert_ft_qqp-49,0.76162326
3,Jeevesh8/init_bert_ft_qqp-49,0.73830956
4,connectivity/bert_ft_qqp-7,0.7684054
5,connectivity/bert_ft_qqp-7,0.65068007
6,Jeevesh8/bert_ft_qqp-40,0.7657742
7,Jeevesh8/bert_ft_qqp-40,0.7423707
8,Jeevesh8/bert_ft_qqp-9,0.76411414
9,Jeevesh8/bert_ft_qqp-9,0.7384203
10,Jeevesh8/bert_ft_qqp-88,0.7662039
11,Jeevesh8/bert_ft_qqp-88,0.75539994
12,connectivity/bert_ft_qqp-25,0.77358776
13,connectivity/bert_ft_qqp-25,0.7420554
14,Jeevesh8/bert_ft_qqp-55,0.76856506
15,Jeevesh8/bert_ft_qqp-55,0.74864054
16,connectivity/bert_ft_qqp-1,0.7709785
17,connectivity/bert_ft_qqp-1,0.75655824
18,Jeevesh8/bert_ft_qqp-39,0.760483
19,Jeevesh8/bert_ft_qqp-39,0.7579836
20,connectivity/bert_ft_qqp-94,0.7697928
21,connectivity/bert_ft_qqp-94,0.7602202
22,connectivity/bert_ft_qqp-96,0.76081246
23,connectivity/bert_ft_qqp-96,0.7412275
24,Jeevesh8/init_bert_ft_qqp-24,0.7661048
25,Jeevesh8/init_bert_ft_qqp-24,0.73728555
26,Jeevesh8/bert_ft_qqp-68,0.7673562
27,Jeevesh8/bert_ft_qqp-68,0.73944765
28,Jeevesh8/init_bert_ft_qqp-28,0.74950814
29,Jeevesh8/init_bert_ft_qqp-28,0.7518897
30,connectivity/bert_ft_qqp-17,0.75094897
31,connectivity/bert_ft_qqp-17,0.74507123
32,ali2066/finetuned_sentence_itr1_2e-05_all_26_02_2022-04_03_26,0.7461874
33,ali2066/finetuned_sentence_itr1_2e-05_all_26_02_2022-04_03_26,0.74128735
34,SetFit/distilbert-base-uncased__sst2__train-16-0,0.76751393
35,SetFit/distilbert-base-uncased__sst2__train-16-0,0.760614
36,aviator-neural/bert-base-uncased-sst2,0.74236864
37,aviator-neural/bert-base-uncased-sst2,0.7175157
38,SetFit/distilbert-base-uncased__sst2__train-32-9,0.7659826
39,SetFit/distilbert-base-uncased__sst2__train-32-9,0.7468282
40,Alassea/glue_sst_classifier,0.7749814
41,Alassea/glue_sst_classifier,0.7609201
42,philschmid/tiny-distilbert-classification,0.495646
43,philschmid/tiny-distilbert-classification,0.4884638
44,moshew/bert-mini-sst2-distilled,0.7008865
45,moshew/bert-mini-sst2-distilled,0.72595066
46,ChrisUPM/BioBERT_Re_trained,0.7284375
47,ChrisUPM/BioBERT_Re_trained,0.7168178
48,vaariis/distilbert-base-uncased-finetuned-emotion,0.75299007
49,vaariis/distilbert-base-uncased-finetuned-emotion,0.741111
50,marcelcastrobr/sagemaker-distilbert-emotion,0.7610579
51,marcelcastrobr/sagemaker-distilbert-emotion,0.76295644
52,jasonyim2/distilbert-base-uncased-finetuned-emotion,0.7554179
53,jasonyim2/distilbert-base-uncased-finetuned-emotion,0.75651336
54,abdelkader/distilbert-base-uncased-finetuned-emotion,0.77333325
55,abdelkader/distilbert-base-uncased-finetuned-emotion,0.75332075
56,moghis/distilbert-base-uncased-finetuned-emotion,0.7648776
57,moghis/distilbert-base-uncased-finetuned-emotion,0.74126333
58,uygarkurt/distilbert-base-uncased-finetuned-emotion,0.7807292
59,uygarkurt/distilbert-base-uncased-finetuned-emotion,0.75180644
60,neibla/distilbert-base-uncased-finetuned-emotion,0.757989
61,neibla/distilbert-base-uncased-finetuned-emotion,0.75955176
62,JB173/distilbert-base-uncased-finetuned-emotion,0.74914235
63,JB173/distilbert-base-uncased-finetuned-emotion,0.74354446
64,Nanatan/distilbert-base-uncased-finetuned-emotion,0.7744559
65,Nanatan/distilbert-base-uncased-finetuned-emotion,0.7694788
66,heranm/finetuning-sentiment-model-3000-samples,0.76238406
67,heranm/finetuning-sentiment-model-3000-samples,0.7357954
68,PrasunMishra/finetuning-sentiment-model-3000-samples,0.767362
69,PrasunMishra/finetuning-sentiment-model-3000-samples,0.7479434
70,yukta10/finetuning-sentiment-model-3000-samples,0.78139037
71,yukta10/finetuning-sentiment-model-3000-samples,0.76549876
72,ncduy/roberta-imdb-sentiment-analysis,0.7864513
73,ncduy/roberta-imdb-sentiment-analysis,0.7850741
74,markt23917/finetuning-sentiment-model-3000-samples,0.76833355
75,markt23917/finetuning-sentiment-model-3000-samples,0.74871314
76,juliensimon/autonlp-imdb-demo-hf-16622767,0.77548474
77,juliensimon/autonlp-imdb-demo-hf-16622767,0.7415562
78,fabriceyhc/bert-base-uncased-imdb,0.74020153
79,fabriceyhc/bert-base-uncased-imdb,0.7169242
80,riyadhctg/distilbert-base-uncased-finetuned-cola,0.75446
81,riyadhctg/distilbert-base-uncased-finetuned-cola,0.74143857
82,connectivity/cola_6ep_ft-33,0.76067483
83,connectivity/cola_6ep_ft-33,0.74763596
84,connectivity/cola_6ep_ft-22,0.7844975
85,connectivity/cola_6ep_ft-22,0.77078325
86,isakbos/Q8BERT_COLA_L_512,0.6422141
87,isakbos/Q8BERT_COLA_L_512,0.5669455
88,jaesun/distilbert-base-uncased-finetuned-cola,0.76389486
89,jaesun/distilbert-base-uncased-finetuned-cola,0.766622
90,usami/distilbert-base-uncased-finetuned-cola,0.7822083
91,usami/distilbert-base-uncased-finetuned-cola,0.7575343
92,Jeevesh8/512seq_len_6ep_bert_ft_cola-91,0.7637782
93,Jeevesh8/512seq_len_6ep_bert_ft_cola-91,0.7450779
94,Jeevesh8/6ep_bert_ft_cola-47,0.76541793
95,Jeevesh8/6ep_bert_ft_cola-47,0.75243837
96,connectivity/cola_6ep_ft-10,0.78036284
97,connectivity/cola_6ep_ft-10,0.76713175
98,Jeevesh8/6ep_bert_ft_cola-12,0.7783848
99,Jeevesh8/6ep_bert_ft_cola-12,0.7633557
100,Jeevesh8/bert_ft_cola-88,0.77307314
101,Jeevesh8/bert_ft_cola-88,0.7637434
102,Jeevesh8/6ep_bert_ft_cola-29,0.75240386
103,Jeevesh8/6ep_bert_ft_cola-29,0.7545582
104,vesteinn/XLMR-ENIS-finetuned-cola,0.7537501
105,vesteinn/XLMR-ENIS-finetuned-cola,0.7544985
106,navsad/navid_test_bert,0.7573586
107,navsad/navid_test_bert,0.760844
108,Jeevesh8/bert_ft_cola-60,0.75893587
109,Jeevesh8/bert_ft_cola-60,0.74939495
110,dapang/distilroberta-base-mic-sym,0.78209585
111,dapang/distilroberta-base-mic-sym,0.7577913
112,Capreolus/bert-base-msmarco,0.7673406
113,Capreolus/bert-base-msmarco,0.7378978
114,Splend1dchan/bert-base-uncased-slue-goldtrascription-e3-lr1e-4,0.7649429
115,Splend1dchan/bert-base-uncased-slue-goldtrascription-e3-lr1e-4,0.7591542
116,Jeevesh8/feather_berts_46,0.76568645
117,Jeevesh8/feather_berts_46,0.7598201
118,JonatanGk/roberta-base-bne-finetuned-cyberbullying-spanish,0.6022906
119,JonatanGk/roberta-base-bne-finetuned-cyberbullying-spanish,0.60219204
120,cambridgeltl/guardian_news_distilbert-base-uncased,0.7609615
121,cambridgeltl/guardian_news_distilbert-base-uncased,0.73558843
122,amyma21/sincere_question_classification,0.77012986
123,amyma21/sincere_question_classification,0.7649482
124,phailyoor/distilbert-base-uncased-finetuned-yahd,0.7407276
125,phailyoor/distilbert-base-uncased-finetuned-yahd,0.724256
126,arianpasquali/distilbert-base-multilingual-cased-toxicity,0.72470003
127,arianpasquali/distilbert-base-multilingual-cased-toxicity,0.70484173
128,connectivity/feather_berts_28,0.77316856
129,connectivity/feather_berts_28,0.7685412
130,liangyuant/distilbert-base-uncased-finetuned-num200-450-405cls,0.7811915
131,liangyuant/distilbert-base-uncased-finetuned-num200-450-405cls,0.7652129
132,DoyyingFace/bert-asian-hate-tweets-asian-unclean-freeze-4,0.76859015
133,DoyyingFace/bert-asian-hate-tweets-asian-unclean-freeze-4,0.76908565
134,Jeevesh8/lecun_feather_berts-3,0.77280605
135,Jeevesh8/lecun_feather_berts-3,0.7629946
136,Giyaseddin/distilroberta-base-finetuned-short-answer-assessment,0.7842188
137,Giyaseddin/distilroberta-base-finetuned-short-answer-assessment,0.7668525
138,AnonymousSub/dummy_2,0.7071159
139,AnonymousSub/dummy_2,0.66860205
140,Jeevesh8/lecun_feather_berts-51,0.77186495
141,Jeevesh8/lecun_feather_berts-51,0.764672
142,viviastaari/finetuning-sentiment-analysis-en-id,0.7109285
143,viviastaari/finetuning-sentiment-analysis-en-id,0.7057632
144,Aureliano/distilbert-base-uncased-if,0.7646447
145,Aureliano/distilbert-base-uncased-if,0.76199377
146,rmihaylov/roberta-base-sentiment-bg,0.72827095
147,rmihaylov/roberta-base-sentiment-bg,0.72578067
148,cardiffnlp/twitter-roberta-base-2021-124m,0.7555474
149,cardiffnlp/twitter-roberta-base-2021-124m,0.7644
150,Jeevesh8/lecun_feather_berts-8,0.77184504
151,Jeevesh8/lecun_feather_berts-8,0.7549496
152,korca/bae-roberta-base-boolq,0.7705376
153,korca/bae-roberta-base-boolq,0.7484214
154,aditeyabaral/finetuned-sail2017-xlm-roberta-base,0.76762784
155,aditeyabaral/finetuned-sail2017-xlm-roberta-base,0.76126313
156,joebobby/finetuning-sentiment-model-5000-samples3,0.77226347
157,joebobby/finetuning-sentiment-model-5000-samples3,0.7547001
158,Jeevesh8/feather_berts_92,0.7709157
159,Jeevesh8/feather_berts_92,0.75713974
160,ASCCCCCCCC/distilbert-base-chinese-amazon_zh_20000,0.6755489
161,ASCCCCCCCC/distilbert-base-chinese-amazon_zh_20000,0.6773522
162,matthewburke/korean_sentiment,0.6813928
163,matthewburke/korean_sentiment,0.6778582
164,IMSyPP/hate_speech_nl,0.61410177
165,IMSyPP/hate_speech_nl,0.603614
166,cointegrated/roberta-base-formality,0.78185636
167,cointegrated/roberta-base-formality,0.7723084
168,IMSyPP/hate_speech_it,0.6868805
169,IMSyPP/hate_speech_it,0.6816196
170,18811449050/bert_finetuning_test,0.7371747
171,18811449050/bert_finetuning_test,0.7320428
172,finiteautomata/betonews-tweetcontext,0.6744841
173,finiteautomata/betonews-tweetcontext,0.67010206
174,Jeevesh8/feather_berts_96,0.77018493
175,Jeevesh8/feather_berts_96,0.7701215
176,Jeevesh8/lecun_feather_berts-7,0.77185804
177,Jeevesh8/lecun_feather_berts-7,0.76282746
178,mrm8488/codebert-base-finetuned-detect-insecure-code,0.74024945
179,mrm8488/codebert-base-finetuned-detect-insecure-code,0.7113099
180,socialmediaie/TRAC2020_IBEN_B_bert-base-multilingual-uncased,0.72666633
181,socialmediaie/TRAC2020_IBEN_B_bert-base-multilingual-uncased,0.7014065
182,zenkri/autotrain-Arabic_Poetry_by_Subject-920730230,0.7722912
183,zenkri/autotrain-Arabic_Poetry_by_Subject-920730230,0.76730895
184,M47Labs/spanish_news_classification_headlines_untrained,0.6864077
185,M47Labs/spanish_news_classification_headlines_untrained,0.6953985
186,bondi/bert-semaphore-prediction-w4,0.68397224
187,bondi/bert-semaphore-prediction-w4,0.67408687
188,classla/bcms-bertic-parlasent-bcs-ter,0.7145714
189,classla/bcms-bertic-parlasent-bcs-ter,0.6945032
190,anferico/bert-for-patents,0.71445006
191,anferico/bert-for-patents,0.6921709
192,ali2066/DistilBERTFINAL_ctxSentence_TRAIN_editorials_TEST_NULL_second_train_set_null_False,0.7764375
193,ali2066/DistilBERTFINAL_ctxSentence_TRAIN_editorials_TEST_NULL_second_train_set_null_False,0.7751822
194,anvay/finetuning-cardiffnlp-sentiment-model,0.79108006
195,anvay/finetuning-cardiffnlp-sentiment-model,0.76877457
196,JonatanGk/roberta-base-ca-finetuned-hate-speech-offensive-catalan,0.6704258
197,JonatanGk/roberta-base-ca-finetuned-hate-speech-offensive-catalan,0.66002023
198,Raychanan/COVID_RandomOver,0.5239911
199,Raychanan/COVID_RandomOver,0.51760364
200,kyleinincubated/autonlp-cat333-624217911,0.6841885
201,kyleinincubated/autonlp-cat333-624217911,0.6843835
202,cardiffnlp/bertweet-base-stance-climate,0.7486975
203,cardiffnlp/bertweet-base-stance-climate,0.7369966
204,nurkayevaa/autonlp-bert-covid-407910458,0.7631307
205,nurkayevaa/autonlp-bert-covid-407910458,0.74228966
206,SetFit/distilbert-base-uncased__hate_speech_offensive__train-16-1,0.77895415
207,SetFit/distilbert-base-uncased__hate_speech_offensive__train-16-1,0.7561229
208,crcb/isear_bert,0.76716864
209,crcb/isear_bert,0.7459254
210,robertou2/roberta-base-bne-finetuned-amazon_reviews_multi,0.7040918
211,robertou2/roberta-base-bne-finetuned-amazon_reviews_multi,0.7005981
212,milyiyo/selectra-small-finetuned-amazon-review,0.65050876
213,milyiyo/selectra-small-finetuned-amazon-review,0.6307657
214,Anthos23/FS-distilroberta-fine-tuned,0.7642153
215,Anthos23/FS-distilroberta-fine-tuned,0.75631934
216,oferweintraub/bert-base-finance-sentiment-noisy-search,0.7603003
217,oferweintraub/bert-base-finance-sentiment-noisy-search,0.7550283
218,pietrotrope/emotion_final,0.7442039
219,pietrotrope/emotion_final,0.73879266
220,aXhyra/emotion_trained_31415,0.75720483
221,aXhyra/emotion_trained_31415,0.75825787
222,aXhyra/presentation_emotion_31415,0.7600043
223,aXhyra/presentation_emotion_31415,0.7395317
224,Recognai/bert-base-spanish-wwm-cased-xnli,0.68134546
225,Recognai/bert-base-spanish-wwm-cased-xnli,0.68007743
226,anirudh21/bert-base-uncased-finetuned-qnli,0.77014065
227,anirudh21/bert-base-uncased-finetuned-qnli,0.77014065
228,aXhyra/demo_sentiment_31415,0.75850576
229,aXhyra/demo_sentiment_31415,0.743923
230,aXhyra/presentation_sentiment_1234567,0.7760365
231,aXhyra/presentation_sentiment_1234567,0.7557689
232,jb2k/bert-base-multilingual-cased-language-detection,0.6998399
233,jb2k/bert-base-multilingual-cased-language-detection,0.68988186
234,vinai/bertweet-base,0.7394024
235,vinai/bertweet-base,0.73338675
236,justinqbui/bertweet-covid19-base-uncased-pretraining-covid-vaccine-tweets,0.7531492
237,justinqbui/bertweet-covid19-base-uncased-pretraining-covid-vaccine-tweets,0.7164326
238,vinai/bertweet-covid19-base-cased,0.74930376
239,vinai/bertweet-covid19-base-cased,0.7546422
240,vinai/bertweet-covid19-base-uncased,0.77461773
241,vinai/bertweet-covid19-base-uncased,0.7586357
242,distilbert-base-uncased,0.7638311
243,distilbert-base-uncased,0.7375467
244,bert-base-uncased,0.7790368
245,bert-base-uncased,0.75630134
246,roberta-base,0.77086425
247,roberta-base,0.7640032
248,bert-base-cased,0.77432036
249,bert-base-cased,0.7500067
250,dhimskyy/wiki-bert,0.6638004
251,dhimskyy/wiki-bert,0.6340907
252,michiyasunaga/LinkBERT-base,0.7589854
253,michiyasunaga/LinkBERT-base,0.7599093
254,bert-large-uncased,0.7627807
255,bert-large-uncased,0.7168247
256,roberta-large,0.77952915
257,roberta-large,0.7345775
258,boychaboy/MNLI_roberta-base,0.78020614
259,boychaboy/MNLI_roberta-base,0.76352704
260,ishan/bert-base-uncased-mnli,0.77163106
261,ishan/bert-base-uncased-mnli,0.7494622
262,emrecan/bert-base-multilingual-cased-snli_tr,0.74518514
263,emrecan/bert-base-multilingual-cased-snli_tr,0.7371157
264,elozano/tweet_offensive_eval,0.6447231
265,elozano/tweet_offensive_eval,0.6502014
266,Hate-speech-CNERG/bert-base-uncased-hatexplain-rationale-two,0.7722206
267,Hate-speech-CNERG/bert-base-uncased-hatexplain-rationale-two,0.7563751
268,aychang/bert-base-cased-trec-coarse,0.75547564
269,aychang/bert-base-cased-trec-coarse,0.741851
270,gchhablani/bert-base-cased-finetuned-wnli,0.7559631
271,gchhablani/bert-base-cased-finetuned-wnli,0.7438361
272,w11wo/sundanese-bert-base-emotion-classifier,0.6656387
273,w11wo/sundanese-bert-base-emotion-classifier,0.65252787
274,gchhablani/bert-base-cased-finetuned-rte,0.76650625
275,gchhablani/bert-base-cased-finetuned-rte,0.76025605
276,mrm8488/electricidad-base-finetuned-pawsx-es,0.67940325
277,mrm8488/electricidad-base-finetuned-pawsx-es,0.6808838
278,manueltonneau/bert-twitter-en-is-hired,0.76396585
279,manueltonneau/bert-twitter-en-is-hired,0.765057
280,Guscode/DKbert-hatespeech-detection,0.65274614
281,Guscode/DKbert-hatespeech-detection,0.629128
