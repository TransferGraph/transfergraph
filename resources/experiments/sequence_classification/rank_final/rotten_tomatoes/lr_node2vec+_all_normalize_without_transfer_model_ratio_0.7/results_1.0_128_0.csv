,model,score
0,milyiyo/selectra-small-finetuned-amazon-review,0.4591092703845002
1,robertou2/roberta-base-bne-finetuned-amazon_reviews_multi,0.6227880004559215
2,SetFit/distilbert-base-uncased__hate_speech_offensive__train-16-1,0.7884842976151522
3,vinai/bertweet-covid19-base-cased,0.670971648811701
4,vinai/bertweet-covid19-base-uncased,0.8544196864808413
5,justinqbui/bertweet-covid19-base-uncased-pretraining-covid-vaccine-tweets,0.8223908041500605
6,jb2k/bert-base-multilingual-cased-language-detection,0.6076400303643734
7,jasonyim2/distilbert-base-uncased-finetuned-emotion,0.8138967618836106
8,marcelcastrobr/sagemaker-distilbert-emotion,0.8096602621089407
9,vaariis/distilbert-base-uncased-finetuned-emotion,0.8201310671636992
10,Nanatan/distilbert-base-uncased-finetuned-emotion,0.7979749678520108
11,riyadhctg/distilbert-base-uncased-finetuned-cola,0.735013000519174
12,connectivity/cola_6ep_ft-33,0.7972624141567581
13,connectivity/cola_6ep_ft-22,0.807296527993119
14,vesteinn/XLMR-ENIS-finetuned-cola,0.774413683058738
15,Jeevesh8/512seq_len_6ep_bert_ft_cola-91,0.7631487081198651
16,jaesun/distilbert-base-uncased-finetuned-cola,0.707444641123679
17,Jeevesh8/6ep_bert_ft_cola-29,0.773218174150055
18,Jeevesh8/bert_ft_cola-60,0.768676998273337
19,navsad/navid_test_bert,0.7526707890751337
20,isakbos/Q8BERT_COLA_L_512,0.5086986453083832
21,ishan/bert-base-uncased-mnli,0.8067776360724336
22,boychaboy/MNLI_roberta-base,0.8684140444583298
23,Alireza1044/albert-base-v2-qnli,0.7585993700778874
24,Jeevesh8/init_bert_ft_qqp-33,0.7655689441758031
25,Jeevesh8/init_bert_ft_qqp-49,0.7848061067933584
26,Jeevesh8/bert_ft_qqp-88,0.8169429727153594
27,Jeevesh8/bert_ft_qqp-9,0.7880192467081389
28,connectivity/bert_ft_qqp-17,0.7973025241628755
29,Jeevesh8/bert_ft_qqp-55,0.8095196308528471
30,Jeevesh8/bert_ft_qqp-40,0.8099860313359368
31,connectivity/bert_ft_qqp-96,0.7941333076659685
32,connectivity/bert_ft_qqp-25,0.8026896612679905
33,Jeevesh8/bert_ft_qqp-68,0.7821204536384382
34,Jeevesh8/init_bert_ft_qqp-24,0.7929282389895199
35,philschmid/tiny-distilbert-classification,-0.03307363027400223
36,ali2066/finetuned_sentence_itr1_2e-05_all_26_02_2022-04_03_26,0.7600291155411275
37,SetFit/distilbert-base-uncased__sst2__train-16-0,0.8191048287097278
38,gchhablani/fnet-base-finetuned-sst2,0.6682054819994593
39,SetFit/distilbert-base-uncased__sst2__train-32-9,0.8192729539594525
40,Alassea/glue_sst_classifier,0.8234857612764116
41,ChrisUPM/BioBERT_Re_trained,0.705208271529047
42,moshew/bert-mini-sst2-distilled,0.6812798199997981
43,Hate-speech-CNERG/bert-base-uncased-hatexplain-rationale-two,0.8164353029334379
44,PrasunMishra/finetuning-sentiment-model-3000-samples,0.850563811741594
45,heranm/finetuning-sentiment-model-3000-samples,0.8528183508897929
46,yukta10/finetuning-sentiment-model-3000-samples,0.8216884839227416
47,markt23917/finetuning-sentiment-model-3000-samples,0.8413567839192478
48,juliensimon/autonlp-imdb-demo-hf-16622767,0.8189980460667023
49,XSY/albert-base-v2-imdb-calssification,0.7312922695183338
50,fabriceyhc/bert-base-uncased-imdb,0.8007025160429561
51,ncduy/roberta-imdb-sentiment-analysis,0.9156717047161407
52,emrecan/bert-base-multilingual-cased-snli_tr,0.7124619604255609
53,nurkayevaa/autonlp-bert-covid-407910458,0.7976125404158864
54,w11wo/sundanese-bert-base-emotion-classifier,0.4955468557147997
55,JNK789/distilbert-base-uncased-finetuned-tweets-emoji-dataset,-0.07100951410812717
56,pietrotrope/emotion_final,0.7695970845660765
57,aXhyra/presentation_emotion_31415,0.7676213573192107
58,aXhyra/emotion_trained_31415,0.7679997684375347
59,elozano/tweet_offensive_eval,0.44455488106987334
60,aXhyra/demo_sentiment_31415,0.7767913453510524
61,nickmuchi/facebook-data2vec-finetuned-finance-classification,0.7385666580561683
62,bert-base-uncased,0.8290546893962587
63,albert-base-v2,0.7130727504096962
64,dhimskyy/wiki-bert,0.517487303980399
65,michiyasunaga/LinkBERT-base,0.798015412847817
66,bert-base-cased,0.8044019617522657
67,roberta-base,0.895705766526566
68,bert-large-uncased,0.751263991212385
69,roberta-large,0.4525769703226499
70,dapang/distilroberta-base-mic-sym,0.8133971003010603
71,cambridgeltl/guardian_news_distilbert-base-uncased,0.7507612598791178
72,Capreolus/bert-base-msmarco,0.8201170756213103
73,Splend1dchan/bert-base-uncased-slue-goldtrascription-e3-lr1e-4,0.803220166737177
74,Jeevesh8/feather_berts_46,0.8183264093161668
75,amyma21/sincere_question_classification,0.7820574720798888
76,arianpasquali/distilbert-base-multilingual-cased-toxicity,0.6319801059372969
77,chiragasarpota/scotus-bert,0.40736154113140627
78,Giyaseddin/distilroberta-base-finetuned-short-answer-assessment,0.7825632513578107
79,IMSyPP/hate_speech_it,0.6247028580974431
80,Jeevesh8/feather_berts_96,0.8196593727570363
81,18811449050/bert_finetuning_test,0.7018470114063119
82,viviastaari/finetuning-sentiment-analysis-en-id,0.5838697639683109
83,AnonymousSub/dummy_2,0.6651580282954094
84,Jeevesh8/lecun_feather_berts-3,0.7960181693076998
85,rmihaylov/roberta-base-sentiment-bg,0.6223053999847319
86,finiteautomata/betonews-tweetcontext,0.5553490327339415
87,Jeevesh8/lecun_feather_berts-8,0.8172729185578278
88,Jeevesh8/lecun_feather_berts-7,0.8118910565582347
89,IMSyPP/hate_speech_nl,0.3950818461207687
90,cardiffnlp/bertweet-base-stance-climate,0.7665796145619949
91,waboucay/camembert-base-finetuned-xnli_fr-finetuned-nli-rua_wl,0.44556553710742997
92,aditeyabaral/finetuned-sail2017-xlm-roberta-base,0.804114604270334
93,M47Labs/spanish_news_classification_headlines_untrained,0.6013628902946548
94,JonatanGk/roberta-base-ca-finetuned-hate-speech-offensive-catalan,0.5969137615394252
95,cointegrated/roberta-base-formality,0.8483034599176338
96,joebobby/finetuning-sentiment-model-5000-samples3,0.8028006936206732
97,Raychanan/COVID_RandomOver,-0.04087299737545369
98,anvay/finetuning-cardiffnlp-sentiment-model,0.8661762887843325
99,bondi/bert-semaphore-prediction-w4,0.5233216444873742
100,zenkri/autotrain-Arabic_Poetry_by_Subject-920730230,0.798360242512755
101,ASCCCCCCCC/distilbert-base-chinese-amazon_zh_20000,0.5536050778723441
102,warwickai/fin-perceiver,0.7412197645442037
103,liangyuant/distilbert-base-uncased-finetuned-num200-450-405cls,0.7795503952841404
104,Aureliano/distilbert-base-uncased-if,0.7811195599854528
105,matthewburke/korean_sentiment,0.5173174114216884
106,ali2066/DistilBERTFINAL_ctxSentence_TRAIN_editorials_TEST_NULL_second_train_set_null_False,0.871143199286864
107,classla/bcms-bertic-parlasent-bcs-ter,0.6545858369004599
108,fgaim/tiroberta-geezswitch,0.48453755693083606
