,model,score
0,Jeevesh8/init_bert_ft_qqp-33,0.75829643
1,Jeevesh8/init_bert_ft_qqp-33,0.771592
2,Jeevesh8/init_bert_ft_qqp-49,0.7574653
3,Jeevesh8/init_bert_ft_qqp-49,0.6751217
4,connectivity/bert_ft_qqp-7,0.6970168
5,connectivity/bert_ft_qqp-7,0.67697656
6,Jeevesh8/bert_ft_qqp-40,0.7614919
7,Jeevesh8/bert_ft_qqp-40,0.7572724
8,Jeevesh8/bert_ft_qqp-9,0.7755909
9,Jeevesh8/bert_ft_qqp-9,0.72952455
10,Jeevesh8/bert_ft_qqp-88,0.78773004
11,Jeevesh8/bert_ft_qqp-88,0.64387554
12,connectivity/bert_ft_qqp-25,0.7583472
13,connectivity/bert_ft_qqp-25,0.75232816
14,Jeevesh8/bert_ft_qqp-55,0.75841606
15,Jeevesh8/bert_ft_qqp-55,0.65742964
16,connectivity/bert_ft_qqp-1,0.7730214
17,connectivity/bert_ft_qqp-1,0.7318823
18,Jeevesh8/bert_ft_qqp-39,0.8013367
19,Jeevesh8/bert_ft_qqp-39,0.69389164
20,connectivity/bert_ft_qqp-94,0.7636927
21,connectivity/bert_ft_qqp-94,0.7450827
22,connectivity/bert_ft_qqp-96,0.75978047
23,connectivity/bert_ft_qqp-96,0.720906
24,Jeevesh8/init_bert_ft_qqp-24,0.7548341
25,Jeevesh8/init_bert_ft_qqp-24,0.6289265
26,Jeevesh8/bert_ft_qqp-68,0.743543
27,Jeevesh8/bert_ft_qqp-68,0.72642165
28,Jeevesh8/init_bert_ft_qqp-28,0.76655215
29,Jeevesh8/init_bert_ft_qqp-28,0.6454779
30,connectivity/bert_ft_qqp-17,0.7436128
31,connectivity/bert_ft_qqp-17,0.65433645
32,ali2066/finetuned_sentence_itr1_2e-05_all_26_02_2022-04_03_26,0.7430059
33,ali2066/finetuned_sentence_itr1_2e-05_all_26_02_2022-04_03_26,0.75547767
34,SetFit/distilbert-base-uncased__sst2__train-16-0,0.7297236
35,SetFit/distilbert-base-uncased__sst2__train-16-0,0.74470514
36,aviator-neural/bert-base-uncased-sst2,0.76268435
37,aviator-neural/bert-base-uncased-sst2,0.6962696
38,SetFit/distilbert-base-uncased__sst2__train-32-9,0.7410446
39,SetFit/distilbert-base-uncased__sst2__train-32-9,0.7216491
40,Alassea/glue_sst_classifier,0.75209254
41,Alassea/glue_sst_classifier,0.7388097
42,philschmid/tiny-distilbert-classification,0.44902635
43,philschmid/tiny-distilbert-classification,0.44582126
44,moshew/bert-mini-sst2-distilled,0.72092587
45,moshew/bert-mini-sst2-distilled,0.6688323
46,ChrisUPM/BioBERT_Re_trained,0.7241856
47,ChrisUPM/BioBERT_Re_trained,0.6432028
48,vaariis/distilbert-base-uncased-finetuned-emotion,0.75411385
49,vaariis/distilbert-base-uncased-finetuned-emotion,0.77399987
50,marcelcastrobr/sagemaker-distilbert-emotion,0.7396286
51,marcelcastrobr/sagemaker-distilbert-emotion,0.75112903
52,jasonyim2/distilbert-base-uncased-finetuned-emotion,0.748091
53,jasonyim2/distilbert-base-uncased-finetuned-emotion,0.75317115
54,abdelkader/distilbert-base-uncased-finetuned-emotion,0.75542057
55,abdelkader/distilbert-base-uncased-finetuned-emotion,0.72217077
56,moghis/distilbert-base-uncased-finetuned-emotion,0.74635357
57,moghis/distilbert-base-uncased-finetuned-emotion,0.7149417
58,uygarkurt/distilbert-base-uncased-finetuned-emotion,0.75630707
59,uygarkurt/distilbert-base-uncased-finetuned-emotion,0.71475
60,neibla/distilbert-base-uncased-finetuned-emotion,0.74259865
61,neibla/distilbert-base-uncased-finetuned-emotion,0.6843486
62,JB173/distilbert-base-uncased-finetuned-emotion,0.7509125
63,JB173/distilbert-base-uncased-finetuned-emotion,0.7354991
64,Nanatan/distilbert-base-uncased-finetuned-emotion,0.73493624
65,Nanatan/distilbert-base-uncased-finetuned-emotion,0.73706496
66,heranm/finetuning-sentiment-model-3000-samples,0.75287783
67,heranm/finetuning-sentiment-model-3000-samples,0.75891685
68,PrasunMishra/finetuning-sentiment-model-3000-samples,0.75757754
69,PrasunMishra/finetuning-sentiment-model-3000-samples,0.7689378
70,yukta10/finetuning-sentiment-model-3000-samples,0.7508746
71,yukta10/finetuning-sentiment-model-3000-samples,0.74178916
72,ncduy/roberta-imdb-sentiment-analysis,0.78511256
73,ncduy/roberta-imdb-sentiment-analysis,0.76270866
74,markt23917/finetuning-sentiment-model-3000-samples,0.7680117
75,markt23917/finetuning-sentiment-model-3000-samples,0.7369539
76,juliensimon/autonlp-imdb-demo-hf-16622767,0.7583287
77,juliensimon/autonlp-imdb-demo-hf-16622767,0.761137
78,fabriceyhc/bert-base-uncased-imdb,0.7321774
79,fabriceyhc/bert-base-uncased-imdb,0.6343066
80,riyadhctg/distilbert-base-uncased-finetuned-cola,0.7305028
81,riyadhctg/distilbert-base-uncased-finetuned-cola,0.73672897
82,connectivity/cola_6ep_ft-33,0.7672974
83,connectivity/cola_6ep_ft-33,0.7166489
84,connectivity/cola_6ep_ft-22,0.7564728
85,connectivity/cola_6ep_ft-22,0.73712164
86,isakbos/Q8BERT_COLA_L_512,0.59798396
87,isakbos/Q8BERT_COLA_L_512,0.5840111
88,jaesun/distilbert-base-uncased-finetuned-cola,0.7352526
89,jaesun/distilbert-base-uncased-finetuned-cola,0.72474885
90,usami/distilbert-base-uncased-finetuned-cola,0.7470256
91,usami/distilbert-base-uncased-finetuned-cola,0.72005105
92,Jeevesh8/512seq_len_6ep_bert_ft_cola-91,0.77034473
93,Jeevesh8/512seq_len_6ep_bert_ft_cola-91,0.6574575
94,Jeevesh8/6ep_bert_ft_cola-47,0.77465844
95,Jeevesh8/6ep_bert_ft_cola-47,0.717674
96,connectivity/cola_6ep_ft-10,0.757838
97,connectivity/cola_6ep_ft-10,0.74074847
98,Jeevesh8/6ep_bert_ft_cola-12,0.7626614
99,Jeevesh8/6ep_bert_ft_cola-12,0.7362357
100,Jeevesh8/bert_ft_cola-88,0.7524137
101,Jeevesh8/bert_ft_cola-88,0.70960087
102,Jeevesh8/6ep_bert_ft_cola-29,0.76204735
103,Jeevesh8/6ep_bert_ft_cola-29,0.72392803
104,vesteinn/XLMR-ENIS-finetuned-cola,0.7458648
105,vesteinn/XLMR-ENIS-finetuned-cola,0.7097537
106,navsad/navid_test_bert,0.76981735
107,navsad/navid_test_bert,0.67131823
108,Jeevesh8/bert_ft_cola-60,0.78749347
109,Jeevesh8/bert_ft_cola-60,0.7166009
110,dapang/distilroberta-base-mic-sym,0.77002126
111,dapang/distilroberta-base-mic-sym,0.75555056
112,Capreolus/bert-base-msmarco,0.7482036
113,Capreolus/bert-base-msmarco,0.71817255
114,Splend1dchan/bert-base-uncased-slue-goldtrascription-e3-lr1e-4,0.7550464
115,Splend1dchan/bert-base-uncased-slue-goldtrascription-e3-lr1e-4,0.7258791
116,Jeevesh8/feather_berts_46,0.7912612
117,Jeevesh8/feather_berts_46,0.7491441
118,JonatanGk/roberta-base-bne-finetuned-cyberbullying-spanish,0.6270182
119,JonatanGk/roberta-base-bne-finetuned-cyberbullying-spanish,0.60295755
120,cambridgeltl/guardian_news_distilbert-base-uncased,0.738042
121,cambridgeltl/guardian_news_distilbert-base-uncased,0.66234004
122,amyma21/sincere_question_classification,0.7458449
123,amyma21/sincere_question_classification,0.74810666
124,phailyoor/distilbert-base-uncased-finetuned-yahd,0.7325186
125,phailyoor/distilbert-base-uncased-finetuned-yahd,0.7068266
126,arianpasquali/distilbert-base-multilingual-cased-toxicity,0.71003157
127,arianpasquali/distilbert-base-multilingual-cased-toxicity,0.65498435
128,connectivity/feather_berts_28,0.7644045
129,connectivity/feather_berts_28,0.7572358
130,liangyuant/distilbert-base-uncased-finetuned-num200-450-405cls,0.7620689
131,liangyuant/distilbert-base-uncased-finetuned-num200-450-405cls,0.7565539
132,DoyyingFace/bert-asian-hate-tweets-asian-unclean-freeze-4,0.7675666
133,DoyyingFace/bert-asian-hate-tweets-asian-unclean-freeze-4,0.7496496
134,Jeevesh8/lecun_feather_berts-3,0.76879877
135,Jeevesh8/lecun_feather_berts-3,0.7204209
136,Giyaseddin/distilroberta-base-finetuned-short-answer-assessment,0.7552297
137,Giyaseddin/distilroberta-base-finetuned-short-answer-assessment,0.7480089
138,AnonymousSub/dummy_2,0.7249524
139,AnonymousSub/dummy_2,0.6050322
140,Jeevesh8/lecun_feather_berts-51,0.76977223
141,Jeevesh8/lecun_feather_berts-51,0.73378164
142,viviastaari/finetuning-sentiment-analysis-en-id,0.70101005
143,viviastaari/finetuning-sentiment-analysis-en-id,0.57856596
144,Aureliano/distilbert-base-uncased-if,0.7403751
145,Aureliano/distilbert-base-uncased-if,0.7308499
146,rmihaylov/roberta-base-sentiment-bg,0.70678425
147,rmihaylov/roberta-base-sentiment-bg,0.5691897
148,cardiffnlp/twitter-roberta-base-2021-124m,0.7705384
149,cardiffnlp/twitter-roberta-base-2021-124m,0.780262
150,Jeevesh8/lecun_feather_berts-8,0.7609618
151,Jeevesh8/lecun_feather_berts-8,0.68902874
152,korca/bae-roberta-base-boolq,0.7677643
153,korca/bae-roberta-base-boolq,0.7396608
154,aditeyabaral/finetuned-sail2017-xlm-roberta-base,0.7746341
155,aditeyabaral/finetuned-sail2017-xlm-roberta-base,0.74911666
156,joebobby/finetuning-sentiment-model-5000-samples3,0.775938
157,joebobby/finetuning-sentiment-model-5000-samples3,0.76957166
158,Jeevesh8/feather_berts_92,0.77361053
159,Jeevesh8/feather_berts_92,0.7899652
160,ASCCCCCCCC/distilbert-base-chinese-amazon_zh_20000,0.65733963
161,ASCCCCCCCC/distilbert-base-chinese-amazon_zh_20000,0.64852214
162,matthewburke/korean_sentiment,0.66089237
163,matthewburke/korean_sentiment,0.6202811
164,IMSyPP/hate_speech_nl,0.59943354
165,IMSyPP/hate_speech_nl,0.5478319
166,cointegrated/roberta-base-formality,0.77085114
167,cointegrated/roberta-base-formality,0.77795833
168,IMSyPP/hate_speech_it,0.6452677
169,IMSyPP/hate_speech_it,0.5939233
170,18811449050/bert_finetuning_test,0.76908314
171,18811449050/bert_finetuning_test,0.724894
172,finiteautomata/betonews-tweetcontext,0.65163755
173,finiteautomata/betonews-tweetcontext,0.5556612
174,Jeevesh8/feather_berts_96,0.7746078
175,Jeevesh8/feather_berts_96,0.74499875
176,Jeevesh8/lecun_feather_berts-7,0.7589151
177,Jeevesh8/lecun_feather_berts-7,0.6949612
178,mrm8488/codebert-base-finetuned-detect-insecure-code,0.71918666
179,mrm8488/codebert-base-finetuned-detect-insecure-code,0.68301845
180,socialmediaie/TRAC2020_IBEN_B_bert-base-multilingual-uncased,0.7164441
181,socialmediaie/TRAC2020_IBEN_B_bert-base-multilingual-uncased,0.5978403
182,zenkri/autotrain-Arabic_Poetry_by_Subject-920730230,0.7796603
183,zenkri/autotrain-Arabic_Poetry_by_Subject-920730230,0.68058616
184,M47Labs/spanish_news_classification_headlines_untrained,0.6777042
185,M47Labs/spanish_news_classification_headlines_untrained,0.49317783
186,bondi/bert-semaphore-prediction-w4,0.6663038
187,bondi/bert-semaphore-prediction-w4,0.65038043
188,classla/bcms-bertic-parlasent-bcs-ter,0.64976764
189,classla/bcms-bertic-parlasent-bcs-ter,0.6977801
190,anferico/bert-for-patents,0.72728163
191,anferico/bert-for-patents,0.66882133
192,ali2066/DistilBERTFINAL_ctxSentence_TRAIN_editorials_TEST_NULL_second_train_set_null_False,0.7979849
193,ali2066/DistilBERTFINAL_ctxSentence_TRAIN_editorials_TEST_NULL_second_train_set_null_False,0.7821662
194,anvay/finetuning-cardiffnlp-sentiment-model,0.79248774
195,anvay/finetuning-cardiffnlp-sentiment-model,0.78196985
196,JonatanGk/roberta-base-ca-finetuned-hate-speech-offensive-catalan,0.6688779
197,JonatanGk/roberta-base-ca-finetuned-hate-speech-offensive-catalan,0.5934704
198,Raychanan/COVID_RandomOver,0.46962762
199,Raychanan/COVID_RandomOver,0.43202043
200,kyleinincubated/autonlp-cat333-624217911,0.73319227
201,kyleinincubated/autonlp-cat333-624217911,0.66270995
202,cardiffnlp/bertweet-base-stance-climate,0.76736516
203,cardiffnlp/bertweet-base-stance-climate,0.7048461
204,nurkayevaa/autonlp-bert-covid-407910458,0.7394116
205,nurkayevaa/autonlp-bert-covid-407910458,0.7409427
206,SetFit/distilbert-base-uncased__hate_speech_offensive__train-16-1,0.7621243
207,SetFit/distilbert-base-uncased__hate_speech_offensive__train-16-1,0.7304929
208,crcb/isear_bert,0.76783854
209,crcb/isear_bert,0.76867217
210,robertou2/roberta-base-bne-finetuned-amazon_reviews_multi,0.7082651
211,robertou2/roberta-base-bne-finetuned-amazon_reviews_multi,0.6980503
212,milyiyo/selectra-small-finetuned-amazon-review,0.68499845
213,milyiyo/selectra-small-finetuned-amazon-review,0.65002286
214,Anthos23/FS-distilroberta-fine-tuned,0.7709841
215,Anthos23/FS-distilroberta-fine-tuned,0.77314246
216,oferweintraub/bert-base-finance-sentiment-noisy-search,0.7859375
217,oferweintraub/bert-base-finance-sentiment-noisy-search,0.7305319
218,pietrotrope/emotion_final,0.762617
219,pietrotrope/emotion_final,0.7283445
220,aXhyra/emotion_trained_31415,0.72976804
221,aXhyra/emotion_trained_31415,0.7701281
222,aXhyra/presentation_emotion_31415,0.7470493
223,aXhyra/presentation_emotion_31415,0.752848
224,Recognai/bert-base-spanish-wwm-cased-xnli,0.69536114
225,Recognai/bert-base-spanish-wwm-cased-xnli,0.6838022
226,anirudh21/bert-base-uncased-finetuned-qnli,0.7693368
227,anirudh21/bert-base-uncased-finetuned-qnli,0.743236
228,aXhyra/demo_sentiment_31415,0.7521282
229,aXhyra/demo_sentiment_31415,0.7121464
230,aXhyra/presentation_sentiment_1234567,0.749701
231,aXhyra/presentation_sentiment_1234567,0.7417861
232,jb2k/bert-base-multilingual-cased-language-detection,0.72480357
233,jb2k/bert-base-multilingual-cased-language-detection,0.5608538
234,vinai/bertweet-base,0.779333
235,vinai/bertweet-base,0.7496414
236,justinqbui/bertweet-covid19-base-uncased-pretraining-covid-vaccine-tweets,0.7626452
237,justinqbui/bertweet-covid19-base-uncased-pretraining-covid-vaccine-tweets,0.7483156
238,vinai/bertweet-covid19-base-cased,0.7740252
239,vinai/bertweet-covid19-base-cased,0.7736241
240,vinai/bertweet-covid19-base-uncased,0.74856156
241,vinai/bertweet-covid19-base-uncased,0.7770405
242,distilbert-base-uncased,0.75975144
243,distilbert-base-uncased,0.74216455
244,bert-base-uncased,0.75561345
245,bert-base-uncased,0.69206387
246,roberta-base,0.7983956
247,roberta-base,0.7505284
248,bert-base-cased,0.7415833
249,bert-base-cased,0.713489
250,dhimskyy/wiki-bert,0.6492432
251,dhimskyy/wiki-bert,0.49689686
252,michiyasunaga/LinkBERT-base,0.7376368
253,michiyasunaga/LinkBERT-base,0.63890284
254,bert-large-uncased,0.7630551
255,bert-large-uncased,0.72459733
256,roberta-large,0.65094733
257,roberta-large,0.8108909
258,boychaboy/MNLI_roberta-base,0.78906417
259,boychaboy/MNLI_roberta-base,0.77729595
260,ishan/bert-base-uncased-mnli,0.7702072
261,ishan/bert-base-uncased-mnli,0.7651351
262,emrecan/bert-base-multilingual-cased-snli_tr,0.7395868
263,emrecan/bert-base-multilingual-cased-snli_tr,0.7061486
264,elozano/tweet_offensive_eval,0.6341535
265,elozano/tweet_offensive_eval,0.5832865
266,Hate-speech-CNERG/bert-base-uncased-hatexplain-rationale-two,0.78866446
267,Hate-speech-CNERG/bert-base-uncased-hatexplain-rationale-two,0.7050282
268,aychang/bert-base-cased-trec-coarse,0.7606693
269,aychang/bert-base-cased-trec-coarse,0.7588643
270,gchhablani/bert-base-cased-finetuned-wnli,0.75487566
271,gchhablani/bert-base-cased-finetuned-wnli,0.6883321
272,w11wo/sundanese-bert-base-emotion-classifier,0.61846155
273,w11wo/sundanese-bert-base-emotion-classifier,0.50653905
274,gchhablani/bert-base-cased-finetuned-rte,0.7588801
275,gchhablani/bert-base-cased-finetuned-rte,0.74444455
276,mrm8488/electricidad-base-finetuned-pawsx-es,0.6424425
277,mrm8488/electricidad-base-finetuned-pawsx-es,0.5775137
278,manueltonneau/bert-twitter-en-is-hired,0.7645914
279,manueltonneau/bert-twitter-en-is-hired,0.6931533
280,Guscode/DKbert-hatespeech-detection,0.64654636
281,Guscode/DKbert-hatespeech-detection,0.531193
