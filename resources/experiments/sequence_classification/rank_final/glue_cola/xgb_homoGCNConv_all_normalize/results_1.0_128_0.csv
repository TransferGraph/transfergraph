,model,score
0,Jeevesh8/init_bert_ft_qqp-33,0.7732285
1,Jeevesh8/init_bert_ft_qqp-49,0.76990473
2,connectivity/bert_ft_qqp-7,0.77472067
3,Jeevesh8/bert_ft_qqp-40,0.77758646
4,Jeevesh8/bert_ft_qqp-9,0.7822553
5,Jeevesh8/bert_ft_qqp-88,0.7871929
6,connectivity/bert_ft_qqp-25,0.7732285
7,Jeevesh8/bert_ft_qqp-55,0.78133464
8,connectivity/bert_ft_qqp-1,0.78133464
9,Jeevesh8/bert_ft_qqp-39,0.7848799
10,connectivity/bert_ft_qqp-94,0.7732285
11,connectivity/bert_ft_qqp-96,0.7732285
12,Jeevesh8/init_bert_ft_qqp-24,0.77758646
13,Jeevesh8/bert_ft_qqp-68,0.77472067
14,Jeevesh8/init_bert_ft_qqp-28,0.78688127
15,connectivity/bert_ft_qqp-17,0.77472067
16,ali2066/finetuned_sentence_itr1_2e-05_all_26_02_2022-04_03_26,0.7622861
17,SetFit/distilbert-base-uncased__sst2__train-16-0,0.76700616
18,gchhablani/fnet-base-finetuned-sst2,0.760362
19,aviator-neural/bert-base-uncased-sst2,0.8011824
20,SetFit/distilbert-base-uncased__sst2__train-32-9,0.76779723
21,Alassea/glue_sst_classifier,0.8038163
22,philschmid/tiny-distilbert-classification,0.4510295
23,moshew/bert-mini-sst2-distilled,0.7709179
24,ChrisUPM/BioBERT_Re_trained,0.7518651
25,vaariis/distilbert-base-uncased-finetuned-emotion,0.74172467
26,marcelcastrobr/sagemaker-distilbert-emotion,0.73734015
27,jasonyim2/distilbert-base-uncased-finetuned-emotion,0.7429101
28,abdelkader/distilbert-base-uncased-finetuned-emotion,0.7347179
29,moghis/distilbert-base-uncased-finetuned-emotion,0.7699152
30,uygarkurt/distilbert-base-uncased-finetuned-emotion,0.7724061
31,neibla/distilbert-base-uncased-finetuned-emotion,0.7397627
32,JB173/distilbert-base-uncased-finetuned-emotion,0.76532865
33,Nanatan/distilbert-base-uncased-finetuned-emotion,0.74162877
34,heranm/finetuning-sentiment-model-3000-samples,0.77641076
35,PrasunMishra/finetuning-sentiment-model-3000-samples,0.7483138
36,yukta10/finetuning-sentiment-model-3000-samples,0.7426951
37,ncduy/roberta-imdb-sentiment-analysis,0.806842
38,markt23917/finetuning-sentiment-model-3000-samples,0.7640666
39,juliensimon/autonlp-imdb-demo-hf-16622767,0.739648
40,fabriceyhc/bert-base-uncased-imdb,0.78203624
41,XSY/albert-base-v2-imdb-calssification,0.7465938
42,riyadhctg/distilbert-base-uncased-finetuned-cola,0.73689157
43,connectivity/cola_6ep_ft-33,0.7669612
44,connectivity/cola_6ep_ft-22,0.76606536
45,gchhablani/fnet-base-finetuned-cola,0.71882993
46,isakbos/Q8BERT_COLA_L_512,0.67724544
47,jaesun/distilbert-base-uncased-finetuned-cola,0.76329345
48,usami/distilbert-base-uncased-finetuned-cola,0.736852
49,Jeevesh8/512seq_len_6ep_bert_ft_cola-91,0.7735752
50,Jeevesh8/6ep_bert_ft_cola-47,0.7767485
51,connectivity/cola_6ep_ft-10,0.76606536
52,Jeevesh8/6ep_bert_ft_cola-12,0.76592135
53,Jeevesh8/bert_ft_cola-88,0.7669612
54,Jeevesh8/6ep_bert_ft_cola-29,0.76729584
55,vesteinn/XLMR-ENIS-finetuned-cola,0.75288427
56,navsad/navid_test_bert,0.7512341
57,Jeevesh8/bert_ft_cola-60,0.7743934
58,dapang/distilroberta-base-mic-sym,0.74137634
59,Capreolus/bert-base-msmarco,0.77084506
60,Splend1dchan/bert-base-uncased-slue-goldtrascription-e3-lr1e-4,0.7684144
61,Jeevesh8/feather_berts_46,0.75943786
62,JonatanGk/roberta-base-bne-finetuned-cyberbullying-spanish,0.63744205
63,cambridgeltl/guardian_news_distilbert-base-uncased,0.71582556
64,amyma21/sincere_question_classification,0.6832272
65,phailyoor/distilbert-base-uncased-finetuned-yahd,0.71300524
66,arianpasquali/distilbert-base-multilingual-cased-toxicity,0.7248107
67,connectivity/feather_berts_28,0.7743715
68,warwickai/fin-perceiver,0.7381008
69,liangyuant/distilbert-base-uncased-finetuned-num200-450-405cls,0.7219545
70,DoyyingFace/bert-asian-hate-tweets-asian-unclean-freeze-4,0.7555232
71,Jeevesh8/lecun_feather_berts-3,0.7743715
72,Giyaseddin/distilroberta-base-finetuned-short-answer-assessment,0.768457
73,AnonymousSub/dummy_2,0.7483416
74,Jeevesh8/lecun_feather_berts-51,0.7743715
75,viviastaari/finetuning-sentiment-analysis-en-id,0.70231956
76,Aureliano/distilbert-base-uncased-if,0.752012
77,rmihaylov/roberta-base-sentiment-bg,0.7109418
78,cardiffnlp/twitter-roberta-base-2021-124m,0.71198934
79,Jeevesh8/lecun_feather_berts-8,0.76832795
80,korca/bae-roberta-base-boolq,0.7798173
81,aditeyabaral/finetuned-sail2017-xlm-roberta-base,0.8007957
82,joebobby/finetuning-sentiment-model-5000-samples3,0.74603
83,YeRyeongLee/electra-base-discriminator-finetuned-filtered-0602,0.4774289
84,Jeevesh8/feather_berts_92,0.7743715
85,ASCCCCCCCC/distilbert-base-chinese-amazon_zh_20000,0.6853604
86,matthewburke/korean_sentiment,0.7231566
87,IMSyPP/hate_speech_nl,0.56700677
88,cointegrated/roberta-base-formality,0.7798173
89,chiragasarpota/scotus-bert,0.45723298
90,IMSyPP/hate_speech_it,0.7035503
91,18811449050/bert_finetuning_test,0.74468535
92,finiteautomata/betonews-tweetcontext,0.65614504
93,Jeevesh8/feather_berts_96,0.7684144
94,Jeevesh8/lecun_feather_berts-7,0.7743715
95,mrm8488/codebert-base-finetuned-detect-insecure-code,0.7548546
96,socialmediaie/TRAC2020_IBEN_B_bert-base-multilingual-uncased,0.75609016
97,zenkri/autotrain-Arabic_Poetry_by_Subject-920730230,0.76307243
98,M47Labs/spanish_news_classification_headlines_untrained,0.7179972
99,bondi/bert-semaphore-prediction-w4,0.66926193
100,classla/bcms-bertic-parlasent-bcs-ter,0.72457665
101,anferico/bert-for-patents,0.74797016
102,waboucay/camembert-base-finetuned-xnli_fr-finetuned-nli-rua_wl,0.56564426
103,ali2066/DistilBERTFINAL_ctxSentence_TRAIN_editorials_TEST_NULL_second_train_set_null_False,0.81509465
104,anvay/finetuning-cardiffnlp-sentiment-model,0.8130786
105,JonatanGk/roberta-base-ca-finetuned-hate-speech-offensive-catalan,0.6848379
106,Raychanan/COVID_RandomOver,0.4129146
107,Monsia/camembert-fr-covid-tweet-classification,0.7260485
108,CAMeL-Lab/bert-base-arabic-camelbert-mix-did-nadi,0.66067696
109,kyleinincubated/autonlp-cat333-624217911,0.7241378
110,CAMeL-Lab/bert-base-arabic-camelbert-da-sentiment,0.51821977
111,cardiffnlp/bertweet-base-stance-climate,0.75609195
112,fgaim/tiroberta-geezswitch,0.68697333
113,nurkayevaa/autonlp-bert-covid-407910458,0.7421728
114,SetFit/distilbert-base-uncased__hate_speech_offensive__train-16-1,0.767645
115,crcb/isear_bert,0.79640293
116,robertou2/roberta-base-bne-finetuned-amazon_reviews_multi,0.7374657
117,milyiyo/selectra-small-finetuned-amazon-review,0.68010265
118,Anthos23/FS-distilroberta-fine-tuned,0.73952556
119,oferweintraub/bert-base-finance-sentiment-noisy-search,0.79289097
120,pietrotrope/emotion_final,0.48068124
121,aXhyra/emotion_trained_31415,0.52218
122,aXhyra/presentation_emotion_31415,0.55211467
123,Recognai/bert-base-spanish-wwm-cased-xnli,0.66803485
124,JNK789/distilbert-base-uncased-finetuned-tweets-emoji-dataset,0.7018624
125,anirudh21/bert-base-uncased-finetuned-qnli,0.80483615
126,Alireza1044/albert-base-v2-qnli,0.755581
127,aXhyra/demo_sentiment_31415,0.7481172
128,aXhyra/presentation_sentiment_1234567,0.74584484
129,jb2k/bert-base-multilingual-cased-language-detection,0.73381615
130,vinai/bertweet-base,0.7306546
131,justinqbui/bertweet-covid19-base-uncased-pretraining-covid-vaccine-tweets,0.72061086
132,vinai/bertweet-covid19-base-cased,0.72061086
133,vinai/bertweet-covid19-base-uncased,0.7217761
134,distilbert-base-uncased,0.76766676
135,bert-base-uncased,0.7804607
136,roberta-base,0.7558166
137,albert-base-v2,0.6518391
138,bert-base-cased,0.7820905
139,dhimskyy/wiki-bert,0.670824
140,michiyasunaga/LinkBERT-base,0.7808569
141,roberta-large,0.69437283
142,bert-large-uncased,0.74978465
143,boychaboy/MNLI_roberta-base,0.8123624
144,ishan/bert-base-uncased-mnli,0.7960796
145,emrecan/bert-base-multilingual-cased-snli_tr,0.7660729
146,elozano/tweet_offensive_eval,0.7486254
147,Hate-speech-CNERG/bert-base-uncased-hatexplain-rationale-two,0.782665
148,aychang/bert-base-cased-trec-coarse,0.7378494
149,gchhablani/bert-base-cased-finetuned-wnli,0.80931705
150,nickmuchi/facebook-data2vec-finetuned-finance-classification,0.7326661
151,w11wo/sundanese-bert-base-emotion-classifier,0.6944452
152,gchhablani/bert-base-cased-finetuned-rte,0.80424625
153,mrm8488/electricidad-base-finetuned-pawsx-es,0.6823198
154,manueltonneau/bert-twitter-en-is-hired,0.777649
155,Guscode/DKbert-hatespeech-detection,0.6427008
