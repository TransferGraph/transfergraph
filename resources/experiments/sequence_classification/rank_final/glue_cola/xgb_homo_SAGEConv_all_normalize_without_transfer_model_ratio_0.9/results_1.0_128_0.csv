,model,score
0,Guscode/DKbert-hatespeech-detection,0.5228334
1,robertou2/roberta-base-bne-finetuned-amazon_reviews_multi,0.68530846
2,milyiyo/selectra-small-finetuned-amazon-review,0.4340206
3,SetFit/distilbert-base-uncased__hate_speech_offensive__train-16-1,0.83699036
4,vinai/bertweet-covid19-base-cased,0.32879168
5,justinqbui/bertweet-covid19-base-uncased-pretraining-covid-vaccine-tweets,0.91479063
6,vinai/bertweet-base,0.9261929
7,vinai/bertweet-covid19-base-uncased,0.9141083
8,jb2k/bert-base-multilingual-cased-language-detection,0.80275136
9,crcb/isear_bert,0.9023015
10,vaariis/distilbert-base-uncased-finetuned-emotion,0.83311915
11,marcelcastrobr/sagemaker-distilbert-emotion,0.8007259
12,jasonyim2/distilbert-base-uncased-finetuned-emotion,0.8255801
13,abdelkader/distilbert-base-uncased-finetuned-emotion,0.82683074
14,uygarkurt/distilbert-base-uncased-finetuned-emotion,0.8446641
15,neibla/distilbert-base-uncased-finetuned-emotion,0.8113391
16,JB173/distilbert-base-uncased-finetuned-emotion,0.85840106
17,Nanatan/distilbert-base-uncased-finetuned-emotion,0.80318356
18,riyadhctg/distilbert-base-uncased-finetuned-cola,0.786548
19,connectivity/cola_6ep_ft-33,0.8789387
20,isakbos/Q8BERT_COLA_L_512,0.65763056
21,gchhablani/fnet-base-finetuned-cola,0.7391047
22,vesteinn/XLMR-ENIS-finetuned-cola,0.85281944
23,jaesun/distilbert-base-uncased-finetuned-cola,0.80675155
24,usami/distilbert-base-uncased-finetuned-cola,0.7466701
25,connectivity/cola_6ep_ft-10,0.86706156
26,Jeevesh8/6ep_bert_ft_cola-12,0.879323
27,Jeevesh8/6ep_bert_ft_cola-47,0.87142795
28,Jeevesh8/6ep_bert_ft_cola-29,0.86875844
29,Jeevesh8/bert_ft_cola-60,0.85670984
30,Jeevesh8/bert_ft_cola-88,0.85941803
31,ishan/bert-base-uncased-mnli,0.8828708
32,boychaboy/MNLI_roberta-base,0.9252695
33,Alireza1044/albert-base-v2-qnli,0.8051495
34,Jeevesh8/init_bert_ft_qqp-33,0.84355885
35,Jeevesh8/init_bert_ft_qqp-49,0.86129767
36,connectivity/bert_ft_qqp-7,0.8545855
37,Jeevesh8/bert_ft_qqp-40,0.86585945
38,Jeevesh8/bert_ft_qqp-9,0.8725269
39,Jeevesh8/bert_ft_qqp-88,0.87399995
40,connectivity/bert_ft_qqp-25,0.8548183
41,Jeevesh8/bert_ft_qqp-55,0.8892275
42,connectivity/bert_ft_qqp-17,0.85177547
43,Jeevesh8/init_bert_ft_qqp-24,0.86055124
44,Jeevesh8/init_bert_ft_qqp-28,0.84530264
45,connectivity/bert_ft_qqp-1,0.876195
46,connectivity/bert_ft_qqp-94,0.87072325
47,Jeevesh8/bert_ft_qqp-39,0.8424164
48,connectivity/bert_ft_qqp-96,0.8570567
49,gchhablani/bert-base-cased-finetuned-rte,0.877106
50,ali2066/finetuned_sentence_itr1_2e-05_all_26_02_2022-04_03_26,0.8054011
51,philschmid/tiny-distilbert-classification,0.10603681
52,SetFit/distilbert-base-uncased__sst2__train-16-0,0.8145156
53,gchhablani/fnet-base-finetuned-sst2,0.7856797
54,moshew/bert-mini-sst2-distilled,0.7679981
55,SetFit/distilbert-base-uncased__sst2__train-32-9,0.8385406
56,aviator-neural/bert-base-uncased-sst2,0.81455195
57,Alassea/glue_sst_classifier,0.8420602
58,ChrisUPM/BioBERT_Re_trained,0.75413877
59,gchhablani/bert-base-cased-finetuned-wnli,0.83437675
60,Hate-speech-CNERG/bert-base-uncased-hatexplain-rationale-two,0.883087
61,heranm/finetuning-sentiment-model-3000-samples,0.83802754
62,PrasunMishra/finetuning-sentiment-model-3000-samples,0.8127676
63,yukta10/finetuning-sentiment-model-3000-samples,0.79055387
64,ncduy/roberta-imdb-sentiment-analysis,0.88829464
65,markt23917/finetuning-sentiment-model-3000-samples,0.84026474
66,juliensimon/autonlp-imdb-demo-hf-16622767,0.8026592
67,XSY/albert-base-v2-imdb-calssification,0.7940278
68,Anthos23/FS-distilroberta-fine-tuned,0.88594186
69,oferweintraub/bert-base-finance-sentiment-noisy-search,0.88483405
70,emrecan/bert-base-multilingual-cased-snli_tr,0.7239753
71,nurkayevaa/autonlp-bert-covid-407910458,0.82817435
72,w11wo/sundanese-bert-base-emotion-classifier,0.571709
73,aychang/bert-base-cased-trec-coarse,0.86652315
74,pietrotrope/emotion_final,0.8177012
75,aXhyra/presentation_emotion_31415,0.84309435
76,elozano/tweet_offensive_eval,0.48595113
77,aXhyra/presentation_sentiment_1234567,0.8402315
78,aXhyra/demo_sentiment_31415,0.86247367
79,manueltonneau/bert-twitter-en-is-hired,0.8744044
80,albert-base-v2,0.6145034
81,bert-base-uncased,0.87232214
82,distilbert-base-uncased,0.86161995
83,dhimskyy/wiki-bert,0.5973875
84,bert-base-cased,0.8689746
85,michiyasunaga/LinkBERT-base,0.8848131
86,roberta-base,0.9101234
87,bert-large-uncased,0.63834596
88,roberta-large,0.6442732
89,Recognai/bert-base-spanish-wwm-cased-xnli,0.6299075
90,dapang/distilroberta-base-mic-sym,0.7992691
91,Capreolus/bert-base-msmarco,0.86571974
92,Splend1dchan/bert-base-uncased-slue-goldtrascription-e3-lr1e-4,0.8659108
93,cambridgeltl/guardian_news_distilbert-base-uncased,0.8058506
94,amyma21/sincere_question_classification,0.80429673
95,Jeevesh8/feather_berts_46,0.8670277
96,JonatanGk/roberta-base-bne-finetuned-cyberbullying-spanish,0.546093
97,arianpasquali/distilbert-base-multilingual-cased-toxicity,0.69153744
98,chiragasarpota/scotus-bert,0.08971282
99,IMSyPP/hate_speech_it,0.6595067
100,connectivity/feather_berts_28,0.8678983
101,liangyuant/distilbert-base-uncased-finetuned-num200-450-405cls,0.8163647
102,Jeevesh8/lecun_feather_berts-3,0.8451382
103,DoyyingFace/bert-asian-hate-tweets-asian-unclean-freeze-4,0.8450242
104,Giyaseddin/distilroberta-base-finetuned-short-answer-assessment,0.84242404
105,viviastaari/finetuning-sentiment-analysis-en-id,0.6836093
106,Jeevesh8/feather_berts_96,0.8773728
107,Jeevesh8/lecun_feather_berts-51,0.8748216
108,18811449050/bert_finetuning_test,0.8156262
109,AnonymousSub/dummy_2,0.7004487
110,finiteautomata/betonews-tweetcontext,0.60924375
111,Aureliano/distilbert-base-uncased-if,0.81664103
112,rmihaylov/roberta-base-sentiment-bg,0.7387701
113,cardiffnlp/twitter-roberta-base-2021-124m,0.8987441
114,Jeevesh8/lecun_feather_berts-8,0.83839667
115,waboucay/camembert-base-finetuned-xnli_fr-finetuned-nli-rua_wl,0.40379342
116,korca/bae-roberta-base-boolq,0.8670671
117,matthewburke/korean_sentiment,0.65491456
118,mrm8488/codebert-base-finetuned-detect-insecure-code,0.7598632
119,aditeyabaral/finetuned-sail2017-xlm-roberta-base,0.8371548
120,cardiffnlp/bertweet-base-stance-climate,0.8480535
121,M47Labs/spanish_news_classification_headlines_untrained,0.6761248
122,CAMeL-Lab/bert-base-arabic-camelbert-da-sentiment,0.437799
123,cointegrated/roberta-base-formality,0.88584983
124,bondi/bert-semaphore-prediction-w4,0.6952344
125,anferico/bert-for-patents,0.77227646
126,fgaim/tiroberta-geezswitch,0.4946311
127,JonatanGk/roberta-base-ca-finetuned-hate-speech-offensive-catalan,0.64186066
128,socialmediaie/TRAC2020_IBEN_B_bert-base-multilingual-uncased,0.75589174
129,Monsia/camembert-fr-covid-tweet-classification,0.74013233
130,Raychanan/COVID_RandomOver,0.03631354
131,anvay/finetuning-cardiffnlp-sentiment-model,0.941014
132,YeRyeongLee/electra-base-discriminator-finetuned-filtered-0602,0.051888946
133,Jeevesh8/feather_berts_92,0.8592175
134,joebobby/finetuning-sentiment-model-5000-samples3,0.81662494
135,CAMeL-Lab/bert-base-arabic-camelbert-mix-did-nadi,0.6392976
136,warwickai/fin-perceiver,0.7759753
137,ali2066/DistilBERTFINAL_ctxSentence_TRAIN_editorials_TEST_NULL_second_train_set_null_False,0.88184685
138,ASCCCCCCCC/distilbert-base-chinese-amazon_zh_20000,0.6397372
139,kyleinincubated/autonlp-cat333-624217911,0.6682417
