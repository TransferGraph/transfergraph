,model,score
0,Jeevesh8/init_bert_ft_qqp-33,0.7985767256943913
1,Jeevesh8/init_bert_ft_qqp-33,0.7985767256943913
2,Jeevesh8/init_bert_ft_qqp-49,0.7900792576554536
3,Jeevesh8/init_bert_ft_qqp-49,0.7900792576554536
4,connectivity/bert_ft_qqp-7,0.7916869625486125
5,connectivity/bert_ft_qqp-7,0.7916869625486125
6,Jeevesh8/bert_ft_qqp-40,0.7908033885894077
7,Jeevesh8/bert_ft_qqp-40,0.7908033885894077
8,Jeevesh8/bert_ft_qqp-9,0.7894341495649471
9,Jeevesh8/bert_ft_qqp-9,0.7894341495649471
10,Jeevesh8/bert_ft_qqp-88,0.8060202866648097
11,Jeevesh8/bert_ft_qqp-88,0.7834923865386949
12,connectivity/bert_ft_qqp-25,0.7906859945105306
13,connectivity/bert_ft_qqp-25,0.7906859945105306
14,Jeevesh8/bert_ft_qqp-55,0.7917051090458844
15,Jeevesh8/bert_ft_qqp-55,0.7904985031683782
16,connectivity/bert_ft_qqp-1,0.7903155441739083
17,connectivity/bert_ft_qqp-1,0.7903155441739083
18,Jeevesh8/bert_ft_qqp-39,0.8058696283740244
19,Jeevesh8/bert_ft_qqp-39,0.7861374159483847
20,connectivity/bert_ft_qqp-94,0.7982981219227855
21,connectivity/bert_ft_qqp-94,0.7982981219227855
22,connectivity/bert_ft_qqp-96,0.7894923119835812
23,connectivity/bert_ft_qqp-96,0.7893677665290357
24,Jeevesh8/init_bert_ft_qqp-24,0.7824139922601606
25,Jeevesh8/init_bert_ft_qqp-24,0.7812073863826545
26,Jeevesh8/bert_ft_qqp-68,0.7834677824481817
27,Jeevesh8/bert_ft_qqp-68,0.7834677824481817
28,Jeevesh8/init_bert_ft_qqp-28,0.8025491502341118
29,Jeevesh8/init_bert_ft_qqp-28,0.7831750507948264
30,connectivity/bert_ft_qqp-17,0.7852886473381727
31,connectivity/bert_ft_qqp-17,0.7852886473381727
32,ali2066/finetuned_sentence_itr1_2e-05_all_26_02_2022-04_03_26,0.7852145626833891
33,ali2066/finetuned_sentence_itr1_2e-05_all_26_02_2022-04_03_26,0.784007956805883
34,SetFit/distilbert-base-uncased__sst2__train-16-0,0.7958131069662557
35,SetFit/distilbert-base-uncased__sst2__train-16-0,0.7946065010887495
36,aviator-neural/bert-base-uncased-sst2,0.8071568072826384
37,aviator-neural/bert-base-uncased-sst2,0.7886312007345049
38,SetFit/distilbert-base-uncased__sst2__train-32-9,0.8044846752969314
39,SetFit/distilbert-base-uncased__sst2__train-32-9,0.8043601298423859
40,Alassea/glue_sst_classifier,0.7925677979085354
41,Alassea/glue_sst_classifier,0.7924432524539899
42,philschmid/tiny-distilbert-classification,0.5824542996571241
43,philschmid/tiny-distilbert-classification,0.5824542996571241
44,moshew/bert-mini-sst2-distilled,0.7997532831431425
45,moshew/bert-mini-sst2-distilled,0.799877828597688
46,ChrisUPM/BioBERT_Re_trained,0.7838088140032938
47,ChrisUPM/BioBERT_Re_trained,0.7838088140032938
48,vaariis/distilbert-base-uncased-finetuned-emotion,0.7931363023831716
49,vaariis/distilbert-base-uncased-finetuned-emotion,0.7930117569286261
50,marcelcastrobr/sagemaker-distilbert-emotion,0.7933542751238223
51,marcelcastrobr/sagemaker-distilbert-emotion,0.7921476692463161
52,jasonyim2/distilbert-base-uncased-finetuned-emotion,0.7902902553536189
53,jasonyim2/distilbert-base-uncased-finetuned-emotion,0.7901657098990733
54,abdelkader/distilbert-base-uncased-finetuned-emotion,0.7840706780471842
55,abdelkader/distilbert-base-uncased-finetuned-emotion,0.7828640721696781
56,moghis/distilbert-base-uncased-finetuned-emotion,0.7916154158933371
57,moghis/distilbert-base-uncased-finetuned-emotion,0.7914908704387916
58,uygarkurt/distilbert-base-uncased-finetuned-emotion,0.7944298465807619
59,uygarkurt/distilbert-base-uncased-finetuned-emotion,0.7943053011262164
60,neibla/distilbert-base-uncased-finetuned-emotion,0.7973332707932751
61,neibla/distilbert-base-uncased-finetuned-emotion,0.7961266649157689
62,JB173/distilbert-base-uncased-finetuned-emotion,0.7928139295392973
63,JB173/distilbert-base-uncased-finetuned-emotion,0.7916073236617912
64,Nanatan/distilbert-base-uncased-finetuned-emotion,0.7933641710525469
65,Nanatan/distilbert-base-uncased-finetuned-emotion,0.7921575651750407
66,heranm/finetuning-sentiment-model-3000-samples,0.7879389189835636
67,heranm/finetuning-sentiment-model-3000-samples,0.7878143735290182
68,PrasunMishra/finetuning-sentiment-model-3000-samples,0.7841087619673205
69,PrasunMishra/finetuning-sentiment-model-3000-samples,0.7829021560898143
70,yukta10/finetuning-sentiment-model-3000-samples,0.7942703745713342
71,yukta10/finetuning-sentiment-model-3000-samples,0.7941458291167888
72,ncduy/roberta-imdb-sentiment-analysis,0.8033032789373651
73,ncduy/roberta-imdb-sentiment-analysis,0.8033032789373651
74,markt23917/finetuning-sentiment-model-3000-samples,0.7979916686237999
75,markt23917/finetuning-sentiment-model-3000-samples,0.7978671231692545
76,juliensimon/autonlp-imdb-demo-hf-16622767,0.7836396822342746
77,juliensimon/autonlp-imdb-demo-hf-16622767,0.7835151367797292
78,fabriceyhc/bert-base-uncased-imdb,0.7876663694686339
79,fabriceyhc/bert-base-uncased-imdb,0.7875418240140885
80,riyadhctg/distilbert-base-uncased-finetuned-cola,0.7850810986008047
81,riyadhctg/distilbert-base-uncased-finetuned-cola,0.7849565531462592
82,connectivity/cola_6ep_ft-33,0.786386249594552
83,connectivity/cola_6ep_ft-33,0.786386249594552
84,connectivity/cola_6ep_ft-22,0.7938015593315221
85,connectivity/cola_6ep_ft-22,0.7938015593315221
86,isakbos/Q8BERT_COLA_L_512,0.7785639795146555
87,isakbos/Q8BERT_COLA_L_512,0.7785639795146555
88,jaesun/distilbert-base-uncased-finetuned-cola,0.7803163283909444
89,jaesun/distilbert-base-uncased-finetuned-cola,0.779109722513438
90,usami/distilbert-base-uncased-finetuned-cola,0.786484878295638
91,usami/distilbert-base-uncased-finetuned-cola,0.7852782724181319
92,Jeevesh8/512seq_len_6ep_bert_ft_cola-91,0.7899897147806917
93,Jeevesh8/512seq_len_6ep_bert_ft_cola-91,0.7899897147806917
94,Jeevesh8/6ep_bert_ft_cola-47,0.806620636810583
95,Jeevesh8/6ep_bert_ft_cola-47,0.7946890669596972
96,connectivity/cola_6ep_ft-10,0.796309088869147
97,connectivity/cola_6ep_ft-10,0.7951024829916408
98,Jeevesh8/6ep_bert_ft_cola-12,0.7860736542166008
99,Jeevesh8/6ep_bert_ft_cola-12,0.7860736542166008
100,Jeevesh8/bert_ft_cola-88,0.7812684762153205
101,Jeevesh8/bert_ft_cola-88,0.7812684762153205
102,Jeevesh8/6ep_bert_ft_cola-29,0.7923374775429943
103,Jeevesh8/6ep_bert_ft_cola-29,0.7923374775429943
104,vesteinn/XLMR-ENIS-finetuned-cola,0.7852438841724916
105,vesteinn/XLMR-ENIS-finetuned-cola,0.7852438841724916
106,navsad/navid_test_bert,0.7901030024809748
107,navsad/navid_test_bert,0.7899784570264293
108,Jeevesh8/bert_ft_cola-60,0.807431018029854
109,Jeevesh8/bert_ft_cola-60,0.7849031179037388
110,dapang/distilroberta-base-mic-sym,0.794218798276339
111,dapang/distilroberta-base-mic-sym,0.7940942528217936
112,Capreolus/bert-base-msmarco,0.7829970824395552
113,Capreolus/bert-base-msmarco,0.7829970824395552
114,Splend1dchan/bert-base-uncased-slue-goldtrascription-e3-lr1e-4,0.7887582770714032
115,Splend1dchan/bert-base-uncased-slue-goldtrascription-e3-lr1e-4,0.7887582770714032
116,Jeevesh8/feather_berts_46,0.8075691925007941
117,Jeevesh8/feather_berts_46,0.7850412923746789
118,JonatanGk/roberta-base-bne-finetuned-cyberbullying-spanish,0.7733597978721167
119,JonatanGk/roberta-base-bne-finetuned-cyberbullying-spanish,0.7550666241062264
120,cambridgeltl/guardian_news_distilbert-base-uncased,0.787655183089821
121,cambridgeltl/guardian_news_distilbert-base-uncased,0.7875306376352755
122,amyma21/sincere_question_classification,0.7858602007038246
123,amyma21/sincere_question_classification,0.7857356552492791
124,phailyoor/distilbert-base-uncased-finetuned-yahd,0.7952925796563077
125,phailyoor/distilbert-base-uncased-finetuned-yahd,0.7940859737788015
126,arianpasquali/distilbert-base-multilingual-cased-toxicity,0.782449456207279
127,arianpasquali/distilbert-base-multilingual-cased-toxicity,0.781242850329773
128,connectivity/feather_berts_28,0.7856317496952109
129,connectivity/feather_berts_28,0.7856317496952109
130,liangyuant/distilbert-base-uncased-finetuned-num200-450-405cls,0.7843370431860968
131,liangyuant/distilbert-base-uncased-finetuned-num200-450-405cls,0.7842124977315512
132,DoyyingFace/bert-asian-hate-tweets-asian-unclean-freeze-4,0.7876867521941914
133,DoyyingFace/bert-asian-hate-tweets-asian-unclean-freeze-4,0.7876867521941914
134,Jeevesh8/lecun_feather_berts-3,0.7837113316390214
135,Jeevesh8/lecun_feather_berts-3,0.7837113316390214
136,Giyaseddin/distilroberta-base-finetuned-short-answer-assessment,0.7861600605675128
137,Giyaseddin/distilroberta-base-finetuned-short-answer-assessment,0.7849534546900068
138,AnonymousSub/dummy_2,0.798104069365701
139,AnonymousSub/dummy_2,0.791275774268985
140,Jeevesh8/lecun_feather_berts-51,0.7855164334965697
141,Jeevesh8/lecun_feather_berts-51,0.7843098276190635
142,viviastaari/finetuning-sentiment-analysis-en-id,0.7825863919399296
143,viviastaari/finetuning-sentiment-analysis-en-id,0.7813797860624235
144,Aureliano/distilbert-base-uncased-if,0.7894158002751933
145,Aureliano/distilbert-base-uncased-if,0.7882091943976871
146,rmihaylov/roberta-base-sentiment-bg,0.7887146106798305
147,rmihaylov/roberta-base-sentiment-bg,0.7885900652252851
148,cardiffnlp/twitter-roberta-base-2021-124m,0.7887391222545682
149,cardiffnlp/twitter-roberta-base-2021-124m,0.7887391222545682
150,Jeevesh8/lecun_feather_berts-8,0.7884722949765908
151,Jeevesh8/lecun_feather_berts-8,0.7883477495220452
152,korca/bae-roberta-base-boolq,0.779373063710987
153,korca/bae-roberta-base-boolq,0.7792485182564416
154,aditeyabaral/finetuned-sail2017-xlm-roberta-base,0.8043201341659283
155,aditeyabaral/finetuned-sail2017-xlm-roberta-base,0.7923885643150425
156,joebobby/finetuning-sentiment-model-5000-samples3,0.7883293981202243
157,joebobby/finetuning-sentiment-model-5000-samples3,0.7883293981202243
158,Jeevesh8/feather_berts_92,0.7994726552815632
159,Jeevesh8/feather_berts_92,0.7994726552815632
160,ASCCCCCCCC/distilbert-base-chinese-amazon_zh_20000,0.7825639836098045
161,ASCCCCCCCC/distilbert-base-chinese-amazon_zh_20000,0.7825639836098045
162,matthewburke/korean_sentiment,0.7847011924323121
163,matthewburke/korean_sentiment,0.7844669340328437
164,IMSyPP/hate_speech_nl,0.768900240048036
165,IMSyPP/hate_speech_nl,0.768900240048036
166,cointegrated/roberta-base-formality,0.7916249188644348
167,cointegrated/roberta-base-formality,0.7916249188644348
168,IMSyPP/hate_speech_it,0.7822176809268762
169,IMSyPP/hate_speech_it,0.7822176809268762
170,18811449050/bert_finetuning_test,0.80431940297868
171,18811449050/bert_finetuning_test,0.7949795762470602
172,finiteautomata/betonews-tweetcontext,0.7728595720747506
173,finiteautomata/betonews-tweetcontext,0.7728595720747506
174,Jeevesh8/feather_berts_96,0.8025290085715632
175,Jeevesh8/feather_berts_96,0.8025290085715632
176,Jeevesh8/lecun_feather_berts-7,0.791538057920703
177,Jeevesh8/lecun_feather_berts-7,0.7914135124661575
178,mrm8488/codebert-base-finetuned-detect-insecure-code,0.7880869536019265
179,mrm8488/codebert-base-finetuned-detect-insecure-code,0.7880869536019265
180,socialmediaie/TRAC2020_IBEN_B_bert-base-multilingual-uncased,0.8013047388061962
181,socialmediaie/TRAC2020_IBEN_B_bert-base-multilingual-uncased,0.785370875377329
182,zenkri/autotrain-Arabic_Poetry_by_Subject-920730230,0.7806617746817692
183,zenkri/autotrain-Arabic_Poetry_by_Subject-920730230,0.7805372292272237
184,M47Labs/spanish_news_classification_headlines_untrained,0.7868809918321635
185,M47Labs/spanish_news_classification_headlines_untrained,0.7868809918321635
186,bondi/bert-semaphore-prediction-w4,0.7853315256572816
187,bondi/bert-semaphore-prediction-w4,0.7850972672578131
188,classla/bcms-bertic-parlasent-bcs-ter,0.7925315746357193
189,classla/bcms-bertic-parlasent-bcs-ter,0.7925315746357193
190,anferico/bert-for-patents,0.8152794866962708
191,anferico/bert-for-patents,0.7936192025719966
192,ali2066/DistilBERTFINAL_ctxSentence_TRAIN_editorials_TEST_NULL_second_train_set_null_False,0.8081517294641302
193,ali2066/DistilBERTFINAL_ctxSentence_TRAIN_editorials_TEST_NULL_second_train_set_null_False,0.7988119027325105
194,anvay/finetuning-cardiffnlp-sentiment-model,0.7983753901374623
195,anvay/finetuning-cardiffnlp-sentiment-model,0.7983753901374623
196,JonatanGk/roberta-base-ca-finetuned-hate-speech-offensive-catalan,0.7812192345418328
197,JonatanGk/roberta-base-ca-finetuned-hate-speech-offensive-catalan,0.7812192345418328
198,Raychanan/COVID_RandomOver,0.6503734116187403
199,Raychanan/COVID_RandomOver,0.6503734116187403
200,kyleinincubated/autonlp-cat333-624217911,0.800954517742111
201,kyleinincubated/autonlp-cat333-624217911,0.7824289111939777
202,cardiffnlp/bertweet-base-stance-climate,0.7837222589295161
203,cardiffnlp/bertweet-base-stance-climate,0.7835977134749705
204,nurkayevaa/autonlp-bert-covid-407910458,0.7843678216591079
205,nurkayevaa/autonlp-bert-covid-407910458,0.7831612157816017
206,SetFit/distilbert-base-uncased__hate_speech_offensive__train-16-1,0.7949645209484199
207,SetFit/distilbert-base-uncased__hate_speech_offensive__train-16-1,0.7937579150709136
208,crcb/isear_bert,0.7999648127307303
209,crcb/isear_bert,0.7999648127307303
210,robertou2/roberta-base-bne-finetuned-amazon_reviews_multi,0.785071746706855
211,robertou2/roberta-base-bne-finetuned-amazon_reviews_multi,0.785071746706855
212,milyiyo/selectra-small-finetuned-amazon-review,0.7397163391206572
213,milyiyo/selectra-small-finetuned-amazon-review,0.7390221552557417
214,Anthos23/FS-distilroberta-fine-tuned,0.7925755176934668
215,Anthos23/FS-distilroberta-fine-tuned,0.7924509722389214
216,oferweintraub/bert-base-finance-sentiment-noisy-search,0.8063247461162188
217,oferweintraub/bert-base-finance-sentiment-noisy-search,0.788307924913155
218,pietrotrope/emotion_final,0.7896940822020427
219,pietrotrope/emotion_final,0.7895695367474973
220,aXhyra/emotion_trained_31415,0.7939960322694837
221,aXhyra/emotion_trained_31415,0.7938714868149382
222,aXhyra/presentation_emotion_31415,0.7823260564087847
223,aXhyra/presentation_emotion_31415,0.7822015109542393
224,Recognai/bert-base-spanish-wwm-cased-xnli,0.7932826025087557
225,Recognai/bert-base-spanish-wwm-cased-xnli,0.7864543074120395
226,anirudh21/bert-base-uncased-finetuned-qnli,0.7876878282676859
227,anirudh21/bert-base-uncased-finetuned-qnli,0.7876878282676859
228,aXhyra/demo_sentiment_31415,0.7824561925363807
229,aXhyra/demo_sentiment_31415,0.7812495866588745
230,aXhyra/presentation_sentiment_1234567,0.7921367514089844
231,aXhyra/presentation_sentiment_1234567,0.7909301455314783
232,jb2k/bert-base-multilingual-cased-language-detection,0.7994341980367041
233,jb2k/bert-base-multilingual-cased-language-detection,0.7770127277307688
234,vinai/bertweet-base,0.7845100069940152
235,vinai/bertweet-base,0.7842388646808309
236,justinqbui/bertweet-covid19-base-uncased-pretraining-covid-vaccine-tweets,0.807174129723948
237,justinqbui/bertweet-covid19-base-uncased-pretraining-covid-vaccine-tweets,0.8059675238464418
238,vinai/bertweet-covid19-base-cased,0.7828754254670257
239,vinai/bertweet-covid19-base-cased,0.7828754254670257
240,vinai/bertweet-covid19-base-uncased,0.798892132635616
241,vinai/bertweet-covid19-base-uncased,0.798892132635616
242,distilbert-base-uncased,0.7921100899271529
243,distilbert-base-uncased,0.7909034840496467
244,bert-base-uncased,0.7896616720601252
245,bert-base-uncased,0.788455066182619
246,roberta-base,0.8082845753382513
247,roberta-base,0.7897589687901179
248,bert-base-cased,0.7844132158715008
249,bert-base-cased,0.7844132158715008
250,dhimskyy/wiki-bert,0.7773408061315068
251,dhimskyy/wiki-bert,0.7693059051572844
252,michiyasunaga/LinkBERT-base,0.7904337173718196
253,michiyasunaga/LinkBERT-base,0.7903091719172741
254,bert-large-uncased,0.7982214636562907
255,bert-large-uncased,0.77961420187879
256,roberta-large,0.7955348257672441
257,roberta-large,0.7698927559192948
258,boychaboy/MNLI_roberta-base,0.7865315873845276
259,boychaboy/MNLI_roberta-base,0.7865315873845276
260,ishan/bert-base-uncased-mnli,0.7863564314479966
261,ishan/bert-base-uncased-mnli,0.7863564314479966
262,emrecan/bert-base-multilingual-cased-snli_tr,0.805091909449576
263,emrecan/bert-base-multilingual-cased-snli_tr,0.7867972781761678
264,elozano/tweet_offensive_eval,0.7764567436050608
265,elozano/tweet_offensive_eval,0.7764567436050608
266,Hate-speech-CNERG/bert-base-uncased-hatexplain-rationale-two,0.805810668673334
267,Hate-speech-CNERG/bert-base-uncased-hatexplain-rationale-two,0.7889011746416856
268,aychang/bert-base-cased-trec-coarse,0.7848808489097623
269,aychang/bert-base-cased-trec-coarse,0.7848808489097623
270,gchhablani/bert-base-cased-finetuned-wnli,0.7922874349103727
271,gchhablani/bert-base-cased-finetuned-wnli,0.7921628894558271
272,w11wo/sundanese-bert-base-emotion-classifier,0.7732406433263553
273,w11wo/sundanese-bert-base-emotion-classifier,0.7732406433263553
274,gchhablani/bert-base-cased-finetuned-rte,0.7919334954258143
275,gchhablani/bert-base-cased-finetuned-rte,0.790726889548308
276,mrm8488/electricidad-base-finetuned-pawsx-es,0.781969668369427
277,mrm8488/electricidad-base-finetuned-pawsx-es,0.781969668369427
278,manueltonneau/bert-twitter-en-is-hired,0.784332239127894
279,manueltonneau/bert-twitter-en-is-hired,0.7831256332503878
280,Guscode/DKbert-hatespeech-detection,0.7823404811763802
281,Guscode/DKbert-hatespeech-detection,0.7823404811763802
