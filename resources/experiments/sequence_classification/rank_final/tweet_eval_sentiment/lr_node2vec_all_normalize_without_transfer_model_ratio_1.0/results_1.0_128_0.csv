,model,score
0,Guscode/DKbert-hatespeech-detection,0.6011794080042457
1,robertou2/roberta-base-bne-finetuned-amazon_reviews_multi,0.8042519976800826
2,milyiyo/selectra-small-finetuned-amazon-review,0.5747104717469838
3,SetFit/distilbert-base-uncased__hate_speech_offensive__train-16-1,0.9050725881099226
4,SetFit/distilbert-base-uncased__hate_speech_offensive__train-16-1,0.9053314104952547
5,vinai/bertweet-base,0.9515126366843891
6,justinqbui/bertweet-covid19-base-uncased-pretraining-covid-vaccine-tweets,0.8986095608463646
7,vinai/bertweet-covid19-base-cased,1.0211702043452129
8,vinai/bertweet-covid19-base-uncased,1.1190938160749204
9,jb2k/bert-base-multilingual-cased-language-detection,0.7566933945876101
10,crcb/isear_bert,1.0118376277716254
11,crcb/isear_bert,1.01594186318522
12,abdelkader/distilbert-base-uncased-finetuned-emotion,0.9070789057161013
13,vaariis/distilbert-base-uncased-finetuned-emotion,0.8757242082252459
14,marcelcastrobr/sagemaker-distilbert-emotion,0.8186549701687569
15,jasonyim2/distilbert-base-uncased-finetuned-emotion,0.8756476839612457
16,abdelkader/distilbert-base-uncased-finetuned-emotion,0.9077333017511656
17,moghis/distilbert-base-uncased-finetuned-emotion,0.8961707655385914
18,uygarkurt/distilbert-base-uncased-finetuned-emotion,0.9002690164487465
19,neibla/distilbert-base-uncased-finetuned-emotion,0.8914229153642057
20,JB173/distilbert-base-uncased-finetuned-emotion,0.8319688629220903
21,Nanatan/distilbert-base-uncased-finetuned-emotion,0.8533002212768286
22,connectivity/cola_6ep_ft-22,0.9227432495641875
23,connectivity/cola_6ep_ft-33,1.01049309817454
24,riyadhctg/distilbert-base-uncased-finetuned-cola,0.8582750441014223
25,connectivity/cola_6ep_ft-33,1.0149553432028133
26,gchhablani/fnet-base-finetuned-cola,0.7205476672309569
27,connectivity/cola_6ep_ft-22,0.9223469913786317
28,vesteinn/XLMR-ENIS-finetuned-cola,0.9010498802219014
29,isakbos/Q8BERT_COLA_L_512,0.5904476957571965
30,jaesun/distilbert-base-uncased-finetuned-cola,0.8739009608066209
31,usami/distilbert-base-uncased-finetuned-cola,0.8069296470812015
32,Jeevesh8/512seq_len_6ep_bert_ft_cola-91,0.9009757154762921
33,Jeevesh8/6ep_bert_ft_cola-47,0.9165688729304406
34,connectivity/cola_6ep_ft-10,0.8896685104467507
35,Jeevesh8/6ep_bert_ft_cola-12,0.8837458644643453
36,Jeevesh8/6ep_bert_ft_cola-29,0.9192158273224316
37,navsad/navid_test_bert,0.8387996820704913
38,Jeevesh8/bert_ft_cola-60,0.9795842562725632
39,Jeevesh8/bert_ft_cola-88,0.9033503459281143
40,ishan/bert-base-uncased-mnli,0.8726477907697436
41,boychaboy/MNLI_roberta-base,1.0493463050692127
42,anirudh21/bert-base-uncased-finetuned-qnli,0.9610840175676072
43,Alireza1044/albert-base-v2-qnli,0.8743389047965658
44,Jeevesh8/init_bert_ft_qqp-49,0.8815395774658041
45,Jeevesh8/init_bert_ft_qqp-33,0.9475880888315886
46,Jeevesh8/init_bert_ft_qqp-49,0.8815915195879823
47,connectivity/bert_ft_qqp-7,0.8705952102139696
48,Jeevesh8/bert_ft_qqp-40,0.9845235104637643
49,Jeevesh8/bert_ft_qqp-9,0.8496199059213699
50,Jeevesh8/bert_ft_qqp-88,0.8865631170856265
51,connectivity/bert_ft_qqp-25,0.8987952575214386
52,Jeevesh8/init_bert_ft_qqp-24,0.9300030072746712
53,Jeevesh8/bert_ft_qqp-55,0.9511310424295333
54,Jeevesh8/bert_ft_qqp-68,0.8690159713987295
55,connectivity/bert_ft_qqp-17,0.8727470045015664
56,Jeevesh8/init_bert_ft_qqp-28,0.8655251499729426
57,connectivity/bert_ft_qqp-1,0.835408923285931
58,Jeevesh8/bert_ft_qqp-39,0.8931106022325215
59,connectivity/bert_ft_qqp-94,0.9298103398837116
60,connectivity/bert_ft_qqp-96,0.9587529888605719
61,gchhablani/bert-base-cased-finetuned-rte,0.9201678640276869
62,SetFit/distilbert-base-uncased__sst2__train-16-0,0.9627028333447005
63,gchhablani/fnet-base-finetuned-sst2,0.8164028463167696
64,philschmid/tiny-distilbert-classification,0.13035681360766693
65,ali2066/finetuned_sentence_itr1_2e-05_all_26_02_2022-04_03_26,0.9175292139845216
66,SetFit/distilbert-base-uncased__sst2__train-16-0,0.9625485156222267
67,gchhablani/fnet-base-finetuned-sst2,0.8199744644002176
68,moshew/bert-mini-sst2-distilled,0.8287864174664609
69,SetFit/distilbert-base-uncased__sst2__train-32-9,0.92576200074816
70,aviator-neural/bert-base-uncased-sst2,0.9485796472332122
71,Alassea/glue_sst_classifier,0.9386837503132273
72,ChrisUPM/BioBERT_Re_trained,0.6964524805641603
73,gchhablani/bert-base-cased-finetuned-wnli,0.8745749037055658
74,Hate-speech-CNERG/bert-base-uncased-hatexplain-rationale-two,0.9152663524535676
75,PrasunMishra/finetuning-sentiment-model-3000-samples,0.9285087693034358
76,yukta10/finetuning-sentiment-model-3000-samples,0.8910621036043093
77,heranm/finetuning-sentiment-model-3000-samples,0.9349263408702084
78,PrasunMishra/finetuning-sentiment-model-3000-samples,0.9291353357623522
79,yukta10/finetuning-sentiment-model-3000-samples,0.8912683427603214
80,ncduy/roberta-imdb-sentiment-analysis,1.0184823065267468
81,markt23917/finetuning-sentiment-model-3000-samples,0.9083990919705327
82,juliensimon/autonlp-imdb-demo-hf-16622767,0.8899386648044667
83,XSY/albert-base-v2-imdb-calssification,0.8536036046268825
84,fabriceyhc/bert-base-uncased-imdb,0.8543854982465422
85,Anthos23/FS-distilroberta-fine-tuned,1.0012893125183364
86,oferweintraub/bert-base-finance-sentiment-noisy-search,0.9187973349190166
87,emrecan/bert-base-multilingual-cased-snli_tr,0.9064327587259732
88,nurkayevaa/autonlp-bert-covid-407910458,0.8333784589649729
89,nurkayevaa/autonlp-bert-covid-407910458,0.8332294415631654
90,cross-encoder/quora-distilroberta-base,0.9303064119809257
91,navteca/quora-roberta-base,0.8709635221581116
92,cross-encoder/quora-roberta-base,0.8458651049529031
93,w11wo/sundanese-bert-base-emotion-classifier,0.6498863106845912
94,aychang/bert-base-cased-trec-coarse,0.8479697849932094
95,JNK789/distilbert-base-uncased-finetuned-tweets-emoji-dataset,0.12739788758778858
96,pietrotrope/emotion_final,0.9086034314514246
97,aXhyra/emotion_trained_31415,0.8979914882032427
98,aXhyra/presentation_emotion_31415,0.8418725021561972
99,elozano/tweet_offensive_eval,0.600411067425274
100,aXhyra/demo_sentiment_31415,0.9529343694339907
101,aXhyra/presentation_sentiment_1234567,0.9920755152086904
102,nickmuchi/facebook-data2vec-finetuned-finance-classification,0.8699413274061052
103,manueltonneau/bert-twitter-en-is-hired,0.8757155475718158
104,distilbert-base-uncased,0.8745628028669803
105,dhimskyy/wiki-bert,0.6533803692499622
106,bert-base-uncased,1.0082128238259598
107,roberta-base,1.0333748400711544
108,bert-base-cased,0.9383441412811249
109,albert-base-v2,0.8540748513632381
110,michiyasunaga/LinkBERT-base,0.8869007532464426
111,Recognai/bert-base-spanish-wwm-cased-xnli,0.7316601139203139
112,mrm8488/electricidad-base-finetuned-pawsx-es,0.6213399126735726
113,Capreolus/bert-base-msmarco,0.888117770199683
114,Jeevesh8/feather_berts_46,0.9896427654584042
115,Splend1dchan/bert-base-uncased-slue-goldtrascription-e3-lr1e-4,0.886764198757678
116,dapang/distilroberta-base-mic-sym,0.9527814060085678
117,dapang/distilroberta-base-mic-sym,0.972980196911622
118,cambridgeltl/guardian_news_distilbert-base-uncased,0.9191469359440279
119,Capreolus/bert-base-msmarco,0.8895668305683768
120,Splend1dchan/bert-base-uncased-slue-goldtrascription-e3-lr1e-4,0.8884883223283857
121,Jeevesh8/feather_berts_46,0.989258981808462
122,JonatanGk/roberta-base-bne-finetuned-cyberbullying-spanish,0.5078073786974675
123,nreimers/mmarco-mMiniLMv2-L6-H384-v1,0.6701285806851528
124,phailyoor/distilbert-base-uncased-finetuned-yahd,0.7863628721807022
125,amyma21/sincere_question_classification,0.9053605140661187
126,arianpasquali/distilbert-base-multilingual-cased-toxicity,0.6939371982676183
127,chiragasarpota/scotus-bert,0.5867636945680755
128,strickvl/nlp-redaction-classifier,0.6405014072266596
129,connectivity/feather_berts_28,0.9599477632424335
130,IMSyPP/hate_speech_it,0.7432041188925467
131,liangyuant/distilbert-base-uncased-finetuned-num200-450-405cls,0.8632956414281427
132,DoyyingFace/bert-asian-hate-tweets-asian-unclean-freeze-4,0.9693886027953984
133,Giyaseddin/distilroberta-base-finetuned-short-answer-assessment,0.9377492264181072
134,saattrupdan/job-listing-relevance-model,1.014985528673502
135,Jeevesh8/lecun_feather_berts-3,0.8931677127722661
136,18811449050/bert_finetuning_test,0.8246449225253006
137,Jeevesh8/feather_berts_96,0.8790418832182114
138,Jeevesh8/lecun_feather_berts-51,0.9635584541300672
139,viviastaari/finetuning-sentiment-analysis-en-id,0.6743685758375689
140,AnonymousSub/dummy_2,0.7293981499275319
141,finiteautomata/betonews-tweetcontext,0.6839350570271041
142,Aureliano/distilbert-base-uncased-if,0.8608396222771527
143,cross-encoder/ms-marco-MiniLM-L-4-v2,0.9787260463247507
144,cardiffnlp/twitter-roberta-base-2021-124m,1.0502137159185188
145,Jeevesh8/lecun_feather_berts-8,0.9119390360144282
146,Jeevesh8/lecun_feather_berts-7,0.8918660152602469
147,morenolq/SumTO_FNS2020,0.8197058016802409
148,IMSyPP/hate_speech_nl,0.5904484890039812
149,korca/bae-roberta-base-boolq,0.9518656422007183
150,matthewburke/korean_sentiment,0.6780046035242423
151,waboucay/camembert-base-finetuned-xnli_fr-finetuned-nli-rua_wl,0.6526480276204214
152,mrm8488/codebert-base-finetuned-detect-insecure-code,0.8892093551794819
153,socialmediaie/TRAC2020_IBEN_B_bert-base-multilingual-uncased,0.7535775342304069
154,aditeyabaral/finetuned-sail2017-xlm-roberta-base,0.9275693108467569
155,cardiffnlp/bertweet-base-stance-climate,0.9951530300614249
156,M47Labs/spanish_news_classification_headlines_untrained,0.7403814924690225
157,zenkri/autotrain-Arabic_Poetry_by_Subject-920730230,0.8880570522067124
158,bondi/bert-semaphore-prediction-w4,0.7105892997310592
159,cointegrated/roberta-base-formality,0.9632897208772131
160,CAMeL-Lab/bert-base-arabic-camelbert-da-sentiment,0.5327002287005307
161,JonatanGk/roberta-base-ca-finetuned-hate-speech-offensive-catalan,0.6860291165006296
162,classla/bcms-bertic-parlasent-bcs-ter,0.7952175307679805
163,Raychanan/COVID_RandomOver,0.0811314627919425
164,ali2066/DistilBERTFINAL_ctxSentence_TRAIN_editorials_TEST_NULL_second_train_set_null_False,1.0500522523012228
165,anvay/finetuning-cardiffnlp-sentiment-model,0.9863072188293388
166,YeRyeongLee/electra-base-discriminator-finetuned-filtered-0602,0.28400576316775117
167,Jeevesh8/feather_berts_92,0.8487570499661732
168,joebobby/finetuning-sentiment-model-5000-samples3,0.8730288225921303
169,CAMeL-Lab/bert-base-arabic-camelbert-mix-did-nadi,0.6772282807800859
170,Monsia/camembert-fr-covid-tweet-classification,0.8656716348786744
171,ASCCCCCCCC/distilbert-base-chinese-amazon_zh_20000,0.7496325002135296
172,kyleinincubated/autonlp-cat333-624217911,0.7385935604222567
173,rmihaylov/roberta-base-sentiment-bg,0.810808172551567
174,fgaim/tiroberta-geezswitch,0.6287209112387397
