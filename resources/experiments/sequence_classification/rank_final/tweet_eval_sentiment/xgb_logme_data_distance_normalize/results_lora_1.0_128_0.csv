,model,score
0,Jeevesh8/init_bert_ft_qqp-33,0.81153
1,Jeevesh8/init_bert_ft_qqp-33,0.8154602
2,Jeevesh8/init_bert_ft_qqp-49,0.8236879
3,Jeevesh8/init_bert_ft_qqp-49,0.8236879
4,Jeevesh8/init_bert_ft_qqp-49,0.8099507
5,connectivity/bert_ft_qqp-7,0.80666417
6,connectivity/bert_ft_qqp-7,0.79835546
7,Jeevesh8/bert_ft_qqp-40,0.83010256
8,Jeevesh8/bert_ft_qqp-40,0.7991693
9,Jeevesh8/bert_ft_qqp-9,0.83808106
10,Jeevesh8/bert_ft_qqp-9,0.85042995
11,Jeevesh8/bert_ft_qqp-88,0.8386595
12,Jeevesh8/bert_ft_qqp-88,0.85638577
13,connectivity/bert_ft_qqp-25,0.8402499
14,connectivity/bert_ft_qqp-25,0.86673164
15,Jeevesh8/bert_ft_qqp-55,0.8507363
16,Jeevesh8/bert_ft_qqp-55,0.834503
17,connectivity/bert_ft_qqp-1,0.8388066
18,connectivity/bert_ft_qqp-1,0.81999546
19,Jeevesh8/bert_ft_qqp-39,0.85224575
20,Jeevesh8/bert_ft_qqp-39,0.81999546
21,connectivity/bert_ft_qqp-94,0.81153
22,connectivity/bert_ft_qqp-94,0.7755017
23,connectivity/bert_ft_qqp-96,0.8490118
24,connectivity/bert_ft_qqp-96,0.8620543
25,Jeevesh8/init_bert_ft_qqp-24,0.83114237
26,Jeevesh8/init_bert_ft_qqp-24,0.8085532
27,Jeevesh8/bert_ft_qqp-68,0.80097204
28,Jeevesh8/bert_ft_qqp-68,0.81361455
29,Jeevesh8/init_bert_ft_qqp-28,0.8592771
30,Jeevesh8/init_bert_ft_qqp-28,0.8434183
31,connectivity/bert_ft_qqp-17,0.81153
32,connectivity/bert_ft_qqp-17,0.7755017
33,ali2066/finetuned_sentence_itr1_2e-05_all_26_02_2022-04_03_26,0.8756014
34,ali2066/finetuned_sentence_itr1_2e-05_all_26_02_2022-04_03_26,0.87412053
35,SetFit/distilbert-base-uncased__sst2__train-16-0,0.83706385
36,SetFit/distilbert-base-uncased__sst2__train-16-0,0.8341706
37,SetFit/distilbert-base-uncased__sst2__train-16-0,0.82485193
38,gchhablani/fnet-base-finetuned-sst2,0.81291336
39,gchhablani/fnet-base-finetuned-sst2,0.78135914
40,aviator-neural/bert-base-uncased-sst2,0.8438695
41,aviator-neural/bert-base-uncased-sst2,0.856912
42,SetFit/distilbert-base-uncased__sst2__train-32-9,0.8501558
43,SetFit/distilbert-base-uncased__sst2__train-32-9,0.8269624
44,Alassea/glue_sst_classifier,0.8567914
45,Alassea/glue_sst_classifier,0.8539863
46,philschmid/tiny-distilbert-classification,0.07942323
47,philschmid/tiny-distilbert-classification,0.11038082
48,moshew/bert-mini-sst2-distilled,0.81986076
49,moshew/bert-mini-sst2-distilled,0.7509964
50,ChrisUPM/BioBERT_Re_trained,0.8077103
51,ChrisUPM/BioBERT_Re_trained,0.7562253
52,vaariis/distilbert-base-uncased-finetuned-emotion,0.83333373
53,vaariis/distilbert-base-uncased-finetuned-emotion,0.8268147
54,marcelcastrobr/sagemaker-distilbert-emotion,0.83443606
55,marcelcastrobr/sagemaker-distilbert-emotion,0.83701646
56,jasonyim2/distilbert-base-uncased-finetuned-emotion,0.8369831
57,jasonyim2/distilbert-base-uncased-finetuned-emotion,0.83505726
58,abdelkader/distilbert-base-uncased-finetuned-emotion,0.7924355
59,abdelkader/distilbert-base-uncased-finetuned-emotion,0.8266336
60,abdelkader/distilbert-base-uncased-finetuned-emotion,0.82743126
61,moghis/distilbert-base-uncased-finetuned-emotion,0.8266336
62,moghis/distilbert-base-uncased-finetuned-emotion,0.831171
63,uygarkurt/distilbert-base-uncased-finetuned-emotion,0.83436716
64,uygarkurt/distilbert-base-uncased-finetuned-emotion,0.8289661
65,neibla/distilbert-base-uncased-finetuned-emotion,0.8356455
66,neibla/distilbert-base-uncased-finetuned-emotion,0.8377695
67,JB173/distilbert-base-uncased-finetuned-emotion,0.8389858
68,JB173/distilbert-base-uncased-finetuned-emotion,0.83324784
69,Nanatan/distilbert-base-uncased-finetuned-emotion,0.8483189
70,Nanatan/distilbert-base-uncased-finetuned-emotion,0.8439316
71,heranm/finetuning-sentiment-model-3000-samples,0.8490298
72,heranm/finetuning-sentiment-model-3000-samples,0.8571175
73,PrasunMishra/finetuning-sentiment-model-3000-samples,0.8278117
74,PrasunMishra/finetuning-sentiment-model-3000-samples,0.8376079
75,PrasunMishra/finetuning-sentiment-model-3000-samples,0.82842445
76,yukta10/finetuning-sentiment-model-3000-samples,0.83940655
77,yukta10/finetuning-sentiment-model-3000-samples,0.8421369
78,yukta10/finetuning-sentiment-model-3000-samples,0.85689914
79,ncduy/roberta-imdb-sentiment-analysis,0.8894074
80,ncduy/roberta-imdb-sentiment-analysis,0.8923103
81,markt23917/finetuning-sentiment-model-3000-samples,0.84761465
82,markt23917/finetuning-sentiment-model-3000-samples,0.8456927
83,juliensimon/autonlp-imdb-demo-hf-16622767,0.8349841
84,juliensimon/autonlp-imdb-demo-hf-16622767,0.82152295
85,fabriceyhc/bert-base-uncased-imdb,0.8149119
86,fabriceyhc/bert-base-uncased-imdb,0.8088211
87,XSY/albert-base-v2-imdb-calssification,0.7817753
88,riyadhctg/distilbert-base-uncased-finetuned-cola,0.83324087
89,riyadhctg/distilbert-base-uncased-finetuned-cola,0.8256058
90,connectivity/cola_6ep_ft-33,0.8888662
91,connectivity/cola_6ep_ft-33,0.8498023
92,connectivity/cola_6ep_ft-33,0.81852657
93,connectivity/cola_6ep_ft-22,0.8414211
94,connectivity/cola_6ep_ft-22,0.85486025
95,connectivity/cola_6ep_ft-22,0.8585716
96,gchhablani/fnet-base-finetuned-cola,0.7904305
97,isakbos/Q8BERT_COLA_L_512,0.5571408
98,isakbos/Q8BERT_COLA_L_512,0.5558563
99,jaesun/distilbert-base-uncased-finetuned-cola,0.85089666
100,jaesun/distilbert-base-uncased-finetuned-cola,0.82274294
101,usami/distilbert-base-uncased-finetuned-cola,0.84153336
102,usami/distilbert-base-uncased-finetuned-cola,0.819032
103,Jeevesh8/512seq_len_6ep_bert_ft_cola-91,0.8343616
104,Jeevesh8/512seq_len_6ep_bert_ft_cola-91,0.80525947
105,Jeevesh8/6ep_bert_ft_cola-47,0.8420529
106,Jeevesh8/6ep_bert_ft_cola-47,0.8459832
107,connectivity/cola_6ep_ft-10,0.8414211
108,connectivity/cola_6ep_ft-10,0.8398059
109,Jeevesh8/6ep_bert_ft_cola-12,0.853417
110,Jeevesh8/6ep_bert_ft_cola-12,0.8571283
111,Jeevesh8/bert_ft_cola-88,0.85326976
112,Jeevesh8/bert_ft_cola-88,0.8557757
113,Jeevesh8/6ep_bert_ft_cola-29,0.8498023
114,Jeevesh8/6ep_bert_ft_cola-29,0.8496163
115,vesteinn/XLMR-ENIS-finetuned-cola,0.9078419
116,vesteinn/XLMR-ENIS-finetuned-cola,0.8987359
117,navsad/navid_test_bert,0.8209931
118,navsad/navid_test_bert,0.8143071
119,Jeevesh8/bert_ft_cola-60,0.8416981
120,Jeevesh8/bert_ft_cola-60,0.84664464
121,dapang/distilroberta-base-mic-sym,0.82608396
122,dapang/distilroberta-base-mic-sym,0.8810192
123,dapang/distilroberta-base-mic-sym,0.87936884
124,Capreolus/bert-base-msmarco,0.87327194
125,Capreolus/bert-base-msmarco,0.82717377
126,Capreolus/bert-base-msmarco,0.8504264
127,Splend1dchan/bert-base-uncased-slue-goldtrascription-e3-lr1e-4,0.896587
128,Splend1dchan/bert-base-uncased-slue-goldtrascription-e3-lr1e-4,0.8627714
129,Splend1dchan/bert-base-uncased-slue-goldtrascription-e3-lr1e-4,0.85941094
130,Jeevesh8/feather_berts_46,0.8559295
131,Jeevesh8/feather_berts_46,0.8559295
132,Jeevesh8/feather_berts_46,0.8418047
133,JonatanGk/roberta-base-bne-finetuned-cyberbullying-spanish,0.5152867
134,JonatanGk/roberta-base-bne-finetuned-cyberbullying-spanish,0.5152867
135,cambridgeltl/guardian_news_distilbert-base-uncased,0.7941856
136,cambridgeltl/guardian_news_distilbert-base-uncased,0.7836896
137,amyma21/sincere_question_classification,0.8537048
138,amyma21/sincere_question_classification,0.83060783
139,phailyoor/distilbert-base-uncased-finetuned-yahd,0.7695647
140,phailyoor/distilbert-base-uncased-finetuned-yahd,0.65063673
141,arianpasquali/distilbert-base-multilingual-cased-toxicity,0.70049477
142,arianpasquali/distilbert-base-multilingual-cased-toxicity,0.75759095
143,connectivity/feather_berts_28,0.84661704
144,connectivity/feather_berts_28,0.84848577
145,liangyuant/distilbert-base-uncased-finetuned-num200-450-405cls,0.8135743
146,liangyuant/distilbert-base-uncased-finetuned-num200-450-405cls,0.69111085
147,DoyyingFace/bert-asian-hate-tweets-asian-unclean-freeze-4,0.8569084
148,DoyyingFace/bert-asian-hate-tweets-asian-unclean-freeze-4,0.8265859
149,Jeevesh8/lecun_feather_berts-3,0.85552114
150,Jeevesh8/lecun_feather_berts-3,0.82721716
151,Giyaseddin/distilroberta-base-finetuned-short-answer-assessment,0.81141144
152,Giyaseddin/distilroberta-base-finetuned-short-answer-assessment,0.85653245
153,AnonymousSub/dummy_2,0.81396013
154,AnonymousSub/dummy_2,0.78200746
155,Jeevesh8/lecun_feather_berts-51,0.85631245
156,Jeevesh8/lecun_feather_berts-51,0.8581813
157,viviastaari/finetuning-sentiment-analysis-en-id,0.62172383
158,viviastaari/finetuning-sentiment-analysis-en-id,0.62366784
159,Aureliano/distilbert-base-uncased-if,0.8560154
160,Aureliano/distilbert-base-uncased-if,0.8316189
161,rmihaylov/roberta-base-sentiment-bg,0.8440083
162,rmihaylov/roberta-base-sentiment-bg,0.808365
163,cardiffnlp/twitter-roberta-base-2021-124m,0.885392
164,cardiffnlp/twitter-roberta-base-2021-124m,0.8922199
165,Jeevesh8/lecun_feather_berts-8,0.83586055
166,Jeevesh8/lecun_feather_berts-8,0.8280085
167,korca/bae-roberta-base-boolq,0.8835692
168,korca/bae-roberta-base-boolq,0.89010197
169,aditeyabaral/finetuned-sail2017-xlm-roberta-base,0.8113531
170,aditeyabaral/finetuned-sail2017-xlm-roberta-base,0.78710663
171,joebobby/finetuning-sentiment-model-5000-samples3,0.86658275
172,joebobby/finetuning-sentiment-model-5000-samples3,0.84744054
173,YeRyeongLee/electra-base-discriminator-finetuned-filtered-0602,0.26124427
174,YeRyeongLee/electra-base-discriminator-finetuned-filtered-0602,0.0114357835
175,Jeevesh8/feather_berts_92,0.8539464
176,Jeevesh8/feather_berts_92,0.85838526
177,ASCCCCCCCC/distilbert-base-chinese-amazon_zh_20000,0.7619784
178,ASCCCCCCCC/distilbert-base-chinese-amazon_zh_20000,0.7114413
179,matthewburke/korean_sentiment,0.6991337
180,matthewburke/korean_sentiment,0.64267117
181,IMSyPP/hate_speech_nl,0.64180464
182,IMSyPP/hate_speech_nl,0.54484457
183,cointegrated/roberta-base-formality,0.85303855
184,cointegrated/roberta-base-formality,0.8342213
185,chiragasarpota/scotus-bert,0.5168756
186,chiragasarpota/scotus-bert,0.48649782
187,IMSyPP/hate_speech_it,0.7936027
188,IMSyPP/hate_speech_it,0.76138914
189,18811449050/bert_finetuning_test,0.8339856
190,18811449050/bert_finetuning_test,0.8478836
191,finiteautomata/betonews-tweetcontext,0.7481817
192,finiteautomata/betonews-tweetcontext,0.66857105
193,Jeevesh8/feather_berts_96,0.8539464
194,Jeevesh8/feather_berts_96,0.82821244
195,Jeevesh8/lecun_feather_berts-7,0.8539464
196,Jeevesh8/lecun_feather_berts-7,0.8481049
197,mrm8488/codebert-base-finetuned-detect-insecure-code,0.7659122
198,mrm8488/codebert-base-finetuned-detect-insecure-code,0.73711777
199,cardiffnlp/bertweet-base-stance-climate,0.8581844
200,cardiffnlp/bertweet-base-stance-climate,0.8622073
201,socialmediaie/TRAC2020_IBEN_B_bert-base-multilingual-uncased,0.8088964
202,socialmediaie/TRAC2020_IBEN_B_bert-base-multilingual-uncased,0.7912342
203,zenkri/autotrain-Arabic_Poetry_by_Subject-920730230,0.8669579
204,zenkri/autotrain-Arabic_Poetry_by_Subject-920730230,0.86707646
205,M47Labs/spanish_news_classification_headlines_untrained,0.79065937
206,M47Labs/spanish_news_classification_headlines_untrained,0.7305351
207,bondi/bert-semaphore-prediction-w4,0.7693583
208,bondi/bert-semaphore-prediction-w4,0.6067933
209,classla/bcms-bertic-parlasent-bcs-ter,0.8159014
210,classla/bcms-bertic-parlasent-bcs-ter,0.797264
211,waboucay/camembert-base-finetuned-xnli_fr-finetuned-nli-rua_wl,0.66743547
212,ali2066/DistilBERTFINAL_ctxSentence_TRAIN_editorials_TEST_NULL_second_train_set_null_False,0.88727224
213,ali2066/DistilBERTFINAL_ctxSentence_TRAIN_editorials_TEST_NULL_second_train_set_null_False,0.8884225
214,anvay/finetuning-cardiffnlp-sentiment-model,0.87760144
215,anvay/finetuning-cardiffnlp-sentiment-model,0.8915393
216,JonatanGk/roberta-base-ca-finetuned-hate-speech-offensive-catalan,0.76099896
217,JonatanGk/roberta-base-ca-finetuned-hate-speech-offensive-catalan,0.65895414
218,Raychanan/COVID_RandomOver,0.23870987
219,Raychanan/COVID_RandomOver,0.024954954
220,Monsia/camembert-fr-covid-tweet-classification,0.93211216
221,CAMeL-Lab/bert-base-arabic-camelbert-mix-did-nadi,0.4864975
222,CAMeL-Lab/bert-base-arabic-camelbert-mix-did-nadi,0.38346714
223,kyleinincubated/autonlp-cat333-624217911,0.72969484
224,kyleinincubated/autonlp-cat333-624217911,0.61767244
225,CAMeL-Lab/bert-base-arabic-camelbert-da-sentiment,0.54563534
226,CAMeL-Lab/bert-base-arabic-camelbert-da-sentiment,0.45329353
227,fgaim/tiroberta-geezswitch,0.78571606
228,nreimers/mmarco-mMiniLMv2-L6-H384-v1,0.7582155
229,nreimers/mmarco-mMiniLMv2-L6-H384-v1,0.58731246
230,strickvl/nlp-redaction-classifier,0.80166584
231,strickvl/nlp-redaction-classifier,0.7961627
232,saattrupdan/job-listing-relevance-model,0.8770996
233,saattrupdan/job-listing-relevance-model,0.7358728
234,morenolq/SumTO_FNS2020,0.7935741
235,morenolq/SumTO_FNS2020,0.7551682
236,cross-encoder/ms-marco-MiniLM-L-4-v2,0.8024255
237,cross-encoder/ms-marco-MiniLM-L-4-v2,0.67915004
238,nurkayevaa/autonlp-bert-covid-407910458,0.8446445
239,nurkayevaa/autonlp-bert-covid-407910458,0.8446445
240,nurkayevaa/autonlp-bert-covid-407910458,0.815211
241,SetFit/distilbert-base-uncased__hate_speech_offensive__train-16-1,0.83481884
242,SetFit/distilbert-base-uncased__hate_speech_offensive__train-16-1,0.8438769
243,SetFit/distilbert-base-uncased__hate_speech_offensive__train-16-1,0.8397232
244,crcb/isear_bert,0.9290803
245,crcb/isear_bert,0.90945125
246,crcb/isear_bert,0.91281545
247,robertou2/roberta-base-bne-finetuned-amazon_reviews_multi,0.7617927
248,robertou2/roberta-base-bne-finetuned-amazon_reviews_multi,0.7617927
249,milyiyo/selectra-small-finetuned-amazon-review,0.5335913
250,milyiyo/selectra-small-finetuned-amazon-review,0.45351505
251,Anthos23/FS-distilroberta-fine-tuned,0.8804095
252,Anthos23/FS-distilroberta-fine-tuned,0.88328034
253,oferweintraub/bert-base-finance-sentiment-noisy-search,0.8534955
254,oferweintraub/bert-base-finance-sentiment-noisy-search,0.8214113
255,pietrotrope/emotion_final,0.8740291
256,pietrotrope/emotion_final,0.8727991
257,aXhyra/emotion_trained_31415,0.8702795
258,aXhyra/emotion_trained_31415,0.86415905
259,aXhyra/presentation_emotion_31415,0.86733603
260,aXhyra/presentation_emotion_31415,0.87631714
261,Recognai/bert-base-spanish-wwm-cased-xnli,0.71865135
262,Recognai/bert-base-spanish-wwm-cased-xnli,0.6519143
263,JNK789/distilbert-base-uncased-finetuned-tweets-emoji-dataset,0.039440457
264,JNK789/distilbert-base-uncased-finetuned-tweets-emoji-dataset,-0.0011554193
265,anirudh21/bert-base-uncased-finetuned-qnli,0.8575868
266,anirudh21/bert-base-uncased-finetuned-qnli,0.84937596
267,Alireza1044/albert-base-v2-qnli,0.86131406
268,aXhyra/demo_sentiment_31415,0.86530834
269,aXhyra/demo_sentiment_31415,0.8532008
270,aXhyra/presentation_sentiment_1234567,0.86618614
271,aXhyra/presentation_sentiment_1234567,0.8568782
272,jb2k/bert-base-multilingual-cased-language-detection,0.77262664
273,jb2k/bert-base-multilingual-cased-language-detection,0.7279766
274,vinai/bertweet-base,0.90175503
275,vinai/bertweet-base,0.90328425
276,justinqbui/bertweet-covid19-base-uncased-pretraining-covid-vaccine-tweets,0.8836124
277,justinqbui/bertweet-covid19-base-uncased-pretraining-covid-vaccine-tweets,0.88439494
278,vinai/bertweet-covid19-base-cased,0.89327127
279,vinai/bertweet-covid19-base-cased,0.9063942
280,vinai/bertweet-covid19-base-uncased,0.8926192
281,vinai/bertweet-covid19-base-uncased,0.90328425
282,distilbert-base-uncased,0.8440224
283,distilbert-base-uncased,0.8420422
284,bert-base-uncased,0.8670898
285,bert-base-uncased,0.86834687
286,roberta-base,0.89044183
287,roberta-base,0.91662484
288,albert-base-v2,0.8303868
289,bert-base-cased,0.8465638
290,bert-base-cased,0.8331247
291,dhimskyy/wiki-bert,0.62962514
292,dhimskyy/wiki-bert,0.5937306
293,michiyasunaga/LinkBERT-base,0.860993
294,michiyasunaga/LinkBERT-base,0.8459523
295,boychaboy/MNLI_roberta-base,0.9082159
296,boychaboy/MNLI_roberta-base,0.9201578
297,ishan/bert-base-uncased-mnli,0.86710757
298,ishan/bert-base-uncased-mnli,0.8730516
299,emrecan/bert-base-multilingual-cased-snli_tr,0.84381515
300,emrecan/bert-base-multilingual-cased-snli_tr,0.76833224
301,elozano/tweet_offensive_eval,0.67012095
302,elozano/tweet_offensive_eval,0.58670086
303,Hate-speech-CNERG/bert-base-uncased-hatexplain-rationale-two,0.84075713
304,Hate-speech-CNERG/bert-base-uncased-hatexplain-rationale-two,0.82174563
305,aychang/bert-base-cased-trec-coarse,0.8538109
306,aychang/bert-base-cased-trec-coarse,0.84811443
307,gchhablani/bert-base-cased-finetuned-wnli,0.8615767
308,gchhablani/bert-base-cased-finetuned-wnli,0.82528543
309,nickmuchi/facebook-data2vec-finetuned-finance-classification,0.9546022
310,w11wo/sundanese-bert-base-emotion-classifier,0.53267854
311,w11wo/sundanese-bert-base-emotion-classifier,0.44022933
312,gchhablani/bert-base-cased-finetuned-rte,0.8364866
313,gchhablani/bert-base-cased-finetuned-rte,0.82897294
314,mrm8488/electricidad-base-finetuned-pawsx-es,0.72479516
315,mrm8488/electricidad-base-finetuned-pawsx-es,0.6488006
316,manueltonneau/bert-twitter-en-is-hired,0.86163837
317,manueltonneau/bert-twitter-en-is-hired,0.857408
318,Guscode/DKbert-hatespeech-detection,0.6689882
319,Guscode/DKbert-hatespeech-detection,0.6481708
320,cross-encoder/quora-distilroberta-base,0.85231435
321,cross-encoder/quora-distilroberta-base,0.8423157
322,navteca/quora-roberta-base,0.8405323
323,navteca/quora-roberta-base,0.81904906
324,cross-encoder/quora-roberta-base,0.8405323
325,cross-encoder/quora-roberta-base,0.79836005
