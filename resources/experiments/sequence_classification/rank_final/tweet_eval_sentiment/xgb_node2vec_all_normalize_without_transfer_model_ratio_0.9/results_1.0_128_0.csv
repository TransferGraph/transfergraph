,model,score
0,Guscode/DKbert-hatespeech-detection,0.70922846
1,robertou2/roberta-base-bne-finetuned-amazon_reviews_multi,0.79681414
2,milyiyo/selectra-small-finetuned-amazon-review,0.52247965
3,SetFit/distilbert-base-uncased__hate_speech_offensive__train-16-1,0.8875081
4,SetFit/distilbert-base-uncased__hate_speech_offensive__train-16-1,0.89149296
5,vinai/bertweet-base,0.9726784
6,justinqbui/bertweet-covid19-base-uncased-pretraining-covid-vaccine-tweets,0.9338117
7,vinai/bertweet-covid19-base-cased,0.938849
8,vinai/bertweet-covid19-base-uncased,0.949417
9,jb2k/bert-base-multilingual-cased-language-detection,0.8385795
10,crcb/isear_bert,0.95328647
11,crcb/isear_bert,0.9441408
12,abdelkader/distilbert-base-uncased-finetuned-emotion,0.85548264
13,vaariis/distilbert-base-uncased-finetuned-emotion,0.86853445
14,marcelcastrobr/sagemaker-distilbert-emotion,0.83586806
15,jasonyim2/distilbert-base-uncased-finetuned-emotion,0.87611616
16,abdelkader/distilbert-base-uncased-finetuned-emotion,0.8635567
17,moghis/distilbert-base-uncased-finetuned-emotion,0.84780157
18,uygarkurt/distilbert-base-uncased-finetuned-emotion,0.8694873
19,neibla/distilbert-base-uncased-finetuned-emotion,0.87725395
20,JB173/distilbert-base-uncased-finetuned-emotion,0.8334216
21,Nanatan/distilbert-base-uncased-finetuned-emotion,0.8487162
22,connectivity/cola_6ep_ft-22,0.8796195
23,connectivity/cola_6ep_ft-33,0.8968551
24,riyadhctg/distilbert-base-uncased-finetuned-cola,0.8530736
25,connectivity/cola_6ep_ft-33,0.8797259
26,connectivity/cola_6ep_ft-22,0.89703065
27,vesteinn/XLMR-ENIS-finetuned-cola,0.9084348
28,isakbos/Q8BERT_COLA_L_512,0.7261525
29,jaesun/distilbert-base-uncased-finetuned-cola,0.84396553
30,usami/distilbert-base-uncased-finetuned-cola,0.86599
31,Jeevesh8/512seq_len_6ep_bert_ft_cola-91,0.9132293
32,connectivity/cola_6ep_ft-10,0.8666294
33,Jeevesh8/6ep_bert_ft_cola-12,0.8765142
34,Jeevesh8/6ep_bert_ft_cola-29,0.90873647
35,navsad/navid_test_bert,0.8735405
36,Jeevesh8/bert_ft_cola-60,0.8892501
37,ishan/bert-base-uncased-mnli,0.8971731
38,boychaboy/MNLI_roberta-base,0.94575423
39,anirudh21/bert-base-uncased-finetuned-qnli,0.9003695
40,Jeevesh8/init_bert_ft_qqp-49,0.9154075
41,Jeevesh8/init_bert_ft_qqp-33,0.8802187
42,Jeevesh8/init_bert_ft_qqp-49,0.9154075
43,connectivity/bert_ft_qqp-7,0.8866383
44,Jeevesh8/bert_ft_qqp-40,0.9056357
45,Jeevesh8/bert_ft_qqp-9,0.9063511
46,Jeevesh8/bert_ft_qqp-88,0.89859647
47,connectivity/bert_ft_qqp-25,0.90829396
48,Jeevesh8/init_bert_ft_qqp-24,0.8605512
49,Jeevesh8/bert_ft_qqp-55,0.8814485
50,Jeevesh8/bert_ft_qqp-68,0.8596149
51,connectivity/bert_ft_qqp-17,0.8837036
52,Jeevesh8/init_bert_ft_qqp-28,0.8907755
53,connectivity/bert_ft_qqp-1,0.8884642
54,connectivity/bert_ft_qqp-94,0.89059603
55,gchhablani/bert-base-cased-finetuned-rte,0.8912831
56,SetFit/distilbert-base-uncased__sst2__train-16-0,0.8783213
57,gchhablani/fnet-base-finetuned-sst2,0.7567721
58,philschmid/tiny-distilbert-classification,0.05531502
59,ali2066/finetuned_sentence_itr1_2e-05_all_26_02_2022-04_03_26,0.8627355
60,SetFit/distilbert-base-uncased__sst2__train-16-0,0.874682
61,gchhablani/fnet-base-finetuned-sst2,0.79208136
62,moshew/bert-mini-sst2-distilled,0.8506391
63,SetFit/distilbert-base-uncased__sst2__train-32-9,0.87126255
64,aviator-neural/bert-base-uncased-sst2,0.85299426
65,Alassea/glue_sst_classifier,0.8657594
66,ChrisUPM/BioBERT_Re_trained,0.7871058
67,gchhablani/bert-base-cased-finetuned-wnli,0.85075796
68,Hate-speech-CNERG/bert-base-uncased-hatexplain-rationale-two,0.88204193
69,PrasunMishra/finetuning-sentiment-model-3000-samples,0.8620513
70,yukta10/finetuning-sentiment-model-3000-samples,0.88058084
71,heranm/finetuning-sentiment-model-3000-samples,0.8827104
72,PrasunMishra/finetuning-sentiment-model-3000-samples,0.8647537
73,yukta10/finetuning-sentiment-model-3000-samples,0.88594246
74,ncduy/roberta-imdb-sentiment-analysis,0.95104146
75,markt23917/finetuning-sentiment-model-3000-samples,0.8677685
76,juliensimon/autonlp-imdb-demo-hf-16622767,0.8591269
77,XSY/albert-base-v2-imdb-calssification,0.8481031
78,fabriceyhc/bert-base-uncased-imdb,0.85761505
79,Anthos23/FS-distilroberta-fine-tuned,0.89605385
80,oferweintraub/bert-base-finance-sentiment-noisy-search,0.8909305
81,emrecan/bert-base-multilingual-cased-snli_tr,0.8332138
82,nurkayevaa/autonlp-bert-covid-407910458,0.83834517
83,nurkayevaa/autonlp-bert-covid-407910458,0.8375137
84,cross-encoder/quora-distilroberta-base,0.8151829
85,navteca/quora-roberta-base,0.88351023
86,cross-encoder/quora-roberta-base,0.8798919
87,w11wo/sundanese-bert-base-emotion-classifier,0.6911431
88,aychang/bert-base-cased-trec-coarse,0.8777824
89,JNK789/distilbert-base-uncased-finetuned-tweets-emoji-dataset,-0.04081018
90,pietrotrope/emotion_final,0.87589777
91,aXhyra/emotion_trained_31415,0.8856669
92,elozano/tweet_offensive_eval,0.7300766
93,aXhyra/demo_sentiment_31415,0.86117804
94,aXhyra/presentation_sentiment_1234567,0.87833023
95,nickmuchi/facebook-data2vec-finetuned-finance-classification,0.8714333
96,manueltonneau/bert-twitter-en-is-hired,0.9101576
97,distilbert-base-uncased,0.8841588
98,dhimskyy/wiki-bert,0.73593736
99,bert-base-uncased,0.8974696
100,roberta-base,0.9592881
101,bert-base-cased,0.8650176
102,albert-base-v2,0.83870363
103,michiyasunaga/LinkBERT-base,0.8949848
104,Recognai/bert-base-spanish-wwm-cased-xnli,0.78142315
105,mrm8488/electricidad-base-finetuned-pawsx-es,0.7239443
106,Capreolus/bert-base-msmarco,0.8835781
107,Jeevesh8/feather_berts_46,0.906859
108,Splend1dchan/bert-base-uncased-slue-goldtrascription-e3-lr1e-4,0.90091884
109,dapang/distilroberta-base-mic-sym,0.92023885
110,dapang/distilroberta-base-mic-sym,0.9262098
111,cambridgeltl/guardian_news_distilbert-base-uncased,0.8393025
112,Capreolus/bert-base-msmarco,0.8694937
113,Splend1dchan/bert-base-uncased-slue-goldtrascription-e3-lr1e-4,0.8829261
114,Jeevesh8/feather_berts_46,0.906859
115,JonatanGk/roberta-base-bne-finetuned-cyberbullying-spanish,0.47591665
116,amyma21/sincere_question_classification,0.8578424
117,chiragasarpota/scotus-bert,0.5429332
118,strickvl/nlp-redaction-classifier,0.90554947
119,connectivity/feather_berts_28,0.8815897
120,IMSyPP/hate_speech_it,0.7833104
121,liangyuant/distilbert-base-uncased-finetuned-num200-450-405cls,0.879616
122,DoyyingFace/bert-asian-hate-tweets-asian-unclean-freeze-4,0.897206
123,Giyaseddin/distilroberta-base-finetuned-short-answer-assessment,0.85720944
124,saattrupdan/job-listing-relevance-model,0.9126476
125,Jeevesh8/lecun_feather_berts-3,0.87291956
126,18811449050/bert_finetuning_test,0.8081372
127,Jeevesh8/feather_berts_96,0.8845391
128,Jeevesh8/lecun_feather_berts-51,0.8839776
129,viviastaari/finetuning-sentiment-analysis-en-id,0.76365364
130,AnonymousSub/dummy_2,0.8477924
131,finiteautomata/betonews-tweetcontext,0.73293495
132,Aureliano/distilbert-base-uncased-if,0.86960995
133,cross-encoder/ms-marco-MiniLM-L-4-v2,0.843604
134,cardiffnlp/twitter-roberta-base-2021-124m,0.9421668
135,Jeevesh8/lecun_feather_berts-8,0.8734393
136,Jeevesh8/lecun_feather_berts-7,0.9294859
137,morenolq/SumTO_FNS2020,0.8290678
138,IMSyPP/hate_speech_nl,0.5696917
139,korca/bae-roberta-base-boolq,0.9165185
140,waboucay/camembert-base-finetuned-xnli_fr-finetuned-nli-rua_wl,0.6786874
141,mrm8488/codebert-base-finetuned-detect-insecure-code,0.8538997
142,socialmediaie/TRAC2020_IBEN_B_bert-base-multilingual-uncased,0.8410492
143,aditeyabaral/finetuned-sail2017-xlm-roberta-base,0.9196003
144,cardiffnlp/bertweet-base-stance-climate,0.94004303
145,M47Labs/spanish_news_classification_headlines_untrained,0.7532874
146,zenkri/autotrain-Arabic_Poetry_by_Subject-920730230,0.90032846
147,bondi/bert-semaphore-prediction-w4,0.79473543
148,cointegrated/roberta-base-formality,0.9167791
149,CAMeL-Lab/bert-base-arabic-camelbert-da-sentiment,0.69356585
150,JonatanGk/roberta-base-ca-finetuned-hate-speech-offensive-catalan,0.80391896
151,classla/bcms-bertic-parlasent-bcs-ter,0.8280429
152,Raychanan/COVID_RandomOver,0.044940874
153,ali2066/DistilBERTFINAL_ctxSentence_TRAIN_editorials_TEST_NULL_second_train_set_null_False,0.9222546
154,YeRyeongLee/electra-base-discriminator-finetuned-filtered-0602,0.32902765
155,Jeevesh8/feather_berts_92,0.90770775
156,joebobby/finetuning-sentiment-model-5000-samples3,0.9034831
157,CAMeL-Lab/bert-base-arabic-camelbert-mix-did-nadi,0.73089254
158,Monsia/camembert-fr-covid-tweet-classification,0.8480868
159,kyleinincubated/autonlp-cat333-624217911,0.74741626
160,rmihaylov/roberta-base-sentiment-bg,0.81001216
161,fgaim/tiroberta-geezswitch,0.6812463
