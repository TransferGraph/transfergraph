,model,score
0,Guscode/DKbert-hatespeech-detection,0.7856922855022581
1,milyiyo/selectra-small-finetuned-amazon-review,0.6400663956837671
2,SetFit/distilbert-base-uncased__hate_speech_offensive__train-16-1,0.8282519050366699
3,SetFit/distilbert-base-uncased__hate_speech_offensive__train-16-1,0.8282519050366699
4,vinai/bertweet-base,0.8243269759120031
5,vinai/bertweet-covid19-base-uncased,0.8318542239235511
6,crcb/isear_bert,0.8432545333259356
7,crcb/isear_bert,0.8432545333259356
8,abdelkader/distilbert-base-uncased-finetuned-emotion,0.8291457902343873
9,abdelkader/distilbert-base-uncased-finetuned-emotion,0.8291457902343873
10,uygarkurt/distilbert-base-uncased-finetuned-emotion,0.8403137613243657
11,neibla/distilbert-base-uncased-finetuned-emotion,0.837418068927606
12,Nanatan/distilbert-base-uncased-finetuned-emotion,0.8329162962124782
13,riyadhctg/distilbert-base-uncased-finetuned-cola,0.828486181879433
14,gchhablani/fnet-base-finetuned-cola,0.8094048125536445
15,isakbos/Q8BERT_COLA_L_512,0.7243719521974035
16,usami/distilbert-base-uncased-finetuned-cola,0.8315876534880511
17,connectivity/cola_6ep_ft-10,0.8332525596581292
18,navsad/navid_test_bert,0.8417524913879392
19,boychaboy/MNLI_roberta-base,0.8359702903178426
20,anirudh21/bert-base-uncased-finetuned-qnli,0.8422564819574236
21,Jeevesh8/init_bert_ft_qqp-49,0.8362291215618574
22,Jeevesh8/init_bert_ft_qqp-49,0.8362291215618574
23,Jeevesh8/bert_ft_qqp-9,0.8357675355002578
24,Jeevesh8/bert_ft_qqp-88,0.8306341456754888
25,connectivity/bert_ft_qqp-25,0.8469758908201377
26,Jeevesh8/init_bert_ft_qqp-24,0.8281769593623705
27,Jeevesh8/bert_ft_qqp-55,0.8334241954826308
28,Jeevesh8/bert_ft_qqp-68,0.8378557772314805
29,Jeevesh8/init_bert_ft_qqp-28,0.8329684684456349
30,Jeevesh8/bert_ft_qqp-39,0.8354951351140447
31,connectivity/bert_ft_qqp-94,0.828408916532074
32,connectivity/bert_ft_qqp-96,0.8326148646232789
33,SetFit/distilbert-base-uncased__sst2__train-16-0,0.837611250250187
34,gchhablani/fnet-base-finetuned-sst2,0.8142762568268318
35,SetFit/distilbert-base-uncased__sst2__train-16-0,0.837611250250187
36,gchhablani/fnet-base-finetuned-sst2,0.8142762568268318
37,aviator-neural/bert-base-uncased-sst2,0.8287996900546218
38,Alassea/glue_sst_classifier,0.8362627438776229
39,gchhablani/bert-base-cased-finetuned-wnli,0.8398504390970812
40,Hate-speech-CNERG/bert-base-uncased-hatexplain-rationale-two,0.8368707676580462
41,PrasunMishra/finetuning-sentiment-model-3000-samples,0.8384184516035437
42,heranm/finetuning-sentiment-model-3000-samples,0.8349668675144837
43,PrasunMishra/finetuning-sentiment-model-3000-samples,0.8384184516035437
44,markt23917/finetuning-sentiment-model-3000-samples,0.8214530566591681
45,Anthos23/FS-distilroberta-fine-tuned,0.8357327755826752
46,oferweintraub/bert-base-finance-sentiment-noisy-search,0.8231498275082904
47,emrecan/bert-base-multilingual-cased-snli_tr,0.8284830300602788
48,cross-encoder/quora-distilroberta-base,0.8331131830817435
49,navteca/quora-roberta-base,0.8059516922031357
50,w11wo/sundanese-bert-base-emotion-classifier,0.7707602716543608
51,aychang/bert-base-cased-trec-coarse,0.8351227210196577
52,JNK789/distilbert-base-uncased-finetuned-tweets-emoji-dataset,0.11965214977232025
53,pietrotrope/emotion_final,0.8353414536491137
54,aXhyra/presentation_sentiment_1234567,0.8327439360080292
55,manueltonneau/bert-twitter-en-is-hired,0.8430431528011171
56,dhimskyy/wiki-bert,0.748518670702466
57,bert-base-uncased,0.841667601607756
58,roberta-base,0.836490974388129
59,albert-base-v2,0.8172287028289652
60,michiyasunaga/LinkBERT-base,0.8322196701651682
61,Jeevesh8/feather_berts_46,0.843602489571256
62,Splend1dchan/bert-base-uncased-slue-goldtrascription-e3-lr1e-4,0.8423458281090965
63,dapang/distilroberta-base-mic-sym,0.8283634907390135
64,dapang/distilroberta-base-mic-sym,0.8283634907390135
65,cambridgeltl/guardian_news_distilbert-base-uncased,0.8346913950297639
66,Splend1dchan/bert-base-uncased-slue-goldtrascription-e3-lr1e-4,0.8423458281090965
67,Jeevesh8/feather_berts_46,0.843602489571256
68,JonatanGk/roberta-base-bne-finetuned-cyberbullying-spanish,0.6186770527078204
69,nreimers/mmarco-mMiniLMv2-L6-H384-v1,0.7900859040573254
70,amyma21/sincere_question_classification,0.8354197633972342
71,arianpasquali/distilbert-base-multilingual-cased-toxicity,0.810122089330308
72,chiragasarpota/scotus-bert,0.7287290125240249
73,strickvl/nlp-redaction-classifier,0.8066544609050073
74,DoyyingFace/bert-asian-hate-tweets-asian-unclean-freeze-4,0.8349791473244258
75,Jeevesh8/lecun_feather_berts-3,0.8343776540414768
76,Jeevesh8/lecun_feather_berts-51,0.8416865844547501
77,viviastaari/finetuning-sentiment-analysis-en-id,0.7869076593529859
78,AnonymousSub/dummy_2,0.8117919169962537
79,finiteautomata/betonews-tweetcontext,0.7631225146773414
80,cardiffnlp/twitter-roberta-base-2021-124m,0.843661898147964
81,Jeevesh8/lecun_feather_berts-8,0.836891728281538
82,Jeevesh8/lecun_feather_berts-7,0.8271915165820477
83,waboucay/camembert-base-finetuned-xnli_fr-finetuned-nli-rua_wl,0.6966449833202522
84,mrm8488/codebert-base-finetuned-detect-insecure-code,0.8227027977652199
85,socialmediaie/TRAC2020_IBEN_B_bert-base-multilingual-uncased,0.8278214869619359
86,aditeyabaral/finetuned-sail2017-xlm-roberta-base,0.8258018107958945
87,M47Labs/spanish_news_classification_headlines_untrained,0.7918481957667183
88,zenkri/autotrain-Arabic_Poetry_by_Subject-920730230,0.8308225898200574
89,JonatanGk/roberta-base-ca-finetuned-hate-speech-offensive-catalan,0.779766939177574
90,Raychanan/COVID_RandomOver,0.18143571213221538
91,Jeevesh8/feather_berts_92,0.8357073404912586
92,CAMeL-Lab/bert-base-arabic-camelbert-mix-did-nadi,0.6754413604117862
93,rmihaylov/roberta-base-sentiment-bg,0.8049169955916586
