,model,score
0,Guscode/DKbert-hatespeech-detection,0.7323753804902001
1,milyiyo/selectra-small-finetuned-amazon-review,0.658258085782614
2,SetFit/distilbert-base-uncased__hate_speech_offensive__train-16-1,0.8523448891217549
3,SetFit/distilbert-base-uncased__hate_speech_offensive__train-16-1,0.8523448891217549
4,vinai/bertweet-base,0.8455841302182185
5,vinai/bertweet-covid19-base-uncased,0.8637704067429139
6,crcb/isear_bert,0.8651500697520577
7,crcb/isear_bert,0.8605011697082623
8,abdelkader/distilbert-base-uncased-finetuned-emotion,0.8447188769326215
9,abdelkader/distilbert-base-uncased-finetuned-emotion,0.8447188769326215
10,uygarkurt/distilbert-base-uncased-finetuned-emotion,0.8579613300214105
11,neibla/distilbert-base-uncased-finetuned-emotion,0.8481467501738456
12,Nanatan/distilbert-base-uncased-finetuned-emotion,0.8451709830565717
13,riyadhctg/distilbert-base-uncased-finetuned-cola,0.8588937448366388
14,gchhablani/fnet-base-finetuned-cola,0.8355275288957433
15,isakbos/Q8BERT_COLA_L_512,0.7449290836051418
16,usami/distilbert-base-uncased-finetuned-cola,0.8604641887338335
17,connectivity/cola_6ep_ft-10,0.8553287175544924
18,navsad/navid_test_bert,0.8412947596530235
19,boychaboy/MNLI_roberta-base,0.8745968414262647
20,anirudh21/bert-base-uncased-finetuned-qnli,0.8524683368264979
21,Jeevesh8/init_bert_ft_qqp-49,0.852051716236711
22,Jeevesh8/init_bert_ft_qqp-49,0.852051716236711
23,Jeevesh8/bert_ft_qqp-9,0.861387157087756
24,Jeevesh8/bert_ft_qqp-88,0.8590969268994548
25,connectivity/bert_ft_qqp-25,0.8601867300151903
26,Jeevesh8/init_bert_ft_qqp-24,0.8644635517504083
27,Jeevesh8/bert_ft_qqp-55,0.8626634656443126
28,Jeevesh8/bert_ft_qqp-68,0.8673332929300366
29,Jeevesh8/init_bert_ft_qqp-28,0.8577951684288695
30,Jeevesh8/bert_ft_qqp-39,0.8472361329382339
31,connectivity/bert_ft_qqp-94,0.8602394529973485
32,connectivity/bert_ft_qqp-96,0.8570387382909498
33,SetFit/distilbert-base-uncased__sst2__train-16-0,0.8558768800028596
34,gchhablani/fnet-base-finetuned-sst2,0.837742643666722
35,SetFit/distilbert-base-uncased__sst2__train-16-0,0.8558768800028596
36,gchhablani/fnet-base-finetuned-sst2,0.8342204594399596
37,aviator-neural/bert-base-uncased-sst2,0.8655671467356136
38,Alassea/glue_sst_classifier,0.860374915800501
39,gchhablani/bert-base-cased-finetuned-wnli,0.8643553947330319
40,Hate-speech-CNERG/bert-base-uncased-hatexplain-rationale-two,0.8546102876079523
41,PrasunMishra/finetuning-sentiment-model-3000-samples,0.859524306989027
42,heranm/finetuning-sentiment-model-3000-samples,0.8547962119899644
43,PrasunMishra/finetuning-sentiment-model-3000-samples,0.859524306989027
44,markt23917/finetuning-sentiment-model-3000-samples,0.8662542333664289
45,Anthos23/FS-distilroberta-fine-tuned,0.8560971915099777
46,oferweintraub/bert-base-finance-sentiment-noisy-search,0.8596962428139244
47,emrecan/bert-base-multilingual-cased-snli_tr,0.8360945043241483
48,cross-encoder/quora-distilroberta-base,0.8228060153503869
49,navteca/quora-roberta-base,0.8392476810531013
50,w11wo/sundanese-bert-base-emotion-classifier,0.7840072467700709
51,aychang/bert-base-cased-trec-coarse,0.8615104586783349
52,JNK789/distilbert-base-uncased-finetuned-tweets-emoji-dataset,0.152656117075031
53,pietrotrope/emotion_final,0.8452382308016629
54,aXhyra/presentation_sentiment_1234567,0.8435787546321752
55,manueltonneau/bert-twitter-en-is-hired,0.8554046549837208
56,dhimskyy/wiki-bert,0.7218035772801684
57,bert-base-uncased,0.8697191516047527
58,roberta-base,0.8702493453587259
59,albert-base-v2,0.8452226938075826
60,michiyasunaga/LinkBERT-base,0.871790532636111
61,Jeevesh8/feather_berts_46,0.8563402364251719
62,Splend1dchan/bert-base-uncased-slue-goldtrascription-e3-lr1e-4,0.845902973924339
63,dapang/distilroberta-base-mic-sym,0.8649466801932193
64,dapang/distilroberta-base-mic-sym,0.8598800564091303
65,cambridgeltl/guardian_news_distilbert-base-uncased,0.8470867116257392
66,Splend1dchan/bert-base-uncased-slue-goldtrascription-e3-lr1e-4,0.8426087462172193
67,Jeevesh8/feather_berts_46,0.8563402364251719
68,JonatanGk/roberta-base-bne-finetuned-cyberbullying-spanish,0.5862009797949779
69,nreimers/mmarco-mMiniLMv2-L6-H384-v1,0.7399463998167758
70,amyma21/sincere_question_classification,0.8581212632356919
71,arianpasquali/distilbert-base-multilingual-cased-toxicity,0.8328201167547192
72,chiragasarpota/scotus-bert,0.6869523934702448
73,strickvl/nlp-redaction-classifier,0.8517464076943051
74,DoyyingFace/bert-asian-hate-tweets-asian-unclean-freeze-4,0.865626136572411
75,Jeevesh8/lecun_feather_berts-3,0.8679533438180564
76,Jeevesh8/lecun_feather_berts-51,0.8657636004376367
77,viviastaari/finetuning-sentiment-analysis-en-id,0.8239778661852458
78,AnonymousSub/dummy_2,0.8436799765497672
79,finiteautomata/betonews-tweetcontext,0.8054376367668165
80,cardiffnlp/twitter-roberta-base-2021-124m,0.8709866283267145
81,Jeevesh8/lecun_feather_berts-8,0.8506423600234656
82,Jeevesh8/lecun_feather_berts-7,0.8599736300949601
83,waboucay/camembert-base-finetuned-xnli_fr-finetuned-nli-rua_wl,0.7940383611125043
84,mrm8488/codebert-base-finetuned-detect-insecure-code,0.8570155826622261
85,socialmediaie/TRAC2020_IBEN_B_bert-base-multilingual-uncased,0.8519905544220048
86,aditeyabaral/finetuned-sail2017-xlm-roberta-base,0.8684638068451274
87,M47Labs/spanish_news_classification_headlines_untrained,0.8147560946894464
88,zenkri/autotrain-Arabic_Poetry_by_Subject-920730230,0.8593214556993288
89,JonatanGk/roberta-base-ca-finetuned-hate-speech-offensive-catalan,0.7717468726853705
90,Raychanan/COVID_RandomOver,0.23458859733090956
91,Jeevesh8/feather_berts_92,0.867122165345227
92,CAMeL-Lab/bert-base-arabic-camelbert-mix-did-nadi,0.708542696554084
93,rmihaylov/roberta-base-sentiment-bg,0.8172706463907304
