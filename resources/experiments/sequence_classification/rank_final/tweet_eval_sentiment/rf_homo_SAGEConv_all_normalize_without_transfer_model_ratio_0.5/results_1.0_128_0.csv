,model,score
0,Guscode/DKbert-hatespeech-detection,0.15794934972173216
1,milyiyo/selectra-small-finetuned-amazon-review,0.15762405480614372
2,SetFit/distilbert-base-uncased__hate_speech_offensive__train-16-1,0.8214630674096776
3,SetFit/distilbert-base-uncased__hate_speech_offensive__train-16-1,0.8214630674096776
4,vinai/bertweet-base,0.8201072210606898
5,vinai/bertweet-covid19-base-uncased,0.593040379578954
6,crcb/isear_bert,0.8327242547585199
7,crcb/isear_bert,0.8213546829896239
8,abdelkader/distilbert-base-uncased-finetuned-emotion,0.8226965699477488
9,abdelkader/distilbert-base-uncased-finetuned-emotion,0.8226965699477488
10,uygarkurt/distilbert-base-uncased-finetuned-emotion,0.8226965699477488
11,neibla/distilbert-base-uncased-finetuned-emotion,0.8253229837306008
12,Nanatan/distilbert-base-uncased-finetuned-emotion,0.82035962253489
13,riyadhctg/distilbert-base-uncased-finetuned-cola,0.8253229837306008
14,gchhablani/fnet-base-finetuned-cola,0.812290759531706
15,isakbos/Q8BERT_COLA_L_512,0.1611872032387735
16,usami/distilbert-base-uncased-finetuned-cola,0.8253229837306008
17,connectivity/cola_6ep_ft-10,0.8278875537333846
18,navsad/navid_test_bert,0.8217957852781416
19,boychaboy/MNLI_roberta-base,0.8172251476985066
20,anirudh21/bert-base-uncased-finetuned-qnli,0.822924192537674
21,Jeevesh8/init_bert_ft_qqp-49,0.8252611399505326
22,Jeevesh8/init_bert_ft_qqp-49,0.8252611399505326
23,Jeevesh8/bert_ft_qqp-9,0.822924192537674
24,Jeevesh8/bert_ft_qqp-88,0.822924192537674
25,connectivity/bert_ft_qqp-25,0.8252611399505326
26,Jeevesh8/init_bert_ft_qqp-24,0.8217957852781416
27,Jeevesh8/bert_ft_qqp-55,0.8252611399505326
28,Jeevesh8/bert_ft_qqp-68,0.8217957852781416
29,Jeevesh8/init_bert_ft_qqp-28,0.8217957852781416
30,Jeevesh8/bert_ft_qqp-39,0.8252611399505326
31,connectivity/bert_ft_qqp-94,0.822924192537674
32,connectivity/bert_ft_qqp-96,0.8217957852781416
33,SetFit/distilbert-base-uncased__sst2__train-16-0,0.8226965699477488
34,gchhablani/fnet-base-finetuned-sst2,0.8357676213761164
35,SetFit/distilbert-base-uncased__sst2__train-16-0,0.8226965699477488
36,gchhablani/fnet-base-finetuned-sst2,0.8243980496072203
37,aviator-neural/bert-base-uncased-sst2,0.8278875537333846
38,Alassea/glue_sst_classifier,0.8278875537333846
39,gchhablani/bert-base-cased-finetuned-wnli,0.8217957852781416
40,Hate-speech-CNERG/bert-base-uncased-hatexplain-rationale-two,0.8216906899996029
41,PrasunMishra/finetuning-sentiment-model-3000-samples,0.8226965699477488
42,heranm/finetuning-sentiment-model-3000-samples,0.8226965699477488
43,PrasunMishra/finetuning-sentiment-model-3000-samples,0.8226965699477488
44,markt23917/finetuning-sentiment-model-3000-samples,0.8253229837306008
45,Anthos23/FS-distilroberta-fine-tuned,0.821990150743011
46,oferweintraub/bert-base-finance-sentiment-noisy-search,0.8205622827400706
47,emrecan/bert-base-multilingual-cased-snli_tr,0.8277786275380502
48,cross-encoder/quora-distilroberta-base,0.5462504616248087
49,navteca/quora-roberta-base,0.5479655418569361
50,w11wo/sundanese-bert-base-emotion-classifier,0.1358957768685438
51,aychang/bert-base-cased-trec-coarse,0.822924192537674
52,JNK789/distilbert-base-uncased-finetuned-tweets-emoji-dataset,0.14763735553744511
53,pietrotrope/emotion_final,0.8253229837306008
54,aXhyra/presentation_sentiment_1234567,0.8191261199968188
55,manueltonneau/bert-twitter-en-is-hired,0.8205622827400706
56,dhimskyy/wiki-bert,0.13246789764117217
57,bert-base-uncased,0.8216906899996029
58,roberta-base,0.8159916451604355
59,albert-base-v2,0.8165354583088245
60,michiyasunaga/LinkBERT-base,0.8205622827400706
61,Jeevesh8/feather_berts_46,0.8216906899996029
62,Splend1dchan/bert-base-uncased-slue-goldtrascription-e3-lr1e-4,0.8353972091813575
63,dapang/distilroberta-base-mic-sym,0.8368173258234584
64,dapang/distilroberta-base-mic-sym,0.821990150743011
65,cambridgeltl/guardian_news_distilbert-base-uncased,0.8214630674096776
66,Splend1dchan/bert-base-uncased-slue-goldtrascription-e3-lr1e-4,0.8240276374124617
67,Jeevesh8/feather_berts_46,0.8216906899996029
68,JonatanGk/roberta-base-bne-finetuned-cyberbullying-spanish,0.14595064874048252
69,nreimers/mmarco-mMiniLMv2-L6-H384-v1,0.33645701415679213
70,amyma21/sincere_question_classification,0.8191261199968188
71,arianpasquali/distilbert-base-multilingual-cased-toxicity,0.8166451555298139
72,chiragasarpota/scotus-bert,0.5011733001349437
73,strickvl/nlp-redaction-classifier,0.5581036886056492
74,DoyyingFace/bert-asian-hate-tweets-asian-unclean-freeze-4,0.8240276374124617
75,Jeevesh8/lecun_feather_berts-3,0.8216906899996029
76,Jeevesh8/lecun_feather_berts-51,0.8216906899996029
77,viviastaari/finetuning-sentiment-analysis-en-id,0.1710626254083927
78,AnonymousSub/dummy_2,0.8215103408201838
79,finiteautomata/betonews-tweetcontext,0.1679618723167149
80,cardiffnlp/twitter-roberta-base-2021-124m,0.8213546829896239
81,Jeevesh8/lecun_feather_berts-8,0.8216906899996029
82,Jeevesh8/lecun_feather_berts-7,0.8205622827400706
83,waboucay/camembert-base-finetuned-xnli_fr-finetuned-nli-rua_wl,0.1715810533296417
84,mrm8488/codebert-base-finetuned-detect-insecure-code,0.8159916451604355
85,socialmediaie/TRAC2020_IBEN_B_bert-base-multilingual-uncased,0.8131079277324159
86,aditeyabaral/finetuned-sail2017-xlm-roberta-base,0.8255394177940357
87,M47Labs/spanish_news_classification_headlines_untrained,0.1588427507369606
88,zenkri/autotrain-Arabic_Poetry_by_Subject-920730230,0.8163276521704145
89,JonatanGk/roberta-base-ca-finetuned-hate-speech-offensive-catalan,0.16742230633660157
90,Raychanan/COVID_RandomOver,0.14562949510603349
91,Jeevesh8/feather_berts_92,0.8216906899996029
92,CAMeL-Lab/bert-base-arabic-camelbert-mix-did-nadi,0.20062123070086801
93,rmihaylov/roberta-base-sentiment-bg,0.8132052444166817
