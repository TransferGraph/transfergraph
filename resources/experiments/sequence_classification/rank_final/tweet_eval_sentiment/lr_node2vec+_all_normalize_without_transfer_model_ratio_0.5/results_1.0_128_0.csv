,model,score
0,Guscode/DKbert-hatespeech-detection,0.6120241455494876
1,milyiyo/selectra-small-finetuned-amazon-review,0.5790671079815163
2,SetFit/distilbert-base-uncased__hate_speech_offensive__train-16-1,0.9225627442507035
3,SetFit/distilbert-base-uncased__hate_speech_offensive__train-16-1,0.9233926318866088
4,vinai/bertweet-base,0.9436102281540452
5,vinai/bertweet-covid19-base-uncased,1.0203010964122887
6,crcb/isear_bert,0.9813004034556351
7,crcb/isear_bert,0.994460216584695
8,abdelkader/distilbert-base-uncased-finetuned-emotion,0.9043647600306279
9,abdelkader/distilbert-base-uncased-finetuned-emotion,0.9064630143133429
10,uygarkurt/distilbert-base-uncased-finetuned-emotion,0.9210564805706855
11,neibla/distilbert-base-uncased-finetuned-emotion,0.9026477234659989
12,Nanatan/distilbert-base-uncased-finetuned-emotion,0.8855483935856472
13,riyadhctg/distilbert-base-uncased-finetuned-cola,0.8917070009534516
14,gchhablani/fnet-base-finetuned-cola,0.7662180848281371
15,isakbos/Q8BERT_COLA_L_512,0.6509125076939534
16,usami/distilbert-base-uncased-finetuned-cola,0.9048832160035307
17,connectivity/cola_6ep_ft-10,0.9571497203744013
18,navsad/navid_test_bert,0.9159352893944073
19,boychaboy/MNLI_roberta-base,1.0392879739479617
20,anirudh21/bert-base-uncased-finetuned-qnli,0.9788187399544114
21,Jeevesh8/init_bert_ft_qqp-49,0.9278014475308858
22,Jeevesh8/init_bert_ft_qqp-49,0.9279679946590371
23,Jeevesh8/bert_ft_qqp-9,0.9346317738226662
24,Jeevesh8/bert_ft_qqp-88,0.9574982354693813
25,connectivity/bert_ft_qqp-25,0.9473010621014222
26,Jeevesh8/init_bert_ft_qqp-24,0.9332310746644543
27,Jeevesh8/bert_ft_qqp-55,0.9513697062852804
28,Jeevesh8/bert_ft_qqp-68,0.9226768104928885
29,Jeevesh8/init_bert_ft_qqp-28,0.9298341332592079
30,Jeevesh8/bert_ft_qqp-39,0.9277238018027567
31,connectivity/bert_ft_qqp-94,0.93615009723845
32,connectivity/bert_ft_qqp-96,0.9329810849870058
33,SetFit/distilbert-base-uncased__sst2__train-16-0,0.9109567662362583
34,gchhablani/fnet-base-finetuned-sst2,0.7584114502865544
35,SetFit/distilbert-base-uncased__sst2__train-16-0,0.9104619621654362
36,gchhablani/fnet-base-finetuned-sst2,0.7698634801557138
37,aviator-neural/bert-base-uncased-sst2,0.8969824179768345
38,Alassea/glue_sst_classifier,0.9218388885379252
39,gchhablani/bert-base-cased-finetuned-wnli,0.946330139410523
40,Hate-speech-CNERG/bert-base-uncased-hatexplain-rationale-two,0.9500778494423036
41,PrasunMishra/finetuning-sentiment-model-3000-samples,0.9405966365682052
42,heranm/finetuning-sentiment-model-3000-samples,0.9384973387095498
43,PrasunMishra/finetuning-sentiment-model-3000-samples,0.9426056581474656
44,markt23917/finetuning-sentiment-model-3000-samples,0.93135673938649
45,Anthos23/FS-distilroberta-fine-tuned,0.958058417226154
46,oferweintraub/bert-base-finance-sentiment-noisy-search,0.9437653607780061
47,emrecan/bert-base-multilingual-cased-snli_tr,0.8436606701388603
48,cross-encoder/quora-distilroberta-base,0.843766035174919
49,navteca/quora-roberta-base,0.9012005894400192
50,w11wo/sundanese-bert-base-emotion-classifier,0.6166912504788394
51,aychang/bert-base-cased-trec-coarse,0.9357797582910151
52,JNK789/distilbert-base-uncased-finetuned-tweets-emoji-dataset,0.12779477401162287
53,pietrotrope/emotion_final,0.9236253346776134
54,aXhyra/presentation_sentiment_1234567,0.9855622167490041
55,manueltonneau/bert-twitter-en-is-hired,0.9649628079081576
56,dhimskyy/wiki-bert,0.6407104936343083
57,bert-base-uncased,0.9641953731451909
58,roberta-base,1.032159274093354
59,albert-base-v2,0.8590098251237409
60,michiyasunaga/LinkBERT-base,0.9426461323036422
61,Jeevesh8/feather_berts_46,0.950864464180123
62,Splend1dchan/bert-base-uncased-slue-goldtrascription-e3-lr1e-4,0.9307456231298179
63,dapang/distilroberta-base-mic-sym,0.8887038633962123
64,dapang/distilroberta-base-mic-sym,0.953469230615815
65,cambridgeltl/guardian_news_distilbert-base-uncased,0.8803027233474536
66,Splend1dchan/bert-base-uncased-slue-goldtrascription-e3-lr1e-4,0.9362738498798643
67,Jeevesh8/feather_berts_46,0.9496339009676669
68,JonatanGk/roberta-base-bne-finetuned-cyberbullying-spanish,0.5169609897571544
69,nreimers/mmarco-mMiniLMv2-L6-H384-v1,0.5461756929370245
70,amyma21/sincere_question_classification,0.9157292536717544
71,arianpasquali/distilbert-base-multilingual-cased-toxicity,0.7681991375236059
72,chiragasarpota/scotus-bert,0.5256287900012218
73,strickvl/nlp-redaction-classifier,0.9427511536064939
74,DoyyingFace/bert-asian-hate-tweets-asian-unclean-freeze-4,0.9479347910858573
75,Jeevesh8/lecun_feather_berts-3,0.9350980596563971
76,Jeevesh8/lecun_feather_berts-51,0.9591260817625047
77,viviastaari/finetuning-sentiment-analysis-en-id,0.7122230760553164
78,AnonymousSub/dummy_2,0.7968651777782574
79,finiteautomata/betonews-tweetcontext,0.6712490736342058
80,cardiffnlp/twitter-roberta-base-2021-124m,1.0203319578196572
81,Jeevesh8/lecun_feather_berts-8,0.9553911679226511
82,Jeevesh8/lecun_feather_berts-7,0.9488942889083083
83,waboucay/camembert-base-finetuned-xnli_fr-finetuned-nli-rua_wl,0.609990514563257
84,mrm8488/codebert-base-finetuned-detect-insecure-code,0.8704548991063003
85,socialmediaie/TRAC2020_IBEN_B_bert-base-multilingual-uncased,0.846556701733964
86,aditeyabaral/finetuned-sail2017-xlm-roberta-base,0.934239930653971
87,M47Labs/spanish_news_classification_headlines_untrained,0.7269511374594142
88,zenkri/autotrain-Arabic_Poetry_by_Subject-920730230,0.937578732956599
89,JonatanGk/roberta-base-ca-finetuned-hate-speech-offensive-catalan,0.7100157476903597
90,Raychanan/COVID_RandomOver,0.10789974759739751
91,Jeevesh8/feather_berts_92,0.9728433447998267
92,CAMeL-Lab/bert-base-arabic-camelbert-mix-did-nadi,0.5898291870539203
93,rmihaylov/roberta-base-sentiment-bg,0.7536290259301154
