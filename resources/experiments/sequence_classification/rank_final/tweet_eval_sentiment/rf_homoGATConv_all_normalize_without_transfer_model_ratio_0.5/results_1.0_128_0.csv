,model,score
0,Guscode/DKbert-hatespeech-detection,0.28958462780175503
1,milyiyo/selectra-small-finetuned-amazon-review,0.2927430142949046
2,SetFit/distilbert-base-uncased__hate_speech_offensive__train-16-1,0.8242848306181714
3,SetFit/distilbert-base-uncased__hate_speech_offensive__train-16-1,0.8242848306181714
4,vinai/bertweet-base,0.3694207111402853
5,vinai/bertweet-covid19-base-uncased,0.736795497678305
6,crcb/isear_bert,0.8231508428864927
7,crcb/isear_bert,0.8231508428864927
8,abdelkader/distilbert-base-uncased-finetuned-emotion,0.8207846311286605
9,abdelkader/distilbert-base-uncased-finetuned-emotion,0.8207846311286605
10,uygarkurt/distilbert-base-uncased-finetuned-emotion,0.8163705231234178
11,neibla/distilbert-base-uncased-finetuned-emotion,0.8130229453244897
12,Nanatan/distilbert-base-uncased-finetuned-emotion,0.8164325976282767
13,riyadhctg/distilbert-base-uncased-finetuned-cola,0.8187994011330503
14,gchhablani/fnet-base-finetuned-cola,0.3484951381429393
15,isakbos/Q8BERT_COLA_L_512,0.29515314072098353
16,usami/distilbert-base-uncased-finetuned-cola,0.7822724882950804
17,connectivity/cola_6ep_ft-10,0.8229112132413263
18,navsad/navid_test_bert,0.5485614034356289
19,boychaboy/MNLI_roberta-base,0.8281149092325454
20,anirudh21/bert-base-uncased-finetuned-qnli,0.8256142457836063
21,Jeevesh8/init_bert_ft_qqp-49,0.8118496856863731
22,Jeevesh8/init_bert_ft_qqp-49,0.8118496856863731
23,Jeevesh8/bert_ft_qqp-9,0.8101011588047454
24,Jeevesh8/bert_ft_qqp-88,0.8232944758274922
25,connectivity/bert_ft_qqp-25,0.8080068786490999
26,Jeevesh8/init_bert_ft_qqp-24,0.8157672901058082
27,Jeevesh8/bert_ft_qqp-55,0.5540458574153718
28,Jeevesh8/bert_ft_qqp-68,0.8118496856863731
29,Jeevesh8/init_bert_ft_qqp-28,0.8102289315923586
30,Jeevesh8/bert_ft_qqp-39,0.8249729327150803
31,connectivity/bert_ft_qqp-94,0.810022398567841
32,connectivity/bert_ft_qqp-96,0.8191600763275665
33,SetFit/distilbert-base-uncased__sst2__train-16-0,0.8163307953069067
34,gchhablani/fnet-base-finetuned-sst2,0.5005993214668212
35,SetFit/distilbert-base-uncased__sst2__train-16-0,0.8163307953069067
36,gchhablani/fnet-base-finetuned-sst2,0.5005993214668212
37,aviator-neural/bert-base-uncased-sst2,0.8195658860359231
38,Alassea/glue_sst_classifier,0.8219377526097819
39,gchhablani/bert-base-cased-finetuned-wnli,0.8187994011330503
40,Hate-speech-CNERG/bert-base-uncased-hatexplain-rationale-two,0.8190980018227075
41,PrasunMishra/finetuning-sentiment-model-3000-samples,0.8156731997611191
42,heranm/finetuning-sentiment-model-3000-samples,0.8044933563770721
43,PrasunMishra/finetuning-sentiment-model-3000-samples,0.8156731997611191
44,markt23917/finetuning-sentiment-model-3000-samples,0.8178959163674966
45,Anthos23/FS-distilroberta-fine-tuned,0.8234692198014021
46,oferweintraub/bert-base-finance-sentiment-noisy-search,0.806284947804388
47,emrecan/bert-base-multilingual-cased-snli_tr,0.8081085465869137
48,cross-encoder/quora-distilroberta-base,0.8070499955387348
49,navteca/quora-roberta-base,0.81963767147523
50,w11wo/sundanese-bert-base-emotion-classifier,0.3403593864682057
51,aychang/bert-base-cased-trec-coarse,0.8164269442564653
52,JNK789/distilbert-base-uncased-finetuned-tweets-emoji-dataset,0.1405482621509219
53,pietrotrope/emotion_final,0.8194894865398408
54,aXhyra/presentation_sentiment_1234567,0.8007654807127444
55,manueltonneau/bert-twitter-en-is-hired,0.8158608430619937
56,dhimskyy/wiki-bert,0.21780567776083642
57,bert-base-uncased,0.8115120675416775
58,roberta-base,0.8187091693108727
59,albert-base-v2,0.8008667417486534
60,michiyasunaga/LinkBERT-base,0.8218226214398834
61,Jeevesh8/feather_berts_46,0.813233165205656
62,Splend1dchan/bert-base-uncased-slue-goldtrascription-e3-lr1e-4,0.8022597653377546
63,dapang/distilroberta-base-mic-sym,0.8132496348461798
64,dapang/distilroberta-base-mic-sym,0.8132496348461798
65,cambridgeltl/guardian_news_distilbert-base-uncased,0.8167500509418265
66,Splend1dchan/bert-base-uncased-slue-goldtrascription-e3-lr1e-4,0.8022597653377546
67,Jeevesh8/feather_berts_46,0.813233165205656
68,JonatanGk/roberta-base-bne-finetuned-cyberbullying-spanish,0.28158786873312147
69,nreimers/mmarco-mMiniLMv2-L6-H384-v1,0.4811990227003124
70,amyma21/sincere_question_classification,0.8124666803027831
71,arianpasquali/distilbert-base-multilingual-cased-toxicity,0.48161891352686553
72,chiragasarpota/scotus-bert,0.26577014540401595
73,strickvl/nlp-redaction-classifier,0.8085736270186569
74,DoyyingFace/bert-asian-hate-tweets-asian-unclean-freeze-4,0.8110096535800366
75,Jeevesh8/lecun_feather_berts-3,0.8089396603987647
76,Jeevesh8/lecun_feather_berts-51,0.8187258539295867
77,viviastaari/finetuning-sentiment-analysis-en-id,0.23591734111256585
78,AnonymousSub/dummy_2,0.28974877566574136
79,finiteautomata/betonews-tweetcontext,0.2693363511760553
80,cardiffnlp/twitter-roberta-base-2021-124m,0.8183995005052437
81,Jeevesh8/lecun_feather_berts-8,0.8188667130886147
82,Jeevesh8/lecun_feather_berts-7,0.8054449156980517
83,waboucay/camembert-base-finetuned-xnli_fr-finetuned-nli-rua_wl,0.25226066475737835
84,mrm8488/codebert-base-finetuned-detect-insecure-code,0.7519428367716425
85,socialmediaie/TRAC2020_IBEN_B_bert-base-multilingual-uncased,0.8134208073520776
86,aditeyabaral/finetuned-sail2017-xlm-roberta-base,0.7073133429994687
87,M47Labs/spanish_news_classification_headlines_untrained,0.6113158680572081
88,zenkri/autotrain-Arabic_Poetry_by_Subject-920730230,0.8077774308553515
89,JonatanGk/roberta-base-ca-finetuned-hate-speech-offensive-catalan,0.4913043606241982
90,Raychanan/COVID_RandomOver,0.14637357458598585
91,Jeevesh8/feather_berts_92,0.8224544437211556
92,CAMeL-Lab/bert-base-arabic-camelbert-mix-did-nadi,0.7929527243813261
93,rmihaylov/roberta-base-sentiment-bg,0.24490542909691115
