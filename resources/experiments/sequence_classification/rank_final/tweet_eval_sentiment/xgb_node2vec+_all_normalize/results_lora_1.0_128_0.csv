,model,score
0,Jeevesh8/init_bert_ft_qqp-33,0.84854543
1,Jeevesh8/init_bert_ft_qqp-33,0.8660631
2,Jeevesh8/init_bert_ft_qqp-49,0.8586706
3,Jeevesh8/init_bert_ft_qqp-49,0.8586706
4,Jeevesh8/init_bert_ft_qqp-49,0.87569904
5,connectivity/bert_ft_qqp-7,0.86202025
6,connectivity/bert_ft_qqp-7,0.86903447
7,Jeevesh8/bert_ft_qqp-40,0.86624926
8,Jeevesh8/bert_ft_qqp-40,0.8755311
9,Jeevesh8/bert_ft_qqp-9,0.8593835
10,Jeevesh8/bert_ft_qqp-9,0.87238634
11,Jeevesh8/bert_ft_qqp-88,0.87153715
12,Jeevesh8/bert_ft_qqp-88,0.88333297
13,connectivity/bert_ft_qqp-25,0.8630141
14,connectivity/bert_ft_qqp-25,0.8638041
15,Jeevesh8/bert_ft_qqp-55,0.8516232
16,Jeevesh8/bert_ft_qqp-55,0.8653096
17,connectivity/bert_ft_qqp-1,0.8644865
18,connectivity/bert_ft_qqp-1,0.8729242
19,Jeevesh8/bert_ft_qqp-39,0.8603048
20,Jeevesh8/bert_ft_qqp-39,0.8723967
21,connectivity/bert_ft_qqp-94,0.85872
22,connectivity/bert_ft_qqp-94,0.8745831
23,connectivity/bert_ft_qqp-96,0.86041886
24,connectivity/bert_ft_qqp-96,0.86658055
25,Jeevesh8/init_bert_ft_qqp-24,0.8674887
26,Jeevesh8/init_bert_ft_qqp-24,0.870498
27,Jeevesh8/bert_ft_qqp-68,0.85138404
28,Jeevesh8/bert_ft_qqp-68,0.8683602
29,Jeevesh8/init_bert_ft_qqp-28,0.8535368
30,Jeevesh8/init_bert_ft_qqp-28,0.8700833
31,connectivity/bert_ft_qqp-17,0.84687734
32,connectivity/bert_ft_qqp-17,0.8600497
33,ali2066/finetuned_sentence_itr1_2e-05_all_26_02_2022-04_03_26,0.8771254
34,ali2066/finetuned_sentence_itr1_2e-05_all_26_02_2022-04_03_26,0.87254494
35,SetFit/distilbert-base-uncased__sst2__train-16-0,0.8834468
36,SetFit/distilbert-base-uncased__sst2__train-16-0,0.88522583
37,SetFit/distilbert-base-uncased__sst2__train-16-0,0.86909723
38,aviator-neural/bert-base-uncased-sst2,0.84361887
39,aviator-neural/bert-base-uncased-sst2,0.8450258
40,SetFit/distilbert-base-uncased__sst2__train-32-9,0.8791143
41,SetFit/distilbert-base-uncased__sst2__train-32-9,0.85745
42,Alassea/glue_sst_classifier,0.85924935
43,Alassea/glue_sst_classifier,0.8797323
44,philschmid/tiny-distilbert-classification,0.5160955
45,philschmid/tiny-distilbert-classification,0.49661744
46,moshew/bert-mini-sst2-distilled,0.8471421
47,moshew/bert-mini-sst2-distilled,0.8418038
48,ChrisUPM/BioBERT_Re_trained,0.77174956
49,ChrisUPM/BioBERT_Re_trained,0.8495482
50,vaariis/distilbert-base-uncased-finetuned-emotion,0.8664965
51,vaariis/distilbert-base-uncased-finetuned-emotion,0.85102445
52,marcelcastrobr/sagemaker-distilbert-emotion,0.85512674
53,marcelcastrobr/sagemaker-distilbert-emotion,0.8498866
54,jasonyim2/distilbert-base-uncased-finetuned-emotion,0.8623331
55,jasonyim2/distilbert-base-uncased-finetuned-emotion,0.8425583
56,abdelkader/distilbert-base-uncased-finetuned-emotion,0.8460412
57,abdelkader/distilbert-base-uncased-finetuned-emotion,0.86029834
58,abdelkader/distilbert-base-uncased-finetuned-emotion,0.84801435
59,moghis/distilbert-base-uncased-finetuned-emotion,0.8647482
60,moghis/distilbert-base-uncased-finetuned-emotion,0.85227734
61,uygarkurt/distilbert-base-uncased-finetuned-emotion,0.86568046
62,uygarkurt/distilbert-base-uncased-finetuned-emotion,0.84995526
63,neibla/distilbert-base-uncased-finetuned-emotion,0.8715859
64,neibla/distilbert-base-uncased-finetuned-emotion,0.86647177
65,JB173/distilbert-base-uncased-finetuned-emotion,0.8663656
66,JB173/distilbert-base-uncased-finetuned-emotion,0.8499317
67,Nanatan/distilbert-base-uncased-finetuned-emotion,0.85384023
68,Nanatan/distilbert-base-uncased-finetuned-emotion,0.8385502
69,heranm/finetuning-sentiment-model-3000-samples,0.87406695
70,heranm/finetuning-sentiment-model-3000-samples,0.8594488
71,PrasunMishra/finetuning-sentiment-model-3000-samples,0.86436284
72,PrasunMishra/finetuning-sentiment-model-3000-samples,0.8848657
73,PrasunMishra/finetuning-sentiment-model-3000-samples,0.86381936
74,yukta10/finetuning-sentiment-model-3000-samples,0.8848719
75,yukta10/finetuning-sentiment-model-3000-samples,0.8820388
76,yukta10/finetuning-sentiment-model-3000-samples,0.8683956
77,ncduy/roberta-imdb-sentiment-analysis,0.90511006
78,ncduy/roberta-imdb-sentiment-analysis,0.9064806
79,markt23917/finetuning-sentiment-model-3000-samples,0.8773333
80,markt23917/finetuning-sentiment-model-3000-samples,0.862066
81,juliensimon/autonlp-imdb-demo-hf-16622767,0.8723782
82,juliensimon/autonlp-imdb-demo-hf-16622767,0.8507923
83,fabriceyhc/bert-base-uncased-imdb,0.855188
84,fabriceyhc/bert-base-uncased-imdb,0.8698617
85,riyadhctg/distilbert-base-uncased-finetuned-cola,0.87461644
86,riyadhctg/distilbert-base-uncased-finetuned-cola,0.8532907
87,connectivity/cola_6ep_ft-33,0.8813058
88,connectivity/cola_6ep_ft-33,0.86552685
89,connectivity/cola_6ep_ft-33,0.8869804
90,connectivity/cola_6ep_ft-22,0.86948615
91,connectivity/cola_6ep_ft-22,0.87043107
92,connectivity/cola_6ep_ft-22,0.88649684
93,isakbos/Q8BERT_COLA_L_512,0.7041857
94,isakbos/Q8BERT_COLA_L_512,0.7641167
95,jaesun/distilbert-base-uncased-finetuned-cola,0.8686379
96,jaesun/distilbert-base-uncased-finetuned-cola,0.85294604
97,usami/distilbert-base-uncased-finetuned-cola,0.8720271
98,usami/distilbert-base-uncased-finetuned-cola,0.86192226
99,Jeevesh8/512seq_len_6ep_bert_ft_cola-91,0.86169475
100,Jeevesh8/512seq_len_6ep_bert_ft_cola-91,0.86032736
101,Jeevesh8/6ep_bert_ft_cola-47,0.864923
102,Jeevesh8/6ep_bert_ft_cola-47,0.8811625
103,connectivity/cola_6ep_ft-10,0.8697175
104,connectivity/cola_6ep_ft-10,0.8826212
105,Jeevesh8/6ep_bert_ft_cola-12,0.8693042
106,Jeevesh8/6ep_bert_ft_cola-12,0.8801812
107,Jeevesh8/bert_ft_cola-88,0.8710263
108,Jeevesh8/bert_ft_cola-88,0.87858623
109,Jeevesh8/6ep_bert_ft_cola-29,0.861222
110,Jeevesh8/6ep_bert_ft_cola-29,0.8807021
111,vesteinn/XLMR-ENIS-finetuned-cola,0.88383925
112,vesteinn/XLMR-ENIS-finetuned-cola,0.885035
113,navsad/navid_test_bert,0.86568755
114,navsad/navid_test_bert,0.8898715
115,Jeevesh8/bert_ft_cola-60,0.8211676
116,Jeevesh8/bert_ft_cola-60,0.888031
117,dapang/distilroberta-base-mic-sym,0.80127597
118,dapang/distilroberta-base-mic-sym,0.8963324
119,dapang/distilroberta-base-mic-sym,0.8758646
120,Capreolus/bert-base-msmarco,0.87721825
121,Capreolus/bert-base-msmarco,0.86784494
122,Capreolus/bert-base-msmarco,0.8845039
123,Splend1dchan/bert-base-uncased-slue-goldtrascription-e3-lr1e-4,0.8765724
124,Splend1dchan/bert-base-uncased-slue-goldtrascription-e3-lr1e-4,0.8619809
125,Splend1dchan/bert-base-uncased-slue-goldtrascription-e3-lr1e-4,0.8732387
126,Jeevesh8/feather_berts_46,0.8711025
127,Jeevesh8/feather_berts_46,0.87459993
128,Jeevesh8/feather_berts_46,0.8797862
129,JonatanGk/roberta-base-bne-finetuned-cyberbullying-spanish,0.6923971
130,JonatanGk/roberta-base-bne-finetuned-cyberbullying-spanish,0.74218285
131,cambridgeltl/guardian_news_distilbert-base-uncased,0.8792155
132,cambridgeltl/guardian_news_distilbert-base-uncased,0.8521536
133,amyma21/sincere_question_classification,0.8759137
134,amyma21/sincere_question_classification,0.8518916
135,phailyoor/distilbert-base-uncased-finetuned-yahd,0.86179674
136,phailyoor/distilbert-base-uncased-finetuned-yahd,0.8350688
137,arianpasquali/distilbert-base-multilingual-cased-toxicity,0.83977354
138,arianpasquali/distilbert-base-multilingual-cased-toxicity,0.8107524
139,connectivity/feather_berts_28,0.8723928
140,connectivity/feather_berts_28,0.8896641
141,liangyuant/distilbert-base-uncased-finetuned-num200-450-405cls,0.8584332
142,liangyuant/distilbert-base-uncased-finetuned-num200-450-405cls,0.8359189
143,DoyyingFace/bert-asian-hate-tweets-asian-unclean-freeze-4,0.8179177
144,DoyyingFace/bert-asian-hate-tweets-asian-unclean-freeze-4,0.88066953
145,Jeevesh8/lecun_feather_berts-3,0.862734
146,Jeevesh8/lecun_feather_berts-3,0.87592554
147,Giyaseddin/distilroberta-base-finetuned-short-answer-assessment,0.8941056
148,Giyaseddin/distilroberta-base-finetuned-short-answer-assessment,0.86417025
149,AnonymousSub/dummy_2,0.83545303
150,AnonymousSub/dummy_2,0.8270398
151,Jeevesh8/lecun_feather_berts-51,0.86829275
152,Jeevesh8/lecun_feather_berts-51,0.88536733
153,viviastaari/finetuning-sentiment-analysis-en-id,0.7923332
154,viviastaari/finetuning-sentiment-analysis-en-id,0.79376894
155,Aureliano/distilbert-base-uncased-if,0.8819007
156,Aureliano/distilbert-base-uncased-if,0.8624767
157,rmihaylov/roberta-base-sentiment-bg,0.85767204
158,rmihaylov/roberta-base-sentiment-bg,0.8104945
159,cardiffnlp/twitter-roberta-base-2021-124m,0.89325464
160,cardiffnlp/twitter-roberta-base-2021-124m,0.90670943
161,Jeevesh8/lecun_feather_berts-8,0.86807704
162,Jeevesh8/lecun_feather_berts-8,0.879557
163,korca/bae-roberta-base-boolq,0.82742584
164,korca/bae-roberta-base-boolq,0.89889205
165,aditeyabaral/finetuned-sail2017-xlm-roberta-base,0.8886945
166,aditeyabaral/finetuned-sail2017-xlm-roberta-base,0.87113684
167,joebobby/finetuning-sentiment-model-5000-samples3,0.81608695
168,joebobby/finetuning-sentiment-model-5000-samples3,0.86739737
169,Jeevesh8/feather_berts_92,0.8664359
170,Jeevesh8/feather_berts_92,0.88464254
171,ASCCCCCCCC/distilbert-base-chinese-amazon_zh_20000,0.7723416
172,ASCCCCCCCC/distilbert-base-chinese-amazon_zh_20000,0.7874788
173,matthewburke/korean_sentiment,0.79065084
174,matthewburke/korean_sentiment,0.7658472
175,IMSyPP/hate_speech_nl,0.7541559
176,IMSyPP/hate_speech_nl,0.7305986
177,cointegrated/roberta-base-formality,0.83266234
178,cointegrated/roberta-base-formality,0.8836872
179,IMSyPP/hate_speech_it,0.81140333
180,IMSyPP/hate_speech_it,0.79916203
181,18811449050/bert_finetuning_test,0.8444293
182,18811449050/bert_finetuning_test,0.84519476
183,finiteautomata/betonews-tweetcontext,0.7796851
184,finiteautomata/betonews-tweetcontext,0.7824663
185,Jeevesh8/feather_berts_96,0.8690386
186,Jeevesh8/feather_berts_96,0.8845415
187,Jeevesh8/lecun_feather_berts-7,0.8752428
188,Jeevesh8/lecun_feather_berts-7,0.88200593
189,mrm8488/codebert-base-finetuned-detect-insecure-code,0.8492451
190,mrm8488/codebert-base-finetuned-detect-insecure-code,0.8584393
191,socialmediaie/TRAC2020_IBEN_B_bert-base-multilingual-uncased,0.8484433
192,socialmediaie/TRAC2020_IBEN_B_bert-base-multilingual-uncased,0.8540612
193,zenkri/autotrain-Arabic_Poetry_by_Subject-920730230,0.86694574
194,zenkri/autotrain-Arabic_Poetry_by_Subject-920730230,0.88385755
195,M47Labs/spanish_news_classification_headlines_untrained,0.8106335
196,M47Labs/spanish_news_classification_headlines_untrained,0.7912973
197,bondi/bert-semaphore-prediction-w4,0.8212577
198,bondi/bert-semaphore-prediction-w4,0.8060873
199,classla/bcms-bertic-parlasent-bcs-ter,0.807032
200,classla/bcms-bertic-parlasent-bcs-ter,0.7939652
201,ali2066/DistilBERTFINAL_ctxSentence_TRAIN_editorials_TEST_NULL_second_train_set_null_False,0.8957393
202,ali2066/DistilBERTFINAL_ctxSentence_TRAIN_editorials_TEST_NULL_second_train_set_null_False,0.9084728
203,anvay/finetuning-cardiffnlp-sentiment-model,0.90154487
204,anvay/finetuning-cardiffnlp-sentiment-model,0.90940785
205,JonatanGk/roberta-base-ca-finetuned-hate-speech-offensive-catalan,0.7287047
206,JonatanGk/roberta-base-ca-finetuned-hate-speech-offensive-catalan,0.7501043
207,Raychanan/COVID_RandomOver,0.51978254
208,Raychanan/COVID_RandomOver,0.6024131
209,kyleinincubated/autonlp-cat333-624217911,0.8004744
210,kyleinincubated/autonlp-cat333-624217911,0.8026134
211,cardiffnlp/bertweet-base-stance-climate,0.87906796
212,cardiffnlp/bertweet-base-stance-climate,0.8861881
213,nreimers/mmarco-mMiniLMv2-L6-H384-v1,0.8406946
214,nreimers/mmarco-mMiniLMv2-L6-H384-v1,0.7862106
215,strickvl/nlp-redaction-classifier,0.8507294
216,strickvl/nlp-redaction-classifier,0.82223314
217,saattrupdan/job-listing-relevance-model,0.8840406
218,saattrupdan/job-listing-relevance-model,0.8681254
219,morenolq/SumTO_FNS2020,0.8540016
220,morenolq/SumTO_FNS2020,0.8624435
221,cross-encoder/ms-marco-MiniLM-L-4-v2,0.8476155
222,cross-encoder/ms-marco-MiniLM-L-4-v2,0.83787924
223,nurkayevaa/autonlp-bert-covid-407910458,0.87960976
224,nurkayevaa/autonlp-bert-covid-407910458,0.8824116
225,nurkayevaa/autonlp-bert-covid-407910458,0.8646197
226,SetFit/distilbert-base-uncased__hate_speech_offensive__train-16-1,0.88847256
227,SetFit/distilbert-base-uncased__hate_speech_offensive__train-16-1,0.88782394
228,SetFit/distilbert-base-uncased__hate_speech_offensive__train-16-1,0.869565
229,crcb/isear_bert,0.9073961
230,crcb/isear_bert,0.8950097
231,crcb/isear_bert,0.90376765
232,robertou2/roberta-base-bne-finetuned-amazon_reviews_multi,0.76454794
233,robertou2/roberta-base-bne-finetuned-amazon_reviews_multi,0.8032153
234,milyiyo/selectra-small-finetuned-amazon-review,0.72812647
235,milyiyo/selectra-small-finetuned-amazon-review,0.75509375
236,Anthos23/FS-distilroberta-fine-tuned,0.88825697
237,Anthos23/FS-distilroberta-fine-tuned,0.8725738
238,oferweintraub/bert-base-finance-sentiment-noisy-search,0.86784583
239,oferweintraub/bert-base-finance-sentiment-noisy-search,0.8812874
240,pietrotrope/emotion_final,0.8785865
241,pietrotrope/emotion_final,0.88093024
242,aXhyra/emotion_trained_31415,0.8781005
243,aXhyra/emotion_trained_31415,0.87439716
244,aXhyra/presentation_emotion_31415,0.8825411
245,aXhyra/presentation_emotion_31415,0.8658156
246,Recognai/bert-base-spanish-wwm-cased-xnli,0.81505007
247,Recognai/bert-base-spanish-wwm-cased-xnli,0.79167676
248,anirudh21/bert-base-uncased-finetuned-qnli,0.8685965
249,anirudh21/bert-base-uncased-finetuned-qnli,0.8840434
250,aXhyra/demo_sentiment_31415,0.8814077
251,aXhyra/demo_sentiment_31415,0.868026
252,aXhyra/presentation_sentiment_1234567,0.8862426
253,aXhyra/presentation_sentiment_1234567,0.87423724
254,jb2k/bert-base-multilingual-cased-language-detection,0.8505367
255,jb2k/bert-base-multilingual-cased-language-detection,0.8167142
256,vinai/bertweet-base,0.89627004
257,vinai/bertweet-base,0.86519283
258,justinqbui/bertweet-covid19-base-uncased-pretraining-covid-vaccine-tweets,0.8952081
259,justinqbui/bertweet-covid19-base-uncased-pretraining-covid-vaccine-tweets,0.90418434
260,vinai/bertweet-covid19-base-cased,0.90027755
261,vinai/bertweet-covid19-base-cased,0.9053565
262,vinai/bertweet-covid19-base-uncased,0.91163045
263,vinai/bertweet-covid19-base-uncased,0.8915656
264,distilbert-base-uncased,0.8871667
265,distilbert-base-uncased,0.88314795
266,bert-base-uncased,0.866337
267,bert-base-uncased,0.884667
268,roberta-base,0.9010439
269,roberta-base,0.91449857
270,bert-base-cased,0.8498747
271,bert-base-cased,0.8498747
272,dhimskyy/wiki-bert,0.7731647
273,dhimskyy/wiki-bert,0.7586465
274,michiyasunaga/LinkBERT-base,0.87131107
275,michiyasunaga/LinkBERT-base,0.87369126
276,boychaboy/MNLI_roberta-base,0.9034031
277,boychaboy/MNLI_roberta-base,0.91347796
278,ishan/bert-base-uncased-mnli,0.8681402
279,ishan/bert-base-uncased-mnli,0.88345766
280,emrecan/bert-base-multilingual-cased-snli_tr,0.84632343
281,emrecan/bert-base-multilingual-cased-snli_tr,0.8320019
282,elozano/tweet_offensive_eval,0.78353345
283,elozano/tweet_offensive_eval,0.772676
284,Hate-speech-CNERG/bert-base-uncased-hatexplain-rationale-two,0.8640182
285,Hate-speech-CNERG/bert-base-uncased-hatexplain-rationale-two,0.8595685
286,aychang/bert-base-cased-trec-coarse,0.8761591
287,aychang/bert-base-cased-trec-coarse,0.8741415
288,gchhablani/bert-base-cased-finetuned-wnli,0.8647846
289,gchhablani/bert-base-cased-finetuned-wnli,0.8551774
290,w11wo/sundanese-bert-base-emotion-classifier,0.7407835
291,w11wo/sundanese-bert-base-emotion-classifier,0.7506829
292,gchhablani/bert-base-cased-finetuned-rte,0.8629995
293,gchhablani/bert-base-cased-finetuned-rte,0.88303155
294,mrm8488/electricidad-base-finetuned-pawsx-es,0.8127745
295,mrm8488/electricidad-base-finetuned-pawsx-es,0.7838435
296,manueltonneau/bert-twitter-en-is-hired,0.86259377
297,manueltonneau/bert-twitter-en-is-hired,0.88857806
298,Guscode/DKbert-hatespeech-detection,0.7539133
299,Guscode/DKbert-hatespeech-detection,0.7513015
300,cross-encoder/quora-distilroberta-base,0.87251765
301,cross-encoder/quora-distilroberta-base,0.85385495
302,navteca/quora-roberta-base,0.8509894
303,navteca/quora-roberta-base,0.8619197
304,cross-encoder/quora-roberta-base,0.8409591
305,cross-encoder/quora-roberta-base,0.82576764
