,model,score
0,Guscode/DKbert-hatespeech-detection,0.69107527
1,robertou2/roberta-base-bne-finetuned-amazon_reviews_multi,0.7196192
2,SetFit/distilbert-base-uncased__hate_speech_offensive__train-16-1,0.87807274
3,SetFit/distilbert-base-uncased__hate_speech_offensive__train-16-1,0.8871929
4,vinai/bertweet-base,0.92916065
5,justinqbui/bertweet-covid19-base-uncased-pretraining-covid-vaccine-tweets,0.95020866
6,vinai/bertweet-covid19-base-uncased,0.96172196
7,jb2k/bert-base-multilingual-cased-language-detection,0.7773947
8,crcb/isear_bert,0.93923473
9,crcb/isear_bert,0.9394573
10,abdelkader/distilbert-base-uncased-finetuned-emotion,0.8550568
11,vaariis/distilbert-base-uncased-finetuned-emotion,0.86162406
12,marcelcastrobr/sagemaker-distilbert-emotion,0.859426
13,abdelkader/distilbert-base-uncased-finetuned-emotion,0.8537775
14,moghis/distilbert-base-uncased-finetuned-emotion,0.856793
15,uygarkurt/distilbert-base-uncased-finetuned-emotion,0.8734485
16,neibla/distilbert-base-uncased-finetuned-emotion,0.87835556
17,JB173/distilbert-base-uncased-finetuned-emotion,0.8584887
18,connectivity/cola_6ep_ft-22,0.93953705
19,connectivity/cola_6ep_ft-33,0.9350068
20,riyadhctg/distilbert-base-uncased-finetuned-cola,0.89607805
21,connectivity/cola_6ep_ft-33,0.92049396
22,gchhablani/fnet-base-finetuned-cola,0.7503185
23,connectivity/cola_6ep_ft-22,0.93953705
24,vesteinn/XLMR-ENIS-finetuned-cola,0.9524362
25,isakbos/Q8BERT_COLA_L_512,0.66374135
26,usami/distilbert-base-uncased-finetuned-cola,0.9031609
27,Jeevesh8/512seq_len_6ep_bert_ft_cola-91,0.9138422
28,Jeevesh8/6ep_bert_ft_cola-47,0.9486117
29,connectivity/cola_6ep_ft-10,0.9317529
30,Jeevesh8/6ep_bert_ft_cola-12,0.93934333
31,navsad/navid_test_bert,0.9329183
32,Jeevesh8/bert_ft_cola-60,0.9490369
33,anirudh21/bert-base-uncased-finetuned-qnli,0.9298579
34,Alireza1044/albert-base-v2-qnli,0.8809492
35,Jeevesh8/init_bert_ft_qqp-49,0.9124554
36,Jeevesh8/init_bert_ft_qqp-33,0.8889025
37,Jeevesh8/init_bert_ft_qqp-49,0.9124554
38,Jeevesh8/bert_ft_qqp-40,0.9307611
39,Jeevesh8/bert_ft_qqp-9,0.9179656
40,Jeevesh8/init_bert_ft_qqp-24,0.905813
41,Jeevesh8/bert_ft_qqp-55,0.8868795
42,Jeevesh8/init_bert_ft_qqp-28,0.9127187
43,connectivity/bert_ft_qqp-1,0.89962304
44,Jeevesh8/bert_ft_qqp-39,0.9165281
45,connectivity/bert_ft_qqp-94,0.90217835
46,connectivity/bert_ft_qqp-96,0.8815857
47,gchhablani/bert-base-cased-finetuned-rte,0.9217607
48,SetFit/distilbert-base-uncased__sst2__train-16-0,0.86312956
49,gchhablani/fnet-base-finetuned-sst2,0.7633514
50,philschmid/tiny-distilbert-classification,-0.010206678
51,SetFit/distilbert-base-uncased__sst2__train-16-0,0.86480373
52,gchhablani/fnet-base-finetuned-sst2,0.76140904
53,moshew/bert-mini-sst2-distilled,0.84029615
54,aviator-neural/bert-base-uncased-sst2,0.8667123
55,Alassea/glue_sst_classifier,0.9013679
56,ChrisUPM/BioBERT_Re_trained,0.8278121
57,gchhablani/bert-base-cased-finetuned-wnli,0.8912403
58,Hate-speech-CNERG/bert-base-uncased-hatexplain-rationale-two,0.92040306
59,PrasunMishra/finetuning-sentiment-model-3000-samples,0.88774633
60,yukta10/finetuning-sentiment-model-3000-samples,0.8846775
61,heranm/finetuning-sentiment-model-3000-samples,0.88241804
62,PrasunMishra/finetuning-sentiment-model-3000-samples,0.89218825
63,yukta10/finetuning-sentiment-model-3000-samples,0.8846775
64,fabriceyhc/bert-base-uncased-imdb,0.88571686
65,Anthos23/FS-distilroberta-fine-tuned,0.9024387
66,emrecan/bert-base-multilingual-cased-snli_tr,0.7958644
67,nurkayevaa/autonlp-bert-covid-407910458,0.86778814
68,nurkayevaa/autonlp-bert-covid-407910458,0.86778814
69,cross-encoder/quora-distilroberta-base,0.80153686
70,navteca/quora-roberta-base,0.8055751
71,w11wo/sundanese-bert-base-emotion-classifier,0.63314396
72,JNK789/distilbert-base-uncased-finetuned-tweets-emoji-dataset,-0.001345121
73,pietrotrope/emotion_final,0.88501734
74,aXhyra/emotion_trained_31415,0.88064146
75,aXhyra/presentation_emotion_31415,0.89382803
76,elozano/tweet_offensive_eval,0.6898083
77,aXhyra/demo_sentiment_31415,0.87844294
78,aXhyra/presentation_sentiment_1234567,0.87940085
79,distilbert-base-uncased,0.85862285
80,dhimskyy/wiki-bert,0.6729493
81,roberta-base,0.94541156
82,bert-base-cased,0.9204119
83,albert-base-v2,0.8001087
84,Recognai/bert-base-spanish-wwm-cased-xnli,0.71566856
85,mrm8488/electricidad-base-finetuned-pawsx-es,0.7120536
86,Capreolus/bert-base-msmarco,0.8949209
87,Splend1dchan/bert-base-uncased-slue-goldtrascription-e3-lr1e-4,0.90891474
88,dapang/distilroberta-base-mic-sym,0.9215212
89,dapang/distilroberta-base-mic-sym,0.9055097
90,cambridgeltl/guardian_news_distilbert-base-uncased,0.875461
91,Capreolus/bert-base-msmarco,0.90358233
92,Splend1dchan/bert-base-uncased-slue-goldtrascription-e3-lr1e-4,0.8975936
93,JonatanGk/roberta-base-bne-finetuned-cyberbullying-spanish,0.4424901
94,nreimers/mmarco-mMiniLMv2-L6-H384-v1,0.61519694
95,phailyoor/distilbert-base-uncased-finetuned-yahd,0.8426798
96,amyma21/sincere_question_classification,0.87916213
97,arianpasquali/distilbert-base-multilingual-cased-toxicity,0.7585976
98,strickvl/nlp-redaction-classifier,0.83999544
99,connectivity/feather_berts_28,0.90801436
100,IMSyPP/hate_speech_it,0.7323274
101,liangyuant/distilbert-base-uncased-finetuned-num200-450-405cls,0.8645335
102,Giyaseddin/distilroberta-base-finetuned-short-answer-assessment,0.905458
103,saattrupdan/job-listing-relevance-model,0.8499731
104,18811449050/bert_finetuning_test,0.8683686
105,Jeevesh8/lecun_feather_berts-51,0.91418827
106,AnonymousSub/dummy_2,0.8238421
107,finiteautomata/betonews-tweetcontext,0.6796153
108,Jeevesh8/lecun_feather_berts-7,0.9176863
109,morenolq/SumTO_FNS2020,0.75899243
110,IMSyPP/hate_speech_nl,0.53135973
111,korca/bae-roberta-base-boolq,0.8941236
112,waboucay/camembert-base-finetuned-xnli_fr-finetuned-nli-rua_wl,0.63840634
113,socialmediaie/TRAC2020_IBEN_B_bert-base-multilingual-uncased,0.84127474
114,zenkri/autotrain-Arabic_Poetry_by_Subject-920730230,0.87520427
115,cointegrated/roberta-base-formality,0.945182
116,CAMeL-Lab/bert-base-arabic-camelbert-da-sentiment,0.548315
117,JonatanGk/roberta-base-ca-finetuned-hate-speech-offensive-catalan,0.6835138
118,classla/bcms-bertic-parlasent-bcs-ter,0.7750556
119,Raychanan/COVID_RandomOver,-0.004826011
120,ali2066/DistilBERTFINAL_ctxSentence_TRAIN_editorials_TEST_NULL_second_train_set_null_False,0.9359529
121,YeRyeongLee/electra-base-discriminator-finetuned-filtered-0602,0.5218299
122,Jeevesh8/feather_berts_92,0.9177638
123,joebobby/finetuning-sentiment-model-5000-samples3,0.8921155
124,Monsia/camembert-fr-covid-tweet-classification,0.78925437
125,kyleinincubated/autonlp-cat333-624217911,0.7082517
