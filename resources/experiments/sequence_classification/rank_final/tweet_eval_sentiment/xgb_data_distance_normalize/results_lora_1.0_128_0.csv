,model,score
0,Jeevesh8/init_bert_ft_qqp-33,0.8439656
1,Jeevesh8/init_bert_ft_qqp-33,0.85367787
2,Jeevesh8/init_bert_ft_qqp-49,0.8439656
3,Jeevesh8/init_bert_ft_qqp-49,0.8439656
4,Jeevesh8/init_bert_ft_qqp-49,0.840114
5,connectivity/bert_ft_qqp-7,0.8439656
6,connectivity/bert_ft_qqp-7,0.8340589
7,Jeevesh8/bert_ft_qqp-40,0.8439656
8,Jeevesh8/bert_ft_qqp-40,0.8101488
9,Jeevesh8/bert_ft_qqp-9,0.8439656
10,Jeevesh8/bert_ft_qqp-9,0.8592944
11,Jeevesh8/bert_ft_qqp-88,0.8439656
12,Jeevesh8/bert_ft_qqp-88,0.8493147
13,connectivity/bert_ft_qqp-25,0.8439656
14,connectivity/bert_ft_qqp-25,0.8494065
15,Jeevesh8/bert_ft_qqp-55,0.8439656
16,Jeevesh8/bert_ft_qqp-55,0.83960766
17,connectivity/bert_ft_qqp-1,0.8439656
18,connectivity/bert_ft_qqp-1,0.8101488
19,Jeevesh8/bert_ft_qqp-39,0.8439656
20,Jeevesh8/bert_ft_qqp-39,0.8101488
21,connectivity/bert_ft_qqp-94,0.8439656
22,connectivity/bert_ft_qqp-94,0.8101488
23,connectivity/bert_ft_qqp-96,0.8439656
24,connectivity/bert_ft_qqp-96,0.8494065
25,Jeevesh8/init_bert_ft_qqp-24,0.8439656
26,Jeevesh8/init_bert_ft_qqp-24,0.8101488
27,Jeevesh8/bert_ft_qqp-68,0.8439656
28,Jeevesh8/bert_ft_qqp-68,0.83960766
29,Jeevesh8/init_bert_ft_qqp-28,0.8439656
30,Jeevesh8/init_bert_ft_qqp-28,0.8376893
31,connectivity/bert_ft_qqp-17,0.8439656
32,connectivity/bert_ft_qqp-17,0.8101488
33,ali2066/finetuned_sentence_itr1_2e-05_all_26_02_2022-04_03_26,0.82226485
34,ali2066/finetuned_sentence_itr1_2e-05_all_26_02_2022-04_03_26,0.83531433
35,SetFit/distilbert-base-uncased__sst2__train-16-0,0.8510949
36,SetFit/distilbert-base-uncased__sst2__train-16-0,0.8516564
37,SetFit/distilbert-base-uncased__sst2__train-16-0,0.8315984
38,gchhablani/fnet-base-finetuned-sst2,0.7325569
39,gchhablani/fnet-base-finetuned-sst2,0.6964513
40,aviator-neural/bert-base-uncased-sst2,0.82204926
41,aviator-neural/bert-base-uncased-sst2,0.82749015
42,SetFit/distilbert-base-uncased__sst2__train-32-9,0.84588444
43,SetFit/distilbert-base-uncased__sst2__train-32-9,0.8234093
44,Alassea/glue_sst_classifier,0.8073027
45,Alassea/glue_sst_classifier,0.8256862
46,philschmid/tiny-distilbert-classification,0.11278269
47,philschmid/tiny-distilbert-classification,0.10803321
48,moshew/bert-mini-sst2-distilled,0.8132327
49,moshew/bert-mini-sst2-distilled,0.74598163
50,ChrisUPM/BioBERT_Re_trained,0.7512242
51,ChrisUPM/BioBERT_Re_trained,0.7871445
52,vaariis/distilbert-base-uncased-finetuned-emotion,0.852746
53,vaariis/distilbert-base-uncased-finetuned-emotion,0.83547
54,marcelcastrobr/sagemaker-distilbert-emotion,0.8454992
55,marcelcastrobr/sagemaker-distilbert-emotion,0.8497976
56,jasonyim2/distilbert-base-uncased-finetuned-emotion,0.8530282
57,jasonyim2/distilbert-base-uncased-finetuned-emotion,0.83959293
58,abdelkader/distilbert-base-uncased-finetuned-emotion,0.82460207
59,abdelkader/distilbert-base-uncased-finetuned-emotion,0.8455071
60,abdelkader/distilbert-base-uncased-finetuned-emotion,0.83232063
61,moghis/distilbert-base-uncased-finetuned-emotion,0.8472632
62,moghis/distilbert-base-uncased-finetuned-emotion,0.84285676
63,uygarkurt/distilbert-base-uncased-finetuned-emotion,0.85244673
64,uygarkurt/distilbert-base-uncased-finetuned-emotion,0.83202136
65,neibla/distilbert-base-uncased-finetuned-emotion,0.85424143
66,neibla/distilbert-base-uncased-finetuned-emotion,0.8569436
67,JB173/distilbert-base-uncased-finetuned-emotion,0.8499264
68,JB173/distilbert-base-uncased-finetuned-emotion,0.8355051
69,Nanatan/distilbert-base-uncased-finetuned-emotion,0.853265
70,Nanatan/distilbert-base-uncased-finetuned-emotion,0.8351569
71,heranm/finetuning-sentiment-model-3000-samples,0.8472719
72,heranm/finetuning-sentiment-model-3000-samples,0.8438213
73,PrasunMishra/finetuning-sentiment-model-3000-samples,0.8123551
74,PrasunMishra/finetuning-sentiment-model-3000-samples,0.8612157
75,PrasunMishra/finetuning-sentiment-model-3000-samples,0.81650186
76,yukta10/finetuning-sentiment-model-3000-samples,0.86264104
77,yukta10/finetuning-sentiment-model-3000-samples,0.8561721
78,yukta10/finetuning-sentiment-model-3000-samples,0.85619116
79,ncduy/roberta-imdb-sentiment-analysis,0.9177811
80,ncduy/roberta-imdb-sentiment-analysis,0.9002046
81,markt23917/finetuning-sentiment-model-3000-samples,0.84662116
82,markt23917/finetuning-sentiment-model-3000-samples,0.8433544
83,juliensimon/autonlp-imdb-demo-hf-16622767,0.8438498
84,juliensimon/autonlp-imdb-demo-hf-16622767,0.8020381
85,fabriceyhc/bert-base-uncased-imdb,0.80879384
86,fabriceyhc/bert-base-uncased-imdb,0.8124683
87,XSY/albert-base-v2-imdb-calssification,0.7991941
88,riyadhctg/distilbert-base-uncased-finetuned-cola,0.83941644
89,riyadhctg/distilbert-base-uncased-finetuned-cola,0.8345518
90,connectivity/cola_6ep_ft-33,0.8899398
91,connectivity/cola_6ep_ft-33,0.84973854
92,connectivity/cola_6ep_ft-33,0.82453465
93,connectivity/cola_6ep_ft-22,0.84973854
94,connectivity/cola_6ep_ft-22,0.84973854
95,connectivity/cola_6ep_ft-22,0.8519403
96,gchhablani/fnet-base-finetuned-cola,0.73718005
97,isakbos/Q8BERT_COLA_L_512,0.555167
98,isakbos/Q8BERT_COLA_L_512,0.5908141
99,jaesun/distilbert-base-uncased-finetuned-cola,0.839716
100,jaesun/distilbert-base-uncased-finetuned-cola,0.80674917
101,usami/distilbert-base-uncased-finetuned-cola,0.83941644
102,usami/distilbert-base-uncased-finetuned-cola,0.83565164
103,Jeevesh8/512seq_len_6ep_bert_ft_cola-91,0.84973854
104,Jeevesh8/512seq_len_6ep_bert_ft_cola-91,0.82453465
105,Jeevesh8/6ep_bert_ft_cola-47,0.84973854
106,Jeevesh8/6ep_bert_ft_cola-47,0.85541457
107,connectivity/cola_6ep_ft-10,0.84973854
108,connectivity/cola_6ep_ft-10,0.8423839
109,Jeevesh8/6ep_bert_ft_cola-12,0.84973854
110,Jeevesh8/6ep_bert_ft_cola-12,0.85541457
111,Jeevesh8/bert_ft_cola-88,0.84973854
112,Jeevesh8/bert_ft_cola-88,0.8510514
113,Jeevesh8/6ep_bert_ft_cola-29,0.84973854
114,Jeevesh8/6ep_bert_ft_cola-29,0.8525792
115,vesteinn/XLMR-ENIS-finetuned-cola,0.867804
116,vesteinn/XLMR-ENIS-finetuned-cola,0.88910687
117,navsad/navid_test_bert,0.79047966
118,navsad/navid_test_bert,0.80338895
119,Jeevesh8/bert_ft_cola-60,0.819829
120,Jeevesh8/bert_ft_cola-60,0.8510514
121,dapang/distilroberta-base-mic-sym,0.9485549
122,dapang/distilroberta-base-mic-sym,0.8839069
123,dapang/distilroberta-base-mic-sym,0.80650836
124,Capreolus/bert-base-msmarco,0.8403254
125,Capreolus/bert-base-msmarco,0.8427454
126,Capreolus/bert-base-msmarco,0.8384759
127,Splend1dchan/bert-base-uncased-slue-goldtrascription-e3-lr1e-4,0.945957
128,Splend1dchan/bert-base-uncased-slue-goldtrascription-e3-lr1e-4,0.86018616
129,Splend1dchan/bert-base-uncased-slue-goldtrascription-e3-lr1e-4,0.865402
130,Jeevesh8/feather_berts_46,0.86018616
131,Jeevesh8/feather_berts_46,0.8595884
132,Jeevesh8/feather_berts_46,0.8446572
133,JonatanGk/roberta-base-bne-finetuned-cyberbullying-spanish,0.3993128
134,JonatanGk/roberta-base-bne-finetuned-cyberbullying-spanish,0.4725182
135,cambridgeltl/guardian_news_distilbert-base-uncased,0.8136297
136,cambridgeltl/guardian_news_distilbert-base-uncased,0.77599156
137,amyma21/sincere_question_classification,0.840636
138,amyma21/sincere_question_classification,0.78785384
139,phailyoor/distilbert-base-uncased-finetuned-yahd,0.8004963
140,phailyoor/distilbert-base-uncased-finetuned-yahd,0.73978806
141,arianpasquali/distilbert-base-multilingual-cased-toxicity,0.6576757
142,arianpasquali/distilbert-base-multilingual-cased-toxicity,0.7020599
143,connectivity/feather_berts_28,0.8595884
144,connectivity/feather_berts_28,0.8574133
145,liangyuant/distilbert-base-uncased-finetuned-num200-450-405cls,0.8022745
146,liangyuant/distilbert-base-uncased-finetuned-num200-450-405cls,0.7709201
147,DoyyingFace/bert-asian-hate-tweets-asian-unclean-freeze-4,0.8011042
148,DoyyingFace/bert-asian-hate-tweets-asian-unclean-freeze-4,0.8071869
149,Jeevesh8/lecun_feather_berts-3,0.86018616
150,Jeevesh8/lecun_feather_berts-3,0.8407315
151,Giyaseddin/distilroberta-base-finetuned-short-answer-assessment,0.804652
152,Giyaseddin/distilroberta-base-finetuned-short-answer-assessment,0.77957225
153,AnonymousSub/dummy_2,0.76774275
154,AnonymousSub/dummy_2,0.7399266
155,Jeevesh8/lecun_feather_berts-51,0.8595884
156,Jeevesh8/lecun_feather_berts-51,0.865402
157,viviastaari/finetuning-sentiment-analysis-en-id,0.6159831
158,viviastaari/finetuning-sentiment-analysis-en-id,0.62953967
159,Aureliano/distilbert-base-uncased-if,0.8252557
160,Aureliano/distilbert-base-uncased-if,0.77821285
161,rmihaylov/roberta-base-sentiment-bg,0.74174327
162,rmihaylov/roberta-base-sentiment-bg,0.7115277
163,cardiffnlp/twitter-roberta-base-2021-124m,0.8080527
164,cardiffnlp/twitter-roberta-base-2021-124m,0.80179214
165,Jeevesh8/lecun_feather_berts-8,0.86018616
166,Jeevesh8/lecun_feather_berts-8,0.81337684
167,korca/bae-roberta-base-boolq,0.82341754
168,korca/bae-roberta-base-boolq,0.8915675
169,aditeyabaral/finetuned-sail2017-xlm-roberta-base,0.8870706
170,aditeyabaral/finetuned-sail2017-xlm-roberta-base,0.7655812
171,joebobby/finetuning-sentiment-model-5000-samples3,0.7080375
172,joebobby/finetuning-sentiment-model-5000-samples3,0.7695919
173,YeRyeongLee/electra-base-discriminator-finetuned-filtered-0602,0.112590544
174,YeRyeongLee/electra-base-discriminator-finetuned-filtered-0602,0.055689126
175,Jeevesh8/feather_berts_92,0.86018616
176,Jeevesh8/feather_berts_92,0.8574133
177,ASCCCCCCCC/distilbert-base-chinese-amazon_zh_20000,0.6502184
178,ASCCCCCCCC/distilbert-base-chinese-amazon_zh_20000,0.61613303
179,matthewburke/korean_sentiment,0.639606
180,matthewburke/korean_sentiment,0.5701526
181,IMSyPP/hate_speech_nl,0.54908293
182,IMSyPP/hate_speech_nl,0.43984848
183,cointegrated/roberta-base-formality,0.82341754
184,cointegrated/roberta-base-formality,0.8915675
185,chiragasarpota/scotus-bert,0.5284033
186,chiragasarpota/scotus-bert,0.44355768
187,IMSyPP/hate_speech_it,0.7016331
188,IMSyPP/hate_speech_it,0.6592565
189,18811449050/bert_finetuning_test,0.8427454
190,18811449050/bert_finetuning_test,0.84734595
191,finiteautomata/betonews-tweetcontext,0.7104621
192,finiteautomata/betonews-tweetcontext,0.5978401
193,Jeevesh8/feather_berts_96,0.8595884
194,Jeevesh8/feather_berts_96,0.8407315
195,Jeevesh8/lecun_feather_berts-7,0.86018616
196,Jeevesh8/lecun_feather_berts-7,0.8145395
197,mrm8488/codebert-base-finetuned-detect-insecure-code,0.8189828
198,mrm8488/codebert-base-finetuned-detect-insecure-code,0.8232376
199,cardiffnlp/bertweet-base-stance-climate,0.8677427
200,cardiffnlp/bertweet-base-stance-climate,0.84240514
201,socialmediaie/TRAC2020_IBEN_B_bert-base-multilingual-uncased,0.789352
202,socialmediaie/TRAC2020_IBEN_B_bert-base-multilingual-uncased,0.7705735
203,zenkri/autotrain-Arabic_Poetry_by_Subject-920730230,0.7842165
204,zenkri/autotrain-Arabic_Poetry_by_Subject-920730230,0.8283864
205,M47Labs/spanish_news_classification_headlines_untrained,0.6797865
206,M47Labs/spanish_news_classification_headlines_untrained,0.5855077
207,bondi/bert-semaphore-prediction-w4,0.71105015
208,bondi/bert-semaphore-prediction-w4,0.54421556
209,classla/bcms-bertic-parlasent-bcs-ter,0.6474638
210,classla/bcms-bertic-parlasent-bcs-ter,0.5703611
211,waboucay/camembert-base-finetuned-xnli_fr-finetuned-nli-rua_wl,0.61230433
212,ali2066/DistilBERTFINAL_ctxSentence_TRAIN_editorials_TEST_NULL_second_train_set_null_False,0.9219189
213,ali2066/DistilBERTFINAL_ctxSentence_TRAIN_editorials_TEST_NULL_second_train_set_null_False,0.92074895
214,anvay/finetuning-cardiffnlp-sentiment-model,0.86640435
215,anvay/finetuning-cardiffnlp-sentiment-model,0.86512
216,JonatanGk/roberta-base-ca-finetuned-hate-speech-offensive-catalan,0.69573784
217,JonatanGk/roberta-base-ca-finetuned-hate-speech-offensive-catalan,0.69819814
218,Raychanan/COVID_RandomOver,0.22938837
219,Raychanan/COVID_RandomOver,0.18048318
220,Monsia/camembert-fr-covid-tweet-classification,0.7893278
221,CAMeL-Lab/bert-base-arabic-camelbert-mix-did-nadi,0.53450173
222,CAMeL-Lab/bert-base-arabic-camelbert-mix-did-nadi,0.42545655
223,kyleinincubated/autonlp-cat333-624217911,0.6502904
224,kyleinincubated/autonlp-cat333-624217911,0.6080278
225,CAMeL-Lab/bert-base-arabic-camelbert-da-sentiment,0.4734678
226,CAMeL-Lab/bert-base-arabic-camelbert-da-sentiment,0.3820653
227,fgaim/tiroberta-geezswitch,0.6161937
228,nreimers/mmarco-mMiniLMv2-L6-H384-v1,0.72481173
229,nreimers/mmarco-mMiniLMv2-L6-H384-v1,0.57713693
230,strickvl/nlp-redaction-classifier,0.7733064
231,strickvl/nlp-redaction-classifier,0.73514724
232,saattrupdan/job-listing-relevance-model,0.86306214
233,saattrupdan/job-listing-relevance-model,0.74515617
234,morenolq/SumTO_FNS2020,0.7552224
235,morenolq/SumTO_FNS2020,0.7484439
236,cross-encoder/ms-marco-MiniLM-L-4-v2,0.7955801
237,cross-encoder/ms-marco-MiniLM-L-4-v2,0.6687048
238,nurkayevaa/autonlp-bert-covid-407910458,0.84786576
239,nurkayevaa/autonlp-bert-covid-407910458,0.84412843
240,nurkayevaa/autonlp-bert-covid-407910458,0.83012444
241,SetFit/distilbert-base-uncased__hate_speech_offensive__train-16-1,0.85245615
242,SetFit/distilbert-base-uncased__hate_speech_offensive__train-16-1,0.85789996
243,SetFit/distilbert-base-uncased__hate_speech_offensive__train-16-1,0.8347925
244,crcb/isear_bert,0.9297332
245,crcb/isear_bert,0.92678666
246,crcb/isear_bert,0.9220357
247,robertou2/roberta-base-bne-finetuned-amazon_reviews_multi,0.61869085
248,robertou2/roberta-base-bne-finetuned-amazon_reviews_multi,0.6531725
249,milyiyo/selectra-small-finetuned-amazon-review,0.54661053
250,milyiyo/selectra-small-finetuned-amazon-review,0.49764863
251,Anthos23/FS-distilroberta-fine-tuned,0.87681293
252,Anthos23/FS-distilroberta-fine-tuned,0.86244094
253,oferweintraub/bert-base-finance-sentiment-noisy-search,0.82401896
254,oferweintraub/bert-base-finance-sentiment-noisy-search,0.80597275
255,pietrotrope/emotion_final,0.84506714
256,pietrotrope/emotion_final,0.8613337
257,aXhyra/emotion_trained_31415,0.8391697
258,aXhyra/emotion_trained_31415,0.8266722
259,aXhyra/presentation_emotion_31415,0.8383393
260,aXhyra/presentation_emotion_31415,0.8296992
261,Recognai/bert-base-spanish-wwm-cased-xnli,0.67473906
262,Recognai/bert-base-spanish-wwm-cased-xnli,0.583491
263,JNK789/distilbert-base-uncased-finetuned-tweets-emoji-dataset,-0.007885535
264,JNK789/distilbert-base-uncased-finetuned-tweets-emoji-dataset,-0.016991587
265,anirudh21/bert-base-uncased-finetuned-qnli,0.85235435
266,anirudh21/bert-base-uncased-finetuned-qnli,0.8669026
267,Alireza1044/albert-base-v2-qnli,0.859745
268,aXhyra/demo_sentiment_31415,0.86947924
269,aXhyra/demo_sentiment_31415,0.84693855
270,aXhyra/presentation_sentiment_1234567,0.86764914
271,aXhyra/presentation_sentiment_1234567,0.8544926
272,jb2k/bert-base-multilingual-cased-language-detection,0.72617847
273,jb2k/bert-base-multilingual-cased-language-detection,0.66134197
274,vinai/bertweet-base,0.8374047
275,vinai/bertweet-base,0.7949588
276,justinqbui/bertweet-covid19-base-uncased-pretraining-covid-vaccine-tweets,0.8515664
277,justinqbui/bertweet-covid19-base-uncased-pretraining-covid-vaccine-tweets,0.81044865
278,vinai/bertweet-covid19-base-cased,0.8515664
279,vinai/bertweet-covid19-base-cased,0.8238889
280,vinai/bertweet-covid19-base-uncased,0.8515664
281,vinai/bertweet-covid19-base-uncased,0.7949588
282,distilbert-base-uncased,0.8722667
283,distilbert-base-uncased,0.868243
284,bert-base-uncased,0.8641157
285,bert-base-uncased,0.8676101
286,roberta-base,0.82729566
287,roberta-base,0.8386306
288,albert-base-v2,0.8275754
289,bert-base-cased,0.8240396
290,bert-base-cased,0.8240396
291,dhimskyy/wiki-bert,0.64550674
292,dhimskyy/wiki-bert,0.5683684
293,michiyasunaga/LinkBERT-base,0.8524075
294,michiyasunaga/LinkBERT-base,0.8377805
295,boychaboy/MNLI_roberta-base,0.9271603
296,boychaboy/MNLI_roberta-base,0.91118354
297,ishan/bert-base-uncased-mnli,0.8415284
298,ishan/bert-base-uncased-mnli,0.8724759
299,emrecan/bert-base-multilingual-cased-snli_tr,0.81106627
300,emrecan/bert-base-multilingual-cased-snli_tr,0.7039322
301,elozano/tweet_offensive_eval,0.7782794
302,elozano/tweet_offensive_eval,0.7558925
303,Hate-speech-CNERG/bert-base-uncased-hatexplain-rationale-two,0.8626521
304,Hate-speech-CNERG/bert-base-uncased-hatexplain-rationale-two,0.83055013
305,aychang/bert-base-cased-trec-coarse,0.8365062
306,aychang/bert-base-cased-trec-coarse,0.856302
307,gchhablani/bert-base-cased-finetuned-wnli,0.84099203
308,gchhablani/bert-base-cased-finetuned-wnli,0.8223947
309,nickmuchi/facebook-data2vec-finetuned-finance-classification,0.7817132
310,w11wo/sundanese-bert-base-emotion-classifier,0.5591752
311,w11wo/sundanese-bert-base-emotion-classifier,0.51676553
312,gchhablani/bert-base-cased-finetuned-rte,0.7115605
313,gchhablani/bert-base-cased-finetuned-rte,0.72377115
314,mrm8488/electricidad-base-finetuned-pawsx-es,0.61717206
315,mrm8488/electricidad-base-finetuned-pawsx-es,0.5699898
316,manueltonneau/bert-twitter-en-is-hired,0.8458326
317,manueltonneau/bert-twitter-en-is-hired,0.85384065
318,Guscode/DKbert-hatespeech-detection,0.5585621
319,Guscode/DKbert-hatespeech-detection,0.5585621
320,cross-encoder/quora-distilroberta-base,0.8520759
321,cross-encoder/quora-distilroberta-base,0.8305625
322,navteca/quora-roberta-base,0.85165626
323,navteca/quora-roberta-base,0.8333423
324,cross-encoder/quora-roberta-base,0.85165626
325,cross-encoder/quora-roberta-base,0.8038385
326,,0.7373529
327,,0.7395116
328,,0.7361913
329,,0.72771746
