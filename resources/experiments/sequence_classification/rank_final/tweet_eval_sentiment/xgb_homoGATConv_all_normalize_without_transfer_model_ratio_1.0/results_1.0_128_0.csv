,model,score
0,Guscode/DKbert-hatespeech-detection,0.40357772
1,robertou2/roberta-base-bne-finetuned-amazon_reviews_multi,0.64128864
2,milyiyo/selectra-small-finetuned-amazon-review,0.29185936
3,SetFit/distilbert-base-uncased__hate_speech_offensive__train-16-1,0.7903556
4,SetFit/distilbert-base-uncased__hate_speech_offensive__train-16-1,0.80006534
5,vinai/bertweet-base,0.7275604
6,justinqbui/bertweet-covid19-base-uncased-pretraining-covid-vaccine-tweets,0.89859843
7,vinai/bertweet-covid19-base-cased,0.92225283
8,vinai/bertweet-covid19-base-uncased,0.9184596
9,jb2k/bert-base-multilingual-cased-language-detection,0.81096816
10,crcb/isear_bert,0.95842725
11,crcb/isear_bert,0.95382214
12,abdelkader/distilbert-base-uncased-finetuned-emotion,0.8010971
13,vaariis/distilbert-base-uncased-finetuned-emotion,0.80009675
14,marcelcastrobr/sagemaker-distilbert-emotion,0.7955268
15,jasonyim2/distilbert-base-uncased-finetuned-emotion,0.8021273
16,abdelkader/distilbert-base-uncased-finetuned-emotion,0.80315566
17,moghis/distilbert-base-uncased-finetuned-emotion,0.8098805
18,uygarkurt/distilbert-base-uncased-finetuned-emotion,0.8036386
19,neibla/distilbert-base-uncased-finetuned-emotion,0.8014669
20,JB173/distilbert-base-uncased-finetuned-emotion,0.78996646
21,Nanatan/distilbert-base-uncased-finetuned-emotion,0.78710747
22,connectivity/cola_6ep_ft-22,0.96932495
23,connectivity/cola_6ep_ft-33,0.9712308
24,riyadhctg/distilbert-base-uncased-finetuned-cola,0.82263124
25,connectivity/cola_6ep_ft-33,0.9619463
26,gchhablani/fnet-base-finetuned-cola,0.7080139
27,connectivity/cola_6ep_ft-22,0.9753063
28,vesteinn/XLMR-ENIS-finetuned-cola,1.0337968
29,isakbos/Q8BERT_COLA_L_512,0.64535147
30,jaesun/distilbert-base-uncased-finetuned-cola,0.85245055
31,usami/distilbert-base-uncased-finetuned-cola,0.8102054
32,Jeevesh8/512seq_len_6ep_bert_ft_cola-91,0.99534935
33,Jeevesh8/6ep_bert_ft_cola-47,0.9679928
34,connectivity/cola_6ep_ft-10,0.96147263
35,Jeevesh8/6ep_bert_ft_cola-12,0.94381535
36,Jeevesh8/6ep_bert_ft_cola-29,0.9542905
37,navsad/navid_test_bert,1.0066401
38,Jeevesh8/bert_ft_cola-60,0.94454193
39,Jeevesh8/bert_ft_cola-88,0.955597
40,ishan/bert-base-uncased-mnli,0.92284274
41,boychaboy/MNLI_roberta-base,0.96249306
42,anirudh21/bert-base-uncased-finetuned-qnli,0.9541566
43,Alireza1044/albert-base-v2-qnli,0.73691046
44,Jeevesh8/init_bert_ft_qqp-49,0.93512505
45,Jeevesh8/init_bert_ft_qqp-33,0.92608845
46,Jeevesh8/init_bert_ft_qqp-49,0.93512505
47,connectivity/bert_ft_qqp-7,0.87935764
48,Jeevesh8/bert_ft_qqp-40,0.9275374
49,Jeevesh8/bert_ft_qqp-9,0.92737705
50,Jeevesh8/bert_ft_qqp-88,0.95065033
51,connectivity/bert_ft_qqp-25,0.9624036
52,Jeevesh8/init_bert_ft_qqp-24,0.92642426
53,Jeevesh8/bert_ft_qqp-55,0.9507501
54,Jeevesh8/bert_ft_qqp-68,0.94664866
55,connectivity/bert_ft_qqp-17,0.92046815
56,Jeevesh8/init_bert_ft_qqp-28,0.9156404
57,connectivity/bert_ft_qqp-1,0.9551059
58,Jeevesh8/bert_ft_qqp-39,0.93029934
59,connectivity/bert_ft_qqp-94,0.9265485
60,connectivity/bert_ft_qqp-96,0.937952
61,gchhablani/bert-base-cased-finetuned-rte,0.9186005
62,SetFit/distilbert-base-uncased__sst2__train-16-0,0.815456
63,gchhablani/fnet-base-finetuned-sst2,0.64644355
64,philschmid/tiny-distilbert-classification,0.08080483
65,ali2066/finetuned_sentence_itr1_2e-05_all_26_02_2022-04_03_26,0.77990913
66,SetFit/distilbert-base-uncased__sst2__train-16-0,0.81181026
67,gchhablani/fnet-base-finetuned-sst2,0.61110616
68,moshew/bert-mini-sst2-distilled,0.67763764
69,SetFit/distilbert-base-uncased__sst2__train-32-9,0.82985663
70,aviator-neural/bert-base-uncased-sst2,0.90583175
71,Alassea/glue_sst_classifier,0.8827417
72,ChrisUPM/BioBERT_Re_trained,0.8159104
73,gchhablani/bert-base-cased-finetuned-wnli,0.92373675
74,Hate-speech-CNERG/bert-base-uncased-hatexplain-rationale-two,0.95091677
75,PrasunMishra/finetuning-sentiment-model-3000-samples,0.82756287
76,yukta10/finetuning-sentiment-model-3000-samples,0.87192595
77,heranm/finetuning-sentiment-model-3000-samples,0.82108605
78,PrasunMishra/finetuning-sentiment-model-3000-samples,0.825389
79,yukta10/finetuning-sentiment-model-3000-samples,0.8632183
80,ncduy/roberta-imdb-sentiment-analysis,0.99806297
81,markt23917/finetuning-sentiment-model-3000-samples,0.8224683
82,juliensimon/autonlp-imdb-demo-hf-16622767,0.778285
83,XSY/albert-base-v2-imdb-calssification,0.6222763
84,fabriceyhc/bert-base-uncased-imdb,0.90000117
85,Anthos23/FS-distilroberta-fine-tuned,0.8169207
86,oferweintraub/bert-base-finance-sentiment-noisy-search,0.97268325
87,emrecan/bert-base-multilingual-cased-snli_tr,0.7901476
88,nurkayevaa/autonlp-bert-covid-407910458,0.820627
89,nurkayevaa/autonlp-bert-covid-407910458,0.82062155
90,cross-encoder/quora-distilroberta-base,0.84663403
91,navteca/quora-roberta-base,0.90556276
92,cross-encoder/quora-roberta-base,0.90093166
93,w11wo/sundanese-bert-base-emotion-classifier,0.5416012
94,aychang/bert-base-cased-trec-coarse,0.81775045
95,JNK789/distilbert-base-uncased-finetuned-tweets-emoji-dataset,0.05636316
96,pietrotrope/emotion_final,0.8563142
97,aXhyra/emotion_trained_31415,0.81674707
98,aXhyra/presentation_emotion_31415,0.84388447
99,elozano/tweet_offensive_eval,0.59968376
100,aXhyra/demo_sentiment_31415,0.82871556
101,aXhyra/presentation_sentiment_1234567,0.8369668
102,nickmuchi/facebook-data2vec-finetuned-finance-classification,0.969787
103,manueltonneau/bert-twitter-en-is-hired,0.938954
104,distilbert-base-uncased,0.8376204
105,dhimskyy/wiki-bert,0.5710438
106,bert-base-uncased,0.9277805
107,roberta-base,0.9333262
108,bert-base-cased,0.9021804
109,albert-base-v2,0.8087258
110,michiyasunaga/LinkBERT-base,0.9085154
111,Recognai/bert-base-spanish-wwm-cased-xnli,0.5910008
112,mrm8488/electricidad-base-finetuned-pawsx-es,0.7160607
113,Capreolus/bert-base-msmarco,0.9576087
114,Jeevesh8/feather_berts_46,0.9369016
115,Splend1dchan/bert-base-uncased-slue-goldtrascription-e3-lr1e-4,0.9563486
116,dapang/distilroberta-base-mic-sym,0.8283329
117,dapang/distilroberta-base-mic-sym,0.8274041
118,cambridgeltl/guardian_news_distilbert-base-uncased,0.79201597
119,Capreolus/bert-base-msmarco,0.9436418
120,Splend1dchan/bert-base-uncased-slue-goldtrascription-e3-lr1e-4,0.94121534
121,Jeevesh8/feather_berts_46,0.9369016
122,JonatanGk/roberta-base-bne-finetuned-cyberbullying-spanish,0.26502705
123,nreimers/mmarco-mMiniLMv2-L6-H384-v1,0.68993384
124,phailyoor/distilbert-base-uncased-finetuned-yahd,0.72780627
125,amyma21/sincere_question_classification,0.8082964
126,arianpasquali/distilbert-base-multilingual-cased-toxicity,0.6844583
127,chiragasarpota/scotus-bert,0.4465881
128,strickvl/nlp-redaction-classifier,0.86920553
129,connectivity/feather_berts_28,0.96613765
130,IMSyPP/hate_speech_it,0.5725094
131,liangyuant/distilbert-base-uncased-finetuned-num200-450-405cls,0.7975908
132,DoyyingFace/bert-asian-hate-tweets-asian-unclean-freeze-4,0.9183587
133,Giyaseddin/distilroberta-base-finetuned-short-answer-assessment,0.78226835
134,saattrupdan/job-listing-relevance-model,0.903742
135,Jeevesh8/lecun_feather_berts-3,0.8730111
136,18811449050/bert_finetuning_test,0.88023466
137,Jeevesh8/feather_berts_96,0.9585672
138,Jeevesh8/lecun_feather_berts-51,0.9220594
139,viviastaari/finetuning-sentiment-analysis-en-id,0.61449707
140,AnonymousSub/dummy_2,0.7053514
141,finiteautomata/betonews-tweetcontext,0.5165778
142,Aureliano/distilbert-base-uncased-if,0.80667907
143,cross-encoder/ms-marco-MiniLM-L-4-v2,0.859063
144,cardiffnlp/twitter-roberta-base-2021-124m,0.8472324
145,Jeevesh8/lecun_feather_berts-8,0.93582195
146,Jeevesh8/lecun_feather_berts-7,0.86931247
147,morenolq/SumTO_FNS2020,0.8188453
148,IMSyPP/hate_speech_nl,0.43168315
149,korca/bae-roberta-base-boolq,0.91567683
150,matthewburke/korean_sentiment,0.6435242
151,waboucay/camembert-base-finetuned-xnli_fr-finetuned-nli-rua_wl,0.5290983
152,mrm8488/codebert-base-finetuned-detect-insecure-code,0.7949386
153,socialmediaie/TRAC2020_IBEN_B_bert-base-multilingual-uncased,0.8406085
154,aditeyabaral/finetuned-sail2017-xlm-roberta-base,0.9836897
155,cardiffnlp/bertweet-base-stance-climate,0.8614001
156,M47Labs/spanish_news_classification_headlines_untrained,0.6698546
157,zenkri/autotrain-Arabic_Poetry_by_Subject-920730230,0.9012848
158,bondi/bert-semaphore-prediction-w4,0.6748113
159,cointegrated/roberta-base-formality,0.9123042
160,CAMeL-Lab/bert-base-arabic-camelbert-da-sentiment,0.45169958
161,JonatanGk/roberta-base-ca-finetuned-hate-speech-offensive-catalan,0.5350338
162,classla/bcms-bertic-parlasent-bcs-ter,0.6805214
163,Raychanan/COVID_RandomOver,0.01679762
164,ali2066/DistilBERTFINAL_ctxSentence_TRAIN_editorials_TEST_NULL_second_train_set_null_False,0.92849547
165,anvay/finetuning-cardiffnlp-sentiment-model,0.8911683
166,YeRyeongLee/electra-base-discriminator-finetuned-filtered-0602,0.3065893
167,Jeevesh8/feather_berts_92,0.94904834
168,joebobby/finetuning-sentiment-model-5000-samples3,0.90411294
169,CAMeL-Lab/bert-base-arabic-camelbert-mix-did-nadi,0.5668335
170,Monsia/camembert-fr-covid-tweet-classification,0.6512338
171,ASCCCCCCCC/distilbert-base-chinese-amazon_zh_20000,0.56113654
172,kyleinincubated/autonlp-cat333-624217911,0.43139374
173,rmihaylov/roberta-base-sentiment-bg,0.60577494
174,fgaim/tiroberta-geezswitch,0.6225818
