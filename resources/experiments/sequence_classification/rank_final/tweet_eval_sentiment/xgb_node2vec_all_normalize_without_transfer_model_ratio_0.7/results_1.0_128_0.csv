,model,score
0,Guscode/DKbert-hatespeech-detection,0.61231774
1,robertou2/roberta-base-bne-finetuned-amazon_reviews_multi,0.49913567
2,SetFit/distilbert-base-uncased__hate_speech_offensive__train-16-1,0.8551781
3,SetFit/distilbert-base-uncased__hate_speech_offensive__train-16-1,0.86367947
4,vinai/bertweet-base,0.84075594
5,justinqbui/bertweet-covid19-base-uncased-pretraining-covid-vaccine-tweets,0.92186254
6,vinai/bertweet-covid19-base-uncased,0.88990134
7,jb2k/bert-base-multilingual-cased-language-detection,0.69944304
8,crcb/isear_bert,0.9438659
9,crcb/isear_bert,0.9604486
10,abdelkader/distilbert-base-uncased-finetuned-emotion,0.8571563
11,vaariis/distilbert-base-uncased-finetuned-emotion,0.8346127
12,marcelcastrobr/sagemaker-distilbert-emotion,0.86141926
13,abdelkader/distilbert-base-uncased-finetuned-emotion,0.85989666
14,moghis/distilbert-base-uncased-finetuned-emotion,0.84784335
15,uygarkurt/distilbert-base-uncased-finetuned-emotion,0.86815566
16,neibla/distilbert-base-uncased-finetuned-emotion,0.86103576
17,JB173/distilbert-base-uncased-finetuned-emotion,0.8415879
18,connectivity/cola_6ep_ft-22,0.92774796
19,connectivity/cola_6ep_ft-33,0.87283266
20,riyadhctg/distilbert-base-uncased-finetuned-cola,0.8660634
21,connectivity/cola_6ep_ft-33,0.8840649
22,gchhablani/fnet-base-finetuned-cola,0.70759547
23,connectivity/cola_6ep_ft-22,0.92774796
24,vesteinn/XLMR-ENIS-finetuned-cola,0.936384
25,isakbos/Q8BERT_COLA_L_512,0.611554
26,usami/distilbert-base-uncased-finetuned-cola,0.8685756
27,Jeevesh8/512seq_len_6ep_bert_ft_cola-91,0.90337247
28,Jeevesh8/6ep_bert_ft_cola-47,0.9014553
29,connectivity/cola_6ep_ft-10,0.9166487
30,Jeevesh8/6ep_bert_ft_cola-12,0.9310889
31,navsad/navid_test_bert,0.9457086
32,Jeevesh8/bert_ft_cola-60,0.91533214
33,anirudh21/bert-base-uncased-finetuned-qnli,0.9319743
34,Alireza1044/albert-base-v2-qnli,0.84879
35,Jeevesh8/init_bert_ft_qqp-49,0.87702996
36,Jeevesh8/init_bert_ft_qqp-33,0.86695945
37,Jeevesh8/init_bert_ft_qqp-49,0.87702996
38,Jeevesh8/bert_ft_qqp-40,0.8822426
39,Jeevesh8/bert_ft_qqp-9,0.89428705
40,Jeevesh8/init_bert_ft_qqp-24,0.8840064
41,Jeevesh8/bert_ft_qqp-55,0.88904905
42,Jeevesh8/init_bert_ft_qqp-28,0.8785217
43,connectivity/bert_ft_qqp-1,0.9229884
44,Jeevesh8/bert_ft_qqp-39,0.8937731
45,connectivity/bert_ft_qqp-94,0.8478745
46,connectivity/bert_ft_qqp-96,0.8966898
47,gchhablani/bert-base-cased-finetuned-rte,0.91164863
48,SetFit/distilbert-base-uncased__sst2__train-16-0,0.84255445
49,gchhablani/fnet-base-finetuned-sst2,0.6505141
50,philschmid/tiny-distilbert-classification,-0.0048053726
51,SetFit/distilbert-base-uncased__sst2__train-16-0,0.84064144
52,gchhablani/fnet-base-finetuned-sst2,0.67076397
53,moshew/bert-mini-sst2-distilled,0.70383763
54,aviator-neural/bert-base-uncased-sst2,0.86845225
55,Alassea/glue_sst_classifier,0.90678036
56,ChrisUPM/BioBERT_Re_trained,0.66542727
57,gchhablani/bert-base-cased-finetuned-wnli,0.91585004
58,Hate-speech-CNERG/bert-base-uncased-hatexplain-rationale-two,0.935297
59,PrasunMishra/finetuning-sentiment-model-3000-samples,0.85917217
60,yukta10/finetuning-sentiment-model-3000-samples,0.8770744
61,heranm/finetuning-sentiment-model-3000-samples,0.8564934
62,PrasunMishra/finetuning-sentiment-model-3000-samples,0.8631534
63,yukta10/finetuning-sentiment-model-3000-samples,0.8770744
64,fabriceyhc/bert-base-uncased-imdb,0.86543804
65,Anthos23/FS-distilroberta-fine-tuned,0.89303577
66,emrecan/bert-base-multilingual-cased-snli_tr,0.80918896
67,nurkayevaa/autonlp-bert-covid-407910458,0.85187244
68,nurkayevaa/autonlp-bert-covid-407910458,0.85187244
69,cross-encoder/quora-distilroberta-base,0.8159917
70,navteca/quora-roberta-base,0.8329561
71,w11wo/sundanese-bert-base-emotion-classifier,0.5354722
72,JNK789/distilbert-base-uncased-finetuned-tweets-emoji-dataset,0.01599049
73,pietrotrope/emotion_final,0.8452568
74,aXhyra/emotion_trained_31415,0.8376632
75,aXhyra/presentation_emotion_31415,0.8810746
76,elozano/tweet_offensive_eval,0.685155
77,aXhyra/demo_sentiment_31415,0.85828483
78,aXhyra/presentation_sentiment_1234567,0.8514819
79,distilbert-base-uncased,0.89038646
80,dhimskyy/wiki-bert,0.49307758
81,roberta-base,0.96577436
82,bert-base-cased,0.9400294
83,albert-base-v2,0.8446372
84,Recognai/bert-base-spanish-wwm-cased-xnli,0.6391261
85,mrm8488/electricidad-base-finetuned-pawsx-es,0.7112133
86,Capreolus/bert-base-msmarco,0.92910105
87,Splend1dchan/bert-base-uncased-slue-goldtrascription-e3-lr1e-4,0.8741643
88,dapang/distilroberta-base-mic-sym,0.8825699
89,dapang/distilroberta-base-mic-sym,0.8932065
90,cambridgeltl/guardian_news_distilbert-base-uncased,0.81991494
91,Capreolus/bert-base-msmarco,0.93581265
92,Splend1dchan/bert-base-uncased-slue-goldtrascription-e3-lr1e-4,0.8670863
93,JonatanGk/roberta-base-bne-finetuned-cyberbullying-spanish,0.44065657
94,nreimers/mmarco-mMiniLMv2-L6-H384-v1,0.6473788
95,phailyoor/distilbert-base-uncased-finetuned-yahd,0.81810653
96,amyma21/sincere_question_classification,0.8283226
97,arianpasquali/distilbert-base-multilingual-cased-toxicity,0.7171939
98,strickvl/nlp-redaction-classifier,0.83817005
99,connectivity/feather_berts_28,0.88805664
100,IMSyPP/hate_speech_it,0.6079362
101,liangyuant/distilbert-base-uncased-finetuned-num200-450-405cls,0.82859814
102,Giyaseddin/distilroberta-base-finetuned-short-answer-assessment,0.88131076
103,saattrupdan/job-listing-relevance-model,0.7790187
104,18811449050/bert_finetuning_test,0.8147158
105,Jeevesh8/lecun_feather_berts-51,0.911639
106,AnonymousSub/dummy_2,0.695487
107,finiteautomata/betonews-tweetcontext,0.6337018
108,Jeevesh8/lecun_feather_berts-7,0.8894507
109,morenolq/SumTO_FNS2020,0.82518166
110,IMSyPP/hate_speech_nl,0.5694057
111,korca/bae-roberta-base-boolq,0.89398915
112,waboucay/camembert-base-finetuned-xnli_fr-finetuned-nli-rua_wl,0.6650964
113,socialmediaie/TRAC2020_IBEN_B_bert-base-multilingual-uncased,0.82307345
114,zenkri/autotrain-Arabic_Poetry_by_Subject-920730230,0.8451413
115,cointegrated/roberta-base-formality,0.93022054
116,CAMeL-Lab/bert-base-arabic-camelbert-da-sentiment,0.5873583
117,JonatanGk/roberta-base-ca-finetuned-hate-speech-offensive-catalan,0.6746831
118,classla/bcms-bertic-parlasent-bcs-ter,0.65988106
119,Raychanan/COVID_RandomOver,0.083841406
120,ali2066/DistilBERTFINAL_ctxSentence_TRAIN_editorials_TEST_NULL_second_train_set_null_False,0.96365094
121,YeRyeongLee/electra-base-discriminator-finetuned-filtered-0602,0.42621207
122,Jeevesh8/feather_berts_92,0.9275124
123,joebobby/finetuning-sentiment-model-5000-samples3,0.93381876
124,Monsia/camembert-fr-covid-tweet-classification,0.6714562
125,kyleinincubated/autonlp-cat333-624217911,0.5957873
