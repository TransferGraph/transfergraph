,model,score
0,Jeevesh8/init_bert_ft_qqp-33,0.8853037927313003
1,Jeevesh8/init_bert_ft_qqp-49,0.8851405142447458
2,Jeevesh8/init_bert_ft_qqp-49,0.8851405142447458
3,connectivity/bert_ft_qqp-7,0.8823310332956105
4,Jeevesh8/bert_ft_qqp-40,0.8862749313688911
5,Jeevesh8/bert_ft_qqp-9,0.8862749313688911
6,Jeevesh8/bert_ft_qqp-88,0.8862749313688911
7,connectivity/bert_ft_qqp-25,0.8862749313688911
8,Jeevesh8/bert_ft_qqp-55,0.8862749313688911
9,connectivity/bert_ft_qqp-1,0.8862749313688911
10,Jeevesh8/bert_ft_qqp-39,0.8862749313688911
11,connectivity/bert_ft_qqp-94,0.8862749313688911
12,connectivity/bert_ft_qqp-96,0.8862749313688911
13,Jeevesh8/init_bert_ft_qqp-24,0.8862749313688911
14,Jeevesh8/bert_ft_qqp-68,0.8823310332956105
15,Jeevesh8/init_bert_ft_qqp-28,0.8862749313688911
16,connectivity/bert_ft_qqp-17,0.8858623624928722
17,ali2066/finetuned_sentence_itr1_2e-05_all_26_02_2022-04_03_26,0.8487032684986088
18,SetFit/distilbert-base-uncased__sst2__train-16-0,0.8528241858814828
19,SetFit/distilbert-base-uncased__sst2__train-16-0,0.8496832193740818
20,gchhablani/fnet-base-finetuned-sst2,0.890325021573995
21,gchhablani/fnet-base-finetuned-sst2,0.8701659170841402
22,aviator-neural/bert-base-uncased-sst2,0.8858525552096006
23,SetFit/distilbert-base-uncased__sst2__train-32-9,0.8539439572101251
24,Alassea/glue_sst_classifier,0.8832934810348247
25,philschmid/tiny-distilbert-classification,0.15581926828531406
26,moshew/bert-mini-sst2-distilled,0.8489296020668502
27,ChrisUPM/BioBERT_Re_trained,0.8068183180800959
28,vaariis/distilbert-base-uncased-finetuned-emotion,0.8517818014352734
29,marcelcastrobr/sagemaker-distilbert-emotion,0.8517818014352734
30,jasonyim2/distilbert-base-uncased-finetuned-emotion,0.8517818014352734
31,abdelkader/distilbert-base-uncased-finetuned-emotion,0.8402042358000079
32,abdelkader/distilbert-base-uncased-finetuned-emotion,0.8517818014352734
33,moghis/distilbert-base-uncased-finetuned-emotion,0.8517818014352734
34,uygarkurt/distilbert-base-uncased-finetuned-emotion,0.8486408349278725
35,neibla/distilbert-base-uncased-finetuned-emotion,0.8517818014352734
36,JB173/distilbert-base-uncased-finetuned-emotion,0.8496671485487791
37,Nanatan/distilbert-base-uncased-finetuned-emotion,0.8529015727639156
38,heranm/finetuning-sentiment-model-3000-samples,0.8535671769874278
39,PrasunMishra/finetuning-sentiment-model-3000-samples,0.8575449275649314
40,PrasunMishra/finetuning-sentiment-model-3000-samples,0.8530053553972934
41,yukta10/finetuning-sentiment-model-3000-samples,0.852020215240964
42,yukta10/finetuning-sentiment-model-3000-samples,0.852020215240964
43,ncduy/roberta-imdb-sentiment-analysis,0.879102570849502
44,markt23917/finetuning-sentiment-model-3000-samples,0.8535671769874278
45,juliensimon/autonlp-imdb-demo-hf-16622767,0.8525820368310986
46,fabriceyhc/bert-base-uncased-imdb,0.8832592334541178
47,XSY/albert-base-v2-imdb-calssification,0.8760002951298662
48,riyadhctg/distilbert-base-uncased-finetuned-cola,0.8546340866418204
49,connectivity/cola_6ep_ft-33,0.9027066262973061
50,connectivity/cola_6ep_ft-33,0.8843150539815757
51,connectivity/cola_6ep_ft-22,0.8843150539815757
52,connectivity/cola_6ep_ft-22,0.8843150539815757
53,gchhablani/fnet-base-finetuned-cola,0.8702709357341394
54,isakbos/Q8BERT_COLA_L_512,0.7461212139531526
55,jaesun/distilbert-base-uncased-finetuned-cola,0.8514931201344196
56,usami/distilbert-base-uncased-finetuned-cola,0.8551780915033804
57,Jeevesh8/512seq_len_6ep_bert_ft_cola-91,0.8843150539815757
58,Jeevesh8/6ep_bert_ft_cola-47,0.8843150539815757
59,connectivity/cola_6ep_ft-10,0.8843150539815757
60,Jeevesh8/6ep_bert_ft_cola-12,0.8843150539815757
61,Jeevesh8/bert_ft_cola-88,0.8843150539815757
62,Jeevesh8/6ep_bert_ft_cola-29,0.8843150539815757
63,vesteinn/XLMR-ENIS-finetuned-cola,0.8870642006976033
64,navsad/navid_test_bert,0.8811767819648106
65,Jeevesh8/bert_ft_cola-60,0.8843150539815757
66,dapang/distilroberta-base-mic-sym,0.9010066135841999
67,dapang/distilroberta-base-mic-sym,0.8505253660766493
68,Capreolus/bert-base-msmarco,0.8959112726820783
69,Capreolus/bert-base-msmarco,0.8799823294945296
70,Splend1dchan/bert-base-uncased-slue-goldtrascription-e3-lr1e-4,0.8985605279298302
71,Splend1dchan/bert-base-uncased-slue-goldtrascription-e3-lr1e-4,0.8777302229297402
72,Jeevesh8/feather_berts_46,0.8803478531504549
73,Jeevesh8/feather_berts_46,0.8803478531504549
74,JonatanGk/roberta-base-bne-finetuned-cyberbullying-spanish,0.6359316857501891
75,cambridgeltl/guardian_news_distilbert-base-uncased,0.6975498840005955
76,amyma21/sincere_question_classification,0.8518739220258129
77,phailyoor/distilbert-base-uncased-finetuned-yahd,0.7048876505528553
78,arianpasquali/distilbert-base-multilingual-cased-toxicity,0.8139030837185737
79,connectivity/feather_berts_28,0.8803478531504549
80,liangyuant/distilbert-base-uncased-finetuned-num200-450-405cls,0.7066680064628317
81,DoyyingFace/bert-asian-hate-tweets-asian-unclean-freeze-4,0.8803478531504549
82,Jeevesh8/lecun_feather_berts-3,0.8803478531504549
83,Giyaseddin/distilroberta-base-finetuned-short-answer-assessment,0.825626468838982
84,AnonymousSub/dummy_2,0.8206966657623457
85,Jeevesh8/lecun_feather_berts-51,0.8803478531504549
86,viviastaari/finetuning-sentiment-analysis-en-id,0.7310086948576335
87,Aureliano/distilbert-base-uncased-if,0.8486246102615133
88,rmihaylov/roberta-base-sentiment-bg,0.8810408063291668
89,cardiffnlp/twitter-roberta-base-2021-124m,0.87359560590217
90,Jeevesh8/lecun_feather_berts-8,0.8803478531504549
91,korca/bae-roberta-base-boolq,0.8731643011103571
92,aditeyabaral/finetuned-sail2017-xlm-roberta-base,0.8953461320410985
93,joebobby/finetuning-sentiment-model-5000-samples3,0.8798947397761989
94,YeRyeongLee/electra-base-discriminator-finetuned-filtered-0602,0.5216693699587792
95,Jeevesh8/feather_berts_92,0.8803478531504549
96,ASCCCCCCCC/distilbert-base-chinese-amazon_zh_20000,0.7800417533241821
97,matthewburke/korean_sentiment,0.7812483028563523
98,IMSyPP/hate_speech_nl,0.7462742822736379
99,cointegrated/roberta-base-formality,0.8170104373288711
100,chiragasarpota/scotus-bert,0.5422836574625037
101,IMSyPP/hate_speech_it,0.822872617679922
102,18811449050/bert_finetuning_test,0.8777797189294566
103,finiteautomata/betonews-tweetcontext,0.794082245183946
104,Jeevesh8/feather_berts_96,0.8803478531504549
105,Jeevesh8/lecun_feather_berts-7,0.8803478531504549
106,mrm8488/codebert-base-finetuned-detect-insecure-code,0.8185477101658399
107,cardiffnlp/bertweet-base-stance-climate,0.8752430569136327
108,socialmediaie/TRAC2020_IBEN_B_bert-base-multilingual-uncased,0.8529317105706136
109,zenkri/autotrain-Arabic_Poetry_by_Subject-920730230,0.8660496149711482
110,M47Labs/spanish_news_classification_headlines_untrained,0.7942058855105643
111,bondi/bert-semaphore-prediction-w4,0.7875607443426186
112,classla/bcms-bertic-parlasent-bcs-ter,0.8534260252171458
113,waboucay/camembert-base-finetuned-xnli_fr-finetuned-nli-rua_wl,0.6114762481363613
114,ali2066/DistilBERTFINAL_ctxSentence_TRAIN_editorials_TEST_NULL_second_train_set_null_False,0.8679955988812705
115,anvay/finetuning-cardiffnlp-sentiment-model,0.8655513028848308
116,JonatanGk/roberta-base-ca-finetuned-hate-speech-offensive-catalan,0.7765621129228828
117,Raychanan/COVID_RandomOver,0.47507306968254476
118,Monsia/camembert-fr-covid-tweet-classification,0.8583937734233895
119,CAMeL-Lab/bert-base-arabic-camelbert-mix-did-nadi,0.6962145047433004
120,kyleinincubated/autonlp-cat333-624217911,0.7607715532728786
121,CAMeL-Lab/bert-base-arabic-camelbert-da-sentiment,0.7480550422159056
122,fgaim/tiroberta-geezswitch,0.7813906246999595
123,nreimers/mmarco-mMiniLMv2-L6-H384-v1,0.7194547016950618
124,strickvl/nlp-redaction-classifier,0.8633877577943956
125,saattrupdan/job-listing-relevance-model,0.8997060799767249
126,morenolq/SumTO_FNS2020,0.7997722725117323
127,cross-encoder/ms-marco-MiniLM-L-4-v2,0.8482233948003729
128,nurkayevaa/autonlp-bert-covid-407910458,0.8527938843738001
129,nurkayevaa/autonlp-bert-covid-407910458,0.8527938843738001
130,SetFit/distilbert-base-uncased__hate_speech_offensive__train-16-1,0.8503257086398386
131,SetFit/distilbert-base-uncased__hate_speech_offensive__train-16-1,0.8534666751472396
132,crcb/isear_bert,0.8980125382137472
133,crcb/isear_bert,0.8777030769925386
134,robertou2/roberta-base-bne-finetuned-amazon_reviews_multi,0.7879383494663645
135,milyiyo/selectra-small-finetuned-amazon-review,0.6070974392688447
136,Anthos23/FS-distilroberta-fine-tuned,0.8522295235402436
137,oferweintraub/bert-base-finance-sentiment-noisy-search,0.8811733584480603
138,pietrotrope/emotion_final,0.8537539599772197
139,aXhyra/emotion_trained_31415,0.8538118610968436
140,aXhyra/presentation_emotion_31415,0.8538118610968436
141,Recognai/bert-base-spanish-wwm-cased-xnli,0.7832664154114712
142,JNK789/distilbert-base-uncased-finetuned-tweets-emoji-dataset,0.327546013124631
143,anirudh21/bert-base-uncased-finetuned-qnli,0.8842061126767975
144,Alireza1044/albert-base-v2-qnli,0.8804668711104782
145,aXhyra/demo_sentiment_31415,0.8521646405701457
146,aXhyra/presentation_sentiment_1234567,0.8521646405701457
147,jb2k/bert-base-multilingual-cased-language-detection,0.8027754338914781
148,vinai/bertweet-base,0.8836833433865448
149,justinqbui/bertweet-covid19-base-uncased-pretraining-covid-vaccine-tweets,0.8791026086691608
150,vinai/bertweet-covid19-base-cased,0.8794681323250861
151,vinai/bertweet-covid19-base-uncased,0.8794681323250861
152,distilbert-base-uncased,0.8540700021880235
153,bert-base-uncased,0.8818864565681649
154,roberta-base,0.8692889245187985
155,albert-base-v2,0.8740316144199883
156,bert-base-cased,0.8804480383504107
157,dhimskyy/wiki-bert,0.7594054234399445
158,michiyasunaga/LinkBERT-base,0.8756868992787308
159,boychaboy/MNLI_roberta-base,0.8832407314613312
160,ishan/bert-base-uncased-mnli,0.885031851877723
161,emrecan/bert-base-multilingual-cased-snli_tr,0.8918661788369487
162,elozano/tweet_offensive_eval,0.7324345834241871
163,Hate-speech-CNERG/bert-base-uncased-hatexplain-rationale-two,0.8822664515500875
164,aychang/bert-base-cased-trec-coarse,0.8831833269981924
165,gchhablani/bert-base-cased-finetuned-wnli,0.8781565042516148
166,nickmuchi/facebook-data2vec-finetuned-finance-classification,0.8320826228940372
167,w11wo/sundanese-bert-base-emotion-classifier,0.7094351650294017
168,gchhablani/bert-base-cased-finetuned-rte,0.8827676944590435
169,mrm8488/electricidad-base-finetuned-pawsx-es,0.7611413724914119
170,manueltonneau/bert-twitter-en-is-hired,0.880672343833274
171,Guscode/DKbert-hatespeech-detection,0.784968693408297
172,cross-encoder/quora-distilroberta-base,0.8150022254256776
173,navteca/quora-roberta-base,0.803691017085196
174,cross-encoder/quora-roberta-base,0.803691017085196
