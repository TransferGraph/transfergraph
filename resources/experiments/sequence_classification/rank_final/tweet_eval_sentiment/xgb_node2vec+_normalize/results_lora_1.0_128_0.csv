,model,score
0,Jeevesh8/init_bert_ft_qqp-33,0.8553521
1,Jeevesh8/init_bert_ft_qqp-33,0.8563096
2,ali2066/finetuned_sentence_itr1_2e-05_all_26_02_2022-04_03_26,0.8681388
3,ali2066/finetuned_sentence_itr1_2e-05_all_26_02_2022-04_03_26,0.8603788
4,vaariis/distilbert-base-uncased-finetuned-emotion,0.86188823
5,vaariis/distilbert-base-uncased-finetuned-emotion,0.83761376
6,heranm/finetuning-sentiment-model-3000-samples,0.87247103
7,heranm/finetuning-sentiment-model-3000-samples,0.8476654
8,marcelcastrobr/sagemaker-distilbert-emotion,0.8490041
9,marcelcastrobr/sagemaker-distilbert-emotion,0.8464797
10,jasonyim2/distilbert-base-uncased-finetuned-emotion,0.86041176
11,jasonyim2/distilbert-base-uncased-finetuned-emotion,0.83726937
12,riyadhctg/distilbert-base-uncased-finetuned-cola,0.8479625
13,riyadhctg/distilbert-base-uncased-finetuned-cola,0.82671124
14,dapang/distilroberta-base-mic-sym,0.83464634
15,dapang/distilroberta-base-mic-sym,0.87993705
16,dapang/distilroberta-base-mic-sym,0.8522091
17,PrasunMishra/finetuning-sentiment-model-3000-samples,0.85734516
18,PrasunMishra/finetuning-sentiment-model-3000-samples,0.86863685
19,PrasunMishra/finetuning-sentiment-model-3000-samples,0.84533024
20,nurkayevaa/autonlp-bert-covid-407910458,0.8654295
21,nurkayevaa/autonlp-bert-covid-407910458,0.86539704
22,nurkayevaa/autonlp-bert-covid-407910458,0.8413355
23,SetFit/distilbert-base-uncased__sst2__train-16-0,0.8541213
24,SetFit/distilbert-base-uncased__sst2__train-16-0,0.8540172
25,SetFit/distilbert-base-uncased__sst2__train-16-0,0.83359057
26,abdelkader/distilbert-base-uncased-finetuned-emotion,0.8385651
27,abdelkader/distilbert-base-uncased-finetuned-emotion,0.85785633
28,abdelkader/distilbert-base-uncased-finetuned-emotion,0.84072405
29,SetFit/distilbert-base-uncased__hate_speech_offensive__train-16-1,0.8782048
30,SetFit/distilbert-base-uncased__hate_speech_offensive__train-16-1,0.8776353
31,SetFit/distilbert-base-uncased__hate_speech_offensive__train-16-1,0.8468702
32,Capreolus/bert-base-msmarco,0.8772519
33,Capreolus/bert-base-msmarco,0.86148417
34,Capreolus/bert-base-msmarco,0.868439
35,Splend1dchan/bert-base-uncased-slue-goldtrascription-e3-lr1e-4,0.86957264
36,Splend1dchan/bert-base-uncased-slue-goldtrascription-e3-lr1e-4,0.85857683
37,Splend1dchan/bert-base-uncased-slue-goldtrascription-e3-lr1e-4,0.86204904
38,crcb/isear_bert,0.8906457
39,crcb/isear_bert,0.88122755
40,crcb/isear_bert,0.88076675
41,connectivity/cola_6ep_ft-33,0.87134475
42,connectivity/cola_6ep_ft-33,0.85398036
43,connectivity/cola_6ep_ft-33,0.851944
44,Jeevesh8/init_bert_ft_qqp-49,0.86295027
45,Jeevesh8/init_bert_ft_qqp-49,0.86295027
46,Jeevesh8/init_bert_ft_qqp-49,0.8618432
47,Jeevesh8/feather_berts_46,0.85233414
48,Jeevesh8/feather_berts_46,0.8595882
49,Jeevesh8/feather_berts_46,0.8539654
50,yukta10/finetuning-sentiment-model-3000-samples,0.86168945
51,yukta10/finetuning-sentiment-model-3000-samples,0.8604884
52,yukta10/finetuning-sentiment-model-3000-samples,0.8375319
53,connectivity/cola_6ep_ft-22,0.86320114
54,connectivity/cola_6ep_ft-22,0.8702656
55,connectivity/cola_6ep_ft-22,0.8651353
56,JonatanGk/roberta-base-bne-finetuned-cyberbullying-spanish,0.6496218
57,JonatanGk/roberta-base-bne-finetuned-cyberbullying-spanish,0.6933146
58,cambridgeltl/guardian_news_distilbert-base-uncased,0.85990024
59,cambridgeltl/guardian_news_distilbert-base-uncased,0.8255551
60,ncduy/roberta-imdb-sentiment-analysis,0.8853834
61,ncduy/roberta-imdb-sentiment-analysis,0.88273245
62,isakbos/Q8BERT_COLA_L_512,0.7040973
63,isakbos/Q8BERT_COLA_L_512,0.7456509
64,connectivity/bert_ft_qqp-7,0.833065
65,connectivity/bert_ft_qqp-7,0.8234084
66,moghis/distilbert-base-uncased-finetuned-emotion,0.8607699
67,moghis/distilbert-base-uncased-finetuned-emotion,0.8497617
68,uygarkurt/distilbert-base-uncased-finetuned-emotion,0.8622589
69,uygarkurt/distilbert-base-uncased-finetuned-emotion,0.8383225
70,amyma21/sincere_question_classification,0.85910416
71,amyma21/sincere_question_classification,0.8341019
72,phailyoor/distilbert-base-uncased-finetuned-yahd,0.8474744
73,phailyoor/distilbert-base-uncased-finetuned-yahd,0.81944007
74,arianpasquali/distilbert-base-multilingual-cased-toxicity,0.8181673
75,arianpasquali/distilbert-base-multilingual-cased-toxicity,0.7930548
76,neibla/distilbert-base-uncased-finetuned-emotion,0.8749139
77,neibla/distilbert-base-uncased-finetuned-emotion,0.8735423
78,robertou2/roberta-base-bne-finetuned-amazon_reviews_multi,0.7339893
79,robertou2/roberta-base-bne-finetuned-amazon_reviews_multi,0.7831676
80,Anthos23/FS-distilroberta-fine-tuned,0.8761044
81,Anthos23/FS-distilroberta-fine-tuned,0.8485779
82,pietrotrope/emotion_final,0.8673582
83,pietrotrope/emotion_final,0.86698616
84,aviator-neural/bert-base-uncased-sst2,0.85547835
85,aviator-neural/bert-base-uncased-sst2,0.85168004
86,Jeevesh8/bert_ft_qqp-40,0.8655337
87,Jeevesh8/bert_ft_qqp-40,0.85467
88,jaesun/distilbert-base-uncased-finetuned-cola,0.8470868
89,jaesun/distilbert-base-uncased-finetuned-cola,0.829087
90,SetFit/distilbert-base-uncased__sst2__train-32-9,0.87149835
91,SetFit/distilbert-base-uncased__sst2__train-32-9,0.84725064
92,usami/distilbert-base-uncased-finetuned-cola,0.8458594
93,usami/distilbert-base-uncased-finetuned-cola,0.82854605
94,connectivity/feather_berts_28,0.8689169
95,connectivity/feather_berts_28,0.87223387
96,Jeevesh8/512seq_len_6ep_bert_ft_cola-91,0.8541883
97,Jeevesh8/512seq_len_6ep_bert_ft_cola-91,0.8367276
98,Jeevesh8/bert_ft_qqp-9,0.8531255
99,Jeevesh8/bert_ft_qqp-9,0.85364676
100,Jeevesh8/bert_ft_qqp-88,0.8533244
101,Jeevesh8/bert_ft_qqp-88,0.8617477
102,Recognai/bert-base-spanish-wwm-cased-xnli,0.79410255
103,Recognai/bert-base-spanish-wwm-cased-xnli,0.77226573
104,markt23917/finetuning-sentiment-model-3000-samples,0.8549901
105,markt23917/finetuning-sentiment-model-3000-samples,0.8326071
106,anirudh21/bert-base-uncased-finetuned-qnli,0.86743045
107,anirudh21/bert-base-uncased-finetuned-qnli,0.86614996
108,Jeevesh8/6ep_bert_ft_cola-47,0.8652087
109,Jeevesh8/6ep_bert_ft_cola-47,0.8590428
110,oferweintraub/bert-base-finance-sentiment-noisy-search,0.8587564
111,oferweintraub/bert-base-finance-sentiment-noisy-search,0.8499402
112,aXhyra/demo_sentiment_31415,0.8628615
113,aXhyra/demo_sentiment_31415,0.83804667
114,milyiyo/selectra-small-finetuned-amazon-review,0.70675814
115,milyiyo/selectra-small-finetuned-amazon-review,0.7234385
116,aXhyra/presentation_sentiment_1234567,0.8664538
117,aXhyra/presentation_sentiment_1234567,0.84510344
118,liangyuant/distilbert-base-uncased-finetuned-num200-450-405cls,0.853052
119,liangyuant/distilbert-base-uncased-finetuned-num200-450-405cls,0.82868767
120,DoyyingFace/bert-asian-hate-tweets-asian-unclean-freeze-4,0.8143468
121,DoyyingFace/bert-asian-hate-tweets-asian-unclean-freeze-4,0.8559788
122,connectivity/cola_6ep_ft-10,0.857674
123,connectivity/cola_6ep_ft-10,0.8620977
124,Jeevesh8/lecun_feather_berts-3,0.85390633
125,Jeevesh8/lecun_feather_berts-3,0.8533982
126,jb2k/bert-base-multilingual-cased-language-detection,0.82962275
127,jb2k/bert-base-multilingual-cased-language-detection,0.8050117
128,Giyaseddin/distilroberta-base-finetuned-short-answer-assessment,0.87169373
129,Giyaseddin/distilroberta-base-finetuned-short-answer-assessment,0.834469
130,connectivity/bert_ft_qqp-25,0.8512756
131,connectivity/bert_ft_qqp-25,0.8525837
132,Jeevesh8/6ep_bert_ft_cola-12,0.8598071
133,Jeevesh8/6ep_bert_ft_cola-12,0.85610497
134,JB173/distilbert-base-uncased-finetuned-emotion,0.8609158
135,JB173/distilbert-base-uncased-finetuned-emotion,0.8382085
136,aXhyra/emotion_trained_31415,0.8524147
137,aXhyra/emotion_trained_31415,0.85193473
138,aXhyra/presentation_emotion_31415,0.8639574
139,aXhyra/presentation_emotion_31415,0.8413527
140,AnonymousSub/dummy_2,0.8222864
141,AnonymousSub/dummy_2,0.80679184
142,Jeevesh8/bert_ft_qqp-55,0.85708195
143,Jeevesh8/bert_ft_qqp-55,0.8542663
144,Jeevesh8/lecun_feather_berts-51,0.8630145
145,Jeevesh8/lecun_feather_berts-51,0.8631338
146,viviastaari/finetuning-sentiment-analysis-en-id,0.791206
147,viviastaari/finetuning-sentiment-analysis-en-id,0.7683467
148,vinai/bertweet-base,0.86626375
149,vinai/bertweet-base,0.82468414
150,distilbert-base-uncased,0.86267996
151,distilbert-base-uncased,0.8604514
152,bert-base-uncased,0.86550075
153,bert-base-uncased,0.8705904
154,roberta-base,0.8791404
155,roberta-base,0.885603
156,Aureliano/distilbert-base-uncased-if,0.8631797
157,Aureliano/distilbert-base-uncased-if,0.8401043
158,rmihaylov/roberta-base-sentiment-bg,0.83750916
159,rmihaylov/roberta-base-sentiment-bg,0.79527366
160,cardiffnlp/twitter-roberta-base-2021-124m,0.8868518
161,cardiffnlp/twitter-roberta-base-2021-124m,0.8838511
162,Alassea/glue_sst_classifier,0.86852425
163,Alassea/glue_sst_classifier,0.87327105
164,Nanatan/distilbert-base-uncased-finetuned-emotion,0.85688007
165,Nanatan/distilbert-base-uncased-finetuned-emotion,0.83153117
166,connectivity/bert_ft_qqp-1,0.8516037
167,connectivity/bert_ft_qqp-1,0.8481333
168,juliensimon/autonlp-imdb-demo-hf-16622767,0.85822755
169,juliensimon/autonlp-imdb-demo-hf-16622767,0.83805877
170,Jeevesh8/bert_ft_qqp-39,0.8602662
171,Jeevesh8/bert_ft_qqp-39,0.85211015
172,Jeevesh8/lecun_feather_berts-8,0.8608235
173,Jeevesh8/lecun_feather_berts-8,0.85741955
174,connectivity/bert_ft_qqp-94,0.85674334
175,connectivity/bert_ft_qqp-94,0.85311157
176,korca/bae-roberta-base-boolq,0.83360165
177,korca/bae-roberta-base-boolq,0.88511497
178,Jeevesh8/bert_ft_cola-88,0.8645701
179,Jeevesh8/bert_ft_cola-88,0.8632558
180,aditeyabaral/finetuned-sail2017-xlm-roberta-base,0.8898937
181,aditeyabaral/finetuned-sail2017-xlm-roberta-base,0.85694015
182,connectivity/bert_ft_qqp-96,0.86828
183,connectivity/bert_ft_qqp-96,0.8684366
184,boychaboy/MNLI_roberta-base,0.8878515
185,boychaboy/MNLI_roberta-base,0.8854178
186,fabriceyhc/bert-base-uncased-imdb,0.85839874
187,fabriceyhc/bert-base-uncased-imdb,0.8569512
188,emrecan/bert-base-multilingual-cased-snli_tr,0.8370616
189,emrecan/bert-base-multilingual-cased-snli_tr,0.81622875
190,elozano/tweet_offensive_eval,0.77904254
191,elozano/tweet_offensive_eval,0.74278826
192,joebobby/finetuning-sentiment-model-5000-samples3,0.8286111
193,joebobby/finetuning-sentiment-model-5000-samples3,0.8684598
194,Jeevesh8/feather_berts_92,0.8649078
195,Jeevesh8/feather_berts_92,0.86858016
196,ASCCCCCCCC/distilbert-base-chinese-amazon_zh_20000,0.7663391
197,ASCCCCCCCC/distilbert-base-chinese-amazon_zh_20000,0.7630086
198,Jeevesh8/6ep_bert_ft_cola-29,0.8611253
199,Jeevesh8/6ep_bert_ft_cola-29,0.8634235
200,bert-base-cased,0.8586287
201,bert-base-cased,0.8586287
202,Hate-speech-CNERG/bert-base-uncased-hatexplain-rationale-two,0.85395956
203,Hate-speech-CNERG/bert-base-uncased-hatexplain-rationale-two,0.8433355
204,matthewburke/korean_sentiment,0.7829435
205,matthewburke/korean_sentiment,0.7658462
206,aychang/bert-base-cased-trec-coarse,0.8751833
207,aychang/bert-base-cased-trec-coarse,0.86315995
208,IMSyPP/hate_speech_nl,0.75710493
209,IMSyPP/hate_speech_nl,0.73775536
210,cointegrated/roberta-base-formality,0.8367062
211,cointegrated/roberta-base-formality,0.8822384
212,philschmid/tiny-distilbert-classification,0.5324556
213,philschmid/tiny-distilbert-classification,0.49137926
214,gchhablani/bert-base-cased-finetuned-wnli,0.87473446
215,gchhablani/bert-base-cased-finetuned-wnli,0.85967416
216,moshew/bert-mini-sst2-distilled,0.7927217
217,moshew/bert-mini-sst2-distilled,0.79714644
218,vesteinn/XLMR-ENIS-finetuned-cola,0.88150024
219,vesteinn/XLMR-ENIS-finetuned-cola,0.8703678
220,IMSyPP/hate_speech_it,0.8114832
221,IMSyPP/hate_speech_it,0.7996951
222,Jeevesh8/init_bert_ft_qqp-24,0.8496282
223,Jeevesh8/init_bert_ft_qqp-24,0.845045
224,Jeevesh8/bert_ft_qqp-68,0.8491896
225,Jeevesh8/bert_ft_qqp-68,0.8549651
226,Jeevesh8/init_bert_ft_qqp-28,0.86723185
227,Jeevesh8/init_bert_ft_qqp-28,0.8554977
228,connectivity/bert_ft_qqp-17,0.8558737
229,connectivity/bert_ft_qqp-17,0.85001343
230,dhimskyy/wiki-bert,0.76860756
231,dhimskyy/wiki-bert,0.73126245
232,18811449050/bert_finetuning_test,0.8447769
233,18811449050/bert_finetuning_test,0.85089463
234,finiteautomata/betonews-tweetcontext,0.8005046
235,finiteautomata/betonews-tweetcontext,0.7802826
236,Jeevesh8/feather_berts_96,0.86896616
237,Jeevesh8/feather_berts_96,0.87006456
238,michiyasunaga/LinkBERT-base,0.8692829
239,michiyasunaga/LinkBERT-base,0.8532083
240,navsad/navid_test_bert,0.8524784
241,navsad/navid_test_bert,0.8630935
242,Jeevesh8/bert_ft_cola-60,0.8234967
243,Jeevesh8/bert_ft_cola-60,0.87355137
244,Jeevesh8/lecun_feather_berts-7,0.8603778
245,Jeevesh8/lecun_feather_berts-7,0.8637923
246,w11wo/sundanese-bert-base-emotion-classifier,0.722295
247,w11wo/sundanese-bert-base-emotion-classifier,0.72063696
248,mrm8488/codebert-base-finetuned-detect-insecure-code,0.8376575
249,mrm8488/codebert-base-finetuned-detect-insecure-code,0.8352857
250,socialmediaie/TRAC2020_IBEN_B_bert-base-multilingual-uncased,0.83887804
251,socialmediaie/TRAC2020_IBEN_B_bert-base-multilingual-uncased,0.8253365
252,ishan/bert-base-uncased-mnli,0.8712018
253,ishan/bert-base-uncased-mnli,0.870876
254,zenkri/autotrain-Arabic_Poetry_by_Subject-920730230,0.8558723
255,zenkri/autotrain-Arabic_Poetry_by_Subject-920730230,0.86175185
256,M47Labs/spanish_news_classification_headlines_untrained,0.8134513
257,M47Labs/spanish_news_classification_headlines_untrained,0.77455115
258,bondi/bert-semaphore-prediction-w4,0.80970323
259,bondi/bert-semaphore-prediction-w4,0.7949785
260,gchhablani/bert-base-cased-finetuned-rte,0.86781
261,gchhablani/bert-base-cased-finetuned-rte,0.873699
262,classla/bcms-bertic-parlasent-bcs-ter,0.8028372
263,classla/bcms-bertic-parlasent-bcs-ter,0.7703148
264,ali2066/DistilBERTFINAL_ctxSentence_TRAIN_editorials_TEST_NULL_second_train_set_null_False,0.8828109
265,ali2066/DistilBERTFINAL_ctxSentence_TRAIN_editorials_TEST_NULL_second_train_set_null_False,0.88934994
266,anvay/finetuning-cardiffnlp-sentiment-model,0.88112
267,anvay/finetuning-cardiffnlp-sentiment-model,0.87405854
268,JonatanGk/roberta-base-ca-finetuned-hate-speech-offensive-catalan,0.71937877
269,JonatanGk/roberta-base-ca-finetuned-hate-speech-offensive-catalan,0.7329117
270,mrm8488/electricidad-base-finetuned-pawsx-es,0.781591
271,mrm8488/electricidad-base-finetuned-pawsx-es,0.7543132
272,Raychanan/COVID_RandomOver,0.5438151
273,Raychanan/COVID_RandomOver,0.632541
274,manueltonneau/bert-twitter-en-is-hired,0.8626817
275,manueltonneau/bert-twitter-en-is-hired,0.8713291
276,kyleinincubated/autonlp-cat333-624217911,0.8027346
277,kyleinincubated/autonlp-cat333-624217911,0.77827054
278,Guscode/DKbert-hatespeech-detection,0.78260326
279,Guscode/DKbert-hatespeech-detection,0.7779506
280,ChrisUPM/BioBERT_Re_trained,0.77932197
281,ChrisUPM/BioBERT_Re_trained,0.8288939
282,justinqbui/bertweet-covid19-base-uncased-pretraining-covid-vaccine-tweets,0.87189716
283,justinqbui/bertweet-covid19-base-uncased-pretraining-covid-vaccine-tweets,0.8735252
284,vinai/bertweet-covid19-base-cased,0.8752505
285,vinai/bertweet-covid19-base-cased,0.88568354
286,vinai/bertweet-covid19-base-uncased,0.879131
287,vinai/bertweet-covid19-base-uncased,0.84296596
288,cardiffnlp/bertweet-base-stance-climate,0.86547387
289,cardiffnlp/bertweet-base-stance-climate,0.8662182
290,nreimers/mmarco-mMiniLMv2-L6-H384-v1,0.8140859
291,nreimers/mmarco-mMiniLMv2-L6-H384-v1,0.7691921
292,strickvl/nlp-redaction-classifier,0.8409854
293,strickvl/nlp-redaction-classifier,0.8141138
294,saattrupdan/job-listing-relevance-model,0.8756039
295,saattrupdan/job-listing-relevance-model,0.8357979
296,cross-encoder/quora-distilroberta-base,0.8503876
297,cross-encoder/quora-distilroberta-base,0.8262707
298,morenolq/SumTO_FNS2020,0.8345985
299,morenolq/SumTO_FNS2020,0.8258887
300,navteca/quora-roberta-base,0.8571114
301,navteca/quora-roberta-base,0.8630799
302,cross-encoder/ms-marco-MiniLM-L-4-v2,0.80731404
303,cross-encoder/ms-marco-MiniLM-L-4-v2,0.801794
304,cross-encoder/quora-roberta-base,0.8126989
305,cross-encoder/quora-roberta-base,0.7735674
