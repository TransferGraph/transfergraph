,model,score
0,Guscode/DKbert-hatespeech-detection,0.67355347
1,robertou2/roberta-base-bne-finetuned-amazon_reviews_multi,0.7867629
2,SetFit/distilbert-base-uncased__hate_speech_offensive__train-16-1,0.91091526
3,SetFit/distilbert-base-uncased__hate_speech_offensive__train-16-1,0.9106309
4,vinai/bertweet-base,0.9784266
5,justinqbui/bertweet-covid19-base-uncased-pretraining-covid-vaccine-tweets,0.946253
6,vinai/bertweet-covid19-base-uncased,0.9484817
7,jb2k/bert-base-multilingual-cased-language-detection,0.82554436
8,crcb/isear_bert,0.9731883
9,crcb/isear_bert,0.9655985
10,abdelkader/distilbert-base-uncased-finetuned-emotion,0.8696616
11,vaariis/distilbert-base-uncased-finetuned-emotion,0.86167157
12,marcelcastrobr/sagemaker-distilbert-emotion,0.8460516
13,abdelkader/distilbert-base-uncased-finetuned-emotion,0.86845195
14,moghis/distilbert-base-uncased-finetuned-emotion,0.86263365
15,uygarkurt/distilbert-base-uncased-finetuned-emotion,0.88277245
16,neibla/distilbert-base-uncased-finetuned-emotion,0.88169754
17,JB173/distilbert-base-uncased-finetuned-emotion,0.88696456
18,connectivity/cola_6ep_ft-22,0.90036035
19,connectivity/cola_6ep_ft-33,0.93497247
20,riyadhctg/distilbert-base-uncased-finetuned-cola,0.8503368
21,connectivity/cola_6ep_ft-33,0.9116312
22,gchhablani/fnet-base-finetuned-cola,0.79039747
23,connectivity/cola_6ep_ft-22,0.90036035
24,vesteinn/XLMR-ENIS-finetuned-cola,0.930891
25,isakbos/Q8BERT_COLA_L_512,0.669861
26,usami/distilbert-base-uncased-finetuned-cola,0.8488633
27,Jeevesh8/512seq_len_6ep_bert_ft_cola-91,0.88417286
28,Jeevesh8/6ep_bert_ft_cola-47,0.90734583
29,connectivity/cola_6ep_ft-10,0.9148429
30,Jeevesh8/6ep_bert_ft_cola-12,0.8819512
31,navsad/navid_test_bert,0.8942156
32,Jeevesh8/bert_ft_cola-60,0.9087025
33,anirudh21/bert-base-uncased-finetuned-qnli,0.9260339
34,Alireza1044/albert-base-v2-qnli,0.8693435
35,Jeevesh8/init_bert_ft_qqp-49,0.91442674
36,Jeevesh8/init_bert_ft_qqp-33,0.86470133
37,Jeevesh8/init_bert_ft_qqp-49,0.91442674
38,Jeevesh8/bert_ft_qqp-40,0.92869186
39,Jeevesh8/bert_ft_qqp-9,0.9081498
40,Jeevesh8/init_bert_ft_qqp-24,0.9044339
41,Jeevesh8/bert_ft_qqp-55,0.9107927
42,Jeevesh8/init_bert_ft_qqp-28,0.87512195
43,connectivity/bert_ft_qqp-1,0.91378194
44,Jeevesh8/bert_ft_qqp-39,0.87948203
45,connectivity/bert_ft_qqp-94,0.89273256
46,connectivity/bert_ft_qqp-96,0.8668679
47,gchhablani/bert-base-cased-finetuned-rte,0.8895659
48,SetFit/distilbert-base-uncased__sst2__train-16-0,0.87742263
49,gchhablani/fnet-base-finetuned-sst2,0.74010664
50,philschmid/tiny-distilbert-classification,0.075563826
51,SetFit/distilbert-base-uncased__sst2__train-16-0,0.87639844
52,gchhablani/fnet-base-finetuned-sst2,0.7617562
53,moshew/bert-mini-sst2-distilled,0.8489796
54,aviator-neural/bert-base-uncased-sst2,0.87587124
55,Alassea/glue_sst_classifier,0.89649385
56,ChrisUPM/BioBERT_Re_trained,0.82777005
57,gchhablani/bert-base-cased-finetuned-wnli,0.8763097
58,Hate-speech-CNERG/bert-base-uncased-hatexplain-rationale-two,0.9012078
59,PrasunMishra/finetuning-sentiment-model-3000-samples,0.8819577
60,yukta10/finetuning-sentiment-model-3000-samples,0.8799097
61,heranm/finetuning-sentiment-model-3000-samples,0.9001462
62,PrasunMishra/finetuning-sentiment-model-3000-samples,0.8923381
63,yukta10/finetuning-sentiment-model-3000-samples,0.8799097
64,fabriceyhc/bert-base-uncased-imdb,0.8645638
65,Anthos23/FS-distilroberta-fine-tuned,0.9047596
66,emrecan/bert-base-multilingual-cased-snli_tr,0.83014023
67,nurkayevaa/autonlp-bert-covid-407910458,0.8746802
68,nurkayevaa/autonlp-bert-covid-407910458,0.8746802
69,cross-encoder/quora-distilroberta-base,0.8345874
70,navteca/quora-roberta-base,0.80087256
71,w11wo/sundanese-bert-base-emotion-classifier,0.65490955
72,JNK789/distilbert-base-uncased-finetuned-tweets-emoji-dataset,0.067227975
73,pietrotrope/emotion_final,0.89412016
74,aXhyra/emotion_trained_31415,0.87596256
75,aXhyra/presentation_emotion_31415,0.91915524
76,elozano/tweet_offensive_eval,0.7365337
77,aXhyra/demo_sentiment_31415,0.90011823
78,aXhyra/presentation_sentiment_1234567,0.88185185
79,distilbert-base-uncased,0.8834463
80,dhimskyy/wiki-bert,0.74531674
81,roberta-base,0.96623385
82,bert-base-cased,0.9088422
83,albert-base-v2,0.8250767
84,Recognai/bert-base-spanish-wwm-cased-xnli,0.72976327
85,mrm8488/electricidad-base-finetuned-pawsx-es,0.7353016
86,Capreolus/bert-base-msmarco,0.919097
87,Splend1dchan/bert-base-uncased-slue-goldtrascription-e3-lr1e-4,0.92464286
88,dapang/distilroberta-base-mic-sym,0.9366705
89,dapang/distilroberta-base-mic-sym,0.9232095
90,cambridgeltl/guardian_news_distilbert-base-uncased,0.8727801
91,Capreolus/bert-base-msmarco,0.93073934
92,Splend1dchan/bert-base-uncased-slue-goldtrascription-e3-lr1e-4,0.9060462
93,JonatanGk/roberta-base-bne-finetuned-cyberbullying-spanish,0.53110826
94,nreimers/mmarco-mMiniLMv2-L6-H384-v1,0.5691489
95,phailyoor/distilbert-base-uncased-finetuned-yahd,0.86200964
96,amyma21/sincere_question_classification,0.8904138
97,arianpasquali/distilbert-base-multilingual-cased-toxicity,0.75980926
98,strickvl/nlp-redaction-classifier,0.81013817
99,connectivity/feather_berts_28,0.9207979
100,IMSyPP/hate_speech_it,0.77709633
101,liangyuant/distilbert-base-uncased-finetuned-num200-450-405cls,0.8930186
102,Giyaseddin/distilroberta-base-finetuned-short-answer-assessment,0.9009975
103,saattrupdan/job-listing-relevance-model,0.8690953
104,18811449050/bert_finetuning_test,0.8500982
105,Jeevesh8/lecun_feather_berts-51,0.908813
106,AnonymousSub/dummy_2,0.8277312
107,finiteautomata/betonews-tweetcontext,0.72071815
108,Jeevesh8/lecun_feather_berts-7,0.91290545
109,morenolq/SumTO_FNS2020,0.8340234
110,IMSyPP/hate_speech_nl,0.56889516
111,korca/bae-roberta-base-boolq,0.92653155
112,waboucay/camembert-base-finetuned-xnli_fr-finetuned-nli-rua_wl,0.73182136
113,socialmediaie/TRAC2020_IBEN_B_bert-base-multilingual-uncased,0.8484602
114,zenkri/autotrain-Arabic_Poetry_by_Subject-920730230,0.9229463
115,cointegrated/roberta-base-formality,0.9335914
116,CAMeL-Lab/bert-base-arabic-camelbert-da-sentiment,0.6222957
117,JonatanGk/roberta-base-ca-finetuned-hate-speech-offensive-catalan,0.76866066
118,classla/bcms-bertic-parlasent-bcs-ter,0.8022623
119,Raychanan/COVID_RandomOver,0.049828034
120,ali2066/DistilBERTFINAL_ctxSentence_TRAIN_editorials_TEST_NULL_second_train_set_null_False,0.9381597
121,YeRyeongLee/electra-base-discriminator-finetuned-filtered-0602,0.40989715
122,Jeevesh8/feather_berts_92,0.91492414
123,joebobby/finetuning-sentiment-model-5000-samples3,0.90863913
124,Monsia/camembert-fr-covid-tweet-classification,0.86074
125,kyleinincubated/autonlp-cat333-624217911,0.73914677
