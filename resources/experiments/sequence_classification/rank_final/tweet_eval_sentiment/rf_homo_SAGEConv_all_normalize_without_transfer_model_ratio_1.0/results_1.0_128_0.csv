,model,score
0,Guscode/DKbert-hatespeech-detection,0.3610897244849397
1,robertou2/roberta-base-bne-finetuned-amazon_reviews_multi,0.5147961292782359
2,milyiyo/selectra-small-finetuned-amazon-review,0.38538437356857586
3,SetFit/distilbert-base-uncased__hate_speech_offensive__train-16-1,0.8544971268980818
4,SetFit/distilbert-base-uncased__hate_speech_offensive__train-16-1,0.8544971268980818
5,vinai/bertweet-base,0.6855177630092402
6,justinqbui/bertweet-covid19-base-uncased-pretraining-covid-vaccine-tweets,0.8317711994157109
7,vinai/bertweet-covid19-base-cased,0.854198185107856
8,vinai/bertweet-covid19-base-uncased,0.852034425733224
9,jb2k/bert-base-multilingual-cased-language-detection,0.6465962788800789
10,crcb/isear_bert,0.8532003208615528
11,crcb/isear_bert,0.8532003208615528
12,abdelkader/distilbert-base-uncased-finetuned-emotion,0.844112458043242
13,vaariis/distilbert-base-uncased-finetuned-emotion,0.8470919516333985
14,marcelcastrobr/sagemaker-distilbert-emotion,0.8474767531508843
15,jasonyim2/distilbert-base-uncased-finetuned-emotion,0.834018776594796
16,abdelkader/distilbert-base-uncased-finetuned-emotion,0.844112458043242
17,moghis/distilbert-base-uncased-finetuned-emotion,0.8440837329826953
18,uygarkurt/distilbert-base-uncased-finetuned-emotion,0.8496756994294671
19,neibla/distilbert-base-uncased-finetuned-emotion,0.8426142072042444
20,JB173/distilbert-base-uncased-finetuned-emotion,0.8487618490335165
21,Nanatan/distilbert-base-uncased-finetuned-emotion,0.8311616703650385
22,connectivity/cola_6ep_ft-22,0.8492942817703295
23,connectivity/cola_6ep_ft-33,0.8476572867425856
24,riyadhctg/distilbert-base-uncased-finetuned-cola,0.5755212391231918
25,connectivity/cola_6ep_ft-33,0.8476572867425856
26,gchhablani/fnet-base-finetuned-cola,0.644695293698437
27,connectivity/cola_6ep_ft-22,0.8492942817703295
28,vesteinn/XLMR-ENIS-finetuned-cola,0.8535916227211033
29,isakbos/Q8BERT_COLA_L_512,0.3358726904224462
30,jaesun/distilbert-base-uncased-finetuned-cola,0.7669180667796728
31,usami/distilbert-base-uncased-finetuned-cola,0.8488792169589797
32,Jeevesh8/512seq_len_6ep_bert_ft_cola-91,0.671692661848549
33,Jeevesh8/6ep_bert_ft_cola-47,0.82747595373688
34,connectivity/cola_6ep_ft-10,0.8406580746390745
35,Jeevesh8/6ep_bert_ft_cola-12,0.8492942817703295
36,Jeevesh8/6ep_bert_ft_cola-29,0.8448824371930627
37,navsad/navid_test_bert,0.8507304065135908
38,Jeevesh8/bert_ft_cola-60,0.8535916227211033
39,Jeevesh8/bert_ft_cola-88,0.8521812217185972
40,ishan/bert-base-uncased-mnli,0.8531612975410452
41,boychaboy/MNLI_roberta-base,0.8361872597453369
42,anirudh21/bert-base-uncased-finetuned-qnli,0.8546203234334666
43,Alireza1044/albert-base-v2-qnli,0.8355196738286331
44,Jeevesh8/init_bert_ft_qqp-49,0.82362359150597
45,Jeevesh8/init_bert_ft_qqp-33,0.854610721864059
46,Jeevesh8/init_bert_ft_qqp-49,0.82362359150597
47,connectivity/bert_ft_qqp-7,0.8525937584748003
48,Jeevesh8/bert_ft_qqp-40,0.8496654011695061
49,Jeevesh8/bert_ft_qqp-9,0.8478253945251525
50,Jeevesh8/bert_ft_qqp-88,0.8531715958010062
51,connectivity/bert_ft_qqp-25,0.8531715958010062
52,Jeevesh8/init_bert_ft_qqp-24,0.8546203234334666
53,Jeevesh8/bert_ft_qqp-55,0.8531715958010062
54,Jeevesh8/bert_ft_qqp-68,0.8204897324129717
55,connectivity/bert_ft_qqp-17,0.8546203234334666
56,Jeevesh8/init_bert_ft_qqp-28,0.854646416156336
57,connectivity/bert_ft_qqp-1,0.8442501671363225
58,Jeevesh8/bert_ft_qqp-39,0.8488652002631469
59,connectivity/bert_ft_qqp-94,0.8531715958010062
60,connectivity/bert_ft_qqp-96,0.8531612975410452
61,gchhablani/bert-base-cased-finetuned-rte,0.8531612975410452
62,SetFit/distilbert-base-uncased__sst2__train-16-0,0.846114281036312
63,gchhablani/fnet-base-finetuned-sst2,0.6319662712231113
64,philschmid/tiny-distilbert-classification,0.1063183578397861
65,ali2066/finetuned_sentence_itr1_2e-05_all_26_02_2022-04_03_26,0.844112458043242
66,SetFit/distilbert-base-uncased__sst2__train-16-0,0.846114281036312
67,gchhablani/fnet-base-finetuned-sst2,0.6319662712231113
68,moshew/bert-mini-sst2-distilled,0.6707240170487643
69,SetFit/distilbert-base-uncased__sst2__train-32-9,0.8531715958010062
70,aviator-neural/bert-base-uncased-sst2,0.832005808477387
71,Alassea/glue_sst_classifier,0.8324208732887367
72,ChrisUPM/BioBERT_Re_trained,0.8487618490335165
73,gchhablani/bert-base-cased-finetuned-wnli,0.8544588195768216
74,Hate-speech-CNERG/bert-base-uncased-hatexplain-rationale-two,0.8531715958010062
75,PrasunMishra/finetuning-sentiment-model-3000-samples,0.8496654011695061
76,yukta10/finetuning-sentiment-model-3000-samples,0.8531715958010062
77,heranm/finetuning-sentiment-model-3000-samples,0.8408513688757204
78,PrasunMishra/finetuning-sentiment-model-3000-samples,0.8496654011695061
79,yukta10/finetuning-sentiment-model-3000-samples,0.8531715958010062
80,ncduy/roberta-imdb-sentiment-analysis,0.8470919516333985
81,markt23917/finetuning-sentiment-model-3000-samples,0.8452832367247063
82,juliensimon/autonlp-imdb-demo-hf-16622767,0.8515151071935716
83,XSY/albert-base-v2-imdb-calssification,0.6857505705830979
84,fabriceyhc/bert-base-uncased-imdb,0.8515027158281098
85,Anthos23/FS-distilroberta-fine-tuned,0.8532003208615528
86,oferweintraub/bert-base-finance-sentiment-noisy-search,0.8540347710952315
87,emrecan/bert-base-multilingual-cased-snli_tr,0.8531715958010062
88,nurkayevaa/autonlp-bert-covid-407910458,0.8463018776158263
89,nurkayevaa/autonlp-bert-covid-407910458,0.8463018776158263
90,cross-encoder/quora-distilroberta-base,0.7868733791038655
91,navteca/quora-roberta-base,0.7793533065250551
92,cross-encoder/quora-roberta-base,0.7868733791038655
93,w11wo/sundanese-bert-base-emotion-classifier,0.33066412324785316
94,aychang/bert-base-cased-trec-coarse,0.8531715958010062
95,JNK789/distilbert-base-uncased-finetuned-tweets-emoji-dataset,0.046656066573990934
96,pietrotrope/emotion_final,0.8463426371851582
97,aXhyra/emotion_trained_31415,0.8511025704373685
98,aXhyra/presentation_emotion_31415,0.8302098749622663
99,elozano/tweet_offensive_eval,0.3031249710118537
100,aXhyra/demo_sentiment_31415,0.8524952800115325
101,aXhyra/presentation_sentiment_1234567,0.8531715958010062
102,nickmuchi/facebook-data2vec-finetuned-finance-classification,0.8529839992214918
103,manueltonneau/bert-twitter-en-is-hired,0.854646416156336
104,distilbert-base-uncased,0.8478253945251525
105,dhimskyy/wiki-bert,0.5274528967185251
106,bert-base-uncased,0.8334928287817511
107,roberta-base,0.854646416156336
108,bert-base-cased,0.8478253945251525
109,albert-base-v2,0.8215018186977906
110,michiyasunaga/LinkBERT-base,0.8532003208615528
111,Recognai/bert-base-spanish-wwm-cased-xnli,0.3471001571764342
112,mrm8488/electricidad-base-finetuned-pawsx-es,0.39522322175947283
113,Capreolus/bert-base-msmarco,0.8478253945251525
114,Jeevesh8/feather_berts_46,0.8540347710952315
115,Splend1dchan/bert-base-uncased-slue-goldtrascription-e3-lr1e-4,0.8531715958010062
116,dapang/distilroberta-base-mic-sym,0.854610721864059
117,dapang/distilroberta-base-mic-sym,0.854610721864059
118,cambridgeltl/guardian_news_distilbert-base-uncased,0.8404363040643709
119,Capreolus/bert-base-msmarco,0.8478253945251525
120,Splend1dchan/bert-base-uncased-slue-goldtrascription-e3-lr1e-4,0.8531715958010062
121,Jeevesh8/feather_berts_46,0.8540347710952315
122,JonatanGk/roberta-base-bne-finetuned-cyberbullying-spanish,0.3121553174097604
123,nreimers/mmarco-mMiniLMv2-L6-H384-v1,0.3739590710608599
124,phailyoor/distilbert-base-uncased-finetuned-yahd,0.8067576605235091
125,amyma21/sincere_question_classification,0.8521812217185972
126,arianpasquali/distilbert-base-multilingual-cased-toxicity,0.6815168307202625
127,chiragasarpota/scotus-bert,0.24746911719653947
128,strickvl/nlp-redaction-classifier,0.7793533065250551
129,connectivity/feather_berts_28,0.8531715958010062
130,IMSyPP/hate_speech_it,0.7221748572219723
131,liangyuant/distilbert-base-uncased-finetuned-num200-450-405cls,0.849999316228873
132,DoyyingFace/bert-asian-hate-tweets-asian-unclean-freeze-4,0.8532003208615528
133,Giyaseddin/distilroberta-base-finetuned-short-answer-assessment,0.8496654011695061
134,saattrupdan/job-listing-relevance-model,0.7836845914036021
135,Jeevesh8/lecun_feather_berts-3,0.8509267650592824
136,18811449050/bert_finetuning_test,0.8528465704531033
137,Jeevesh8/feather_berts_96,0.8430162051287676
138,Jeevesh8/lecun_feather_berts-51,0.8532003208615528
139,viviastaari/finetuning-sentiment-analysis-en-id,0.5788360639685795
140,AnonymousSub/dummy_2,0.6781144244517096
141,finiteautomata/betonews-tweetcontext,0.5201669716871193
142,Aureliano/distilbert-base-uncased-if,0.8437821458537108
143,cross-encoder/ms-marco-MiniLM-L-4-v2,0.7868733791038655
144,cardiffnlp/twitter-roberta-base-2021-124m,0.8532003208615528
145,Jeevesh8/lecun_feather_berts-8,0.8531715958010062
146,Jeevesh8/lecun_feather_berts-7,0.8531715958010062
147,morenolq/SumTO_FNS2020,0.787288443915215
148,IMSyPP/hate_speech_nl,0.3684761559297819
149,korca/bae-roberta-base-boolq,0.8488652002631469
150,matthewburke/korean_sentiment,0.5317768628007293
151,waboucay/camembert-base-finetuned-xnli_fr-finetuned-nli-rua_wl,0.4411794234178099
152,mrm8488/codebert-base-finetuned-detect-insecure-code,0.8479717750159443
153,socialmediaie/TRAC2020_IBEN_B_bert-base-multilingual-uncased,0.8497420218514773
154,aditeyabaral/finetuned-sail2017-xlm-roberta-base,0.854646416156336
155,cardiffnlp/bertweet-base-stance-climate,0.8504224177970998
156,M47Labs/spanish_news_classification_headlines_untrained,0.6532378635955112
157,zenkri/autotrain-Arabic_Poetry_by_Subject-920730230,0.8546203234334666
158,bondi/bert-semaphore-prediction-w4,0.38139771491042807
159,cointegrated/roberta-base-formality,0.8487618490335165
160,CAMeL-Lab/bert-base-arabic-camelbert-da-sentiment,0.2652305640888296
161,JonatanGk/roberta-base-ca-finetuned-hate-speech-offensive-catalan,0.699213051705009
162,classla/bcms-bertic-parlasent-bcs-ter,0.6706903564659774
163,Raychanan/COVID_RandomOver,0.06431605753839481
164,ali2066/DistilBERTFINAL_ctxSentence_TRAIN_editorials_TEST_NULL_second_train_set_null_False,0.8509650754032027
165,anvay/finetuning-cardiffnlp-sentiment-model,0.854646416156336
166,YeRyeongLee/electra-base-discriminator-finetuned-filtered-0602,0.1778794931285363
167,Jeevesh8/feather_berts_92,0.854610721864059
168,joebobby/finetuning-sentiment-model-5000-samples3,0.8531715958010062
169,CAMeL-Lab/bert-base-arabic-camelbert-mix-did-nadi,0.6486978060529477
170,Monsia/camembert-fr-covid-tweet-classification,0.7006277585497037
171,ASCCCCCCCC/distilbert-base-chinese-amazon_zh_20000,0.6924340874939945
172,kyleinincubated/autonlp-cat333-624217911,0.6629316933719249
173,rmihaylov/roberta-base-sentiment-bg,0.648768581335895
174,fgaim/tiroberta-geezswitch,0.38358598126134497
