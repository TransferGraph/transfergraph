,model,score
0,Guscode/DKbert-hatespeech-detection,0.2671976
1,robertou2/roberta-base-bne-finetuned-amazon_reviews_multi,0.47325823
2,SetFit/distilbert-base-uncased__hate_speech_offensive__train-16-1,0.81801116
3,SetFit/distilbert-base-uncased__hate_speech_offensive__train-16-1,0.8202058
4,vinai/bertweet-base,0.7839259
5,justinqbui/bertweet-covid19-base-uncased-pretraining-covid-vaccine-tweets,0.8413275
6,vinai/bertweet-covid19-base-uncased,0.8896098
7,jb2k/bert-base-multilingual-cased-language-detection,0.5095624
8,crcb/isear_bert,0.9140063
9,crcb/isear_bert,0.9330235
10,abdelkader/distilbert-base-uncased-finetuned-emotion,0.7688367
11,vaariis/distilbert-base-uncased-finetuned-emotion,0.7430035
12,marcelcastrobr/sagemaker-distilbert-emotion,0.77678144
13,abdelkader/distilbert-base-uncased-finetuned-emotion,0.7723939
14,moghis/distilbert-base-uncased-finetuned-emotion,0.72908074
15,uygarkurt/distilbert-base-uncased-finetuned-emotion,0.70706064
16,neibla/distilbert-base-uncased-finetuned-emotion,0.75259984
17,JB173/distilbert-base-uncased-finetuned-emotion,0.744265
18,connectivity/cola_6ep_ft-22,0.8796012
19,connectivity/cola_6ep_ft-33,0.82381225
20,riyadhctg/distilbert-base-uncased-finetuned-cola,0.7725499
21,connectivity/cola_6ep_ft-33,0.83694077
22,gchhablani/fnet-base-finetuned-cola,0.66295004
23,connectivity/cola_6ep_ft-22,0.8796012
24,vesteinn/XLMR-ENIS-finetuned-cola,0.89451754
25,isakbos/Q8BERT_COLA_L_512,0.46168375
26,usami/distilbert-base-uncased-finetuned-cola,0.8077443
27,Jeevesh8/512seq_len_6ep_bert_ft_cola-91,0.83844066
28,Jeevesh8/6ep_bert_ft_cola-47,0.8452306
29,connectivity/cola_6ep_ft-10,0.8811669
30,Jeevesh8/6ep_bert_ft_cola-12,0.8520888
31,navsad/navid_test_bert,0.84487927
32,Jeevesh8/bert_ft_cola-60,0.8723599
33,anirudh21/bert-base-uncased-finetuned-qnli,0.84959567
34,Alireza1044/albert-base-v2-qnli,0.7157996
35,Jeevesh8/init_bert_ft_qqp-49,0.8333965
36,Jeevesh8/init_bert_ft_qqp-33,0.8281949
37,Jeevesh8/init_bert_ft_qqp-49,0.8333965
38,Jeevesh8/bert_ft_qqp-40,0.87335694
39,Jeevesh8/bert_ft_qqp-9,0.84907436
40,Jeevesh8/init_bert_ft_qqp-24,0.8223274
41,Jeevesh8/bert_ft_qqp-55,0.8516462
42,Jeevesh8/init_bert_ft_qqp-28,0.8109073
43,connectivity/bert_ft_qqp-1,0.8169474
44,Jeevesh8/bert_ft_qqp-39,0.81908214
45,connectivity/bert_ft_qqp-94,0.8375018
46,connectivity/bert_ft_qqp-96,0.84670293
47,gchhablani/bert-base-cased-finetuned-rte,0.8536585
48,SetFit/distilbert-base-uncased__sst2__train-16-0,0.8058947
49,gchhablani/fnet-base-finetuned-sst2,0.5640245
50,philschmid/tiny-distilbert-classification,0.11952225
51,SetFit/distilbert-base-uncased__sst2__train-16-0,0.80333394
52,gchhablani/fnet-base-finetuned-sst2,0.58007413
53,moshew/bert-mini-sst2-distilled,0.58243114
54,aviator-neural/bert-base-uncased-sst2,0.7828551
55,Alassea/glue_sst_classifier,0.8298508
56,ChrisUPM/BioBERT_Re_trained,0.62671643
57,gchhablani/bert-base-cased-finetuned-wnli,0.8131463
58,Hate-speech-CNERG/bert-base-uncased-hatexplain-rationale-two,0.7913153
59,PrasunMishra/finetuning-sentiment-model-3000-samples,0.7888699
60,yukta10/finetuning-sentiment-model-3000-samples,0.79919726
61,heranm/finetuning-sentiment-model-3000-samples,0.7995678
62,PrasunMishra/finetuning-sentiment-model-3000-samples,0.79452574
63,yukta10/finetuning-sentiment-model-3000-samples,0.79919726
64,fabriceyhc/bert-base-uncased-imdb,0.810999
65,Anthos23/FS-distilroberta-fine-tuned,0.8602037
66,emrecan/bert-base-multilingual-cased-snli_tr,0.7336185
67,nurkayevaa/autonlp-bert-covid-407910458,0.8302848
68,nurkayevaa/autonlp-bert-covid-407910458,0.8302848
69,cross-encoder/quora-distilroberta-base,0.60164785
70,navteca/quora-roberta-base,0.6512214
71,w11wo/sundanese-bert-base-emotion-classifier,0.34163755
72,JNK789/distilbert-base-uncased-finetuned-tweets-emoji-dataset,0.09579142
73,pietrotrope/emotion_final,0.79157925
74,aXhyra/emotion_trained_31415,0.7652512
75,aXhyra/presentation_emotion_31415,0.7890226
76,elozano/tweet_offensive_eval,0.53573364
77,aXhyra/demo_sentiment_31415,0.7982478
78,aXhyra/presentation_sentiment_1234567,0.7954177
79,distilbert-base-uncased,0.8021096
80,dhimskyy/wiki-bert,0.33735117
81,roberta-base,1.0072567
82,bert-base-cased,0.8575056
83,albert-base-v2,0.77672553
84,Recognai/bert-base-spanish-wwm-cased-xnli,0.43896836
85,mrm8488/electricidad-base-finetuned-pawsx-es,0.48250818
86,Capreolus/bert-base-msmarco,0.8719157
87,Splend1dchan/bert-base-uncased-slue-goldtrascription-e3-lr1e-4,0.8382093
88,dapang/distilroberta-base-mic-sym,0.88750577
89,dapang/distilroberta-base-mic-sym,0.9163318
90,cambridgeltl/guardian_news_distilbert-base-uncased,0.6725402
91,Capreolus/bert-base-msmarco,0.8795333
92,Splend1dchan/bert-base-uncased-slue-goldtrascription-e3-lr1e-4,0.8255298
93,JonatanGk/roberta-base-bne-finetuned-cyberbullying-spanish,0.42226675
94,nreimers/mmarco-mMiniLMv2-L6-H384-v1,0.6931667
95,phailyoor/distilbert-base-uncased-finetuned-yahd,0.67096
96,amyma21/sincere_question_classification,0.81423855
97,arianpasquali/distilbert-base-multilingual-cased-toxicity,0.565305
98,strickvl/nlp-redaction-classifier,0.6712454
99,connectivity/feather_berts_28,0.8606368
100,IMSyPP/hate_speech_it,0.4315951
101,liangyuant/distilbert-base-uncased-finetuned-num200-450-405cls,0.7821884
102,Giyaseddin/distilroberta-base-finetuned-short-answer-assessment,0.8686882
103,saattrupdan/job-listing-relevance-model,0.5574276
104,18811449050/bert_finetuning_test,0.7445681
105,Jeevesh8/lecun_feather_berts-51,0.8554966
106,AnonymousSub/dummy_2,0.5528018
107,finiteautomata/betonews-tweetcontext,0.43821764
108,Jeevesh8/lecun_feather_berts-7,0.8359276
109,morenolq/SumTO_FNS2020,0.7293023
110,IMSyPP/hate_speech_nl,0.39832243
111,korca/bae-roberta-base-boolq,0.8751396
112,waboucay/camembert-base-finetuned-xnli_fr-finetuned-nli-rua_wl,0.4053035
113,socialmediaie/TRAC2020_IBEN_B_bert-base-multilingual-uncased,0.65682304
114,zenkri/autotrain-Arabic_Poetry_by_Subject-920730230,0.7982075
115,cointegrated/roberta-base-formality,0.93874496
116,CAMeL-Lab/bert-base-arabic-camelbert-da-sentiment,0.517191
117,JonatanGk/roberta-base-ca-finetuned-hate-speech-offensive-catalan,0.43275413
118,classla/bcms-bertic-parlasent-bcs-ter,0.50761485
119,Raychanan/COVID_RandomOver,0.17035575
120,ali2066/DistilBERTFINAL_ctxSentence_TRAIN_editorials_TEST_NULL_second_train_set_null_False,0.95851606
121,YeRyeongLee/electra-base-discriminator-finetuned-filtered-0602,0.30770528
122,Jeevesh8/feather_berts_92,0.9169579
123,joebobby/finetuning-sentiment-model-5000-samples3,0.82711923
124,Monsia/camembert-fr-covid-tweet-classification,0.62974
125,kyleinincubated/autonlp-cat333-624217911,0.48765483
