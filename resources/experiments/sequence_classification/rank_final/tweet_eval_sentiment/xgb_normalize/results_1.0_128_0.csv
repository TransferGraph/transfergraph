,model,score
0,Jeevesh8/init_bert_ft_qqp-33,0.894519
1,ali2066/finetuned_sentence_itr1_2e-05_all_26_02_2022-04_03_26,0.8201687
2,vaariis/distilbert-base-uncased-finetuned-emotion,0.8379438
3,heranm/finetuning-sentiment-model-3000-samples,0.8504813
4,marcelcastrobr/sagemaker-distilbert-emotion,0.8225023
5,jasonyim2/distilbert-base-uncased-finetuned-emotion,0.8287562
6,riyadhctg/distilbert-base-uncased-finetuned-cola,0.81161284
7,dapang/distilroberta-base-mic-sym,0.8814125
8,dapang/distilroberta-base-mic-sym,0.8823035
9,PrasunMishra/finetuning-sentiment-model-3000-samples,0.79578376
10,PrasunMishra/finetuning-sentiment-model-3000-samples,0.82558733
11,nurkayevaa/autonlp-bert-covid-407910458,0.84201163
12,nurkayevaa/autonlp-bert-covid-407910458,0.84201163
13,SetFit/distilbert-base-uncased__sst2__train-16-0,0.82491505
14,SetFit/distilbert-base-uncased__sst2__train-16-0,0.8328244
15,abdelkader/distilbert-base-uncased-finetuned-emotion,0.7954118
16,abdelkader/distilbert-base-uncased-finetuned-emotion,0.8287562
17,SetFit/distilbert-base-uncased__hate_speech_offensive__train-16-1,0.8559243
18,SetFit/distilbert-base-uncased__hate_speech_offensive__train-16-1,0.8529596
19,gchhablani/fnet-base-finetuned-sst2,0.73120886
20,gchhablani/fnet-base-finetuned-sst2,0.7399167
21,Capreolus/bert-base-msmarco,0.8686811
22,Capreolus/bert-base-msmarco,0.87146825
23,Splend1dchan/bert-base-uncased-slue-goldtrascription-e3-lr1e-4,0.9034866
24,Splend1dchan/bert-base-uncased-slue-goldtrascription-e3-lr1e-4,0.8863046
25,crcb/isear_bert,0.93581265
26,crcb/isear_bert,1.0168192
27,connectivity/cola_6ep_ft-33,0.8994686
28,connectivity/cola_6ep_ft-33,0.893881
29,Jeevesh8/init_bert_ft_qqp-49,0.89468664
30,Jeevesh8/init_bert_ft_qqp-49,0.89468664
31,Jeevesh8/feather_berts_46,0.8863046
32,Jeevesh8/feather_berts_46,0.88613695
33,yukta10/finetuning-sentiment-model-3000-samples,0.8233621
34,yukta10/finetuning-sentiment-model-3000-samples,0.82558733
35,connectivity/cola_6ep_ft-22,0.893881
36,connectivity/cola_6ep_ft-22,0.89371336
37,JonatanGk/roberta-base-bne-finetuned-cyberbullying-spanish,0.5567397
38,cambridgeltl/guardian_news_distilbert-base-uncased,0.7959467
39,gchhablani/fnet-base-finetuned-cola,0.703785
40,ncduy/roberta-imdb-sentiment-analysis,1.0042472
41,isakbos/Q8BERT_COLA_L_512,0.74657667
42,connectivity/bert_ft_qqp-7,0.89468664
43,moghis/distilbert-base-uncased-finetuned-emotion,0.82865846
44,uygarkurt/distilbert-base-uncased-finetuned-emotion,0.82000124
45,amyma21/sincere_question_classification,0.80953836
46,phailyoor/distilbert-base-uncased-finetuned-yahd,0.7427641
47,arianpasquali/distilbert-base-multilingual-cased-toxicity,0.70385516
48,neibla/distilbert-base-uncased-finetuned-emotion,0.82865846
49,robertou2/roberta-base-bne-finetuned-amazon_reviews_multi,0.79836285
50,Anthos23/FS-distilroberta-fine-tuned,0.9001079
51,pietrotrope/emotion_final,0.80996346
52,aviator-neural/bert-base-uncased-sst2,0.8756613
53,Jeevesh8/bert_ft_qqp-40,0.894519
54,jaesun/distilbert-base-uncased-finetuned-cola,0.8028137
55,SetFit/distilbert-base-uncased__sst2__train-32-9,0.8464906
56,usami/distilbert-base-uncased-finetuned-cola,0.8193272
57,connectivity/feather_berts_28,0.88613695
58,Jeevesh8/512seq_len_6ep_bert_ft_cola-91,0.893881
59,Jeevesh8/bert_ft_qqp-9,0.89468664
60,Jeevesh8/bert_ft_qqp-88,0.89468664
61,Recognai/bert-base-spanish-wwm-cased-xnli,0.73202676
62,markt23917/finetuning-sentiment-model-3000-samples,0.8407567
63,JNK789/distilbert-base-uncased-finetuned-tweets-emoji-dataset,0.059916265
64,anirudh21/bert-base-uncased-finetuned-qnli,0.90635705
65,Jeevesh8/6ep_bert_ft_cola-47,0.89371336
66,oferweintraub/bert-base-finance-sentiment-noisy-search,0.89023995
67,aXhyra/demo_sentiment_31415,0.8420388
68,milyiyo/selectra-small-finetuned-amazon-review,0.5512378
69,aXhyra/presentation_sentiment_1234567,0.8400111
70,Alireza1044/albert-base-v2-qnli,0.8837656
71,liangyuant/distilbert-base-uncased-finetuned-num200-450-405cls,0.82067025
72,DoyyingFace/bert-asian-hate-tweets-asian-unclean-freeze-4,0.87051207
73,connectivity/cola_6ep_ft-10,0.893881
74,Jeevesh8/lecun_feather_berts-3,0.8863046
75,jb2k/bert-base-multilingual-cased-language-detection,0.81144536
76,Giyaseddin/distilroberta-base-finetuned-short-answer-assessment,0.84925365
77,connectivity/bert_ft_qqp-25,0.89468664
78,Jeevesh8/6ep_bert_ft_cola-12,0.89371336
79,JB173/distilbert-base-uncased-finetuned-emotion,0.81969947
80,aXhyra/emotion_trained_31415,0.83675516
81,aXhyra/presentation_emotion_31415,0.84124905
82,AnonymousSub/dummy_2,0.8129629
83,Jeevesh8/bert_ft_qqp-55,0.89468664
84,Jeevesh8/lecun_feather_berts-51,0.88613695
85,viviastaari/finetuning-sentiment-analysis-en-id,0.6647427
86,vinai/bertweet-base,0.8997661
87,distilbert-base-uncased,0.83294684
88,bert-base-uncased,0.918658
89,roberta-base,0.9555091
90,Aureliano/distilbert-base-uncased-if,0.8180211
91,rmihaylov/roberta-base-sentiment-bg,0.80155957
92,cardiffnlp/twitter-roberta-base-2021-124m,0.8988705
93,Alassea/glue_sst_classifier,0.8767282
94,Nanatan/distilbert-base-uncased-finetuned-emotion,0.82839596
95,connectivity/bert_ft_qqp-1,0.89468664
96,juliensimon/autonlp-imdb-demo-hf-16622767,0.81764644
97,Jeevesh8/bert_ft_qqp-39,0.894519
98,Jeevesh8/lecun_feather_berts-8,0.8863046
99,connectivity/bert_ft_qqp-94,0.894519
100,korca/bae-roberta-base-boolq,0.9427543
101,Jeevesh8/bert_ft_cola-88,0.89371336
102,aditeyabaral/finetuned-sail2017-xlm-roberta-base,0.9433399
103,connectivity/bert_ft_qqp-96,0.894519
104,boychaboy/MNLI_roberta-base,1.0072658
105,fabriceyhc/bert-base-uncased-imdb,0.86942106
106,emrecan/bert-base-multilingual-cased-snli_tr,0.8574533
107,elozano/tweet_offensive_eval,0.83370245
108,joebobby/finetuning-sentiment-model-5000-samples3,0.91801906
109,YeRyeongLee/electra-base-discriminator-finetuned-filtered-0602,0.38614562
110,Jeevesh8/feather_berts_92,0.88613695
111,ASCCCCCCCC/distilbert-base-chinese-amazon_zh_20000,0.6795429
112,Jeevesh8/6ep_bert_ft_cola-29,0.89371336
113,albert-base-v2,0.8613905
114,bert-base-cased,0.90154314
115,Hate-speech-CNERG/bert-base-uncased-hatexplain-rationale-two,0.8937167
116,matthewburke/korean_sentiment,0.69785964
117,aychang/bert-base-cased-trec-coarse,0.8788318
118,IMSyPP/hate_speech_nl,0.6085579
119,cointegrated/roberta-base-formality,0.9427543
120,XSY/albert-base-v2-imdb-calssification,0.8347143
121,philschmid/tiny-distilbert-classification,0.041133367
122,gchhablani/bert-base-cased-finetuned-wnli,0.8625526
123,moshew/bert-mini-sst2-distilled,0.891895
124,chiragasarpota/scotus-bert,0.669783
125,vesteinn/XLMR-ENIS-finetuned-cola,0.91061145
126,IMSyPP/hate_speech_it,0.74473464
127,Jeevesh8/init_bert_ft_qqp-24,0.89468664
128,nickmuchi/facebook-data2vec-finetuned-finance-classification,0.8749192
129,Jeevesh8/bert_ft_qqp-68,0.89468664
130,Jeevesh8/init_bert_ft_qqp-28,0.894519
131,connectivity/bert_ft_qqp-17,0.894519
132,dhimskyy/wiki-bert,0.65806437
133,justinqbui/bertweet-covid19-base-uncased-pretraining-covid-vaccine-tweets,0.9033175
134,18811449050/bert_finetuning_test,0.87146825
135,vinai/bertweet-covid19-base-cased,0.9033175
136,finiteautomata/betonews-tweetcontext,0.7484149
137,Jeevesh8/feather_berts_96,0.88613695
138,michiyasunaga/LinkBERT-base,0.8867282
139,navsad/navid_test_bert,0.85235953
140,vinai/bertweet-covid19-base-uncased,0.9033175
141,Jeevesh8/bert_ft_cola-60,0.8932181
142,Jeevesh8/lecun_feather_berts-7,0.88613695
143,w11wo/sundanese-bert-base-emotion-classifier,0.6819681
144,mrm8488/codebert-base-finetuned-detect-insecure-code,0.8852464
145,cardiffnlp/bertweet-base-stance-climate,0.90673393
146,socialmediaie/TRAC2020_IBEN_B_bert-base-multilingual-uncased,0.8246036
147,ishan/bert-base-uncased-mnli,0.906658
148,zenkri/autotrain-Arabic_Poetry_by_Subject-920730230,0.89192766
149,M47Labs/spanish_news_classification_headlines_untrained,0.76093733
150,bondi/bert-semaphore-prediction-w4,0.7475589
151,gchhablani/bert-base-cased-finetuned-rte,0.878783
152,classla/bcms-bertic-parlasent-bcs-ter,0.7865056
153,waboucay/camembert-base-finetuned-xnli_fr-finetuned-nli-rua_wl,0.7124052
154,ali2066/DistilBERTFINAL_ctxSentence_TRAIN_editorials_TEST_NULL_second_train_set_null_False,0.9203686
155,anvay/finetuning-cardiffnlp-sentiment-model,0.948105
156,JonatanGk/roberta-base-ca-finetuned-hate-speech-offensive-catalan,0.8209533
157,mrm8488/electricidad-base-finetuned-pawsx-es,0.7926321
158,Raychanan/COVID_RandomOver,0.07415726
159,Monsia/camembert-fr-covid-tweet-classification,0.80543107
160,manueltonneau/bert-twitter-en-is-hired,0.90528345
161,CAMeL-Lab/bert-base-arabic-camelbert-mix-did-nadi,0.6190126
162,kyleinincubated/autonlp-cat333-624217911,0.70990914
163,Guscode/DKbert-hatespeech-detection,0.70941067
164,CAMeL-Lab/bert-base-arabic-camelbert-da-sentiment,0.61666536
165,fgaim/tiroberta-geezswitch,0.6862119
166,ChrisUPM/BioBERT_Re_trained,0.83577245
167,nreimers/mmarco-mMiniLMv2-L6-H384-v1,0.7043119
168,strickvl/nlp-redaction-classifier,0.85342073
169,saattrupdan/job-listing-relevance-model,0.8914028
170,cross-encoder/quora-distilroberta-base,0.84962434
171,morenolq/SumTO_FNS2020,0.7735053
172,navteca/quora-roberta-base,0.9412161
173,cross-encoder/ms-marco-MiniLM-L-4-v2,0.81823367
174,cross-encoder/quora-roberta-base,0.9412161
