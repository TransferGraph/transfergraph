,model,score
0,Jeevesh8/init_bert_ft_qqp-33,0.7968065537406523
1,Jeevesh8/init_bert_ft_qqp-33,0.8021703037004191
2,Jeevesh8/init_bert_ft_qqp-33,0.7927625575513764
3,Jeevesh8/init_bert_ft_qqp-49,0.81822722902267
4,Jeevesh8/init_bert_ft_qqp-49,0.8118621860402123
5,connectivity/bert_ft_qqp-7,0.8370791896104589
6,connectivity/bert_ft_qqp-7,0.8274708608689528
7,Jeevesh8/bert_ft_qqp-40,0.8405038215379015
8,Jeevesh8/bert_ft_qqp-40,0.8359904167875603
9,Jeevesh8/bert_ft_qqp-9,0.8297227714756674
10,Jeevesh8/bert_ft_qqp-9,0.821151364366735
11,Jeevesh8/bert_ft_qqp-88,0.8045157326818281
12,Jeevesh8/bert_ft_qqp-88,0.800198068410533
13,connectivity/bert_ft_qqp-25,0.8485755757365043
14,connectivity/bert_ft_qqp-25,0.8454987155041742
15,Jeevesh8/bert_ft_qqp-55,0.8247681407854001
16,Jeevesh8/bert_ft_qqp-55,0.8216784207437828
17,connectivity/bert_ft_qqp-1,0.8143403589109237
18,connectivity/bert_ft_qqp-1,0.8112893564115781
19,Jeevesh8/bert_ft_qqp-39,0.8415459033523365
20,Jeevesh8/bert_ft_qqp-39,0.8380952622889823
21,connectivity/bert_ft_qqp-94,0.804591127389019
22,connectivity/bert_ft_qqp-94,0.799364045861295
23,connectivity/bert_ft_qqp-96,0.8423221469398927
24,connectivity/bert_ft_qqp-96,0.8340520980526707
25,Jeevesh8/init_bert_ft_qqp-24,0.8325075344059196
26,Jeevesh8/init_bert_ft_qqp-24,0.8315883201890004
27,Jeevesh8/bert_ft_qqp-68,0.8299725707051115
28,Jeevesh8/bert_ft_qqp-68,0.8265646537443403
29,Jeevesh8/init_bert_ft_qqp-28,0.8192898867377192
30,Jeevesh8/init_bert_ft_qqp-28,0.8153779041559336
31,Jeevesh8/init_bert_ft_qqp-28,0.8153594114788467
32,connectivity/bert_ft_qqp-17,0.8069099854118065
33,connectivity/bert_ft_qqp-17,0.8017411374819865
34,ali2066/finetuned_sentence_itr1_2e-05_all_26_02_2022-04_03_26,0.8891890326740495
35,ali2066/finetuned_sentence_itr1_2e-05_all_26_02_2022-04_03_26,0.8884192414677863
36,SetFit/distilbert-base-uncased__sst2__train-16-0,0.9136854611792837
37,SetFit/distilbert-base-uncased__sst2__train-16-0,0.9117555449078063
38,aviator-neural/bert-base-uncased-sst2,0.810161272219315
39,aviator-neural/bert-base-uncased-sst2,0.8071143574980896
40,SetFit/distilbert-base-uncased__sst2__train-32-9,0.9242209284324547
41,SetFit/distilbert-base-uncased__sst2__train-32-9,0.9223016018921624
42,Alassea/glue_sst_classifier,0.8462988146548441
43,Alassea/glue_sst_classifier,0.8424406621826822
44,philschmid/tiny-distilbert-classification,0.6834716503070201
45,philschmid/tiny-distilbert-classification,0.6827477681388239
46,moshew/bert-mini-sst2-distilled,0.7697504417017981
47,moshew/bert-mini-sst2-distilled,0.7688727313191375
48,ChrisUPM/BioBERT_Re_trained,0.802091777014635
49,ChrisUPM/BioBERT_Re_trained,0.7927483375797615
50,vaariis/distilbert-base-uncased-finetuned-emotion,0.8913964823838328
51,vaariis/distilbert-base-uncased-finetuned-emotion,0.8892488928150796
52,marcelcastrobr/sagemaker-distilbert-emotion,0.8864940709023319
53,marcelcastrobr/sagemaker-distilbert-emotion,0.8835368053877674
54,jasonyim2/distilbert-base-uncased-finetuned-emotion,0.8805623016136133
55,jasonyim2/distilbert-base-uncased-finetuned-emotion,0.8773802533974208
56,abdelkader/distilbert-base-uncased-finetuned-emotion,0.8812517950946931
57,abdelkader/distilbert-base-uncased-finetuned-emotion,0.8793279714632541
58,moghis/distilbert-base-uncased-finetuned-emotion,0.8799898403989035
59,moghis/distilbert-base-uncased-finetuned-emotion,0.8780549830620178
60,uygarkurt/distilbert-base-uncased-finetuned-emotion,0.9128524959842377
61,uygarkurt/distilbert-base-uncased-finetuned-emotion,0.9107188660312491
62,neibla/distilbert-base-uncased-finetuned-emotion,0.9102404064679028
63,neibla/distilbert-base-uncased-finetuned-emotion,0.908188757425219
64,JB173/distilbert-base-uncased-finetuned-emotion,0.8871210743868249
65,JB173/distilbert-base-uncased-finetuned-emotion,0.8839845987157043
66,Nanatan/distilbert-base-uncased-finetuned-emotion,0.8916118931814635
67,Nanatan/distilbert-base-uncased-finetuned-emotion,0.8887002337169241
68,heranm/finetuning-sentiment-model-3000-samples,0.9016168886746306
69,heranm/finetuning-sentiment-model-3000-samples,0.8990424250898004
70,PrasunMishra/finetuning-sentiment-model-3000-samples,0.9074430528654269
71,PrasunMishra/finetuning-sentiment-model-3000-samples,0.9043961920238905
72,yukta10/finetuning-sentiment-model-3000-samples,0.8878310544465245
73,yukta10/finetuning-sentiment-model-3000-samples,0.8854558507604643
74,ncduy/roberta-imdb-sentiment-analysis,0.9200009245115512
75,ncduy/roberta-imdb-sentiment-analysis,0.9137729248713913
76,markt23917/finetuning-sentiment-model-3000-samples,0.8940089087364937
77,markt23917/finetuning-sentiment-model-3000-samples,0.891044808810006
78,juliensimon/autonlp-imdb-demo-hf-16622767,0.8922909418589162
79,juliensimon/autonlp-imdb-demo-hf-16622767,0.8899833985065797
80,fabriceyhc/bert-base-uncased-imdb,0.811201235093298
81,fabriceyhc/bert-base-uncased-imdb,0.8102675988236377
82,riyadhctg/distilbert-base-uncased-finetuned-cola,0.8983625750130839
83,riyadhctg/distilbert-base-uncased-finetuned-cola,0.8960307852580068
84,connectivity/cola_6ep_ft-33,0.8262279703346171
85,connectivity/cola_6ep_ft-33,0.8213008849911143
86,connectivity/cola_6ep_ft-22,0.8212317993557652
87,connectivity/cola_6ep_ft-22,0.8180985523713973
88,isakbos/Q8BERT_COLA_L_512,0.6602427930190674
89,isakbos/Q8BERT_COLA_L_512,0.6511015180496879
90,jaesun/distilbert-base-uncased-finetuned-cola,0.8586887347598127
91,jaesun/distilbert-base-uncased-finetuned-cola,0.8567146284023448
92,usami/distilbert-base-uncased-finetuned-cola,0.8637622359515802
93,usami/distilbert-base-uncased-finetuned-cola,0.8614363918361475
94,Jeevesh8/512seq_len_6ep_bert_ft_cola-91,0.7921778373595483
95,Jeevesh8/512seq_len_6ep_bert_ft_cola-91,0.7892484174236565
96,Jeevesh8/6ep_bert_ft_cola-47,0.8132056006128346
97,Jeevesh8/6ep_bert_ft_cola-47,0.8092829766556517
98,connectivity/cola_6ep_ft-10,0.8376974416104044
99,connectivity/cola_6ep_ft-10,0.8319349731812853
100,Jeevesh8/6ep_bert_ft_cola-12,0.8213990732760772
101,Jeevesh8/6ep_bert_ft_cola-12,0.8170518432467113
102,Jeevesh8/bert_ft_cola-88,0.8413607846867757
103,Jeevesh8/bert_ft_cola-88,0.8326680798223625
104,Jeevesh8/6ep_bert_ft_cola-29,0.8154280964343789
105,Jeevesh8/6ep_bert_ft_cola-29,0.8063220649953972
106,vesteinn/XLMR-ENIS-finetuned-cola,0.9043812776987581
107,vesteinn/XLMR-ENIS-finetuned-cola,0.9000291247810297
108,navsad/navid_test_bert,0.8038119541103433
109,navsad/navid_test_bert,0.7998843700718361
110,Jeevesh8/bert_ft_cola-60,0.8197997119386788
111,Jeevesh8/bert_ft_cola-60,0.8137122519107292
112,dapang/distilroberta-base-mic-sym,0.9065344435007745
113,dapang/distilroberta-base-mic-sym,0.9036771445691576
114,Capreolus/bert-base-msmarco,0.8076302687952229
115,Capreolus/bert-base-msmarco,0.8037369932983438
116,Splend1dchan/bert-base-uncased-slue-goldtrascription-e3-lr1e-4,0.8432049013609038
117,Splend1dchan/bert-base-uncased-slue-goldtrascription-e3-lr1e-4,0.8395662295565887
118,Jeevesh8/feather_berts_46,0.8311727964887954
119,Jeevesh8/feather_berts_46,0.8281438874204524
120,JonatanGk/roberta-base-bne-finetuned-cyberbullying-spanish,0.8082258532479963
121,JonatanGk/roberta-base-bne-finetuned-cyberbullying-spanish,0.8035910361947445
122,cambridgeltl/guardian_news_distilbert-base-uncased,0.8696888458529607
123,cambridgeltl/guardian_news_distilbert-base-uncased,0.8665818121346722
124,amyma21/sincere_question_classification,0.8967059008596076
125,amyma21/sincere_question_classification,0.8941671938373972
126,phailyoor/distilbert-base-uncased-finetuned-yahd,0.8863994848875991
127,phailyoor/distilbert-base-uncased-finetuned-yahd,0.8844460167243423
128,arianpasquali/distilbert-base-multilingual-cased-toxicity,0.881672366483754
129,arianpasquali/distilbert-base-multilingual-cased-toxicity,0.8780939674075112
130,connectivity/feather_berts_28,0.8435407985324903
131,connectivity/feather_berts_28,0.8396115748567625
132,liangyuant/distilbert-base-uncased-finetuned-num200-450-405cls,0.9137421117412814
133,liangyuant/distilbert-base-uncased-finetuned-num200-450-405cls,0.9116517473827344
134,DoyyingFace/bert-asian-hate-tweets-asian-unclean-freeze-4,0.8393457784334868
135,DoyyingFace/bert-asian-hate-tweets-asian-unclean-freeze-4,0.8355197543533126
136,Jeevesh8/lecun_feather_berts-3,0.8522845786190559
137,Jeevesh8/lecun_feather_berts-3,0.8460247294079142
138,Giyaseddin/distilroberta-base-finetuned-short-answer-assessment,0.8893127332109545
139,Giyaseddin/distilroberta-base-finetuned-short-answer-assessment,0.8861401694872142
140,AnonymousSub/dummy_2,0.7816301375275942
141,AnonymousSub/dummy_2,0.7744196466286896
142,Jeevesh8/lecun_feather_berts-51,0.8447938649524045
143,Jeevesh8/lecun_feather_berts-51,0.8401204531448943
144,viviastaari/finetuning-sentiment-analysis-en-id,0.8243285320616187
145,viviastaari/finetuning-sentiment-analysis-en-id,0.8209944486757351
146,Aureliano/distilbert-base-uncased-if,0.8976940127904862
147,Aureliano/distilbert-base-uncased-if,0.8944774340976809
148,rmihaylov/roberta-base-sentiment-bg,0.8330538123513098
149,rmihaylov/roberta-base-sentiment-bg,0.8299405485406011
150,cardiffnlp/twitter-roberta-base-2021-124m,0.9288047160079991
151,cardiffnlp/twitter-roberta-base-2021-124m,0.9249773851182626
152,Jeevesh8/lecun_feather_berts-8,0.8361038153830287
153,Jeevesh8/lecun_feather_berts-8,0.8310389701156513
154,korca/bae-roberta-base-boolq,0.913310285687709
155,korca/bae-roberta-base-boolq,0.9099414851787265
156,aditeyabaral/finetuned-sail2017-xlm-roberta-base,0.9165461282213299
157,aditeyabaral/finetuned-sail2017-xlm-roberta-base,0.9077163181256029
158,joebobby/finetuning-sentiment-model-5000-samples3,0.8474421780921011
159,joebobby/finetuning-sentiment-model-5000-samples3,0.8439242007198282
160,Jeevesh8/feather_berts_92,0.837724660138798
161,Jeevesh8/feather_berts_92,0.8334311376033516
162,ASCCCCCCCC/distilbert-base-chinese-amazon_zh_20000,0.7779234885774557
163,ASCCCCCCCC/distilbert-base-chinese-amazon_zh_20000,0.7740346566260707
164,matthewburke/korean_sentiment,0.7844931725648084
165,matthewburke/korean_sentiment,0.7813446285189479
166,IMSyPP/hate_speech_nl,0.7272772748379784
167,IMSyPP/hate_speech_nl,0.7213585772705854
168,cointegrated/roberta-base-formality,0.9187713894703213
169,cointegrated/roberta-base-formality,0.9129827848061348
170,IMSyPP/hate_speech_it,0.7709927829953186
171,IMSyPP/hate_speech_it,0.7661132163726141
172,18811449050/bert_finetuning_test,0.797558579348076
173,18811449050/bert_finetuning_test,0.7892978817527156
174,finiteautomata/betonews-tweetcontext,0.7534794148198072
175,finiteautomata/betonews-tweetcontext,0.7485293734578835
176,Jeevesh8/feather_berts_96,0.8346313558617845
177,Jeevesh8/feather_berts_96,0.8262635820765859
178,Jeevesh8/lecun_feather_berts-7,0.8255129969872619
179,Jeevesh8/lecun_feather_berts-7,0.820377837291143
180,mrm8488/codebert-base-finetuned-detect-insecure-code,0.8772305895296726
181,mrm8488/codebert-base-finetuned-detect-insecure-code,0.8726209149866475
182,socialmediaie/TRAC2020_IBEN_B_bert-base-multilingual-uncased,0.7944697940139153
183,socialmediaie/TRAC2020_IBEN_B_bert-base-multilingual-uncased,0.7899595667127028
184,zenkri/autotrain-Arabic_Poetry_by_Subject-920730230,0.8002448189575284
185,zenkri/autotrain-Arabic_Poetry_by_Subject-920730230,0.7944524419109943
186,M47Labs/spanish_news_classification_headlines_untrained,0.755380774164179
187,M47Labs/spanish_news_classification_headlines_untrained,0.7489955754515827
188,bondi/bert-semaphore-prediction-w4,0.7308263614142316
189,bondi/bert-semaphore-prediction-w4,0.7258130649405303
190,classla/bcms-bertic-parlasent-bcs-ter,0.8549219682244857
191,classla/bcms-bertic-parlasent-bcs-ter,0.8514007062694577
192,anferico/bert-for-patents,0.8050325495805887
193,anferico/bert-for-patents,0.7971643908878777
194,ali2066/DistilBERTFINAL_ctxSentence_TRAIN_editorials_TEST_NULL_second_train_set_null_False,0.9137597345397958
195,ali2066/DistilBERTFINAL_ctxSentence_TRAIN_editorials_TEST_NULL_second_train_set_null_False,0.9084898643496894
196,anvay/finetuning-cardiffnlp-sentiment-model,0.9270448480799289
197,anvay/finetuning-cardiffnlp-sentiment-model,0.921399805248196
198,JonatanGk/roberta-base-ca-finetuned-hate-speech-offensive-catalan,0.8110032096786775
199,JonatanGk/roberta-base-ca-finetuned-hate-speech-offensive-catalan,0.8048923905904064
200,Raychanan/COVID_RandomOver,0.6043103120671778
201,Raychanan/COVID_RandomOver,0.5982675678039844
202,kyleinincubated/autonlp-cat333-624217911,0.7772641365684327
203,kyleinincubated/autonlp-cat333-624217911,0.7734117826478554
204,cardiffnlp/bertweet-base-stance-climate,0.9007903767561067
205,cardiffnlp/bertweet-base-stance-climate,0.8967422723051486
206,nurkayevaa/autonlp-bert-covid-407910458,0.9091878938819142
207,nurkayevaa/autonlp-bert-covid-407910458,0.9069073698945735
208,SetFit/distilbert-base-uncased__hate_speech_offensive__train-16-1,0.9139745481757997
209,SetFit/distilbert-base-uncased__hate_speech_offensive__train-16-1,0.9118268919583834
210,crcb/isear_bert,0.9180683634076592
211,crcb/isear_bert,0.9128313118913836
212,robertou2/roberta-base-bne-finetuned-amazon_reviews_multi,0.88152245437667
213,robertou2/roberta-base-bne-finetuned-amazon_reviews_multi,0.8758239472268159
214,milyiyo/selectra-small-finetuned-amazon-review,0.8070342169131656
215,milyiyo/selectra-small-finetuned-amazon-review,0.8054525173671813
216,Anthos23/FS-distilroberta-fine-tuned,0.9000164145444759
217,Anthos23/FS-distilroberta-fine-tuned,0.8975846854085373
218,oferweintraub/bert-base-finance-sentiment-noisy-search,0.8240586884415799
219,oferweintraub/bert-base-finance-sentiment-noisy-search,0.818513126652863
220,pietrotrope/emotion_final,0.879837502348708
221,pietrotrope/emotion_final,0.8772416666892138
222,aXhyra/emotion_trained_31415,0.9061174160623051
223,aXhyra/emotion_trained_31415,0.9009079586780921
224,aXhyra/presentation_emotion_31415,0.8777142825751092
225,aXhyra/presentation_emotion_31415,0.8747153665070269
226,Recognai/bert-base-spanish-wwm-cased-xnli,0.7815025489119699
227,Recognai/bert-base-spanish-wwm-cased-xnli,0.7775201177758259
228,anirudh21/bert-base-uncased-finetuned-qnli,0.8266173056100564
229,anirudh21/bert-base-uncased-finetuned-qnli,0.8224592240300851
230,aXhyra/demo_sentiment_31415,0.8933319015941659
231,aXhyra/demo_sentiment_31415,0.891371852439588
232,aXhyra/presentation_sentiment_1234567,0.9152515825374812
233,aXhyra/presentation_sentiment_1234567,0.9129191755095268
234,jb2k/bert-base-multilingual-cased-language-detection,0.7763660382242372
235,jb2k/bert-base-multilingual-cased-language-detection,0.7689686762272767
236,vinai/bertweet-base,0.89411836642915
237,vinai/bertweet-base,0.8895691128660962
238,justinqbui/bertweet-covid19-base-uncased-pretraining-covid-vaccine-tweets,0.9155245027311831
239,justinqbui/bertweet-covid19-base-uncased-pretraining-covid-vaccine-tweets,0.9115200642155542
240,vinai/bertweet-covid19-base-cased,0.877599224244146
241,vinai/bertweet-covid19-base-cased,0.8732553278042162
242,vinai/bertweet-covid19-base-uncased,0.9234298407865614
243,vinai/bertweet-covid19-base-uncased,0.917732553060115
244,distilbert-base-uncased,0.9211514150235436
245,distilbert-base-uncased,0.9184189877075788
246,bert-base-uncased,0.8120185957688364
247,bert-base-uncased,0.806812257153606
248,roberta-base,0.9225378803189352
249,roberta-base,0.9176830382281222
250,bert-base-cased,0.8451859146934663
251,bert-base-cased,0.8416345906333615
252,dhimskyy/wiki-bert,0.7194942817428561
253,dhimskyy/wiki-bert,0.7135474849403972
254,michiyasunaga/LinkBERT-base,0.8197536345611985
255,michiyasunaga/LinkBERT-base,0.814221771708011
256,bert-large-uncased,0.8112089006278653
257,bert-large-uncased,0.8020001887682027
258,roberta-large,0.9085755758952418
259,roberta-large,0.885597266189454
260,boychaboy/MNLI_roberta-base,0.9110102151500882
261,boychaboy/MNLI_roberta-base,0.9067372239110173
262,ishan/bert-base-uncased-mnli,0.8316421791797626
263,ishan/bert-base-uncased-mnli,0.8260070498284302
264,emrecan/bert-base-multilingual-cased-snli_tr,0.8011392776435106
265,emrecan/bert-base-multilingual-cased-snli_tr,0.7937957371059802
266,elozano/tweet_offensive_eval,0.8243022131086015
267,elozano/tweet_offensive_eval,0.8203847292801121
268,Hate-speech-CNERG/bert-base-uncased-hatexplain-rationale-two,0.8469724225452107
269,Hate-speech-CNERG/bert-base-uncased-hatexplain-rationale-two,0.8438305593208312
270,aychang/bert-base-cased-trec-coarse,0.8374767526479878
271,aychang/bert-base-cased-trec-coarse,0.833096932808395
272,gchhablani/bert-base-cased-finetuned-wnli,0.8463256219261035
273,gchhablani/bert-base-cased-finetuned-wnli,0.8415721106413266
274,w11wo/sundanese-bert-base-emotion-classifier,0.7275565793118908
275,w11wo/sundanese-bert-base-emotion-classifier,0.7231356850355981
276,gchhablani/bert-base-cased-finetuned-rte,0.8437334677747621
277,gchhablani/bert-base-cased-finetuned-rte,0.839894536526131
278,mrm8488/electricidad-base-finetuned-pawsx-es,0.8122220200423119
279,mrm8488/electricidad-base-finetuned-pawsx-es,0.8093739588617709
280,manueltonneau/bert-twitter-en-is-hired,0.8179369341044032
281,manueltonneau/bert-twitter-en-is-hired,0.8123952352900348
282,Guscode/DKbert-hatespeech-detection,0.727076075143435
283,Guscode/DKbert-hatespeech-detection,0.7217118874820445
