,model,score
0,Jeevesh8/init_bert_ft_qqp-33,0.90510005
1,Jeevesh8/init_bert_ft_qqp-33,0.8964523
2,Jeevesh8/init_bert_ft_qqp-33,0.8457303
3,ali2066/finetuned_sentence_itr1_2e-05_all_26_02_2022-04_03_26,0.8717172
4,ali2066/finetuned_sentence_itr1_2e-05_all_26_02_2022-04_03_26,0.87789184
5,vaariis/distilbert-base-uncased-finetuned-emotion,0.8514851
6,vaariis/distilbert-base-uncased-finetuned-emotion,0.84684217
7,heranm/finetuning-sentiment-model-3000-samples,0.866053
8,heranm/finetuning-sentiment-model-3000-samples,0.8433802
9,marcelcastrobr/sagemaker-distilbert-emotion,0.8570211
10,marcelcastrobr/sagemaker-distilbert-emotion,0.8508342
11,jasonyim2/distilbert-base-uncased-finetuned-emotion,0.860051
12,jasonyim2/distilbert-base-uncased-finetuned-emotion,0.84888834
13,riyadhctg/distilbert-base-uncased-finetuned-cola,0.8465734
14,riyadhctg/distilbert-base-uncased-finetuned-cola,0.8362831
15,dapang/distilroberta-base-mic-sym,0.87538177
16,dapang/distilroberta-base-mic-sym,0.8665051
17,PrasunMishra/finetuning-sentiment-model-3000-samples,0.872424
18,PrasunMishra/finetuning-sentiment-model-3000-samples,0.85795957
19,nurkayevaa/autonlp-bert-covid-407910458,0.8572171
20,nurkayevaa/autonlp-bert-covid-407910458,0.86603135
21,SetFit/distilbert-base-uncased__sst2__train-16-0,0.8776954
22,SetFit/distilbert-base-uncased__sst2__train-16-0,0.8590799
23,abdelkader/distilbert-base-uncased-finetuned-emotion,0.8782358
24,abdelkader/distilbert-base-uncased-finetuned-emotion,0.86018705
25,SetFit/distilbert-base-uncased__hate_speech_offensive__train-16-1,0.8705829
26,SetFit/distilbert-base-uncased__hate_speech_offensive__train-16-1,0.84677947
27,Capreolus/bert-base-msmarco,0.90859187
28,Capreolus/bert-base-msmarco,0.8630233
29,Splend1dchan/bert-base-uncased-slue-goldtrascription-e3-lr1e-4,0.9133789
30,Splend1dchan/bert-base-uncased-slue-goldtrascription-e3-lr1e-4,0.8624054
31,crcb/isear_bert,0.9121358
32,crcb/isear_bert,0.86502975
33,connectivity/cola_6ep_ft-33,0.91477174
34,connectivity/cola_6ep_ft-33,0.8693109
35,Jeevesh8/init_bert_ft_qqp-49,0.9099197
36,Jeevesh8/init_bert_ft_qqp-49,0.8654694
37,Jeevesh8/feather_berts_46,0.923861
38,Jeevesh8/feather_berts_46,0.880763
39,yukta10/finetuning-sentiment-model-3000-samples,0.85805017
40,yukta10/finetuning-sentiment-model-3000-samples,0.84634966
41,connectivity/cola_6ep_ft-22,0.92643327
42,connectivity/cola_6ep_ft-22,0.8724868
43,JonatanGk/roberta-base-bne-finetuned-cyberbullying-spanish,0.8266713
44,JonatanGk/roberta-base-bne-finetuned-cyberbullying-spanish,0.724716
45,cambridgeltl/guardian_news_distilbert-base-uncased,0.86298186
46,cambridgeltl/guardian_news_distilbert-base-uncased,0.84080344
47,ncduy/roberta-imdb-sentiment-analysis,0.92104995
48,ncduy/roberta-imdb-sentiment-analysis,0.86297286
49,isakbos/Q8BERT_COLA_L_512,0.82963914
50,isakbos/Q8BERT_COLA_L_512,0.7466642
51,connectivity/bert_ft_qqp-7,0.8801188
52,connectivity/bert_ft_qqp-7,0.82699656
53,moghis/distilbert-base-uncased-finetuned-emotion,0.85587424
54,moghis/distilbert-base-uncased-finetuned-emotion,0.84098935
55,uygarkurt/distilbert-base-uncased-finetuned-emotion,0.8717629
56,uygarkurt/distilbert-base-uncased-finetuned-emotion,0.8665189
57,amyma21/sincere_question_classification,0.86459476
58,amyma21/sincere_question_classification,0.85156935
59,phailyoor/distilbert-base-uncased-finetuned-yahd,0.8602446
60,phailyoor/distilbert-base-uncased-finetuned-yahd,0.8407299
61,arianpasquali/distilbert-base-multilingual-cased-toxicity,0.8334231
62,arianpasquali/distilbert-base-multilingual-cased-toxicity,0.8155184
63,neibla/distilbert-base-uncased-finetuned-emotion,0.86620015
64,neibla/distilbert-base-uncased-finetuned-emotion,0.854535
65,robertou2/roberta-base-bne-finetuned-amazon_reviews_multi,0.8926615
66,robertou2/roberta-base-bne-finetuned-amazon_reviews_multi,0.7925844
67,Anthos23/FS-distilroberta-fine-tuned,0.86255205
68,Anthos23/FS-distilroberta-fine-tuned,0.85249853
69,pietrotrope/emotion_final,0.89173055
70,pietrotrope/emotion_final,0.87248355
71,aviator-neural/bert-base-uncased-sst2,0.9062268
72,aviator-neural/bert-base-uncased-sst2,0.84990925
73,Jeevesh8/bert_ft_qqp-40,0.9070151
74,Jeevesh8/bert_ft_qqp-40,0.8404838
75,jaesun/distilbert-base-uncased-finetuned-cola,0.8549338
76,jaesun/distilbert-base-uncased-finetuned-cola,0.83837
77,SetFit/distilbert-base-uncased__sst2__train-32-9,0.8617021
78,SetFit/distilbert-base-uncased__sst2__train-32-9,0.849926
79,usami/distilbert-base-uncased-finetuned-cola,0.8176562
80,usami/distilbert-base-uncased-finetuned-cola,0.8185008
81,connectivity/feather_berts_28,0.9283315
82,connectivity/feather_berts_28,0.873487
83,Jeevesh8/512seq_len_6ep_bert_ft_cola-91,0.9158052
84,Jeevesh8/512seq_len_6ep_bert_ft_cola-91,0.8549424
85,Jeevesh8/bert_ft_qqp-9,0.9143775
86,Jeevesh8/bert_ft_qqp-9,0.88556063
87,Jeevesh8/bert_ft_qqp-88,0.93580353
88,Jeevesh8/bert_ft_qqp-88,0.8842278
89,Recognai/bert-base-spanish-wwm-cased-xnli,0.8734654
90,Recognai/bert-base-spanish-wwm-cased-xnli,0.7572369
91,markt23917/finetuning-sentiment-model-3000-samples,0.86560094
92,markt23917/finetuning-sentiment-model-3000-samples,0.85091037
93,anirudh21/bert-base-uncased-finetuned-qnli,0.9194658
94,anirudh21/bert-base-uncased-finetuned-qnli,0.86518663
95,Jeevesh8/6ep_bert_ft_cola-47,0.91215163
96,Jeevesh8/6ep_bert_ft_cola-47,0.86558574
97,oferweintraub/bert-base-finance-sentiment-noisy-search,0.9183197
98,oferweintraub/bert-base-finance-sentiment-noisy-search,0.87495834
99,aXhyra/demo_sentiment_31415,0.8819733
100,aXhyra/demo_sentiment_31415,0.8721659
101,milyiyo/selectra-small-finetuned-amazon-review,0.8040719
102,milyiyo/selectra-small-finetuned-amazon-review,0.78828275
103,aXhyra/presentation_sentiment_1234567,0.86800057
104,aXhyra/presentation_sentiment_1234567,0.86180663
105,liangyuant/distilbert-base-uncased-finetuned-num200-450-405cls,0.8542567
106,liangyuant/distilbert-base-uncased-finetuned-num200-450-405cls,0.8388763
107,DoyyingFace/bert-asian-hate-tweets-asian-unclean-freeze-4,0.91292465
108,DoyyingFace/bert-asian-hate-tweets-asian-unclean-freeze-4,0.8699067
109,connectivity/cola_6ep_ft-10,0.9163209
110,connectivity/cola_6ep_ft-10,0.86282897
111,Jeevesh8/lecun_feather_berts-3,0.90873533
112,Jeevesh8/lecun_feather_berts-3,0.86633956
113,jb2k/bert-base-multilingual-cased-language-detection,0.8860768
114,jb2k/bert-base-multilingual-cased-language-detection,0.8054305
115,Giyaseddin/distilroberta-base-finetuned-short-answer-assessment,0.86098856
116,Giyaseddin/distilroberta-base-finetuned-short-answer-assessment,0.8487374
117,connectivity/bert_ft_qqp-25,0.92789924
118,connectivity/bert_ft_qqp-25,0.8755726
119,Jeevesh8/6ep_bert_ft_cola-12,0.9019944
120,Jeevesh8/6ep_bert_ft_cola-12,0.8516957
121,JB173/distilbert-base-uncased-finetuned-emotion,0.87072605
122,JB173/distilbert-base-uncased-finetuned-emotion,0.8513101
123,aXhyra/emotion_trained_31415,0.91606337
124,aXhyra/emotion_trained_31415,0.84700155
125,aXhyra/presentation_emotion_31415,0.86059296
126,aXhyra/presentation_emotion_31415,0.8447293
127,AnonymousSub/dummy_2,0.8645993
128,AnonymousSub/dummy_2,0.8127154
129,Jeevesh8/bert_ft_qqp-55,0.9290448
130,Jeevesh8/bert_ft_qqp-55,0.87406594
131,Jeevesh8/lecun_feather_berts-51,0.9111744
132,Jeevesh8/lecun_feather_berts-51,0.8633582
133,viviastaari/finetuning-sentiment-analysis-en-id,0.8177084
134,viviastaari/finetuning-sentiment-analysis-en-id,0.8112721
135,vinai/bertweet-base,0.94649404
136,vinai/bertweet-base,0.88985765
137,distilbert-base-uncased,0.88235885
138,distilbert-base-uncased,0.86363655
139,bert-base-uncased,0.9240019
140,bert-base-uncased,0.8860435
141,roberta-base,0.9440283
142,roberta-base,0.889336
143,Aureliano/distilbert-base-uncased-if,0.8446933
144,Aureliano/distilbert-base-uncased-if,0.816405
145,rmihaylov/roberta-base-sentiment-bg,0.8164781
146,rmihaylov/roberta-base-sentiment-bg,0.75524646
147,cardiffnlp/twitter-roberta-base-2021-124m,0.9388665
148,cardiffnlp/twitter-roberta-base-2021-124m,0.8770298
149,Alassea/glue_sst_classifier,0.9063902
150,Alassea/glue_sst_classifier,0.86601
151,Nanatan/distilbert-base-uncased-finetuned-emotion,0.8494633
152,Nanatan/distilbert-base-uncased-finetuned-emotion,0.83815444
153,connectivity/bert_ft_qqp-1,0.91715765
154,connectivity/bert_ft_qqp-1,0.8771259
155,juliensimon/autonlp-imdb-demo-hf-16622767,0.85357994
156,juliensimon/autonlp-imdb-demo-hf-16622767,0.8525416
157,Jeevesh8/bert_ft_qqp-39,0.9198381
158,Jeevesh8/bert_ft_qqp-39,0.86761487
159,Jeevesh8/lecun_feather_berts-8,0.92575693
160,Jeevesh8/lecun_feather_berts-8,0.8812734
161,connectivity/bert_ft_qqp-94,0.9339878
162,connectivity/bert_ft_qqp-94,0.8883327
163,korca/bae-roberta-base-boolq,0.90741855
164,korca/bae-roberta-base-boolq,0.8440351
165,Jeevesh8/bert_ft_cola-88,0.90452754
166,Jeevesh8/bert_ft_cola-88,0.8612396
167,aditeyabaral/finetuned-sail2017-xlm-roberta-base,0.8970574
168,aditeyabaral/finetuned-sail2017-xlm-roberta-base,0.824783
169,connectivity/bert_ft_qqp-96,0.90375024
170,connectivity/bert_ft_qqp-96,0.86847985
171,boychaboy/MNLI_roberta-base,0.93898666
172,boychaboy/MNLI_roberta-base,0.88280874
173,fabriceyhc/bert-base-uncased-imdb,0.92485845
174,fabriceyhc/bert-base-uncased-imdb,0.88013476
175,emrecan/bert-base-multilingual-cased-snli_tr,0.88388664
176,emrecan/bert-base-multilingual-cased-snli_tr,0.83769596
177,elozano/tweet_offensive_eval,0.87903404
178,elozano/tweet_offensive_eval,0.79967695
179,joebobby/finetuning-sentiment-model-5000-samples3,0.926426
180,joebobby/finetuning-sentiment-model-5000-samples3,0.87533885
181,Jeevesh8/feather_berts_92,0.9316066
182,Jeevesh8/feather_berts_92,0.8878231
183,ASCCCCCCCC/distilbert-base-chinese-amazon_zh_20000,0.8533373
184,ASCCCCCCCC/distilbert-base-chinese-amazon_zh_20000,0.78480285
185,Jeevesh8/6ep_bert_ft_cola-29,0.9130529
186,Jeevesh8/6ep_bert_ft_cola-29,0.8678185
187,bert-base-cased,0.9099309
188,bert-base-cased,0.87250304
189,Hate-speech-CNERG/bert-base-uncased-hatexplain-rationale-two,0.9211625
190,Hate-speech-CNERG/bert-base-uncased-hatexplain-rationale-two,0.8734297
191,matthewburke/korean_sentiment,0.8833973
192,matthewburke/korean_sentiment,0.8278592
193,aychang/bert-base-cased-trec-coarse,0.9342222
194,aychang/bert-base-cased-trec-coarse,0.87821823
195,IMSyPP/hate_speech_nl,0.82099247
196,IMSyPP/hate_speech_nl,0.7833231
197,cointegrated/roberta-base-formality,0.93801904
198,cointegrated/roberta-base-formality,0.88663113
199,philschmid/tiny-distilbert-classification,0.32220766
200,philschmid/tiny-distilbert-classification,0.32886955
201,gchhablani/bert-base-cased-finetuned-wnli,0.9138217
202,gchhablani/bert-base-cased-finetuned-wnli,0.8649547
203,moshew/bert-mini-sst2-distilled,0.8535464
204,moshew/bert-mini-sst2-distilled,0.84079146
205,vesteinn/XLMR-ENIS-finetuned-cola,0.89594114
206,vesteinn/XLMR-ENIS-finetuned-cola,0.8382265
207,IMSyPP/hate_speech_it,0.89214224
208,IMSyPP/hate_speech_it,0.8243561
209,Jeevesh8/init_bert_ft_qqp-24,0.9166029
210,Jeevesh8/init_bert_ft_qqp-24,0.87756765
211,Jeevesh8/bert_ft_qqp-68,0.89777493
212,Jeevesh8/bert_ft_qqp-68,0.85485405
213,Jeevesh8/init_bert_ft_qqp-28,0.91612905
214,Jeevesh8/init_bert_ft_qqp-28,0.8734522
215,Jeevesh8/init_bert_ft_qqp-28,0.8734522
216,connectivity/bert_ft_qqp-17,0.9186484
217,connectivity/bert_ft_qqp-17,0.86842984
218,dhimskyy/wiki-bert,0.85507154
219,dhimskyy/wiki-bert,0.7801274
220,18811449050/bert_finetuning_test,0.885222
221,18811449050/bert_finetuning_test,0.8518773
222,finiteautomata/betonews-tweetcontext,0.8623009
223,finiteautomata/betonews-tweetcontext,0.7581346
224,Jeevesh8/feather_berts_96,0.9105081
225,Jeevesh8/feather_berts_96,0.8707595
226,michiyasunaga/LinkBERT-base,0.8965304
227,michiyasunaga/LinkBERT-base,0.8568223
228,navsad/navid_test_bert,0.91213995
229,navsad/navid_test_bert,0.8442371
230,Jeevesh8/bert_ft_cola-60,0.91509986
231,Jeevesh8/bert_ft_cola-60,0.8709704
232,Jeevesh8/lecun_feather_berts-7,0.92231506
233,Jeevesh8/lecun_feather_berts-7,0.8649658
234,w11wo/sundanese-bert-base-emotion-classifier,0.8270218
235,w11wo/sundanese-bert-base-emotion-classifier,0.75943464
236,mrm8488/codebert-base-finetuned-detect-insecure-code,0.9113252
237,mrm8488/codebert-base-finetuned-detect-insecure-code,0.8345932
238,socialmediaie/TRAC2020_IBEN_B_bert-base-multilingual-uncased,0.9133963
239,socialmediaie/TRAC2020_IBEN_B_bert-base-multilingual-uncased,0.8535114
240,ishan/bert-base-uncased-mnli,0.9195833
241,ishan/bert-base-uncased-mnli,0.8750493
242,zenkri/autotrain-Arabic_Poetry_by_Subject-920730230,0.9147318
243,zenkri/autotrain-Arabic_Poetry_by_Subject-920730230,0.8572363
244,M47Labs/spanish_news_classification_headlines_untrained,0.89218074
245,M47Labs/spanish_news_classification_headlines_untrained,0.79053575
246,bondi/bert-semaphore-prediction-w4,0.8677093
247,bondi/bert-semaphore-prediction-w4,0.785007
248,gchhablani/bert-base-cased-finetuned-rte,0.9045825
249,gchhablani/bert-base-cased-finetuned-rte,0.8580164
250,classla/bcms-bertic-parlasent-bcs-ter,0.8750775
251,classla/bcms-bertic-parlasent-bcs-ter,0.7951978
252,anferico/bert-for-patents,0.88177997
253,anferico/bert-for-patents,0.88051665
254,ali2066/DistilBERTFINAL_ctxSentence_TRAIN_editorials_TEST_NULL_second_train_set_null_False,0.9396236
255,ali2066/DistilBERTFINAL_ctxSentence_TRAIN_editorials_TEST_NULL_second_train_set_null_False,0.8764626
256,anvay/finetuning-cardiffnlp-sentiment-model,0.9248458
257,anvay/finetuning-cardiffnlp-sentiment-model,0.85691565
258,JonatanGk/roberta-base-ca-finetuned-hate-speech-offensive-catalan,0.8559252
259,JonatanGk/roberta-base-ca-finetuned-hate-speech-offensive-catalan,0.77007073
260,mrm8488/electricidad-base-finetuned-pawsx-es,0.83664674
261,mrm8488/electricidad-base-finetuned-pawsx-es,0.7515155
262,Raychanan/COVID_RandomOver,0.47793803
263,Raychanan/COVID_RandomOver,0.4644803
264,manueltonneau/bert-twitter-en-is-hired,0.9199279
265,manueltonneau/bert-twitter-en-is-hired,0.8751785
266,kyleinincubated/autonlp-cat333-624217911,0.87783635
267,kyleinincubated/autonlp-cat333-624217911,0.78794163
268,Guscode/DKbert-hatespeech-detection,0.8176972
269,Guscode/DKbert-hatespeech-detection,0.75614387
270,bert-large-uncased,0.8936316
271,bert-large-uncased,0.8882031
272,ChrisUPM/BioBERT_Re_trained,0.8864933
273,ChrisUPM/BioBERT_Re_trained,0.8396128
274,roberta-large,0.91130686
275,roberta-large,0.8951201
276,justinqbui/bertweet-covid19-base-uncased-pretraining-covid-vaccine-tweets,0.94349295
277,justinqbui/bertweet-covid19-base-uncased-pretraining-covid-vaccine-tweets,0.87998974
278,vinai/bertweet-covid19-base-cased,0.7821354
279,vinai/bertweet-covid19-base-cased,0.8934107
280,vinai/bertweet-covid19-base-uncased,0.92052734
281,vinai/bertweet-covid19-base-uncased,0.85982835
282,cardiffnlp/bertweet-base-stance-climate,0.93404484
283,cardiffnlp/bertweet-base-stance-climate,0.88330555
