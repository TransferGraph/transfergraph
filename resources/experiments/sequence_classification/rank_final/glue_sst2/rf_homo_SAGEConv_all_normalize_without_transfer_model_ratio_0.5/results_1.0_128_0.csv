,model,score
0,Guscode/DKbert-hatespeech-detection,0.8816523810110765
1,milyiyo/selectra-small-finetuned-amazon-review,0.881315767126521
2,robertou2/roberta-base-bne-finetuned-amazon_reviews_multi,0.949816794011469
3,vinai/bertweet-covid19-base-cased,0.9360916099662064
4,vinai/bertweet-covid19-base-uncased,0.9777424374074887
5,neibla/distilbert-base-uncased-finetuned-emotion,0.9776317941876045
6,JB173/distilbert-base-uncased-finetuned-emotion,0.9799679967896382
7,Nanatan/distilbert-base-uncased-finetuned-emotion,0.9759797083387315
8,connectivity/cola_6ep_ft-22,0.9618367294956145
9,gchhablani/fnet-base-finetuned-cola,0.8896010973433925
10,jaesun/distilbert-base-uncased-finetuned-cola,0.9317759272547741
11,usami/distilbert-base-uncased-finetuned-cola,0.9771560343019123
12,vesteinn/XLMR-ENIS-finetuned-cola,0.9768709011640041
13,connectivity/cola_6ep_ft-10,0.9766750961532737
14,Jeevesh8/6ep_bert_ft_cola-29,0.9766750961532737
15,Jeevesh8/bert_ft_cola-60,0.9772877412971579
16,ishan/bert-base-uncased-mnli,0.9726090041366667
17,boychaboy/MNLI_roberta-base,0.9804941447226622
18,anirudh21/bert-base-uncased-finetuned-qnli,0.9771948160297756
19,Alireza1044/albert-base-v2-qnli,0.9750588223978671
20,Jeevesh8/init_bert_ft_qqp-33,0.9767610264666893
21,Jeevesh8/init_bert_ft_qqp-33,0.9767610264666893
22,Jeevesh8/init_bert_ft_qqp-49,0.951914239213812
23,connectivity/bert_ft_qqp-7,0.9769224969295037
24,Jeevesh8/bert_ft_qqp-88,0.9766750961532737
25,connectivity/bert_ft_qqp-25,0.9769495958148703
26,Jeevesh8/bert_ft_qqp-9,0.9642905757338172
27,Jeevesh8/bert_ft_qqp-68,0.979117692099235
28,Jeevesh8/init_bert_ft_qqp-28,0.9766750961532737
29,connectivity/bert_ft_qqp-94,0.9767299170741133
30,connectivity/bert_ft_qqp-96,0.9766750961532737
31,philschmid/tiny-distilbert-classification,0.2518212588912605
32,ali2066/finetuned_sentence_itr1_2e-05_all_26_02_2022-04_03_26,0.9763171332313505
33,SetFit/distilbert-base-uncased__sst2__train-16-0,0.9772108552227519
34,gchhablani/fnet-base-finetuned-sst2,0.9184579305676853
35,SetFit/distilbert-base-uncased__sst2__train-32-9,0.9757616029369656
36,gchhablani/bert-base-cased-finetuned-wnli,0.9769495958148703
37,heranm/finetuning-sentiment-model-3000-samples,0.9768955789625485
38,PrasunMishra/finetuning-sentiment-model-3000-samples,0.9792093671562776
39,yukta10/finetuning-sentiment-model-3000-samples,0.9795854344335824
40,juliensimon/autonlp-imdb-demo-hf-16622767,0.9714708489762728
41,fabriceyhc/bert-base-uncased-imdb,0.9757043474965552
42,oferweintraub/bert-base-finance-sentiment-noisy-search,0.9766750961532737
43,emrecan/bert-base-multilingual-cased-snli_tr,0.976824223112563
44,nurkayevaa/autonlp-bert-covid-407910458,0.9623176676442532
45,aychang/bert-base-cased-trec-coarse,0.9767610264666893
46,aXhyra/presentation_emotion_31415,0.9643431602595419
47,aXhyra/demo_sentiment_31415,0.9772377303399077
48,manueltonneau/bert-twitter-en-is-hired,0.9772985871026851
49,distilbert-base-uncased,0.9774775179403159
50,dhimskyy/wiki-bert,0.8830572908486944
51,bert-base-cased,0.9770304337330116
52,albert-base-v2,0.9559816310161903
53,bert-large-uncased,0.891212430695423
54,dapang/distilroberta-base-mic-sym,0.9775553421716107
55,Capreolus/bert-base-msmarco,0.9767544619256913
56,phailyoor/distilbert-base-uncased-finetuned-yahd,0.8877539382028974
57,arianpasquali/distilbert-base-multilingual-cased-toxicity,0.9519093457102763
58,JonatanGk/roberta-base-bne-finetuned-cyberbullying-spanish,0.8832372989677605
59,chiragasarpota/scotus-bert,0.8721541417253007
60,liangyuant/distilbert-base-uncased-finetuned-num200-450-405cls,0.9778818286836328
61,Jeevesh8/lecun_feather_berts-51,0.9768177068816374
62,Aureliano/distilbert-base-uncased-if,0.9774383511005443
63,finiteautomata/betonews-tweetcontext,0.875169450821709
64,cardiffnlp/twitter-roberta-base-2021-124m,0.9828027113601656
65,korca/bae-roberta-base-boolq,0.9771706538407845
66,Jeevesh8/lecun_feather_berts-7,0.9767838520019317
67,mrm8488/codebert-base-finetuned-detect-insecure-code,0.976990778224826
68,cardiffnlp/bertweet-base-stance-climate,0.9828027113601656
69,matthewburke/korean_sentiment,0.8833727507862831
70,aditeyabaral/finetuned-sail2017-xlm-roberta-base,0.9770973597477286
71,classla/bcms-bertic-parlasent-bcs-ter,0.934560280384407
72,waboucay/camembert-base-finetuned-xnli_fr-finetuned-nli-rua_wl,0.8543142966074135
73,YeRyeongLee/electra-base-discriminator-finetuned-filtered-0602,0.625281749720784
74,anvay/finetuning-cardiffnlp-sentiment-model,0.9808842974740134
75,kyleinincubated/autonlp-cat333-624217911,0.9605929366446453
76,CAMeL-Lab/bert-base-arabic-camelbert-da-sentiment,0.8870648564881586
77,fgaim/tiroberta-geezswitch,0.9399879353988445
