,model,score
0,Guscode/DKbert-hatespeech-detection,0.7282057456960159
1,milyiyo/selectra-small-finetuned-amazon-review,0.7880808649736308
2,robertou2/roberta-base-bne-finetuned-amazon_reviews_multi,0.7682678479231632
3,vinai/bertweet-covid19-base-cased,0.7879555467591831
4,vinai/bertweet-covid19-base-uncased,0.8380408831209614
5,neibla/distilbert-base-uncased-finetuned-emotion,0.8448357053347896
6,JB173/distilbert-base-uncased-finetuned-emotion,0.8408076094354092
7,Nanatan/distilbert-base-uncased-finetuned-emotion,0.8347185575213955
8,connectivity/cola_6ep_ft-22,0.8412904889142329
9,gchhablani/fnet-base-finetuned-cola,0.8076591079476014
10,jaesun/distilbert-base-uncased-finetuned-cola,0.8296826163499259
11,usami/distilbert-base-uncased-finetuned-cola,0.8374390292414078
12,vesteinn/XLMR-ENIS-finetuned-cola,0.8128294573849361
13,connectivity/cola_6ep_ft-10,0.8372507170253908
14,Jeevesh8/6ep_bert_ft_cola-29,0.8454197950329079
15,Jeevesh8/bert_ft_cola-60,0.8399458130912005
16,ishan/bert-base-uncased-mnli,0.8421652941157534
17,boychaboy/MNLI_roberta-base,0.8462798004089023
18,anirudh21/bert-base-uncased-finetuned-qnli,0.842992168991037
19,Alireza1044/albert-base-v2-qnli,0.8415272840813955
20,Jeevesh8/init_bert_ft_qqp-33,0.8323855168917662
21,Jeevesh8/init_bert_ft_qqp-33,0.833676111651998
22,Jeevesh8/init_bert_ft_qqp-49,0.8508144444154557
23,connectivity/bert_ft_qqp-7,0.8466604233083782
24,Jeevesh8/bert_ft_qqp-88,0.8429676425181312
25,connectivity/bert_ft_qqp-25,0.8491171040363639
26,Jeevesh8/bert_ft_qqp-9,0.8463619372164031
27,Jeevesh8/bert_ft_qqp-68,0.8476683134060322
28,Jeevesh8/init_bert_ft_qqp-28,0.847553422178828
29,connectivity/bert_ft_qqp-94,0.8373556559214567
30,connectivity/bert_ft_qqp-96,0.8438523675801144
31,philschmid/tiny-distilbert-classification,0.218604957044308
32,ali2066/finetuned_sentence_itr1_2e-05_all_26_02_2022-04_03_26,0.829179697247914
33,SetFit/distilbert-base-uncased__sst2__train-16-0,0.8339000926321962
34,gchhablani/fnet-base-finetuned-sst2,0.8145082668564195
35,SetFit/distilbert-base-uncased__sst2__train-32-9,0.8426714685925434
36,gchhablani/bert-base-cased-finetuned-wnli,0.8387680931631597
37,heranm/finetuning-sentiment-model-3000-samples,0.8356374032199018
38,PrasunMishra/finetuning-sentiment-model-3000-samples,0.8479640124478827
39,yukta10/finetuning-sentiment-model-3000-samples,0.8424845477961833
40,juliensimon/autonlp-imdb-demo-hf-16622767,0.8290392681847978
41,fabriceyhc/bert-base-uncased-imdb,0.8404935317412547
42,oferweintraub/bert-base-finance-sentiment-noisy-search,0.8390817490936111
43,emrecan/bert-base-multilingual-cased-snli_tr,0.8348609500046195
44,nurkayevaa/autonlp-bert-covid-407910458,0.8401457832688198
45,aychang/bert-base-cased-trec-coarse,0.8390136000957631
46,aXhyra/presentation_emotion_31415,0.8449358200026158
47,aXhyra/demo_sentiment_31415,0.8388946087713371
48,manueltonneau/bert-twitter-en-is-hired,0.8459118561541663
49,distilbert-base-uncased,0.8461473457358701
50,dhimskyy/wiki-bert,0.7759135323868307
51,bert-base-cased,0.8452794133209945
52,albert-base-v2,0.833200727799882
53,bert-large-uncased,0.8011911728426411
54,dapang/distilroberta-base-mic-sym,0.839104992760305
55,Capreolus/bert-base-msmarco,0.8454197427807191
56,phailyoor/distilbert-base-uncased-finetuned-yahd,0.8249328388812839
57,arianpasquali/distilbert-base-multilingual-cased-toxicity,0.8177713114104486
58,JonatanGk/roberta-base-bne-finetuned-cyberbullying-spanish,0.7415333629918466
59,chiragasarpota/scotus-bert,0.7480683084171215
60,liangyuant/distilbert-base-uncased-finetuned-num200-450-405cls,0.8393732036558877
61,Jeevesh8/lecun_feather_berts-51,0.8394663949195098
62,Aureliano/distilbert-base-uncased-if,0.8275074410072436
63,finiteautomata/betonews-tweetcontext,0.7646930901613733
64,cardiffnlp/twitter-roberta-base-2021-124m,0.8396480931954186
65,korca/bae-roberta-base-boolq,0.8415583843736723
66,Jeevesh8/lecun_feather_berts-7,0.825706897433744
67,mrm8488/codebert-base-finetuned-detect-insecure-code,0.826479932069671
68,cardiffnlp/bertweet-base-stance-climate,0.8305301232075322
69,matthewburke/korean_sentiment,0.7810415090511057
70,aditeyabaral/finetuned-sail2017-xlm-roberta-base,0.8337437417081354
71,classla/bcms-bertic-parlasent-bcs-ter,0.8013285187725959
72,waboucay/camembert-base-finetuned-xnli_fr-finetuned-nli-rua_wl,0.6920790669554593
73,YeRyeongLee/electra-base-discriminator-finetuned-filtered-0602,0.38355309135223037
74,anvay/finetuning-cardiffnlp-sentiment-model,0.8278347350703338
75,kyleinincubated/autonlp-cat333-624217911,0.8223749138689146
76,CAMeL-Lab/bert-base-arabic-camelbert-da-sentiment,0.718892427741019
77,fgaim/tiroberta-geezswitch,0.7769473484492759
