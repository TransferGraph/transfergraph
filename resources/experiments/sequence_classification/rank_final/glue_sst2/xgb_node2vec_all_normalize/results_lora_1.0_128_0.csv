,model,score
0,Jeevesh8/init_bert_ft_qqp-33,0.7334228
1,Jeevesh8/init_bert_ft_qqp-33,0.72902083
2,Jeevesh8/init_bert_ft_qqp-33,0.71714973
3,Jeevesh8/init_bert_ft_qqp-49,0.745148
4,Jeevesh8/init_bert_ft_qqp-49,0.74357074
5,connectivity/bert_ft_qqp-7,0.726672
6,connectivity/bert_ft_qqp-7,0.718365
7,Jeevesh8/bert_ft_qqp-40,0.7555486
8,Jeevesh8/bert_ft_qqp-40,0.7442862
9,Jeevesh8/bert_ft_qqp-9,0.7450992
10,Jeevesh8/bert_ft_qqp-9,0.7476478
11,Jeevesh8/bert_ft_qqp-88,0.7450162
12,Jeevesh8/bert_ft_qqp-88,0.7355517
13,connectivity/bert_ft_qqp-25,0.73459566
14,connectivity/bert_ft_qqp-25,0.7275509
15,Jeevesh8/bert_ft_qqp-55,0.7376464
16,Jeevesh8/bert_ft_qqp-55,0.7327174
17,connectivity/bert_ft_qqp-1,0.74616724
18,connectivity/bert_ft_qqp-1,0.743446
19,Jeevesh8/bert_ft_qqp-39,0.7315895
20,Jeevesh8/bert_ft_qqp-39,0.7327567
21,connectivity/bert_ft_qqp-94,0.7509629
22,connectivity/bert_ft_qqp-94,0.74802756
23,connectivity/bert_ft_qqp-96,0.72595316
24,connectivity/bert_ft_qqp-96,0.72897357
25,Jeevesh8/init_bert_ft_qqp-24,0.72600996
26,Jeevesh8/init_bert_ft_qqp-24,0.72331506
27,Jeevesh8/bert_ft_qqp-68,0.731571
28,Jeevesh8/bert_ft_qqp-68,0.71911216
29,Jeevesh8/init_bert_ft_qqp-28,0.7456742
30,Jeevesh8/init_bert_ft_qqp-28,0.7280344
31,Jeevesh8/init_bert_ft_qqp-28,0.7280344
32,connectivity/bert_ft_qqp-17,0.750331
33,connectivity/bert_ft_qqp-17,0.7327997
34,ali2066/finetuned_sentence_itr1_2e-05_all_26_02_2022-04_03_26,0.7555211
35,ali2066/finetuned_sentence_itr1_2e-05_all_26_02_2022-04_03_26,0.75908744
36,SetFit/distilbert-base-uncased__sst2__train-16-0,0.75269264
37,SetFit/distilbert-base-uncased__sst2__train-16-0,0.7434687
38,aviator-neural/bert-base-uncased-sst2,0.7733484
39,aviator-neural/bert-base-uncased-sst2,0.76305145
40,SetFit/distilbert-base-uncased__sst2__train-32-9,0.76238114
41,SetFit/distilbert-base-uncased__sst2__train-32-9,0.75050443
42,Alassea/glue_sst_classifier,0.7468617
43,Alassea/glue_sst_classifier,0.74413323
44,philschmid/tiny-distilbert-classification,0.48032844
45,philschmid/tiny-distilbert-classification,0.49035853
46,moshew/bert-mini-sst2-distilled,0.7266021
47,moshew/bert-mini-sst2-distilled,0.71189076
48,ChrisUPM/BioBERT_Re_trained,0.7258532
49,ChrisUPM/BioBERT_Re_trained,0.7175491
50,vaariis/distilbert-base-uncased-finetuned-emotion,0.73053855
51,vaariis/distilbert-base-uncased-finetuned-emotion,0.7325894
52,marcelcastrobr/sagemaker-distilbert-emotion,0.7505327
53,marcelcastrobr/sagemaker-distilbert-emotion,0.7319973
54,jasonyim2/distilbert-base-uncased-finetuned-emotion,0.7468053
55,jasonyim2/distilbert-base-uncased-finetuned-emotion,0.738715
56,abdelkader/distilbert-base-uncased-finetuned-emotion,0.73813254
57,abdelkader/distilbert-base-uncased-finetuned-emotion,0.72244346
58,moghis/distilbert-base-uncased-finetuned-emotion,0.74646163
59,moghis/distilbert-base-uncased-finetuned-emotion,0.74067384
60,uygarkurt/distilbert-base-uncased-finetuned-emotion,0.73381895
61,uygarkurt/distilbert-base-uncased-finetuned-emotion,0.7301541
62,neibla/distilbert-base-uncased-finetuned-emotion,0.7367368
63,neibla/distilbert-base-uncased-finetuned-emotion,0.7338907
64,JB173/distilbert-base-uncased-finetuned-emotion,0.7434459
65,JB173/distilbert-base-uncased-finetuned-emotion,0.7383561
66,Nanatan/distilbert-base-uncased-finetuned-emotion,0.73712367
67,Nanatan/distilbert-base-uncased-finetuned-emotion,0.74229074
68,heranm/finetuning-sentiment-model-3000-samples,0.7484516
69,heranm/finetuning-sentiment-model-3000-samples,0.7403093
70,PrasunMishra/finetuning-sentiment-model-3000-samples,0.757401
71,PrasunMishra/finetuning-sentiment-model-3000-samples,0.7442552
72,yukta10/finetuning-sentiment-model-3000-samples,0.75642186
73,yukta10/finetuning-sentiment-model-3000-samples,0.7347644
74,ncduy/roberta-imdb-sentiment-analysis,0.7532242
75,ncduy/roberta-imdb-sentiment-analysis,0.7417279
76,markt23917/finetuning-sentiment-model-3000-samples,0.74212986
77,markt23917/finetuning-sentiment-model-3000-samples,0.74006474
78,juliensimon/autonlp-imdb-demo-hf-16622767,0.7409141
79,juliensimon/autonlp-imdb-demo-hf-16622767,0.73080075
80,fabriceyhc/bert-base-uncased-imdb,0.7222794
81,fabriceyhc/bert-base-uncased-imdb,0.7175721
82,riyadhctg/distilbert-base-uncased-finetuned-cola,0.7222744
83,riyadhctg/distilbert-base-uncased-finetuned-cola,0.71125144
84,connectivity/cola_6ep_ft-33,0.7509703
85,connectivity/cola_6ep_ft-33,0.74664116
86,connectivity/cola_6ep_ft-22,0.73355377
87,connectivity/cola_6ep_ft-22,0.72760487
88,isakbos/Q8BERT_COLA_L_512,0.6517191
89,isakbos/Q8BERT_COLA_L_512,0.62718135
90,jaesun/distilbert-base-uncased-finetuned-cola,0.72943795
91,jaesun/distilbert-base-uncased-finetuned-cola,0.7074556
92,usami/distilbert-base-uncased-finetuned-cola,0.7463902
93,usami/distilbert-base-uncased-finetuned-cola,0.72170144
94,Jeevesh8/512seq_len_6ep_bert_ft_cola-91,0.7151714
95,Jeevesh8/512seq_len_6ep_bert_ft_cola-91,0.7142504
96,Jeevesh8/6ep_bert_ft_cola-47,0.7219361
97,Jeevesh8/6ep_bert_ft_cola-47,0.7186683
98,connectivity/cola_6ep_ft-10,0.7415214
99,connectivity/cola_6ep_ft-10,0.7239516
100,Jeevesh8/6ep_bert_ft_cola-12,0.71739894
101,Jeevesh8/6ep_bert_ft_cola-12,0.702943
102,Jeevesh8/bert_ft_cola-88,0.71587074
103,Jeevesh8/bert_ft_cola-88,0.7191563
104,Jeevesh8/6ep_bert_ft_cola-29,0.7180783
105,Jeevesh8/6ep_bert_ft_cola-29,0.7192771
106,vesteinn/XLMR-ENIS-finetuned-cola,0.74366313
107,vesteinn/XLMR-ENIS-finetuned-cola,0.7332508
108,navsad/navid_test_bert,0.723567
109,navsad/navid_test_bert,0.7096375
110,Jeevesh8/bert_ft_cola-60,0.736178
111,Jeevesh8/bert_ft_cola-60,0.7207522
112,dapang/distilroberta-base-mic-sym,0.76250595
113,dapang/distilroberta-base-mic-sym,0.76194733
114,Capreolus/bert-base-msmarco,0.7408988
115,Capreolus/bert-base-msmarco,0.73274016
116,Splend1dchan/bert-base-uncased-slue-goldtrascription-e3-lr1e-4,0.7433573
117,Splend1dchan/bert-base-uncased-slue-goldtrascription-e3-lr1e-4,0.7446034
118,Jeevesh8/feather_berts_46,0.7565803
119,Jeevesh8/feather_berts_46,0.7551334
120,JonatanGk/roberta-base-bne-finetuned-cyberbullying-spanish,0.6471157
121,JonatanGk/roberta-base-bne-finetuned-cyberbullying-spanish,0.63536906
122,cambridgeltl/guardian_news_distilbert-base-uncased,0.7367894
123,cambridgeltl/guardian_news_distilbert-base-uncased,0.7393108
124,amyma21/sincere_question_classification,0.73519427
125,amyma21/sincere_question_classification,0.7426218
126,phailyoor/distilbert-base-uncased-finetuned-yahd,0.7428411
127,phailyoor/distilbert-base-uncased-finetuned-yahd,0.7248672
128,arianpasquali/distilbert-base-multilingual-cased-toxicity,0.7097081
129,arianpasquali/distilbert-base-multilingual-cased-toxicity,0.69750494
130,connectivity/feather_berts_28,0.753845
131,connectivity/feather_berts_28,0.7438632
132,liangyuant/distilbert-base-uncased-finetuned-num200-450-405cls,0.7531595
133,liangyuant/distilbert-base-uncased-finetuned-num200-450-405cls,0.7360244
134,DoyyingFace/bert-asian-hate-tweets-asian-unclean-freeze-4,0.7468533
135,DoyyingFace/bert-asian-hate-tweets-asian-unclean-freeze-4,0.743506
136,Jeevesh8/lecun_feather_berts-3,0.75350404
137,Jeevesh8/lecun_feather_berts-3,0.7520952
138,Giyaseddin/distilroberta-base-finetuned-short-answer-assessment,0.7542613
139,Giyaseddin/distilroberta-base-finetuned-short-answer-assessment,0.74139535
140,AnonymousSub/dummy_2,0.6983993
141,AnonymousSub/dummy_2,0.685934
142,Jeevesh8/lecun_feather_berts-51,0.751334
143,Jeevesh8/lecun_feather_berts-51,0.7501612
144,viviastaari/finetuning-sentiment-analysis-en-id,0.67980444
145,viviastaari/finetuning-sentiment-analysis-en-id,0.6632707
146,Aureliano/distilbert-base-uncased-if,0.7337509
147,Aureliano/distilbert-base-uncased-if,0.73745763
148,rmihaylov/roberta-base-sentiment-bg,0.7156895
149,rmihaylov/roberta-base-sentiment-bg,0.6982072
150,cardiffnlp/twitter-roberta-base-2021-124m,0.7684137
151,cardiffnlp/twitter-roberta-base-2021-124m,0.7592507
152,Jeevesh8/lecun_feather_berts-8,0.7549408
153,Jeevesh8/lecun_feather_berts-8,0.75479734
154,korca/bae-roberta-base-boolq,0.7427952
155,korca/bae-roberta-base-boolq,0.7355448
156,aditeyabaral/finetuned-sail2017-xlm-roberta-base,0.7415378
157,aditeyabaral/finetuned-sail2017-xlm-roberta-base,0.7350376
158,joebobby/finetuning-sentiment-model-5000-samples3,0.76342213
159,joebobby/finetuning-sentiment-model-5000-samples3,0.75498134
160,Jeevesh8/feather_berts_92,0.761609
161,Jeevesh8/feather_berts_92,0.7549897
162,ASCCCCCCCC/distilbert-base-chinese-amazon_zh_20000,0.6828571
163,ASCCCCCCCC/distilbert-base-chinese-amazon_zh_20000,0.6757695
164,matthewburke/korean_sentiment,0.7181971
165,matthewburke/korean_sentiment,0.7102582
166,IMSyPP/hate_speech_nl,0.6520373
167,IMSyPP/hate_speech_nl,0.6529085
168,cointegrated/roberta-base-formality,0.74876636
169,cointegrated/roberta-base-formality,0.749562
170,IMSyPP/hate_speech_it,0.7156928
171,IMSyPP/hate_speech_it,0.69836515
172,18811449050/bert_finetuning_test,0.72219217
173,18811449050/bert_finetuning_test,0.726138
174,finiteautomata/betonews-tweetcontext,0.7144415
175,finiteautomata/betonews-tweetcontext,0.69323075
176,Jeevesh8/feather_berts_96,0.73956746
177,Jeevesh8/feather_berts_96,0.7426171
178,Jeevesh8/lecun_feather_berts-7,0.76098204
179,Jeevesh8/lecun_feather_berts-7,0.7545818
180,mrm8488/codebert-base-finetuned-detect-insecure-code,0.7362256
181,mrm8488/codebert-base-finetuned-detect-insecure-code,0.7199594
182,socialmediaie/TRAC2020_IBEN_B_bert-base-multilingual-uncased,0.7198654
183,socialmediaie/TRAC2020_IBEN_B_bert-base-multilingual-uncased,0.714346
184,zenkri/autotrain-Arabic_Poetry_by_Subject-920730230,0.7552334
185,zenkri/autotrain-Arabic_Poetry_by_Subject-920730230,0.7425401
186,M47Labs/spanish_news_classification_headlines_untrained,0.70684516
187,M47Labs/spanish_news_classification_headlines_untrained,0.6838746
188,bondi/bert-semaphore-prediction-w4,0.7068181
189,bondi/bert-semaphore-prediction-w4,0.6746894
190,classla/bcms-bertic-parlasent-bcs-ter,0.722681
191,classla/bcms-bertic-parlasent-bcs-ter,0.70428383
192,anferico/bert-for-patents,0.71018815
193,anferico/bert-for-patents,0.70516145
194,ali2066/DistilBERTFINAL_ctxSentence_TRAIN_editorials_TEST_NULL_second_train_set_null_False,0.76672053
195,ali2066/DistilBERTFINAL_ctxSentence_TRAIN_editorials_TEST_NULL_second_train_set_null_False,0.7545079
196,anvay/finetuning-cardiffnlp-sentiment-model,0.7478632
197,anvay/finetuning-cardiffnlp-sentiment-model,0.75303
198,JonatanGk/roberta-base-ca-finetuned-hate-speech-offensive-catalan,0.7051036
199,JonatanGk/roberta-base-ca-finetuned-hate-speech-offensive-catalan,0.6887461
200,Raychanan/COVID_RandomOver,0.5455667
201,Raychanan/COVID_RandomOver,0.5578196
202,kyleinincubated/autonlp-cat333-624217911,0.7049372
203,kyleinincubated/autonlp-cat333-624217911,0.6759622
204,cardiffnlp/bertweet-base-stance-climate,0.75421864
205,cardiffnlp/bertweet-base-stance-climate,0.755863
206,nurkayevaa/autonlp-bert-covid-407910458,0.74737567
207,nurkayevaa/autonlp-bert-covid-407910458,0.7453243
208,SetFit/distilbert-base-uncased__hate_speech_offensive__train-16-1,0.752473
209,SetFit/distilbert-base-uncased__hate_speech_offensive__train-16-1,0.73428535
210,crcb/isear_bert,0.75777185
211,crcb/isear_bert,0.7531086
212,robertou2/roberta-base-bne-finetuned-amazon_reviews_multi,0.7032368
213,robertou2/roberta-base-bne-finetuned-amazon_reviews_multi,0.6849766
214,milyiyo/selectra-small-finetuned-amazon-review,0.6911549
215,milyiyo/selectra-small-finetuned-amazon-review,0.67140704
216,Anthos23/FS-distilroberta-fine-tuned,0.759085
217,Anthos23/FS-distilroberta-fine-tuned,0.74723417
218,oferweintraub/bert-base-finance-sentiment-noisy-search,0.7569972
219,oferweintraub/bert-base-finance-sentiment-noisy-search,0.7416922
220,pietrotrope/emotion_final,0.757562
221,pietrotrope/emotion_final,0.74642783
222,aXhyra/emotion_trained_31415,0.74561
223,aXhyra/emotion_trained_31415,0.7421488
224,aXhyra/presentation_emotion_31415,0.73937905
225,aXhyra/presentation_emotion_31415,0.7392691
226,Recognai/bert-base-spanish-wwm-cased-xnli,0.7150577
227,Recognai/bert-base-spanish-wwm-cased-xnli,0.6972042
228,anirudh21/bert-base-uncased-finetuned-qnli,0.7572988
229,anirudh21/bert-base-uncased-finetuned-qnli,0.74513155
230,aXhyra/demo_sentiment_31415,0.75972724
231,aXhyra/demo_sentiment_31415,0.74919784
232,aXhyra/presentation_sentiment_1234567,0.74112725
233,aXhyra/presentation_sentiment_1234567,0.7484056
234,jb2k/bert-base-multilingual-cased-language-detection,0.6898213
235,jb2k/bert-base-multilingual-cased-language-detection,0.6747941
236,vinai/bertweet-base,0.7201775
237,vinai/bertweet-base,0.71232784
238,justinqbui/bertweet-covid19-base-uncased-pretraining-covid-vaccine-tweets,0.73999155
239,justinqbui/bertweet-covid19-base-uncased-pretraining-covid-vaccine-tweets,0.7405582
240,vinai/bertweet-covid19-base-cased,0.62273717
241,vinai/bertweet-covid19-base-cased,0.74735606
242,vinai/bertweet-covid19-base-uncased,0.769005
243,vinai/bertweet-covid19-base-uncased,0.76554054
244,distilbert-base-uncased,0.7581462
245,distilbert-base-uncased,0.7432014
246,bert-base-uncased,0.74138826
247,bert-base-uncased,0.7431534
248,roberta-base,0.7552453
249,roberta-base,0.7548374
250,bert-base-cased,0.751495
251,bert-base-cased,0.7503766
252,dhimskyy/wiki-bert,0.67890745
253,dhimskyy/wiki-bert,0.6503108
254,michiyasunaga/LinkBERT-base,0.7358011
255,michiyasunaga/LinkBERT-base,0.73562765
256,bert-large-uncased,0.70126206
257,bert-large-uncased,0.69880617
258,roberta-large,0.77243334
259,roberta-large,0.7503075
260,boychaboy/MNLI_roberta-base,0.75209695
261,boychaboy/MNLI_roberta-base,0.7379466
262,ishan/bert-base-uncased-mnli,0.74980503
263,ishan/bert-base-uncased-mnli,0.73711914
264,emrecan/bert-base-multilingual-cased-snli_tr,0.73071057
265,emrecan/bert-base-multilingual-cased-snli_tr,0.7268646
266,elozano/tweet_offensive_eval,0.69846076
267,elozano/tweet_offensive_eval,0.692797
268,Hate-speech-CNERG/bert-base-uncased-hatexplain-rationale-two,0.75054294
269,Hate-speech-CNERG/bert-base-uncased-hatexplain-rationale-two,0.7551646
270,aychang/bert-base-cased-trec-coarse,0.76068884
271,aychang/bert-base-cased-trec-coarse,0.75222236
272,gchhablani/bert-base-cased-finetuned-wnli,0.7327933
273,gchhablani/bert-base-cased-finetuned-wnli,0.73071355
274,w11wo/sundanese-bert-base-emotion-classifier,0.7002249
275,w11wo/sundanese-bert-base-emotion-classifier,0.68417513
276,gchhablani/bert-base-cased-finetuned-rte,0.7453633
277,gchhablani/bert-base-cased-finetuned-rte,0.7326373
278,mrm8488/electricidad-base-finetuned-pawsx-es,0.7105213
279,mrm8488/electricidad-base-finetuned-pawsx-es,0.69825476
280,manueltonneau/bert-twitter-en-is-hired,0.7528348
281,manueltonneau/bert-twitter-en-is-hired,0.73956066
282,Guscode/DKbert-hatespeech-detection,0.6969596
283,Guscode/DKbert-hatespeech-detection,0.6922402
