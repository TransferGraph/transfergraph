,model,score
0,Guscode/DKbert-hatespeech-detection,0.7759433462596639
1,milyiyo/selectra-small-finetuned-amazon-review,0.7815020247589041
2,robertou2/roberta-base-bne-finetuned-amazon_reviews_multi,0.8048437929921498
3,vinai/bertweet-covid19-base-cased,0.7814165562626961
4,vinai/bertweet-covid19-base-uncased,0.8374218225379133
5,neibla/distilbert-base-uncased-finetuned-emotion,0.8441323463328818
6,JB173/distilbert-base-uncased-finetuned-emotion,0.8333854260648452
7,Nanatan/distilbert-base-uncased-finetuned-emotion,0.8400853168972336
8,connectivity/cola_6ep_ft-22,0.8471649623414548
9,gchhablani/fnet-base-finetuned-cola,0.8031340408331473
10,jaesun/distilbert-base-uncased-finetuned-cola,0.8353589588493093
11,usami/distilbert-base-uncased-finetuned-cola,0.8432736355901337
12,vesteinn/XLMR-ENIS-finetuned-cola,0.8327717546677981
13,connectivity/cola_6ep_ft-10,0.8306338829694134
14,Jeevesh8/6ep_bert_ft_cola-29,0.8243451107418143
15,Jeevesh8/bert_ft_cola-60,0.8344230494823638
16,ishan/bert-base-uncased-mnli,0.8381379661060919
17,boychaboy/MNLI_roberta-base,0.8482702529239541
18,anirudh21/bert-base-uncased-finetuned-qnli,0.8533617695653676
19,Alireza1044/albert-base-v2-qnli,0.8428942335358098
20,Jeevesh8/init_bert_ft_qqp-33,0.8461704635870833
21,Jeevesh8/init_bert_ft_qqp-33,0.8461704635870833
22,Jeevesh8/init_bert_ft_qqp-49,0.8471657658837602
23,connectivity/bert_ft_qqp-7,0.8478936594099267
24,Jeevesh8/bert_ft_qqp-88,0.8310386629369764
25,connectivity/bert_ft_qqp-25,0.8471583636780035
26,Jeevesh8/bert_ft_qqp-9,0.8453790249905931
27,Jeevesh8/bert_ft_qqp-68,0.8431941889381035
28,Jeevesh8/init_bert_ft_qqp-28,0.8369209272428035
29,connectivity/bert_ft_qqp-94,0.8430232467006045
30,connectivity/bert_ft_qqp-96,0.8446208247038723
31,philschmid/tiny-distilbert-classification,0.15951896575500382
32,ali2066/finetuned_sentence_itr1_2e-05_all_26_02_2022-04_03_26,0.8308751141757508
33,SetFit/distilbert-base-uncased__sst2__train-16-0,0.8426606266345117
34,gchhablani/fnet-base-finetuned-sst2,0.799670431753068
35,SetFit/distilbert-base-uncased__sst2__train-32-9,0.8433100554927772
36,gchhablani/bert-base-cased-finetuned-wnli,0.8337882590155506
37,heranm/finetuning-sentiment-model-3000-samples,0.834856710121952
38,PrasunMishra/finetuning-sentiment-model-3000-samples,0.845120382817893
39,yukta10/finetuning-sentiment-model-3000-samples,0.8430547442849314
40,juliensimon/autonlp-imdb-demo-hf-16622767,0.8364040975331083
41,fabriceyhc/bert-base-uncased-imdb,0.8384902198163029
42,oferweintraub/bert-base-finance-sentiment-noisy-search,0.8451644155509616
43,emrecan/bert-base-multilingual-cased-snli_tr,0.835933001686618
44,nurkayevaa/autonlp-bert-covid-407910458,0.8429992006781384
45,aychang/bert-base-cased-trec-coarse,0.8445013537732273
46,aXhyra/presentation_emotion_31415,0.8440137801428189
47,aXhyra/demo_sentiment_31415,0.84984688911494
48,manueltonneau/bert-twitter-en-is-hired,0.8441214012735578
49,distilbert-base-uncased,0.8395791671256144
50,dhimskyy/wiki-bert,0.7646600618115584
51,bert-base-cased,0.8406820727638646
52,albert-base-v2,0.814589496093094
53,bert-large-uncased,0.8107786776342144
54,dapang/distilroberta-base-mic-sym,0.8505106301491749
55,Capreolus/bert-base-msmarco,0.8374116897901404
56,phailyoor/distilbert-base-uncased-finetuned-yahd,0.8247665879815991
57,arianpasquali/distilbert-base-multilingual-cased-toxicity,0.8150859659786367
58,JonatanGk/roberta-base-bne-finetuned-cyberbullying-spanish,0.6960086373736245
59,chiragasarpota/scotus-bert,0.7316737308127328
60,liangyuant/distilbert-base-uncased-finetuned-num200-450-405cls,0.8202568678378274
61,Jeevesh8/lecun_feather_berts-51,0.8430489991755025
62,Aureliano/distilbert-base-uncased-if,0.8275023312065131
63,finiteautomata/betonews-tweetcontext,0.7408301280790839
64,cardiffnlp/twitter-roberta-base-2021-124m,0.8435259559070913
65,korca/bae-roberta-base-boolq,0.8410628486092131
66,Jeevesh8/lecun_feather_berts-7,0.8308669508039687
67,mrm8488/codebert-base-finetuned-detect-insecure-code,0.8296634538250133
68,cardiffnlp/bertweet-base-stance-climate,0.8156059774088164
69,matthewburke/korean_sentiment,0.7451218719877896
70,aditeyabaral/finetuned-sail2017-xlm-roberta-base,0.8298267472811233
71,classla/bcms-bertic-parlasent-bcs-ter,0.8205237999322246
72,waboucay/camembert-base-finetuned-xnli_fr-finetuned-nli-rua_wl,0.7173268749304451
73,YeRyeongLee/electra-base-discriminator-finetuned-filtered-0602,0.34411386516784986
74,anvay/finetuning-cardiffnlp-sentiment-model,0.8451649859788682
75,kyleinincubated/autonlp-cat333-624217911,0.8190107312306469
76,CAMeL-Lab/bert-base-arabic-camelbert-da-sentiment,0.6958003710159061
77,fgaim/tiroberta-geezswitch,0.7766924270644715
