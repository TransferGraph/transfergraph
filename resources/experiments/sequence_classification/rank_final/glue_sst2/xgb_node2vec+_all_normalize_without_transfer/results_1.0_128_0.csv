,model,score
0,Guscode/DKbert-hatespeech-detection,0.46789885
1,milyiyo/selectra-small-finetuned-amazon-review,0.60087466
2,robertou2/roberta-base-bne-finetuned-amazon_reviews_multi,0.7425381
3,SetFit/distilbert-base-uncased__hate_speech_offensive__train-16-1,0.770493
4,vinai/bertweet-base,0.81574816
5,justinqbui/bertweet-covid19-base-uncased-pretraining-covid-vaccine-tweets,0.8437135
6,vinai/bertweet-covid19-base-cased,0.3188309
7,vinai/bertweet-covid19-base-uncased,0.88820416
8,jb2k/bert-base-multilingual-cased-language-detection,0.70142907
9,crcb/isear_bert,0.9228078
10,vaariis/distilbert-base-uncased-finetuned-emotion,0.80087155
11,marcelcastrobr/sagemaker-distilbert-emotion,0.77848715
12,jasonyim2/distilbert-base-uncased-finetuned-emotion,0.8160482
13,abdelkader/distilbert-base-uncased-finetuned-emotion,0.7825306
14,moghis/distilbert-base-uncased-finetuned-emotion,0.76957405
15,uygarkurt/distilbert-base-uncased-finetuned-emotion,0.8068349
16,neibla/distilbert-base-uncased-finetuned-emotion,0.8316857
17,JB173/distilbert-base-uncased-finetuned-emotion,0.7498116
18,Nanatan/distilbert-base-uncased-finetuned-emotion,0.787766
19,riyadhctg/distilbert-base-uncased-finetuned-cola,0.7603932
20,connectivity/cola_6ep_ft-22,0.84078544
21,gchhablani/fnet-base-finetuned-cola,0.59923905
22,connectivity/cola_6ep_ft-33,0.8174057
23,jaesun/distilbert-base-uncased-finetuned-cola,0.7460258
24,usami/distilbert-base-uncased-finetuned-cola,0.765915
25,vesteinn/XLMR-ENIS-finetuned-cola,0.7395983
26,Jeevesh8/512seq_len_6ep_bert_ft_cola-91,0.7608923
27,isakbos/Q8BERT_COLA_L_512,0.6167497
28,Jeevesh8/6ep_bert_ft_cola-47,0.8045197
29,Jeevesh8/6ep_bert_ft_cola-12,0.7701692
30,connectivity/cola_6ep_ft-10,0.8154338
31,Jeevesh8/6ep_bert_ft_cola-29,0.8066217
32,navsad/navid_test_bert,0.75848424
33,Jeevesh8/bert_ft_cola-60,0.7856188
34,Jeevesh8/bert_ft_cola-88,0.802999
35,ishan/bert-base-uncased-mnli,0.89063025
36,boychaboy/MNLI_roberta-base,0.89482063
37,anirudh21/bert-base-uncased-finetuned-qnli,0.85396755
38,Alireza1044/albert-base-v2-qnli,0.78615844
39,Jeevesh8/init_bert_ft_qqp-33,0.7815059
40,Jeevesh8/init_bert_ft_qqp-33,0.7907143
41,Jeevesh8/init_bert_ft_qqp-49,0.80993664
42,Jeevesh8/bert_ft_qqp-40,0.85542923
43,connectivity/bert_ft_qqp-7,0.83059937
44,Jeevesh8/bert_ft_qqp-88,0.81031007
45,connectivity/bert_ft_qqp-25,0.8075935
46,Jeevesh8/bert_ft_qqp-9,0.8292605
47,Jeevesh8/bert_ft_qqp-55,0.8161793
48,Jeevesh8/init_bert_ft_qqp-24,0.8091407
49,Jeevesh8/bert_ft_qqp-68,0.8115314
50,Jeevesh8/init_bert_ft_qqp-28,0.78194433
51,connectivity/bert_ft_qqp-17,0.85012716
52,connectivity/bert_ft_qqp-1,0.80591863
53,Jeevesh8/bert_ft_qqp-39,0.8273318
54,connectivity/bert_ft_qqp-94,0.8561326
55,connectivity/bert_ft_qqp-96,0.81291044
56,gchhablani/bert-base-cased-finetuned-rte,0.81923985
57,philschmid/tiny-distilbert-classification,0.13737555
58,ali2066/finetuned_sentence_itr1_2e-05_all_26_02_2022-04_03_26,0.8848274
59,SetFit/distilbert-base-uncased__sst2__train-16-0,0.79982084
60,gchhablani/fnet-base-finetuned-sst2,0.6982182
61,moshew/bert-mini-sst2-distilled,0.68615276
62,SetFit/distilbert-base-uncased__sst2__train-32-9,0.80126613
63,aviator-neural/bert-base-uncased-sst2,0.8949212
64,Alassea/glue_sst_classifier,0.83084834
65,ChrisUPM/BioBERT_Re_trained,0.7551495
66,gchhablani/bert-base-cased-finetuned-wnli,0.7987929
67,Hate-speech-CNERG/bert-base-uncased-hatexplain-rationale-two,0.83573985
68,heranm/finetuning-sentiment-model-3000-samples,0.8333204
69,PrasunMishra/finetuning-sentiment-model-3000-samples,0.81091183
70,yukta10/finetuning-sentiment-model-3000-samples,0.78231364
71,ncduy/roberta-imdb-sentiment-analysis,0.9299203
72,markt23917/finetuning-sentiment-model-3000-samples,0.8047368
73,juliensimon/autonlp-imdb-demo-hf-16622767,0.822041
74,XSY/albert-base-v2-imdb-calssification,0.6453206
75,fabriceyhc/bert-base-uncased-imdb,0.77330524
76,Anthos23/FS-distilroberta-fine-tuned,0.8207795
77,oferweintraub/bert-base-finance-sentiment-noisy-search,0.8466115
78,emrecan/bert-base-multilingual-cased-snli_tr,0.79435337
79,nurkayevaa/autonlp-bert-covid-407910458,0.8178466
80,w11wo/sundanese-bert-base-emotion-classifier,0.6544043
81,aychang/bert-base-cased-trec-coarse,0.8359786
82,JNK789/distilbert-base-uncased-finetuned-tweets-emoji-dataset,0.16198364
83,pietrotrope/emotion_final,0.83012253
84,aXhyra/presentation_emotion_31415,0.8291319
85,aXhyra/emotion_trained_31415,0.8007501
86,elozano/tweet_offensive_eval,0.62908226
87,aXhyra/demo_sentiment_31415,0.8467293
88,aXhyra/presentation_sentiment_1234567,0.81231755
89,nickmuchi/facebook-data2vec-finetuned-finance-classification,0.7934446
90,manueltonneau/bert-twitter-en-is-hired,0.848184
91,distilbert-base-uncased,0.83062917
92,dhimskyy/wiki-bert,0.688602
93,bert-base-uncased,0.8930491
94,bert-base-cased,0.8254914
95,roberta-base,0.97075814
96,albert-base-v2,0.7674628
97,michiyasunaga/LinkBERT-base,0.8360763
98,bert-large-uncased,0.5539507
99,roberta-large,0.64823145
100,Recognai/bert-base-spanish-wwm-cased-xnli,0.60094327
101,mrm8488/electricidad-base-finetuned-pawsx-es,0.66785467
102,dapang/distilroberta-base-mic-sym,0.863761
103,Splend1dchan/bert-base-uncased-slue-goldtrascription-e3-lr1e-4,0.805931
104,Capreolus/bert-base-msmarco,0.8717022
105,cambridgeltl/guardian_news_distilbert-base-uncased,0.72659326
106,amyma21/sincere_question_classification,0.79857236
107,phailyoor/distilbert-base-uncased-finetuned-yahd,0.757337
108,Jeevesh8/feather_berts_46,0.8532593
109,arianpasquali/distilbert-base-multilingual-cased-toxicity,0.69557637
110,JonatanGk/roberta-base-bne-finetuned-cyberbullying-spanish,0.6429945
111,chiragasarpota/scotus-bert,0.53691244
112,connectivity/feather_berts_28,0.8176773
113,liangyuant/distilbert-base-uncased-finetuned-num200-450-405cls,0.7983027
114,IMSyPP/hate_speech_it,0.6450698
115,Giyaseddin/distilroberta-base-finetuned-short-answer-assessment,0.84440637
116,DoyyingFace/bert-asian-hate-tweets-asian-unclean-freeze-4,0.8339245
117,viviastaari/finetuning-sentiment-analysis-en-id,0.60924935
118,Jeevesh8/lecun_feather_berts-51,0.8595502
119,Aureliano/distilbert-base-uncased-if,0.7845483
120,Jeevesh8/lecun_feather_berts-3,0.8141059
121,rmihaylov/roberta-base-sentiment-bg,0.6988011
122,AnonymousSub/dummy_2,0.7180321
123,18811449050/bert_finetuning_test,0.73000944
124,finiteautomata/betonews-tweetcontext,0.6334903
125,Jeevesh8/feather_berts_96,0.8879093
126,cardiffnlp/twitter-roberta-base-2021-124m,0.9487439
127,Jeevesh8/lecun_feather_berts-8,0.84767324
128,korca/bae-roberta-base-boolq,0.8735458
129,Jeevesh8/lecun_feather_berts-7,0.8742396
130,mrm8488/codebert-base-finetuned-detect-insecure-code,0.77412516
131,cardiffnlp/bertweet-base-stance-climate,0.8372504
132,matthewburke/korean_sentiment,0.6001426
133,socialmediaie/TRAC2020_IBEN_B_bert-base-multilingual-uncased,0.76025224
134,IMSyPP/hate_speech_nl,0.58233035
135,zenkri/autotrain-Arabic_Poetry_by_Subject-920730230,0.85592747
136,M47Labs/spanish_news_classification_headlines_untrained,0.6994485
137,bondi/bert-semaphore-prediction-w4,0.5987736
138,cointegrated/roberta-base-formality,0.89013785
139,aditeyabaral/finetuned-sail2017-xlm-roberta-base,0.8385768
140,classla/bcms-bertic-parlasent-bcs-ter,0.7046799
141,joebobby/finetuning-sentiment-model-5000-samples3,0.8501068
142,anferico/bert-for-patents,0.6449442
143,waboucay/camembert-base-finetuned-xnli_fr-finetuned-nli-rua_wl,0.5249925
144,ali2066/DistilBERTFINAL_ctxSentence_TRAIN_editorials_TEST_NULL_second_train_set_null_False,0.9119697
145,YeRyeongLee/electra-base-discriminator-finetuned-filtered-0602,0.3557824
146,anvay/finetuning-cardiffnlp-sentiment-model,0.9681377
147,Jeevesh8/feather_berts_92,0.8757839
148,JonatanGk/roberta-base-ca-finetuned-hate-speech-offensive-catalan,0.6548635
149,Raychanan/COVID_RandomOver,0.1382129
150,Monsia/camembert-fr-covid-tweet-classification,0.65910023
151,CAMeL-Lab/bert-base-arabic-camelbert-mix-did-nadi,0.5798635
152,ASCCCCCCCC/distilbert-base-chinese-amazon_zh_20000,0.57899934
153,kyleinincubated/autonlp-cat333-624217911,0.5645975
154,CAMeL-Lab/bert-base-arabic-camelbert-da-sentiment,0.555035
155,fgaim/tiroberta-geezswitch,0.6626296
