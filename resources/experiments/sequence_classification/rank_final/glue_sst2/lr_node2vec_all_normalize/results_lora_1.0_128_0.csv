,model,score
0,Jeevesh8/init_bert_ft_qqp-33,0.788186444799921
1,Jeevesh8/init_bert_ft_qqp-33,0.7946404042285041
2,Jeevesh8/init_bert_ft_qqp-33,0.7833204858102766
3,Jeevesh8/init_bert_ft_qqp-49,0.8199230326553554
4,Jeevesh8/init_bert_ft_qqp-49,0.8122642623028771
5,connectivity/bert_ft_qqp-7,0.8215366623155583
6,connectivity/bert_ft_qqp-7,0.8099753918724322
7,Jeevesh8/bert_ft_qqp-40,0.8264934615953845
8,Jeevesh8/bert_ft_qqp-40,0.8210626843663984
9,Jeevesh8/bert_ft_qqp-9,0.8386455584879547
10,Jeevesh8/bert_ft_qqp-9,0.8283319692748351
11,Jeevesh8/bert_ft_qqp-88,0.8269887544983593
12,Jeevesh8/bert_ft_qqp-88,0.8217935029966668
13,connectivity/bert_ft_qqp-25,0.8357783617268278
14,connectivity/bert_ft_qqp-25,0.8320761139979385
15,Jeevesh8/bert_ft_qqp-55,0.8125383369005741
16,Jeevesh8/bert_ft_qqp-55,0.8088206155407319
17,connectivity/bert_ft_qqp-1,0.8222021906692379
18,connectivity/bert_ft_qqp-1,0.8185310563891197
19,Jeevesh8/bert_ft_qqp-39,0.8294695544258233
20,Jeevesh8/bert_ft_qqp-39,0.8253175530102949
21,connectivity/bert_ft_qqp-94,0.8213363005799021
22,connectivity/bert_ft_qqp-94,0.8150467881375112
23,connectivity/bert_ft_qqp-96,0.8105696445450361
24,connectivity/bert_ft_qqp-96,0.8006186661454301
25,Jeevesh8/init_bert_ft_qqp-24,0.7925940331948677
26,Jeevesh8/init_bert_ft_qqp-24,0.7914879840116146
27,Jeevesh8/bert_ft_qqp-68,0.7966157320617958
28,Jeevesh8/bert_ft_qqp-68,0.7925151386400708
29,Jeevesh8/init_bert_ft_qqp-28,0.7962991119159643
30,Jeevesh8/init_bert_ft_qqp-28,0.7915919989711864
31,Jeevesh8/init_bert_ft_qqp-28,0.7915697475633953
32,connectivity/bert_ft_qqp-17,0.8071423339512096
33,connectivity/bert_ft_qqp-17,0.8009228913817754
34,ali2066/finetuned_sentence_itr1_2e-05_all_26_02_2022-04_03_26,0.8952190389063299
35,ali2066/finetuned_sentence_itr1_2e-05_all_26_02_2022-04_03_26,0.8942927837208776
36,SetFit/distilbert-base-uncased__sst2__train-16-0,0.9167440137490639
37,SetFit/distilbert-base-uncased__sst2__train-16-0,0.9144218321764501
38,aviator-neural/bert-base-uncased-sst2,0.8190776345350278
39,aviator-neural/bert-base-uncased-sst2,0.81541141889473
40,SetFit/distilbert-base-uncased__sst2__train-32-9,0.9016548653090941
41,SetFit/distilbert-base-uncased__sst2__train-32-9,0.899345425884407
42,Alassea/glue_sst_classifier,0.8550643923740038
43,Alassea/glue_sst_classifier,0.850422050782506
44,philschmid/tiny-distilbert-classification,0.6388092421648873
45,philschmid/tiny-distilbert-classification,0.6379382272630636
46,moshew/bert-mini-sst2-distilled,0.7887584562870269
47,moshew/bert-mini-sst2-distilled,0.7877023468035071
48,ChrisUPM/BioBERT_Re_trained,0.7903124300410409
49,ChrisUPM/BioBERT_Re_trained,0.7790698890038152
50,vaariis/distilbert-base-uncased-finetuned-emotion,0.9176919838684297
51,vaariis/distilbert-base-uncased-finetuned-emotion,0.9151078857933985
52,marcelcastrobr/sagemaker-distilbert-emotion,0.913749706332055
53,marcelcastrobr/sagemaker-distilbert-emotion,0.910191361555786
54,jasonyim2/distilbert-base-uncased-finetuned-emotion,0.9007894501715208
55,jasonyim2/distilbert-base-uncased-finetuned-emotion,0.8969606344658763
56,abdelkader/distilbert-base-uncased-finetuned-emotion,0.898691345065626
57,abdelkader/distilbert-base-uncased-finetuned-emotion,0.8963764944931365
58,moghis/distilbert-base-uncased-finetuned-emotion,0.899775977609863
59,moghis/distilbert-base-uncased-finetuned-emotion,0.8974478506751583
60,uygarkurt/distilbert-base-uncased-finetuned-emotion,0.914422938279819
61,uygarkurt/distilbert-base-uncased-finetuned-emotion,0.9118556371834801
62,neibla/distilbert-base-uncased-finetuned-emotion,0.886392747140205
63,neibla/distilbert-base-uncased-finetuned-emotion,0.8839240899912896
64,JB173/distilbert-base-uncased-finetuned-emotion,0.9062900099236431
65,JB173/distilbert-base-uncased-finetuned-emotion,0.9025160296147191
66,Nanatan/distilbert-base-uncased-finetuned-emotion,0.9110279139124284
67,Nanatan/distilbert-base-uncased-finetuned-emotion,0.9075244448478852
68,heranm/finetuning-sentiment-model-3000-samples,0.8964315861606467
69,heranm/finetuning-sentiment-model-3000-samples,0.8933338497539369
70,PrasunMishra/finetuning-sentiment-model-3000-samples,0.9026881543003805
71,PrasunMishra/finetuning-sentiment-model-3000-samples,0.899022003491093
72,yukta10/finetuning-sentiment-model-3000-samples,0.9018203165063177
73,yukta10/finetuning-sentiment-model-3000-samples,0.89896234058659
74,ncduy/roberta-imdb-sentiment-analysis,0.9307750633112479
75,ncduy/roberta-imdb-sentiment-analysis,0.9232811910576336
76,markt23917/finetuning-sentiment-model-3000-samples,0.897427369695047
77,markt23917/finetuning-sentiment-model-3000-samples,0.8938608013778597
78,juliensimon/autonlp-imdb-demo-hf-16622767,0.9105169632412135
79,juliensimon/autonlp-imdb-demo-hf-16622767,0.9077403999622793
80,fabriceyhc/bert-base-uncased-imdb,0.7828662754367032
81,fabriceyhc/bert-base-uncased-imdb,0.7817428728451133
82,riyadhctg/distilbert-base-uncased-finetuned-cola,0.8734376494955296
83,riyadhctg/distilbert-base-uncased-finetuned-cola,0.8706319116091372
84,connectivity/cola_6ep_ft-33,0.8205768160607528
85,connectivity/cola_6ep_ft-33,0.8146482755533356
86,connectivity/cola_6ep_ft-22,0.8204583869746283
87,connectivity/cola_6ep_ft-22,0.8166882915994667
88,isakbos/Q8BERT_COLA_L_512,0.6390265469273004
89,isakbos/Q8BERT_COLA_L_512,0.6280272613117452
90,jaesun/distilbert-base-uncased-finetuned-cola,0.8941043867990581
91,jaesun/distilbert-base-uncased-finetuned-cola,0.8917290332806479
92,usami/distilbert-base-uncased-finetuned-cola,0.8860893769868073
93,usami/distilbert-base-uncased-finetuned-cola,0.883290793221567
94,Jeevesh8/512seq_len_6ep_bert_ft_cola-91,0.8174395575526213
95,Jeevesh8/512seq_len_6ep_bert_ft_cola-91,0.8139147181105624
96,Jeevesh8/6ep_bert_ft_cola-47,0.8203606500890246
97,Jeevesh8/6ep_bert_ft_cola-47,0.8156407328551594
98,connectivity/cola_6ep_ft-10,0.8362819160364472
99,connectivity/cola_6ep_ft-10,0.8293481965810305
100,Jeevesh8/6ep_bert_ft_cola-12,0.821982326493242
101,Jeevesh8/6ep_bert_ft_cola-12,0.8167514998427271
102,Jeevesh8/bert_ft_cola-88,0.826340118687325
103,Jeevesh8/bert_ft_cola-88,0.8158805773327893
104,Jeevesh8/6ep_bert_ft_cola-29,0.8351237499120651
105,Jeevesh8/6ep_bert_ft_cola-29,0.8241668712537719
106,vesteinn/XLMR-ENIS-finetuned-cola,0.90027535971415
107,vesteinn/XLMR-ENIS-finetuned-cola,0.8950386095731664
108,navsad/navid_test_bert,0.8151285115916431
109,navsad/navid_test_bert,0.8104026261146889
110,Jeevesh8/bert_ft_cola-60,0.8259817775242371
111,Jeevesh8/bert_ft_cola-60,0.8186570102740467
112,dapang/distilroberta-base-mic-sym,0.9088803548908075
113,dapang/distilroberta-base-mic-sym,0.9054422954140768
114,Capreolus/bert-base-msmarco,0.8182946580154388
115,Capreolus/bert-base-msmarco,0.813610054465752
116,Splend1dchan/bert-base-uncased-slue-goldtrascription-e3-lr1e-4,0.8404339696327333
117,Splend1dchan/bert-base-uncased-slue-goldtrascription-e3-lr1e-4,0.8360557192714878
118,Jeevesh8/feather_berts_46,0.8180750861038536
119,Jeevesh8/feather_berts_46,0.8144305358569959
120,JonatanGk/roberta-base-bne-finetuned-cyberbullying-spanish,0.78151272394074
121,JonatanGk/roberta-base-bne-finetuned-cyberbullying-spanish,0.7759358567405594
122,cambridgeltl/guardian_news_distilbert-base-uncased,0.8805332077908592
123,cambridgeltl/guardian_news_distilbert-base-uncased,0.8767946536614744
124,amyma21/sincere_question_classification,0.9044398052538959
125,amyma21/sincere_question_classification,0.9013850931130789
126,phailyoor/distilbert-base-uncased-finetuned-yahd,0.8681226067337137
127,phailyoor/distilbert-base-uncased-finetuned-yahd,0.86577208622749
128,arianpasquali/distilbert-base-multilingual-cased-toxicity,0.871424867594168
129,arianpasquali/distilbert-base-multilingual-cased-toxicity,0.8671191406996293
130,connectivity/feather_berts_28,0.8148791678174778
131,connectivity/feather_berts_28,0.8101513094386956
132,liangyuant/distilbert-base-uncased-finetuned-num200-450-405cls,0.8945592088153947
133,liangyuant/distilbert-base-uncased-finetuned-num200-450-405cls,0.8920439672656927
134,DoyyingFace/bert-asian-hate-tweets-asian-unclean-freeze-4,0.8279959703925143
135,DoyyingFace/bert-asian-hate-tweets-asian-unclean-freeze-4,0.8233922874521367
136,Jeevesh8/lecun_feather_berts-3,0.8298960372382435
137,Jeevesh8/lecun_feather_berts-3,0.8223638418263018
138,Giyaseddin/distilroberta-base-finetuned-short-answer-assessment,0.9028967450742671
139,Giyaseddin/distilroberta-base-finetuned-short-answer-assessment,0.8990793416324211
140,AnonymousSub/dummy_2,0.7817843451365135
141,AnonymousSub/dummy_2,0.7731082852771307
142,Jeevesh8/lecun_feather_berts-51,0.8225323204799829
143,Jeevesh8/lecun_feather_berts-51,0.8169090139453801
144,viviastaari/finetuning-sentiment-analysis-en-id,0.8484642695407109
145,viviastaari/finetuning-sentiment-analysis-en-id,0.8444525167436171
146,Aureliano/distilbert-base-uncased-if,0.8960071150889396
147,Aureliano/distilbert-base-uncased-if,0.8921367504116284
148,rmihaylov/roberta-base-sentiment-bg,0.8374764979395832
149,rmihaylov/roberta-base-sentiment-bg,0.8337304474197965
150,cardiffnlp/twitter-roberta-base-2021-124m,0.9186466864714187
151,cardiffnlp/twitter-roberta-base-2021-124m,0.9140414311057874
152,Jeevesh8/lecun_feather_berts-8,0.8191658913518762
153,Jeevesh8/lecun_feather_berts-8,0.8130715905151672
154,korca/bae-roberta-base-boolq,0.9142860010885161
155,korca/bae-roberta-base-boolq,0.9102324747364212
156,aditeyabaral/finetuned-sail2017-xlm-roberta-base,0.9157488421795121
157,aditeyabaral/finetuned-sail2017-xlm-roberta-base,0.9051243282578391
158,joebobby/finetuning-sentiment-model-5000-samples3,0.81486007389224
159,joebobby/finetuning-sentiment-model-5000-samples3,0.8106270497204142
160,Jeevesh8/feather_berts_92,0.8561245564304556
161,Jeevesh8/feather_berts_92,0.8509583535952503
162,ASCCCCCCCC/distilbert-base-chinese-amazon_zh_20000,0.7393802726269573
163,ASCCCCCCCC/distilbert-base-chinese-amazon_zh_20000,0.7347010157959942
164,matthewburke/korean_sentiment,0.8118387333706684
165,matthewburke/korean_sentiment,0.8080502317284377
166,IMSyPP/hate_speech_nl,0.728003365424148
167,IMSyPP/hate_speech_nl,0.7208816624632461
168,cointegrated/roberta-base-formality,0.9233689647857388
169,cointegrated/roberta-base-formality,0.916403796772502
170,IMSyPP/hate_speech_it,0.7627849333340209
171,IMSyPP/hate_speech_it,0.7569135699691685
172,18811449050/bert_finetuning_test,0.820457004815664
173,18811449050/bert_finetuning_test,0.810517278405567
174,finiteautomata/betonews-tweetcontext,0.7334831688950807
175,finiteautomata/betonews-tweetcontext,0.7275270064417041
176,Jeevesh8/feather_berts_96,0.8364099395728691
177,Jeevesh8/feather_berts_96,0.8263413731925711
178,Jeevesh8/lecun_feather_berts-7,0.8310889087702626
179,Jeevesh8/lecun_feather_berts-7,0.824910001739427
180,mrm8488/codebert-base-finetuned-detect-insecure-code,0.8801484021856784
181,mrm8488/codebert-base-finetuned-detect-insecure-code,0.8746017878388475
182,socialmediaie/TRAC2020_IBEN_B_bert-base-multilingual-uncased,0.7713942682303006
183,socialmediaie/TRAC2020_IBEN_B_bert-base-multilingual-uncased,0.765967314283145
184,zenkri/autotrain-Arabic_Poetry_by_Subject-920730230,0.8084000975760764
185,zenkri/autotrain-Arabic_Poetry_by_Subject-920730230,0.801430390424587
186,M47Labs/spanish_news_classification_headlines_untrained,0.7497167486378737
187,M47Labs/spanish_news_classification_headlines_untrained,0.7420337258005583
188,bondi/bert-semaphore-prediction-w4,0.7286220005618662
189,bondi/bert-semaphore-prediction-w4,0.722589726073416
190,classla/bcms-bertic-parlasent-bcs-ter,0.8598621427445978
191,classla/bcms-bertic-parlasent-bcs-ter,0.8556251663818609
192,anferico/bert-for-patents,0.8068737034874351
193,anferico/bert-for-patents,0.7974063015090965
194,ali2066/DistilBERTFINAL_ctxSentence_TRAIN_editorials_TEST_NULL_second_train_set_null_False,0.9380717466743635
195,ali2066/DistilBERTFINAL_ctxSentence_TRAIN_editorials_TEST_NULL_second_train_set_null_False,0.9317307485562625
196,anvay/finetuning-cardiffnlp-sentiment-model,0.9243364650092688
197,anvay/finetuning-cardiffnlp-sentiment-model,0.9175440385013408
198,JonatanGk/roberta-base-ca-finetuned-hate-speech-offensive-catalan,0.8183452663547581
199,JonatanGk/roberta-base-ca-finetuned-hate-speech-offensive-catalan,0.8109923921963909
200,Raychanan/COVID_RandomOver,0.6163560099539772
201,Raychanan/COVID_RandomOver,0.609085047175233
202,kyleinincubated/autonlp-cat333-624217911,0.7658083750960518
203,kyleinincubated/autonlp-cat333-624217911,0.7611730106412498
204,cardiffnlp/bertweet-base-stance-climate,0.9061674722553577
205,cardiffnlp/bertweet-base-stance-climate,0.9012965699789421
206,nurkayevaa/autonlp-bert-covid-407910458,0.9035131797613968
207,nurkayevaa/autonlp-bert-covid-407910458,0.9007691276708613
208,SetFit/distilbert-base-uncased__hate_speech_offensive__train-16-1,0.9158344377009784
209,SetFit/distilbert-base-uncased__hate_speech_offensive__train-16-1,0.9132502594306043
210,crcb/isear_bert,0.9293685129738269
211,crcb/isear_bert,0.9230670040919864
212,robertou2/roberta-base-bne-finetuned-amazon_reviews_multi,0.8363549560908773
213,robertou2/roberta-base-bne-finetuned-amazon_reviews_multi,0.8294981983701559
214,milyiyo/selectra-small-finetuned-amazon-review,0.8018485444503712
215,milyiyo/selectra-small-finetuned-amazon-review,0.7999453564243516
216,Anthos23/FS-distilroberta-fine-tuned,0.9126486437559373
217,Anthos23/FS-distilroberta-fine-tuned,0.9097226533010556
218,oferweintraub/bert-base-finance-sentiment-noisy-search,0.8172493722991018
219,oferweintraub/bert-base-finance-sentiment-noisy-search,0.8105766468623187
220,pietrotrope/emotion_final,0.9209990735602325
221,pietrotrope/emotion_final,0.9178756210959471
222,aXhyra/emotion_trained_31415,0.9111768608854862
223,aXhyra/emotion_trained_31415,0.9049085547834422
224,aXhyra/presentation_emotion_31415,0.8962320081111547
225,aXhyra/presentation_emotion_31415,0.8926235470944576
226,Recognai/bert-base-spanish-wwm-cased-xnli,0.7538284307821045
227,Recognai/bert-base-spanish-wwm-cased-xnli,0.7490365502558695
228,anirudh21/bert-base-uncased-finetuned-qnli,0.8434011013035939
229,anirudh21/bert-base-uncased-finetuned-qnli,0.8383978684871557
230,aXhyra/demo_sentiment_31415,0.9128670797411416
231,aXhyra/demo_sentiment_31415,0.9105086406236282
232,aXhyra/presentation_sentiment_1234567,0.8923132605347417
233,aXhyra/presentation_sentiment_1234567,0.8895067799116192
234,jb2k/bert-base-multilingual-cased-language-detection,0.7722527403790505
235,jb2k/bert-base-multilingual-cased-language-detection,0.763351826920176
236,vinai/bertweet-base,0.9046789285708046
237,vinai/bertweet-base,0.8992050160755317
238,justinqbui/bertweet-covid19-base-uncased-pretraining-covid-vaccine-tweets,0.9205959153255789
239,justinqbui/bertweet-covid19-base-uncased-pretraining-covid-vaccine-tweets,0.9157775543080104
240,vinai/bertweet-covid19-base-cased,0.9104819661954636
241,vinai/bertweet-covid19-base-cased,0.9052551507033982
242,vinai/bertweet-covid19-base-uncased,0.8787166007774068
243,vinai/bertweet-covid19-base-uncased,0.8718613103341051
244,distilbert-base-uncased,0.909090721930369
245,distilbert-base-uncased,0.9058029148604889
246,bert-base-uncased,0.8333581534248786
247,bert-base-uncased,0.8270935999974808
248,roberta-base,0.9154834474350633
249,roberta-base,0.9096418339890018
250,bert-base-cased,0.8254990231377379
251,bert-base-cased,0.8212258743941184
252,dhimskyy/wiki-bert,0.733721112764327
253,dhimskyy/wiki-bert,0.7265655992558699
254,michiyasunaga/LinkBERT-base,0.8180767714609658
255,michiyasunaga/LinkBERT-base,0.8114205293380555
256,bert-large-uncased,0.7897531884992528
257,bert-large-uncased,0.7786727591023612
258,roberta-large,0.9147763771535773
259,roberta-large,0.8871276090918719
260,boychaboy/MNLI_roberta-base,0.9150941781524075
261,boychaboy/MNLI_roberta-base,0.9099526797040245
262,ishan/bert-base-uncased-mnli,0.8254856765186116
263,ishan/bert-base-uncased-mnli,0.8187051784564129
264,emrecan/bert-base-multilingual-cased-snli_tr,0.7922235336321923
265,emrecan/bert-base-multilingual-cased-snli_tr,0.783387381118208
266,elozano/tweet_offensive_eval,0.8169767270798424
267,elozano/tweet_offensive_eval,0.8122629947319795
268,Hate-speech-CNERG/bert-base-uncased-hatexplain-rationale-two,0.814226830468109
269,Hate-speech-CNERG/bert-base-uncased-hatexplain-rationale-two,0.8104463675583157
270,aychang/bert-base-cased-trec-coarse,0.8277906475319827
271,aychang/bert-base-cased-trec-coarse,0.8225206070265031
272,gchhablani/bert-base-cased-finetuned-wnli,0.8406456459622369
273,gchhablani/bert-base-cased-finetuned-wnli,0.8349259593240859
274,w11wo/sundanese-bert-base-emotion-classifier,0.735864115238525
275,w11wo/sundanese-bert-base-emotion-classifier,0.7305446517081092
276,gchhablani/bert-base-cased-finetuned-rte,0.8251429519822385
277,gchhablani/bert-base-cased-finetuned-rte,0.8205237384257473
278,mrm8488/electricidad-base-finetuned-pawsx-es,0.8202671098669876
279,mrm8488/electricidad-base-finetuned-pawsx-es,0.8168401657612384
280,manueltonneau/bert-twitter-en-is-hired,0.8275202471690657
281,manueltonneau/bert-twitter-en-is-hired,0.8208521698758212
282,Guscode/DKbert-hatespeech-detection,0.7411087620890792
283,Guscode/DKbert-hatespeech-detection,0.7346542759937903
