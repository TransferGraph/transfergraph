,model,score
0,Guscode/DKbert-hatespeech-detection,0.5371489526726667
1,robertou2/roberta-base-bne-finetuned-amazon_reviews_multi,0.6247780694437801
2,milyiyo/selectra-small-finetuned-amazon-review,0.5494479277387478
3,SetFit/distilbert-base-uncased__hate_speech_offensive__train-16-1,0.7361749414592216
4,vinai/bertweet-base,0.7619167258210331
5,vinai/bertweet-covid19-base-cased,0.8786394885342298
6,justinqbui/bertweet-covid19-base-uncased-pretraining-covid-vaccine-tweets,0.8069146855045356
7,vinai/bertweet-covid19-base-uncased,0.7753002165824975
8,jb2k/bert-base-multilingual-cased-language-detection,0.635726907115257
9,crcb/isear_bert,0.8232998030431776
10,vaariis/distilbert-base-uncased-finetuned-emotion,0.8107527115300479
11,marcelcastrobr/sagemaker-distilbert-emotion,0.716334328640906
12,jasonyim2/distilbert-base-uncased-finetuned-emotion,0.7670693845910461
13,abdelkader/distilbert-base-uncased-finetuned-emotion,0.7590687185385466
14,moghis/distilbert-base-uncased-finetuned-emotion,0.7559292247480837
15,uygarkurt/distilbert-base-uncased-finetuned-emotion,0.8422439969485574
16,neibla/distilbert-base-uncased-finetuned-emotion,0.808281814854671
17,JB173/distilbert-base-uncased-finetuned-emotion,0.7985743205234894
18,Nanatan/distilbert-base-uncased-finetuned-emotion,0.7691159798036115
19,riyadhctg/distilbert-base-uncased-finetuned-cola,0.7787818417756387
20,connectivity/cola_6ep_ft-33,0.8125490204586157
21,connectivity/cola_6ep_ft-22,0.7650403050142434
22,gchhablani/fnet-base-finetuned-cola,0.6650355539460717
23,vesteinn/XLMR-ENIS-finetuned-cola,0.8321432177502018
24,isakbos/Q8BERT_COLA_L_512,0.5547451213277805
25,jaesun/distilbert-base-uncased-finetuned-cola,0.6611767895890857
26,usami/distilbert-base-uncased-finetuned-cola,0.7357796938432357
27,Jeevesh8/512seq_len_6ep_bert_ft_cola-91,0.7195022129524855
28,Jeevesh8/6ep_bert_ft_cola-47,0.76134239192479
29,connectivity/cola_6ep_ft-10,0.8557923728569491
30,Jeevesh8/6ep_bert_ft_cola-12,0.7943409426218184
31,Jeevesh8/6ep_bert_ft_cola-29,0.7278170917777911
32,Jeevesh8/bert_ft_cola-60,0.8298383164623339
33,navsad/navid_test_bert,0.7672792564086798
34,Jeevesh8/bert_ft_cola-88,0.8560105245654148
35,ishan/bert-base-uncased-mnli,0.7749423779693505
36,boychaboy/MNLI_roberta-base,0.7949616180772845
37,anirudh21/bert-base-uncased-finetuned-qnli,0.7291282063799273
38,Alireza1044/albert-base-v2-qnli,0.7113278061763002
39,Jeevesh8/init_bert_ft_qqp-33,0.8145200572428016
40,Jeevesh8/init_bert_ft_qqp-49,0.7669675223960107
41,connectivity/bert_ft_qqp-7,0.7881217641026664
42,Jeevesh8/bert_ft_qqp-40,0.758331112971518
43,Jeevesh8/bert_ft_qqp-9,0.749434798681778
44,Jeevesh8/bert_ft_qqp-88,0.8082869439622193
45,connectivity/bert_ft_qqp-25,0.7409406287067514
46,Jeevesh8/bert_ft_qqp-55,0.8413525026465153
47,Jeevesh8/init_bert_ft_qqp-24,0.814278203446455
48,Jeevesh8/init_bert_ft_qqp-28,0.8308725427532638
49,connectivity/bert_ft_qqp-17,0.8158329216271871
50,Jeevesh8/bert_ft_qqp-68,0.8623506560776767
51,connectivity/bert_ft_qqp-1,0.7787955713643109
52,connectivity/bert_ft_qqp-94,0.8082951422209494
53,Jeevesh8/bert_ft_qqp-39,0.7415558642229954
54,connectivity/bert_ft_qqp-96,0.7316973613527206
55,gchhablani/bert-base-cased-finetuned-rte,0.8006471572284618
56,philschmid/tiny-distilbert-classification,0.11096040285319642
57,ali2066/finetuned_sentence_itr1_2e-05_all_26_02_2022-04_03_26,0.7356372159808818
58,SetFit/distilbert-base-uncased__sst2__train-16-0,0.7659362478399867
59,gchhablani/fnet-base-finetuned-sst2,0.6623965635783238
60,moshew/bert-mini-sst2-distilled,0.7636590825674956
61,aviator-neural/bert-base-uncased-sst2,0.7653993833244368
62,SetFit/distilbert-base-uncased__sst2__train-32-9,0.7999262157011023
63,Alassea/glue_sst_classifier,0.8199046115546851
64,ChrisUPM/BioBERT_Re_trained,0.6867513087443483
65,gchhablani/bert-base-cased-finetuned-wnli,0.7558849239961758
66,Hate-speech-CNERG/bert-base-uncased-hatexplain-rationale-two,0.8872565674370733
67,heranm/finetuning-sentiment-model-3000-samples,0.7532139150235035
68,PrasunMishra/finetuning-sentiment-model-3000-samples,0.8266230514603614
69,yukta10/finetuning-sentiment-model-3000-samples,0.7862487415759123
70,ncduy/roberta-imdb-sentiment-analysis,0.8754214636351936
71,markt23917/finetuning-sentiment-model-3000-samples,0.7653124210175508
72,juliensimon/autonlp-imdb-demo-hf-16622767,0.7613260251425957
73,XSY/albert-base-v2-imdb-calssification,0.6718524821165601
74,fabriceyhc/bert-base-uncased-imdb,0.7441511378062043
75,Anthos23/FS-distilroberta-fine-tuned,0.8089408985973353
76,oferweintraub/bert-base-finance-sentiment-noisy-search,0.8329262173778895
77,emrecan/bert-base-multilingual-cased-snli_tr,0.7247858279173421
78,nurkayevaa/autonlp-bert-covid-407910458,0.842259377568405
79,cross-encoder/quora-distilroberta-base,0.9536405474187617
80,navteca/quora-roberta-base,0.674116462937646
81,cross-encoder/quora-roberta-base,0.7177294744878031
82,w11wo/sundanese-bert-base-emotion-classifier,0.5313629851205213
83,aychang/bert-base-cased-trec-coarse,0.6939989702069344
84,JNK789/distilbert-base-uncased-finetuned-tweets-emoji-dataset,-0.033844391230262616
85,pietrotrope/emotion_final,0.7928190534175416
86,aXhyra/emotion_trained_31415,0.8788942719298869
87,aXhyra/presentation_emotion_31415,0.7940874742533494
88,elozano/tweet_offensive_eval,0.591690576943597
89,aXhyra/demo_sentiment_31415,0.8312456829710626
90,aXhyra/presentation_sentiment_1234567,0.7531890177339691
91,nickmuchi/facebook-data2vec-finetuned-finance-classification,0.74377923007311
92,manueltonneau/bert-twitter-en-is-hired,0.758693999599829
93,bert-base-uncased,0.7975698592090681
94,dhimskyy/wiki-bert,0.561446339934522
95,distilbert-base-uncased,0.7564194021714608
96,albert-base-v2,0.7629691343909804
97,bert-base-cased,0.8230104520649564
98,michiyasunaga/LinkBERT-base,0.7815975449781415
99,roberta-base,0.8302618946782332
100,bert-large-uncased,0.6712043867277424
101,roberta-large,0.5251803846624761
102,Recognai/bert-base-spanish-wwm-cased-xnli,0.612518991415355
103,mrm8488/electricidad-base-finetuned-pawsx-es,0.6332285413212425
104,dapang/distilroberta-base-mic-sym,0.8743974699994553
105,Capreolus/bert-base-msmarco,0.8497393477979285
106,Splend1dchan/bert-base-uncased-slue-goldtrascription-e3-lr1e-4,0.7796307564088433
107,Jeevesh8/feather_berts_46,0.9046843146249903
108,JonatanGk/roberta-base-bne-finetuned-cyberbullying-spanish,0.48000396652979266
109,cambridgeltl/guardian_news_distilbert-base-uncased,0.7405320808448337
110,amyma21/sincere_question_classification,0.7743099442736149
111,phailyoor/distilbert-base-uncased-finetuned-yahd,0.7272499036060206
112,nreimers/mmarco-mMiniLMv2-L6-H384-v1,0.8223832972383822
113,arianpasquali/distilbert-base-multilingual-cased-toxicity,0.6415635247499406
114,strickvl/nlp-redaction-classifier,0.8774458752497251
115,connectivity/feather_berts_28,0.7614336920324547
116,IMSyPP/hate_speech_it,0.6617345366537511
117,chiragasarpota/scotus-bert,0.5069706482232212
118,saattrupdan/job-listing-relevance-model,0.8760890089448786
119,warwickai/fin-perceiver,0.7688721376075125
120,liangyuant/distilbert-base-uncased-finetuned-num200-450-405cls,0.749013336355401
121,DoyyingFace/bert-asian-hate-tweets-asian-unclean-freeze-4,0.714492260406237
122,Jeevesh8/lecun_feather_berts-3,0.7888627970199312
123,Giyaseddin/distilroberta-base-finetuned-short-answer-assessment,0.7539656115270931
124,18811449050/bert_finetuning_test,0.7832930126600335
125,Jeevesh8/lecun_feather_berts-51,0.8332973714910574
126,Jeevesh8/feather_berts_96,0.8226770546637575
127,AnonymousSub/dummy_2,0.6687083377991503
128,viviastaari/finetuning-sentiment-analysis-en-id,0.5935912313758416
129,finiteautomata/betonews-tweetcontext,0.5892452990970283
130,Aureliano/distilbert-base-uncased-if,0.769249211348194
131,rmihaylov/roberta-base-sentiment-bg,0.6036736622539868
132,cardiffnlp/twitter-roberta-base-2021-124m,0.7730233373034422
133,Jeevesh8/lecun_feather_berts-8,0.7567589377793738
134,anferico/bert-for-patents,0.6532491878465374
135,morenolq/SumTO_FNS2020,0.8590365222212547
136,IMSyPP/hate_speech_nl,0.4091024814932723
137,cross-encoder/ms-marco-MiniLM-L-4-v2,0.9445053312114984
138,Jeevesh8/lecun_feather_berts-7,0.7643681831282639
139,matthewburke/korean_sentiment,0.6352467716859631
140,waboucay/camembert-base-finetuned-xnli_fr-finetuned-nli-rua_wl,0.5281665351122026
141,aditeyabaral/finetuned-sail2017-xlm-roberta-base,0.8030137478667464
142,socialmediaie/TRAC2020_IBEN_B_bert-base-multilingual-uncased,0.6506344169768024
143,korca/bae-roberta-base-boolq,0.8306263022617713
144,mrm8488/codebert-base-finetuned-detect-insecure-code,0.7275731028432182
145,M47Labs/spanish_news_classification_headlines_untrained,0.6130947785557916
146,cardiffnlp/bertweet-base-stance-climate,0.6953174397717246
147,zenkri/autotrain-Arabic_Poetry_by_Subject-920730230,0.8255232040367096
148,cointegrated/roberta-base-formality,0.8354260424024336
149,fgaim/tiroberta-geezswitch,0.4387730076888771
150,CAMeL-Lab/bert-base-arabic-camelbert-da-sentiment,0.4779142561099431
151,bondi/bert-semaphore-prediction-w4,0.516750454342344
152,classla/bcms-bertic-parlasent-bcs-ter,0.6725558915386476
153,ali2066/DistilBERTFINAL_ctxSentence_TRAIN_editorials_TEST_NULL_second_train_set_null_False,0.8739818331192974
154,Raychanan/COVID_RandomOver,-0.026711479002432092
155,anvay/finetuning-cardiffnlp-sentiment-model,0.8615322352128905
156,joebobby/finetuning-sentiment-model-5000-samples3,0.7633309738862903
157,JonatanGk/roberta-base-ca-finetuned-hate-speech-offensive-catalan,0.6294265234153773
158,Jeevesh8/feather_berts_92,0.8327808639521929
159,YeRyeongLee/electra-base-discriminator-finetuned-filtered-0602,0.21227242405994728
160,CAMeL-Lab/bert-base-arabic-camelbert-mix-did-nadi,0.45628148457310674
161,Monsia/camembert-fr-covid-tweet-classification,0.7277775842659069
162,ASCCCCCCCC/distilbert-base-chinese-amazon_zh_20000,0.5544506810703713
163,kyleinincubated/autonlp-cat333-624217911,0.5974101324209763
