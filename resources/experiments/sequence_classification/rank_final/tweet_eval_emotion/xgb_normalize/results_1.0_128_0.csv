,model,score
0,Jeevesh8/init_bert_ft_qqp-33,0.69877046
1,ali2066/finetuned_sentence_itr1_2e-05_all_26_02_2022-04_03_26,0.64118636
2,vaariis/distilbert-base-uncased-finetuned-emotion,0.6569074
3,heranm/finetuning-sentiment-model-3000-samples,0.6978547
4,marcelcastrobr/sagemaker-distilbert-emotion,0.66325957
5,jasonyim2/distilbert-base-uncased-finetuned-emotion,0.6569807
6,riyadhctg/distilbert-base-uncased-finetuned-cola,0.60029644
7,dapang/distilroberta-base-mic-sym,0.87923676
8,PrasunMishra/finetuning-sentiment-model-3000-samples,0.7246686
9,nurkayevaa/autonlp-bert-covid-407910458,0.7128518
10,SetFit/distilbert-base-uncased__sst2__train-16-0,0.71236235
11,abdelkader/distilbert-base-uncased-finetuned-emotion,0.6772772
12,SetFit/distilbert-base-uncased__hate_speech_offensive__train-16-1,0.65987176
13,gchhablani/fnet-base-finetuned-sst2,0.61132485
14,Capreolus/bert-base-msmarco,0.7126191
15,Splend1dchan/bert-base-uncased-slue-goldtrascription-e3-lr1e-4,0.7585019
16,crcb/isear_bert,0.8399375
17,connectivity/cola_6ep_ft-33,0.62501335
18,Jeevesh8/init_bert_ft_qqp-49,0.6735586
19,Jeevesh8/feather_berts_46,0.7585019
20,yukta10/finetuning-sentiment-model-3000-samples,0.66469353
21,connectivity/cola_6ep_ft-22,0.5915825
22,JonatanGk/roberta-base-bne-finetuned-cyberbullying-spanish,0.5022397
23,cambridgeltl/guardian_news_distilbert-base-uncased,0.644714
24,gchhablani/fnet-base-finetuned-cola,0.55501795
25,ncduy/roberta-imdb-sentiment-analysis,0.78941715
26,isakbos/Q8BERT_COLA_L_512,0.4875092
27,connectivity/bert_ft_qqp-7,0.6735586
28,moghis/distilbert-base-uncased-finetuned-emotion,0.6674134
29,uygarkurt/distilbert-base-uncased-finetuned-emotion,0.66180253
30,amyma21/sincere_question_classification,0.72777045
31,phailyoor/distilbert-base-uncased-finetuned-yahd,0.6362367
32,arianpasquali/distilbert-base-multilingual-cased-toxicity,0.5850362
33,neibla/distilbert-base-uncased-finetuned-emotion,0.6528458
34,robertou2/roberta-base-bne-finetuned-amazon_reviews_multi,0.6838532
35,Anthos23/FS-distilroberta-fine-tuned,0.82665837
36,pietrotrope/emotion_final,0.63984853
37,aviator-neural/bert-base-uncased-sst2,0.66475046
38,Jeevesh8/bert_ft_qqp-40,0.6735586
39,jaesun/distilbert-base-uncased-finetuned-cola,0.5725266
40,SetFit/distilbert-base-uncased__sst2__train-32-9,0.71161765
41,usami/distilbert-base-uncased-finetuned-cola,0.60766536
42,connectivity/feather_berts_28,0.75415796
43,Jeevesh8/512seq_len_6ep_bert_ft_cola-91,0.61008435
44,Jeevesh8/bert_ft_qqp-9,0.7002725
45,Jeevesh8/bert_ft_qqp-88,0.7002725
46,Recognai/bert-base-spanish-wwm-cased-xnli,0.53690964
47,markt23917/finetuning-sentiment-model-3000-samples,0.6900114
48,JNK789/distilbert-base-uncased-finetuned-tweets-emoji-dataset,-0.08133495
49,warwickai/fin-perceiver,0.7531975
50,anirudh21/bert-base-uncased-finetuned-qnli,0.7161816
51,Jeevesh8/6ep_bert_ft_cola-47,0.62501335
52,oferweintraub/bert-base-finance-sentiment-noisy-search,0.6764472
53,aXhyra/demo_sentiment_31415,0.70168054
54,milyiyo/selectra-small-finetuned-amazon-review,0.56523114
55,aXhyra/presentation_sentiment_1234567,0.70958287
56,Alireza1044/albert-base-v2-qnli,0.64526707
57,liangyuant/distilbert-base-uncased-finetuned-num200-450-405cls,0.69222695
58,DoyyingFace/bert-asian-hate-tweets-asian-unclean-freeze-4,0.7129516
59,connectivity/cola_6ep_ft-10,0.6330749
60,Jeevesh8/lecun_feather_berts-3,0.7486469
61,jb2k/bert-base-multilingual-cased-language-detection,0.5509399
62,Giyaseddin/distilroberta-base-finetuned-short-answer-assessment,0.8179922
63,connectivity/bert_ft_qqp-25,0.6735586
64,Jeevesh8/6ep_bert_ft_cola-12,0.5915825
65,JB173/distilbert-base-uncased-finetuned-emotion,0.6475888
66,aXhyra/emotion_trained_31415,0.71125835
67,aXhyra/presentation_emotion_31415,0.7048753
68,AnonymousSub/dummy_2,0.6270302
69,Jeevesh8/bert_ft_qqp-55,0.7002725
70,Jeevesh8/lecun_feather_berts-51,0.7585019
71,viviastaari/finetuning-sentiment-analysis-en-id,0.5217232
72,vinai/bertweet-base,0.88427454
73,distilbert-base-uncased,0.7083535
74,bert-base-uncased,0.76713973
75,roberta-base,0.83073765
76,Aureliano/distilbert-base-uncased-if,0.66955084
77,rmihaylov/roberta-base-sentiment-bg,0.6096353
78,cardiffnlp/twitter-roberta-base-2021-124m,0.9273985
79,Alassea/glue_sst_classifier,0.6946463
80,Nanatan/distilbert-base-uncased-finetuned-emotion,0.66490734
81,connectivity/bert_ft_qqp-1,0.7012556
82,juliensimon/autonlp-imdb-demo-hf-16622767,0.6968321
83,Jeevesh8/bert_ft_qqp-39,0.6300023
84,Jeevesh8/lecun_feather_berts-8,0.7643165
85,connectivity/bert_ft_qqp-94,0.7040795
86,korca/bae-roberta-base-boolq,0.7788539
87,Jeevesh8/bert_ft_cola-88,0.6358485
88,aditeyabaral/finetuned-sail2017-xlm-roberta-base,0.709978
89,connectivity/bert_ft_qqp-96,0.7040795
90,boychaboy/MNLI_roberta-base,0.93459815
91,fabriceyhc/bert-base-uncased-imdb,0.60240024
92,emrecan/bert-base-multilingual-cased-snli_tr,0.7040765
93,elozano/tweet_offensive_eval,0.29776415
94,joebobby/finetuning-sentiment-model-5000-samples3,0.7874908
95,YeRyeongLee/electra-base-discriminator-finetuned-filtered-0602,0.15675552
96,Jeevesh8/feather_berts_92,0.7643165
97,ASCCCCCCCC/distilbert-base-chinese-amazon_zh_20000,0.5542899
98,Jeevesh8/6ep_bert_ft_cola-29,0.6358485
99,albert-base-v2,0.7419895
100,bert-base-cased,0.7123891
101,Hate-speech-CNERG/bert-base-uncased-hatexplain-rationale-two,0.6862026
102,matthewburke/korean_sentiment,0.48366728
103,aychang/bert-base-cased-trec-coarse,0.74454534
104,IMSyPP/hate_speech_nl,0.40949845
105,cointegrated/roberta-base-formality,0.83700764
106,XSY/albert-base-v2-imdb-calssification,0.66836625
107,philschmid/tiny-distilbert-classification,0.009008754
108,gchhablani/bert-base-cased-finetuned-wnli,0.6821357
109,moshew/bert-mini-sst2-distilled,0.5791147
110,chiragasarpota/scotus-bert,0.16228615
111,vesteinn/XLMR-ENIS-finetuned-cola,0.6210304
112,IMSyPP/hate_speech_it,0.6004477
113,Jeevesh8/init_bert_ft_qqp-24,0.6735586
114,nickmuchi/facebook-data2vec-finetuned-finance-classification,0.68542796
115,Jeevesh8/bert_ft_qqp-68,0.6931483
116,Jeevesh8/init_bert_ft_qqp-28,0.6735586
117,connectivity/bert_ft_qqp-17,0.69869834
118,dhimskyy/wiki-bert,0.57204944
119,justinqbui/bertweet-covid19-base-uncased-pretraining-covid-vaccine-tweets,0.8941813
120,18811449050/bert_finetuning_test,0.7327939
121,vinai/bertweet-covid19-base-cased,0.89225
122,finiteautomata/betonews-tweetcontext,0.52093726
123,Jeevesh8/feather_berts_96,0.76637465
124,michiyasunaga/LinkBERT-base,0.7449066
125,navsad/navid_test_bert,0.6697767
126,vinai/bertweet-covid19-base-uncased,0.88427454
127,Jeevesh8/bert_ft_cola-60,0.6036584
128,Jeevesh8/lecun_feather_berts-7,0.75415796
129,w11wo/sundanese-bert-base-emotion-classifier,0.47311792
130,mrm8488/codebert-base-finetuned-detect-insecure-code,0.76037395
131,cardiffnlp/bertweet-base-stance-climate,0.6382059
132,socialmediaie/TRAC2020_IBEN_B_bert-base-multilingual-uncased,0.58263487
133,ishan/bert-base-uncased-mnli,0.71146905
134,zenkri/autotrain-Arabic_Poetry_by_Subject-920730230,0.7609494
135,M47Labs/spanish_news_classification_headlines_untrained,0.6108241
136,bondi/bert-semaphore-prediction-w4,0.52320856
137,gchhablani/bert-base-cased-finetuned-rte,0.71177375
138,classla/bcms-bertic-parlasent-bcs-ter,0.662661
139,anferico/bert-for-patents,0.520557
140,waboucay/camembert-base-finetuned-xnli_fr-finetuned-nli-rua_wl,0.39535528
141,ali2066/DistilBERTFINAL_ctxSentence_TRAIN_editorials_TEST_NULL_second_train_set_null_False,0.9825275
142,anvay/finetuning-cardiffnlp-sentiment-model,0.96455073
143,JonatanGk/roberta-base-ca-finetuned-hate-speech-offensive-catalan,0.55009395
144,mrm8488/electricidad-base-finetuned-pawsx-es,0.5831078
145,Raychanan/COVID_RandomOver,0.22533242
146,Monsia/camembert-fr-covid-tweet-classification,0.72048366
147,manueltonneau/bert-twitter-en-is-hired,0.7422958
148,CAMeL-Lab/bert-base-arabic-camelbert-mix-did-nadi,0.5327025
149,kyleinincubated/autonlp-cat333-624217911,0.5753448
150,Guscode/DKbert-hatespeech-detection,0.5593233
151,CAMeL-Lab/bert-base-arabic-camelbert-da-sentiment,0.44230777
152,bert-large-uncased,0.37428808
153,fgaim/tiroberta-geezswitch,0.4934013
154,ChrisUPM/BioBERT_Re_trained,0.648918
155,roberta-large,0.48051262
156,nreimers/mmarco-mMiniLMv2-L6-H384-v1,0.73835975
157,strickvl/nlp-redaction-classifier,0.66928923
158,saattrupdan/job-listing-relevance-model,0.6931441
159,cross-encoder/quora-distilroberta-base,0.5467292
160,morenolq/SumTO_FNS2020,0.6454739
161,navteca/quora-roberta-base,0.4707242
162,cross-encoder/ms-marco-MiniLM-L-4-v2,0.63875145
163,cross-encoder/quora-roberta-base,0.45984504
