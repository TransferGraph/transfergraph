,model,score
0,milyiyo/selectra-small-finetuned-amazon-review,0.490974
1,SetFit/distilbert-base-uncased__hate_speech_offensive__train-16-1,0.71901876
2,vinai/bertweet-base,0.852703
3,justinqbui/bertweet-covid19-base-uncased-pretraining-covid-vaccine-tweets,0.8536877
4,jb2k/bert-base-multilingual-cased-language-detection,0.5433895
5,jasonyim2/distilbert-base-uncased-finetuned-emotion,0.74030775
6,abdelkader/distilbert-base-uncased-finetuned-emotion,0.68726194
7,uygarkurt/distilbert-base-uncased-finetuned-emotion,0.7963238
8,neibla/distilbert-base-uncased-finetuned-emotion,0.71719545
9,JB173/distilbert-base-uncased-finetuned-emotion,0.72126544
10,connectivity/cola_6ep_ft-33,0.76769006
11,gchhablani/fnet-base-finetuned-cola,0.50816405
12,vesteinn/XLMR-ENIS-finetuned-cola,0.7424451
13,isakbos/Q8BERT_COLA_L_512,0.41536373
14,jaesun/distilbert-base-uncased-finetuned-cola,0.6141497
15,usami/distilbert-base-uncased-finetuned-cola,0.67818236
16,Jeevesh8/512seq_len_6ep_bert_ft_cola-91,0.76009136
17,connectivity/cola_6ep_ft-10,0.76877016
18,Jeevesh8/6ep_bert_ft_cola-12,0.7672832
19,Jeevesh8/bert_ft_cola-60,0.7340289
20,navsad/navid_test_bert,0.71690965
21,Jeevesh8/bert_ft_cola-88,0.7496754
22,boychaboy/MNLI_roberta-base,0.9462358
23,anirudh21/bert-base-uncased-finetuned-qnli,0.76787895
24,Alireza1044/albert-base-v2-qnli,0.74503285
25,Jeevesh8/bert_ft_qqp-40,0.83228105
26,Jeevesh8/bert_ft_qqp-9,0.74356073
27,Jeevesh8/bert_ft_qqp-88,0.78130645
28,connectivity/bert_ft_qqp-25,0.7982226
29,Jeevesh8/init_bert_ft_qqp-24,0.7522145
30,Jeevesh8/init_bert_ft_qqp-28,0.7636262
31,connectivity/bert_ft_qqp-17,0.75433886
32,connectivity/bert_ft_qqp-1,0.7614874
33,connectivity/bert_ft_qqp-94,0.7737911
34,Jeevesh8/bert_ft_qqp-39,0.7736452
35,connectivity/bert_ft_qqp-96,0.7657624
36,gchhablani/bert-base-cased-finetuned-rte,0.801214
37,philschmid/tiny-distilbert-classification,0.11739541
38,moshew/bert-mini-sst2-distilled,0.6227372
39,SetFit/distilbert-base-uncased__sst2__train-32-9,0.7608543
40,Alassea/glue_sst_classifier,0.8179055
41,ChrisUPM/BioBERT_Re_trained,0.67507964
42,gchhablani/bert-base-cased-finetuned-wnli,0.7284754
43,Hate-speech-CNERG/bert-base-uncased-hatexplain-rationale-two,0.79793024
44,PrasunMishra/finetuning-sentiment-model-3000-samples,0.7897793
45,yukta10/finetuning-sentiment-model-3000-samples,0.68279105
46,ncduy/roberta-imdb-sentiment-analysis,0.8481711
47,markt23917/finetuning-sentiment-model-3000-samples,0.7309625
48,juliensimon/autonlp-imdb-demo-hf-16622767,0.7206645
49,fabriceyhc/bert-base-uncased-imdb,0.72449845
50,oferweintraub/bert-base-finance-sentiment-noisy-search,0.77785546
51,cross-encoder/quora-distilroberta-base,0.69173986
52,cross-encoder/quora-roberta-base,0.7539575
53,JNK789/distilbert-base-uncased-finetuned-tweets-emoji-dataset,0.09684615
54,pietrotrope/emotion_final,0.7251546
55,aXhyra/emotion_trained_31415,0.7434681
56,aXhyra/presentation_emotion_31415,0.75559187
57,elozano/tweet_offensive_eval,0.19524576
58,aXhyra/demo_sentiment_31415,0.74800533
59,aXhyra/presentation_sentiment_1234567,0.75178003
60,nickmuchi/facebook-data2vec-finetuned-finance-classification,0.76644015
61,manueltonneau/bert-twitter-en-is-hired,0.887859
62,dhimskyy/wiki-bert,0.37433237
63,distilbert-base-uncased,0.69148856
64,albert-base-v2,0.7934656
65,michiyasunaga/LinkBERT-base,0.80458635
66,roberta-base,0.9207726
67,bert-large-uncased,0.3299283
68,Recognai/bert-base-spanish-wwm-cased-xnli,0.4517429
69,mrm8488/electricidad-base-finetuned-pawsx-es,0.45318955
70,dapang/distilroberta-base-mic-sym,0.83136594
71,Capreolus/bert-base-msmarco,0.7920647
72,Splend1dchan/bert-base-uncased-slue-goldtrascription-e3-lr1e-4,0.82398653
73,Jeevesh8/feather_berts_46,0.844615
74,cambridgeltl/guardian_news_distilbert-base-uncased,0.6748324
75,amyma21/sincere_question_classification,0.78119594
76,phailyoor/distilbert-base-uncased-finetuned-yahd,0.7261837
77,nreimers/mmarco-mMiniLMv2-L6-H384-v1,0.8068254
78,arianpasquali/distilbert-base-multilingual-cased-toxicity,0.5496106
79,strickvl/nlp-redaction-classifier,0.6502261
80,connectivity/feather_berts_28,0.8051149
81,chiragasarpota/scotus-bert,0.2419329
82,saattrupdan/job-listing-relevance-model,0.5251872
83,liangyuant/distilbert-base-uncased-finetuned-num200-450-405cls,0.70076996
84,DoyyingFace/bert-asian-hate-tweets-asian-unclean-freeze-4,0.7847491
85,Giyaseddin/distilroberta-base-finetuned-short-answer-assessment,0.827167
86,18811449050/bert_finetuning_test,0.67911583
87,Jeevesh8/lecun_feather_berts-51,0.8131472
88,Jeevesh8/feather_berts_96,0.82492054
89,AnonymousSub/dummy_2,0.5456662
90,viviastaari/finetuning-sentiment-analysis-en-id,0.4454004
91,finiteautomata/betonews-tweetcontext,0.38589087
92,Aureliano/distilbert-base-uncased-if,0.7394271
93,rmihaylov/roberta-base-sentiment-bg,0.557132
94,cardiffnlp/twitter-roberta-base-2021-124m,0.894224
95,Jeevesh8/lecun_feather_berts-8,0.79419035
96,anferico/bert-for-patents,0.55521846
97,morenolq/SumTO_FNS2020,0.7595138
98,Jeevesh8/lecun_feather_berts-7,0.8230896
99,matthewburke/korean_sentiment,0.44313514
100,waboucay/camembert-base-finetuned-xnli_fr-finetuned-nli-rua_wl,0.3190646
101,socialmediaie/TRAC2020_IBEN_B_bert-base-multilingual-uncased,0.6117836
102,korca/bae-roberta-base-boolq,0.85893697
103,cardiffnlp/bertweet-base-stance-climate,0.666434
104,zenkri/autotrain-Arabic_Poetry_by_Subject-920730230,0.76426667
105,CAMeL-Lab/bert-base-arabic-camelbert-da-sentiment,0.259234
106,classla/bcms-bertic-parlasent-bcs-ter,0.5399223
107,ali2066/DistilBERTFINAL_ctxSentence_TRAIN_editorials_TEST_NULL_second_train_set_null_False,0.9511541
108,Raychanan/COVID_RandomOver,0.10624114
109,JonatanGk/roberta-base-ca-finetuned-hate-speech-offensive-catalan,0.3715979
110,CAMeL-Lab/bert-base-arabic-camelbert-mix-did-nadi,0.42230976
111,Monsia/camembert-fr-covid-tweet-classification,0.6273683
112,ASCCCCCCCC/distilbert-base-chinese-amazon_zh_20000,0.4073797
113,kyleinincubated/autonlp-cat333-624217911,0.4360607
