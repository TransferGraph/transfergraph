,model,score
0,Jeevesh8/init_bert_ft_qqp-33,0.70136607
1,Jeevesh8/init_bert_ft_qqp-49,0.69322515
2,connectivity/bert_ft_qqp-7,0.69902086
3,Jeevesh8/bert_ft_qqp-40,0.7102281
4,Jeevesh8/bert_ft_qqp-9,0.6946107
5,Jeevesh8/bert_ft_qqp-88,0.70222974
6,connectivity/bert_ft_qqp-25,0.7013628
7,Jeevesh8/bert_ft_qqp-55,0.69918567
8,connectivity/bert_ft_qqp-1,0.69386226
9,Jeevesh8/bert_ft_qqp-39,0.6949207
10,connectivity/bert_ft_qqp-94,0.69993246
11,connectivity/bert_ft_qqp-96,0.6958761
12,Jeevesh8/init_bert_ft_qqp-24,0.6970785
13,Jeevesh8/bert_ft_qqp-68,0.69428307
14,Jeevesh8/init_bert_ft_qqp-28,0.6970785
15,connectivity/bert_ft_qqp-17,0.69477826
16,ali2066/finetuned_sentence_itr1_2e-05_all_26_02_2022-04_03_26,0.6858834
17,SetFit/distilbert-base-uncased__sst2__train-16-0,0.70172244
18,gchhablani/fnet-base-finetuned-sst2,0.67080003
19,aviator-neural/bert-base-uncased-sst2,0.7013395
20,SetFit/distilbert-base-uncased__sst2__train-32-9,0.69512695
21,Alassea/glue_sst_classifier,0.7021943
22,philschmid/tiny-distilbert-classification,0.47507107
23,moshew/bert-mini-sst2-distilled,0.65809596
24,ChrisUPM/BioBERT_Re_trained,0.6819152
25,vaariis/distilbert-base-uncased-finetuned-emotion,0.68731296
26,marcelcastrobr/sagemaker-distilbert-emotion,0.6853748
27,jasonyim2/distilbert-base-uncased-finetuned-emotion,0.68434674
28,abdelkader/distilbert-base-uncased-finetuned-emotion,0.67229104
29,moghis/distilbert-base-uncased-finetuned-emotion,0.68580246
30,uygarkurt/distilbert-base-uncased-finetuned-emotion,0.6863473
31,neibla/distilbert-base-uncased-finetuned-emotion,0.6804833
32,JB173/distilbert-base-uncased-finetuned-emotion,0.6707846
33,Nanatan/distilbert-base-uncased-finetuned-emotion,0.6826483
34,heranm/finetuning-sentiment-model-3000-samples,0.7036957
35,PrasunMishra/finetuning-sentiment-model-3000-samples,0.70216966
36,yukta10/finetuning-sentiment-model-3000-samples,0.6805782
37,ncduy/roberta-imdb-sentiment-analysis,0.74274784
38,markt23917/finetuning-sentiment-model-3000-samples,0.67688924
39,juliensimon/autonlp-imdb-demo-hf-16622767,0.6737147
40,fabriceyhc/bert-base-uncased-imdb,0.6863439
41,XSY/albert-base-v2-imdb-calssification,0.6788553
42,riyadhctg/distilbert-base-uncased-finetuned-cola,0.67612153
43,connectivity/cola_6ep_ft-33,0.6883268
44,connectivity/cola_6ep_ft-22,0.6894947
45,gchhablani/fnet-base-finetuned-cola,0.6557452
46,isakbos/Q8BERT_COLA_L_512,0.6404749
47,jaesun/distilbert-base-uncased-finetuned-cola,0.65372384
48,usami/distilbert-base-uncased-finetuned-cola,0.67615384
49,Jeevesh8/512seq_len_6ep_bert_ft_cola-91,0.68137
50,Jeevesh8/6ep_bert_ft_cola-47,0.67781305
51,connectivity/cola_6ep_ft-10,0.68743515
52,Jeevesh8/6ep_bert_ft_cola-12,0.68223757
53,Jeevesh8/bert_ft_cola-88,0.69158113
54,Jeevesh8/6ep_bert_ft_cola-29,0.68403375
55,vesteinn/XLMR-ENIS-finetuned-cola,0.67701226
56,navsad/navid_test_bert,0.6753032
57,Jeevesh8/bert_ft_cola-60,0.6860055
58,dapang/distilroberta-base-mic-sym,0.7418909
59,Capreolus/bert-base-msmarco,0.70510066
60,Splend1dchan/bert-base-uncased-slue-goldtrascription-e3-lr1e-4,0.71380407
61,Jeevesh8/feather_berts_46,0.70582217
62,JonatanGk/roberta-base-bne-finetuned-cyberbullying-spanish,0.6328453
63,cambridgeltl/guardian_news_distilbert-base-uncased,0.6736027
64,amyma21/sincere_question_classification,0.7071125
65,phailyoor/distilbert-base-uncased-finetuned-yahd,0.6744844
66,arianpasquali/distilbert-base-multilingual-cased-toxicity,0.6576936
67,connectivity/feather_berts_28,0.70905375
68,warwickai/fin-perceiver,0.7078051
69,liangyuant/distilbert-base-uncased-finetuned-num200-450-405cls,0.6847983
70,DoyyingFace/bert-asian-hate-tweets-asian-unclean-freeze-4,0.7073498
71,Jeevesh8/lecun_feather_berts-3,0.7075866
72,Giyaseddin/distilroberta-base-finetuned-short-answer-assessment,0.73580056
73,AnonymousSub/dummy_2,0.6570813
74,Jeevesh8/lecun_feather_berts-51,0.7124048
75,viviastaari/finetuning-sentiment-analysis-en-id,0.63406825
76,Aureliano/distilbert-base-uncased-if,0.6748866
77,rmihaylov/roberta-base-sentiment-bg,0.67994595
78,cardiffnlp/twitter-roberta-base-2021-124m,0.76975876
79,Jeevesh8/lecun_feather_berts-8,0.70991397
80,korca/bae-roberta-base-boolq,0.75337565
81,aditeyabaral/finetuned-sail2017-xlm-roberta-base,0.7076417
82,joebobby/finetuning-sentiment-model-5000-samples3,0.71868634
83,YeRyeongLee/electra-base-discriminator-finetuned-filtered-0602,0.52297765
84,Jeevesh8/feather_berts_92,0.73072386
85,ASCCCCCCCC/distilbert-base-chinese-amazon_zh_20000,0.6703322
86,matthewburke/korean_sentiment,0.62738323
87,IMSyPP/hate_speech_nl,0.6230029
88,cointegrated/roberta-base-formality,0.7497914
89,chiragasarpota/scotus-bert,0.52471185
90,IMSyPP/hate_speech_it,0.66399163
91,18811449050/bert_finetuning_test,0.67532873
92,finiteautomata/betonews-tweetcontext,0.640969
93,Jeevesh8/feather_berts_96,0.701801
94,Jeevesh8/lecun_feather_berts-7,0.7124048
95,mrm8488/codebert-base-finetuned-detect-insecure-code,0.7223834
96,socialmediaie/TRAC2020_IBEN_B_bert-base-multilingual-uncased,0.65482134
97,zenkri/autotrain-Arabic_Poetry_by_Subject-920730230,0.70299786
98,M47Labs/spanish_news_classification_headlines_untrained,0.679154
99,bondi/bert-semaphore-prediction-w4,0.6432509
100,classla/bcms-bertic-parlasent-bcs-ter,0.67243636
101,anferico/bert-for-patents,0.6437719
102,waboucay/camembert-base-finetuned-xnli_fr-finetuned-nli-rua_wl,0.5859076
103,ali2066/DistilBERTFINAL_ctxSentence_TRAIN_editorials_TEST_NULL_second_train_set_null_False,0.7784307
104,anvay/finetuning-cardiffnlp-sentiment-model,0.78082985
105,JonatanGk/roberta-base-ca-finetuned-hate-speech-offensive-catalan,0.65830284
106,Raychanan/COVID_RandomOver,0.54212946
107,Monsia/camembert-fr-covid-tweet-classification,0.686722
108,CAMeL-Lab/bert-base-arabic-camelbert-mix-did-nadi,0.6448641
109,kyleinincubated/autonlp-cat333-624217911,0.66895074
110,CAMeL-Lab/bert-base-arabic-camelbert-da-sentiment,0.62537783
111,cardiffnlp/bertweet-base-stance-climate,0.7423457
112,fgaim/tiroberta-geezswitch,0.67212385
113,nreimers/mmarco-mMiniLMv2-L6-H384-v1,0.7181009
114,strickvl/nlp-redaction-classifier,0.67852455
115,saattrupdan/job-listing-relevance-model,0.7123656
116,morenolq/SumTO_FNS2020,0.6812243
117,cross-encoder/ms-marco-MiniLM-L-4-v2,0.6700209
118,nurkayevaa/autonlp-bert-covid-407910458,0.7007688
119,SetFit/distilbert-base-uncased__hate_speech_offensive__train-16-1,0.6848917
120,crcb/isear_bert,0.74668604
121,robertou2/roberta-base-bne-finetuned-amazon_reviews_multi,0.69568866
122,milyiyo/selectra-small-finetuned-amazon-review,0.6596483
123,Anthos23/FS-distilroberta-fine-tuned,0.74017006
124,oferweintraub/bert-base-finance-sentiment-noisy-search,0.6977018
125,pietrotrope/emotion_final,0.6917341
126,aXhyra/emotion_trained_31415,0.69047177
127,aXhyra/presentation_emotion_31415,0.69359064
128,Recognai/bert-base-spanish-wwm-cased-xnli,0.6442826
129,JNK789/distilbert-base-uncased-finetuned-tweets-emoji-dataset,0.5056384
130,anirudh21/bert-base-uncased-finetuned-qnli,0.7046147
131,Alireza1044/albert-base-v2-qnli,0.6770637
132,aXhyra/demo_sentiment_31415,0.69078803
133,aXhyra/presentation_sentiment_1234567,0.7055553
134,jb2k/bert-base-multilingual-cased-language-detection,0.6455852
135,vinai/bertweet-base,0.7674523
136,justinqbui/bertweet-covid19-base-uncased-pretraining-covid-vaccine-tweets,0.75190926
137,vinai/bertweet-covid19-base-cased,0.69191533
138,vinai/bertweet-covid19-base-uncased,0.77158153
139,distilbert-base-uncased,0.6914066
140,bert-base-uncased,0.70348895
141,roberta-base,0.769992
142,albert-base-v2,0.7013247
143,bert-base-cased,0.71172744
144,dhimskyy/wiki-bert,0.6423054
145,michiyasunaga/LinkBERT-base,0.71477616
146,roberta-large,0.5812691
147,bert-large-uncased,0.60017186
148,boychaboy/MNLI_roberta-base,0.7805672
149,ishan/bert-base-uncased-mnli,0.6987176
150,emrecan/bert-base-multilingual-cased-snli_tr,0.6970298
151,elozano/tweet_offensive_eval,0.55994445
152,Hate-speech-CNERG/bert-base-uncased-hatexplain-rationale-two,0.71853286
153,aychang/bert-base-cased-trec-coarse,0.68583846
154,gchhablani/bert-base-cased-finetuned-wnli,0.689665
155,nickmuchi/facebook-data2vec-finetuned-finance-classification,0.6805452
156,w11wo/sundanese-bert-base-emotion-classifier,0.65451735
157,gchhablani/bert-base-cased-finetuned-rte,0.70167947
158,mrm8488/electricidad-base-finetuned-pawsx-es,0.6543558
159,manueltonneau/bert-twitter-en-is-hired,0.73848575
160,Guscode/DKbert-hatespeech-detection,0.64456093
161,cross-encoder/quora-distilroberta-base,0.7186968
162,navteca/quora-roberta-base,0.72530746
163,cross-encoder/quora-roberta-base,0.7206086
