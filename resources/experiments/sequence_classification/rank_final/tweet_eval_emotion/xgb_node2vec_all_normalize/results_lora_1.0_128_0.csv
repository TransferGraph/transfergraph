,model,score
0,Jeevesh8/init_bert_ft_qqp-33,0.821582
1,Jeevesh8/init_bert_ft_qqp-33,0.84057415
2,Jeevesh8/init_bert_ft_qqp-49,0.8636221
3,Jeevesh8/init_bert_ft_qqp-49,0.7982389
4,connectivity/bert_ft_qqp-7,0.84965104
5,connectivity/bert_ft_qqp-7,0.83278716
6,Jeevesh8/bert_ft_qqp-40,0.8848488
7,Jeevesh8/bert_ft_qqp-40,0.81529945
8,Jeevesh8/bert_ft_qqp-9,0.8437436
9,Jeevesh8/bert_ft_qqp-9,0.8115197
10,Jeevesh8/bert_ft_qqp-88,0.81961536
11,Jeevesh8/bert_ft_qqp-88,0.8041248
12,connectivity/bert_ft_qqp-25,0.8165635
13,connectivity/bert_ft_qqp-25,0.80723184
14,Jeevesh8/bert_ft_qqp-55,0.8403451
15,Jeevesh8/bert_ft_qqp-55,0.80721366
16,connectivity/bert_ft_qqp-1,0.83036464
17,connectivity/bert_ft_qqp-1,0.819885
18,Jeevesh8/bert_ft_qqp-39,0.84246325
19,Jeevesh8/bert_ft_qqp-39,0.819248
20,connectivity/bert_ft_qqp-94,0.8025536
21,connectivity/bert_ft_qqp-94,0.79015404
22,connectivity/bert_ft_qqp-96,0.8179869
23,connectivity/bert_ft_qqp-96,0.8092776
24,Jeevesh8/init_bert_ft_qqp-24,0.81817555
25,Jeevesh8/init_bert_ft_qqp-24,0.801268
26,Jeevesh8/bert_ft_qqp-68,0.7772264
27,Jeevesh8/bert_ft_qqp-68,0.8020924
28,Jeevesh8/init_bert_ft_qqp-28,0.8354672
29,Jeevesh8/init_bert_ft_qqp-28,0.7994584
30,connectivity/bert_ft_qqp-17,0.86517566
31,connectivity/bert_ft_qqp-17,0.8067103
32,ali2066/finetuned_sentence_itr1_2e-05_all_26_02_2022-04_03_26,0.85412157
33,ali2066/finetuned_sentence_itr1_2e-05_all_26_02_2022-04_03_26,0.84970516
34,SetFit/distilbert-base-uncased__sst2__train-16-0,0.8319788
35,SetFit/distilbert-base-uncased__sst2__train-16-0,0.8403498
36,aviator-neural/bert-base-uncased-sst2,0.848771
37,aviator-neural/bert-base-uncased-sst2,0.8105196
38,SetFit/distilbert-base-uncased__sst2__train-32-9,0.8329828
39,SetFit/distilbert-base-uncased__sst2__train-32-9,0.8291412
40,Alassea/glue_sst_classifier,0.85122204
41,Alassea/glue_sst_classifier,0.8383381
42,philschmid/tiny-distilbert-classification,0.4609765
43,philschmid/tiny-distilbert-classification,0.45972872
44,moshew/bert-mini-sst2-distilled,0.82722396
45,moshew/bert-mini-sst2-distilled,0.83648723
46,ChrisUPM/BioBERT_Re_trained,0.8208451
47,ChrisUPM/BioBERT_Re_trained,0.7962075
48,vaariis/distilbert-base-uncased-finetuned-emotion,0.81919205
49,vaariis/distilbert-base-uncased-finetuned-emotion,0.8439699
50,marcelcastrobr/sagemaker-distilbert-emotion,0.8145035
51,marcelcastrobr/sagemaker-distilbert-emotion,0.8183939
52,jasonyim2/distilbert-base-uncased-finetuned-emotion,0.8141252
53,jasonyim2/distilbert-base-uncased-finetuned-emotion,0.8278678
54,abdelkader/distilbert-base-uncased-finetuned-emotion,0.8261145
55,abdelkader/distilbert-base-uncased-finetuned-emotion,0.8146516
56,moghis/distilbert-base-uncased-finetuned-emotion,0.82456905
57,moghis/distilbert-base-uncased-finetuned-emotion,0.8182122
58,uygarkurt/distilbert-base-uncased-finetuned-emotion,0.8219319
59,uygarkurt/distilbert-base-uncased-finetuned-emotion,0.81285644
60,neibla/distilbert-base-uncased-finetuned-emotion,0.824546
61,neibla/distilbert-base-uncased-finetuned-emotion,0.84335977
62,JB173/distilbert-base-uncased-finetuned-emotion,0.82043624
63,JB173/distilbert-base-uncased-finetuned-emotion,0.8358678
64,Nanatan/distilbert-base-uncased-finetuned-emotion,0.82764727
65,Nanatan/distilbert-base-uncased-finetuned-emotion,0.80415696
66,heranm/finetuning-sentiment-model-3000-samples,0.83313936
67,heranm/finetuning-sentiment-model-3000-samples,0.83313936
68,PrasunMishra/finetuning-sentiment-model-3000-samples,0.8367585
69,PrasunMishra/finetuning-sentiment-model-3000-samples,0.83712983
70,yukta10/finetuning-sentiment-model-3000-samples,0.8239648
71,yukta10/finetuning-sentiment-model-3000-samples,0.8372467
72,ncduy/roberta-imdb-sentiment-analysis,0.8372572
73,ncduy/roberta-imdb-sentiment-analysis,0.81787443
74,markt23917/finetuning-sentiment-model-3000-samples,0.83156663
75,markt23917/finetuning-sentiment-model-3000-samples,0.8267368
76,juliensimon/autonlp-imdb-demo-hf-16622767,0.83590394
77,juliensimon/autonlp-imdb-demo-hf-16622767,0.836054
78,fabriceyhc/bert-base-uncased-imdb,0.7800506
79,fabriceyhc/bert-base-uncased-imdb,0.7673835
80,riyadhctg/distilbert-base-uncased-finetuned-cola,0.83189875
81,riyadhctg/distilbert-base-uncased-finetuned-cola,0.8518271
82,connectivity/cola_6ep_ft-33,0.8711475
83,connectivity/cola_6ep_ft-33,0.82635224
84,connectivity/cola_6ep_ft-22,0.8699294
85,connectivity/cola_6ep_ft-22,0.8273823
86,isakbos/Q8BERT_COLA_L_512,0.70759755
87,isakbos/Q8BERT_COLA_L_512,0.66148883
88,jaesun/distilbert-base-uncased-finetuned-cola,0.81954044
89,jaesun/distilbert-base-uncased-finetuned-cola,0.8332594
90,usami/distilbert-base-uncased-finetuned-cola,0.8311257
91,usami/distilbert-base-uncased-finetuned-cola,0.8335059
92,Jeevesh8/512seq_len_6ep_bert_ft_cola-91,0.8638915
93,Jeevesh8/512seq_len_6ep_bert_ft_cola-91,0.80914307
94,Jeevesh8/6ep_bert_ft_cola-47,0.8604973
95,Jeevesh8/6ep_bert_ft_cola-47,0.82185835
96,connectivity/cola_6ep_ft-10,0.8350002
97,connectivity/cola_6ep_ft-10,0.83486533
98,Jeevesh8/6ep_bert_ft_cola-12,0.8337943
99,Jeevesh8/6ep_bert_ft_cola-12,0.8371171
100,Jeevesh8/bert_ft_cola-88,0.8380443
101,Jeevesh8/bert_ft_cola-88,0.8452233
102,Jeevesh8/6ep_bert_ft_cola-29,0.82782704
103,Jeevesh8/6ep_bert_ft_cola-29,0.8403927
104,vesteinn/XLMR-ENIS-finetuned-cola,0.83100706
105,vesteinn/XLMR-ENIS-finetuned-cola,0.8347064
106,navsad/navid_test_bert,0.83769035
107,navsad/navid_test_bert,0.8054998
108,Jeevesh8/bert_ft_cola-60,0.84306854
109,Jeevesh8/bert_ft_cola-60,0.824463
110,dapang/distilroberta-base-mic-sym,0.855916
111,dapang/distilroberta-base-mic-sym,0.83520824
112,Capreolus/bert-base-msmarco,0.8462998
113,Capreolus/bert-base-msmarco,0.8433175
114,Splend1dchan/bert-base-uncased-slue-goldtrascription-e3-lr1e-4,0.87063646
115,Splend1dchan/bert-base-uncased-slue-goldtrascription-e3-lr1e-4,0.8419324
116,Jeevesh8/feather_berts_46,0.8688647
117,Jeevesh8/feather_berts_46,0.84686553
118,JonatanGk/roberta-base-bne-finetuned-cyberbullying-spanish,0.68420565
119,JonatanGk/roberta-base-bne-finetuned-cyberbullying-spanish,0.6876491
120,cambridgeltl/guardian_news_distilbert-base-uncased,0.8271639
121,cambridgeltl/guardian_news_distilbert-base-uncased,0.8343165
122,amyma21/sincere_question_classification,0.84238976
123,amyma21/sincere_question_classification,0.84387875
124,phailyoor/distilbert-base-uncased-finetuned-yahd,0.80494446
125,phailyoor/distilbert-base-uncased-finetuned-yahd,0.7893563
126,arianpasquali/distilbert-base-multilingual-cased-toxicity,0.78316534
127,arianpasquali/distilbert-base-multilingual-cased-toxicity,0.7820328
128,connectivity/feather_berts_28,0.8469027
129,connectivity/feather_berts_28,0.8223474
130,liangyuant/distilbert-base-uncased-finetuned-num200-450-405cls,0.8179798
131,liangyuant/distilbert-base-uncased-finetuned-num200-450-405cls,0.8022497
132,DoyyingFace/bert-asian-hate-tweets-asian-unclean-freeze-4,0.85293186
133,DoyyingFace/bert-asian-hate-tweets-asian-unclean-freeze-4,0.84589326
134,Jeevesh8/lecun_feather_berts-3,0.8569107
135,Jeevesh8/lecun_feather_berts-3,0.83411115
136,Giyaseddin/distilroberta-base-finetuned-short-answer-assessment,0.8511855
137,Giyaseddin/distilroberta-base-finetuned-short-answer-assessment,0.824753
138,AnonymousSub/dummy_2,0.75885093
139,AnonymousSub/dummy_2,0.75326633
140,Jeevesh8/lecun_feather_berts-51,0.86833197
141,Jeevesh8/lecun_feather_berts-51,0.84543645
142,viviastaari/finetuning-sentiment-analysis-en-id,0.72593516
143,viviastaari/finetuning-sentiment-analysis-en-id,0.7233815
144,Aureliano/distilbert-base-uncased-if,0.8337198
145,Aureliano/distilbert-base-uncased-if,0.8277124
146,rmihaylov/roberta-base-sentiment-bg,0.78316116
147,rmihaylov/roberta-base-sentiment-bg,0.77554744
148,cardiffnlp/twitter-roberta-base-2021-124m,0.84208626
149,cardiffnlp/twitter-roberta-base-2021-124m,0.8393961
150,Jeevesh8/lecun_feather_berts-8,0.8329161
151,Jeevesh8/lecun_feather_berts-8,0.827139
152,korca/bae-roberta-base-boolq,0.8465022
153,korca/bae-roberta-base-boolq,0.7976581
154,aditeyabaral/finetuned-sail2017-xlm-roberta-base,0.8130579
155,aditeyabaral/finetuned-sail2017-xlm-roberta-base,0.8127653
156,joebobby/finetuning-sentiment-model-5000-samples3,0.84639484
157,joebobby/finetuning-sentiment-model-5000-samples3,0.84346014
158,Jeevesh8/feather_berts_92,0.8451714
159,Jeevesh8/feather_berts_92,0.830979
160,ASCCCCCCCC/distilbert-base-chinese-amazon_zh_20000,0.7487969
161,ASCCCCCCCC/distilbert-base-chinese-amazon_zh_20000,0.7323822
162,matthewburke/korean_sentiment,0.6801122
163,matthewburke/korean_sentiment,0.6921248
164,IMSyPP/hate_speech_nl,0.7132562
165,IMSyPP/hate_speech_nl,0.71454453
166,cointegrated/roberta-base-formality,0.8470314
167,cointegrated/roberta-base-formality,0.82703114
168,IMSyPP/hate_speech_it,0.767682
169,IMSyPP/hate_speech_it,0.7617569
170,18811449050/bert_finetuning_test,0.83187807
171,18811449050/bert_finetuning_test,0.8194817
172,finiteautomata/betonews-tweetcontext,0.714217
173,finiteautomata/betonews-tweetcontext,0.73086834
174,Jeevesh8/feather_berts_96,0.8503847
175,Jeevesh8/feather_berts_96,0.83684695
176,Jeevesh8/lecun_feather_berts-7,0.8786867
177,Jeevesh8/lecun_feather_berts-7,0.8421483
178,mrm8488/codebert-base-finetuned-detect-insecure-code,0.79204506
179,mrm8488/codebert-base-finetuned-detect-insecure-code,0.77779114
180,socialmediaie/TRAC2020_IBEN_B_bert-base-multilingual-uncased,0.78104657
181,socialmediaie/TRAC2020_IBEN_B_bert-base-multilingual-uncased,0.76512223
182,zenkri/autotrain-Arabic_Poetry_by_Subject-920730230,0.8172467
183,zenkri/autotrain-Arabic_Poetry_by_Subject-920730230,0.808132
184,M47Labs/spanish_news_classification_headlines_untrained,0.7278418
185,M47Labs/spanish_news_classification_headlines_untrained,0.73629653
186,bondi/bert-semaphore-prediction-w4,0.7237873
187,bondi/bert-semaphore-prediction-w4,0.7344701
188,classla/bcms-bertic-parlasent-bcs-ter,0.7604407
189,classla/bcms-bertic-parlasent-bcs-ter,0.7351332
190,anferico/bert-for-patents,0.768893
191,anferico/bert-for-patents,0.7720962
192,ali2066/DistilBERTFINAL_ctxSentence_TRAIN_editorials_TEST_NULL_second_train_set_null_False,0.85120934
193,ali2066/DistilBERTFINAL_ctxSentence_TRAIN_editorials_TEST_NULL_second_train_set_null_False,0.8313991
194,anvay/finetuning-cardiffnlp-sentiment-model,0.8400707
195,anvay/finetuning-cardiffnlp-sentiment-model,0.8243831
196,JonatanGk/roberta-base-ca-finetuned-hate-speech-offensive-catalan,0.70533335
197,JonatanGk/roberta-base-ca-finetuned-hate-speech-offensive-catalan,0.71770406
198,Raychanan/COVID_RandomOver,0.5554505
199,Raychanan/COVID_RandomOver,0.5625703
200,kyleinincubated/autonlp-cat333-624217911,0.677204
201,kyleinincubated/autonlp-cat333-624217911,0.6963079
202,cardiffnlp/bertweet-base-stance-climate,0.82848036
203,cardiffnlp/bertweet-base-stance-climate,0.8075749
204,nreimers/mmarco-mMiniLMv2-L6-H384-v1,0.80802125
205,nreimers/mmarco-mMiniLMv2-L6-H384-v1,0.80859816
206,strickvl/nlp-redaction-classifier,0.7955055
207,strickvl/nlp-redaction-classifier,0.8032688
208,saattrupdan/job-listing-relevance-model,0.7950538
209,saattrupdan/job-listing-relevance-model,0.7820642
210,morenolq/SumTO_FNS2020,0.81419617
211,morenolq/SumTO_FNS2020,0.8021497
212,cross-encoder/ms-marco-MiniLM-L-4-v2,0.8268612
213,cross-encoder/ms-marco-MiniLM-L-4-v2,0.83026725
214,nurkayevaa/autonlp-bert-covid-407910458,0.836002
215,nurkayevaa/autonlp-bert-covid-407910458,0.8364354
216,SetFit/distilbert-base-uncased__hate_speech_offensive__train-16-1,0.8366336
217,SetFit/distilbert-base-uncased__hate_speech_offensive__train-16-1,0.8375377
218,crcb/isear_bert,0.83553654
219,crcb/isear_bert,0.8231528
220,robertou2/roberta-base-bne-finetuned-amazon_reviews_multi,0.7543969
221,robertou2/roberta-base-bne-finetuned-amazon_reviews_multi,0.74617094
222,milyiyo/selectra-small-finetuned-amazon-review,0.6973585
223,milyiyo/selectra-small-finetuned-amazon-review,0.7033518
224,Anthos23/FS-distilroberta-fine-tuned,0.8426791
225,Anthos23/FS-distilroberta-fine-tuned,0.86231333
226,oferweintraub/bert-base-finance-sentiment-noisy-search,0.8666823
227,oferweintraub/bert-base-finance-sentiment-noisy-search,0.8354634
228,pietrotrope/emotion_final,0.8373241
229,pietrotrope/emotion_final,0.84597254
230,aXhyra/emotion_trained_31415,0.8343055
231,aXhyra/emotion_trained_31415,0.82601786
232,aXhyra/presentation_emotion_31415,0.82237047
233,aXhyra/presentation_emotion_31415,0.82033694
234,Recognai/bert-base-spanish-wwm-cased-xnli,0.7371259
235,Recognai/bert-base-spanish-wwm-cased-xnli,0.73154575
236,anirudh21/bert-base-uncased-finetuned-qnli,0.8748976
237,anirudh21/bert-base-uncased-finetuned-qnli,0.8384688
238,aXhyra/demo_sentiment_31415,0.8479837
239,aXhyra/demo_sentiment_31415,0.848823
240,aXhyra/presentation_sentiment_1234567,0.8436413
241,aXhyra/presentation_sentiment_1234567,0.83637315
242,jb2k/bert-base-multilingual-cased-language-detection,0.7438476
243,jb2k/bert-base-multilingual-cased-language-detection,0.7276599
244,vinai/bertweet-base,0.83933026
245,vinai/bertweet-base,0.83043116
246,justinqbui/bertweet-covid19-base-uncased-pretraining-covid-vaccine-tweets,0.82869726
247,justinqbui/bertweet-covid19-base-uncased-pretraining-covid-vaccine-tweets,0.80630517
248,vinai/bertweet-covid19-base-cased,0.8460215
249,vinai/bertweet-covid19-base-cased,0.8236523
250,vinai/bertweet-covid19-base-uncased,0.83799475
251,vinai/bertweet-covid19-base-uncased,0.8161498
252,distilbert-base-uncased,0.8344419
253,distilbert-base-uncased,0.8313648
254,bert-base-uncased,0.87669915
255,bert-base-uncased,0.8455664
256,roberta-base,0.8369653
257,roberta-base,0.83689535
258,bert-base-cased,0.8449556
259,bert-base-cased,0.8401427
260,dhimskyy/wiki-bert,0.6725928
261,dhimskyy/wiki-bert,0.6424366
262,michiyasunaga/LinkBERT-base,0.8661886
263,michiyasunaga/LinkBERT-base,0.845078
264,bert-large-uncased,0.77464026
265,bert-large-uncased,0.8004259
266,roberta-large,0.81964546
267,roberta-large,0.8444546
268,boychaboy/MNLI_roberta-base,0.84528965
269,boychaboy/MNLI_roberta-base,0.83099127
270,ishan/bert-base-uncased-mnli,0.82523376
271,ishan/bert-base-uncased-mnli,0.815289
272,emrecan/bert-base-multilingual-cased-snli_tr,0.8023365
273,emrecan/bert-base-multilingual-cased-snli_tr,0.76492035
274,elozano/tweet_offensive_eval,0.71249664
275,elozano/tweet_offensive_eval,0.7334161
276,Hate-speech-CNERG/bert-base-uncased-hatexplain-rationale-two,0.8506629
277,Hate-speech-CNERG/bert-base-uncased-hatexplain-rationale-two,0.8474941
278,aychang/bert-base-cased-trec-coarse,0.8210741
279,aychang/bert-base-cased-trec-coarse,0.8210056
280,gchhablani/bert-base-cased-finetuned-wnli,0.8286702
281,gchhablani/bert-base-cased-finetuned-wnli,0.8252437
282,w11wo/sundanese-bert-base-emotion-classifier,0.7003441
283,w11wo/sundanese-bert-base-emotion-classifier,0.69108915
284,gchhablani/bert-base-cased-finetuned-rte,0.810027
285,gchhablani/bert-base-cased-finetuned-rte,0.8100461
286,mrm8488/electricidad-base-finetuned-pawsx-es,0.7030601
287,mrm8488/electricidad-base-finetuned-pawsx-es,0.7067247
288,manueltonneau/bert-twitter-en-is-hired,0.8379811
289,manueltonneau/bert-twitter-en-is-hired,0.83471876
290,Guscode/DKbert-hatespeech-detection,0.76282614
291,Guscode/DKbert-hatespeech-detection,0.72874546
292,cross-encoder/quora-distilroberta-base,0.81782734
293,cross-encoder/quora-distilroberta-base,0.804054
294,navteca/quora-roberta-base,0.8107001
295,navteca/quora-roberta-base,0.7939708
296,cross-encoder/quora-roberta-base,0.82804745
297,cross-encoder/quora-roberta-base,0.80839443
