,model,score
0,Guscode/DKbert-hatespeech-detection,0.4819389809252857
1,robertou2/roberta-base-bne-finetuned-amazon_reviews_multi,0.7672375291256457
2,milyiyo/selectra-small-finetuned-amazon-review,0.5597367962364843
3,SetFit/distilbert-base-uncased__hate_speech_offensive__train-16-1,0.7006073869455625
4,vinai/bertweet-base,0.7511932635291921
5,vinai/bertweet-covid19-base-cased,0.7131687680963426
6,justinqbui/bertweet-covid19-base-uncased-pretraining-covid-vaccine-tweets,0.9715956925978325
7,vinai/bertweet-covid19-base-uncased,0.6805598593019968
8,jb2k/bert-base-multilingual-cased-language-detection,0.5820402718167813
9,crcb/isear_bert,0.8414643173768
10,vaariis/distilbert-base-uncased-finetuned-emotion,0.7815824759200223
11,marcelcastrobr/sagemaker-distilbert-emotion,0.7680029969372498
12,jasonyim2/distilbert-base-uncased-finetuned-emotion,0.7576150620463654
13,abdelkader/distilbert-base-uncased-finetuned-emotion,0.7514847963465182
14,moghis/distilbert-base-uncased-finetuned-emotion,0.7263177479977614
15,uygarkurt/distilbert-base-uncased-finetuned-emotion,0.7964353665337457
16,neibla/distilbert-base-uncased-finetuned-emotion,0.749896276224403
17,JB173/distilbert-base-uncased-finetuned-emotion,0.7574187793628677
18,Nanatan/distilbert-base-uncased-finetuned-emotion,0.8062238080055841
19,riyadhctg/distilbert-base-uncased-finetuned-cola,0.7790320478507463
20,connectivity/cola_6ep_ft-33,0.7549405035188986
21,connectivity/cola_6ep_ft-22,0.7968233814373626
22,gchhablani/fnet-base-finetuned-cola,0.7551980262532908
23,vesteinn/XLMR-ENIS-finetuned-cola,0.7360756323004789
24,isakbos/Q8BERT_COLA_L_512,0.5798050947326576
25,jaesun/distilbert-base-uncased-finetuned-cola,0.6715340304137069
26,usami/distilbert-base-uncased-finetuned-cola,0.7348735242035717
27,Jeevesh8/512seq_len_6ep_bert_ft_cola-91,0.7493576265622036
28,Jeevesh8/6ep_bert_ft_cola-47,0.7551250789234829
29,connectivity/cola_6ep_ft-10,0.8354048085127168
30,Jeevesh8/6ep_bert_ft_cola-12,0.774523943398225
31,Jeevesh8/6ep_bert_ft_cola-29,0.7204685651107171
32,Jeevesh8/bert_ft_cola-60,0.7578154211566915
33,navsad/navid_test_bert,0.759366665404828
34,Jeevesh8/bert_ft_cola-88,0.7554622533796916
35,ishan/bert-base-uncased-mnli,0.8694433799404137
36,boychaboy/MNLI_roberta-base,0.8142990270384554
37,anirudh21/bert-base-uncased-finetuned-qnli,0.8043296501220233
38,Alireza1044/albert-base-v2-qnli,0.7937748451855885
39,Jeevesh8/init_bert_ft_qqp-33,0.849301008307821
40,Jeevesh8/init_bert_ft_qqp-49,0.7763688206417351
41,connectivity/bert_ft_qqp-7,0.8328778165365948
42,Jeevesh8/bert_ft_qqp-40,0.8089735870138627
43,Jeevesh8/bert_ft_qqp-9,0.8326048517300648
44,Jeevesh8/bert_ft_qqp-88,0.8599376449793836
45,connectivity/bert_ft_qqp-25,0.8328184053048033
46,Jeevesh8/bert_ft_qqp-55,0.7928361979355592
47,Jeevesh8/init_bert_ft_qqp-24,0.8317148879963947
48,Jeevesh8/init_bert_ft_qqp-28,0.8359503011530729
49,connectivity/bert_ft_qqp-17,0.7546940425086505
50,Jeevesh8/bert_ft_qqp-68,0.7047161142338421
51,connectivity/bert_ft_qqp-1,0.8242906085562911
52,connectivity/bert_ft_qqp-94,0.748195336145358
53,Jeevesh8/bert_ft_qqp-39,0.7385432781789394
54,connectivity/bert_ft_qqp-96,0.7854224207696313
55,gchhablani/bert-base-cased-finetuned-rte,0.7477914139811014
56,philschmid/tiny-distilbert-classification,0.13752990909278184
57,ali2066/finetuned_sentence_itr1_2e-05_all_26_02_2022-04_03_26,0.7600158698820244
58,SetFit/distilbert-base-uncased__sst2__train-16-0,0.7964096864690311
59,gchhablani/fnet-base-finetuned-sst2,0.6035708449099599
60,moshew/bert-mini-sst2-distilled,0.7321363362228194
61,aviator-neural/bert-base-uncased-sst2,0.790651364326188
62,SetFit/distilbert-base-uncased__sst2__train-32-9,0.7148478950967758
63,Alassea/glue_sst_classifier,0.8007928785664595
64,ChrisUPM/BioBERT_Re_trained,0.7686473795500183
65,gchhablani/bert-base-cased-finetuned-wnli,0.7865163207617367
66,Hate-speech-CNERG/bert-base-uncased-hatexplain-rationale-two,0.8031078265939398
67,heranm/finetuning-sentiment-model-3000-samples,0.7866270227765824
68,PrasunMishra/finetuning-sentiment-model-3000-samples,0.7309082229241408
69,yukta10/finetuning-sentiment-model-3000-samples,0.7074267618461091
70,ncduy/roberta-imdb-sentiment-analysis,0.9044332627455537
71,markt23917/finetuning-sentiment-model-3000-samples,0.7270064071374758
72,juliensimon/autonlp-imdb-demo-hf-16622767,0.81668160768697
73,XSY/albert-base-v2-imdb-calssification,0.6444925040807317
74,fabriceyhc/bert-base-uncased-imdb,0.7407074815955774
75,Anthos23/FS-distilroberta-fine-tuned,0.8336357773276177
76,oferweintraub/bert-base-finance-sentiment-noisy-search,0.7797619402647932
77,emrecan/bert-base-multilingual-cased-snli_tr,0.6938438926470364
78,nurkayevaa/autonlp-bert-covid-407910458,0.8012537142926972
79,cross-encoder/quora-distilroberta-base,0.9881468859655105
80,navteca/quora-roberta-base,0.7461654920329308
81,cross-encoder/quora-roberta-base,0.7005633125238434
82,w11wo/sundanese-bert-base-emotion-classifier,0.5114608095492794
83,aychang/bert-base-cased-trec-coarse,0.7692264526503094
84,JNK789/distilbert-base-uncased-finetuned-tweets-emoji-dataset,-0.014949656113198206
85,pietrotrope/emotion_final,0.7087930003400653
86,aXhyra/emotion_trained_31415,0.7761154483351338
87,aXhyra/presentation_emotion_31415,0.7653731465288116
88,elozano/tweet_offensive_eval,0.5797124180203694
89,aXhyra/demo_sentiment_31415,0.7647034642956214
90,aXhyra/presentation_sentiment_1234567,0.7119178125954995
91,nickmuchi/facebook-data2vec-finetuned-finance-classification,0.8161513205581227
92,manueltonneau/bert-twitter-en-is-hired,0.8847446948407443
93,bert-base-uncased,0.8057563358229761
94,dhimskyy/wiki-bert,0.6592203989112719
95,distilbert-base-uncased,0.802934251305961
96,albert-base-v2,0.7778344559071592
97,bert-base-cased,0.8992495323258822
98,michiyasunaga/LinkBERT-base,0.7367016077087105
99,roberta-base,0.8815242068541852
100,bert-large-uncased,0.5163689041521099
101,roberta-large,0.4796332564898161
102,Recognai/bert-base-spanish-wwm-cased-xnli,0.6579070211495516
103,mrm8488/electricidad-base-finetuned-pawsx-es,0.5916147066761459
104,dapang/distilroberta-base-mic-sym,0.8108836174943901
105,Capreolus/bert-base-msmarco,0.7496396074666043
106,Splend1dchan/bert-base-uncased-slue-goldtrascription-e3-lr1e-4,0.7863602954280564
107,Jeevesh8/feather_berts_46,0.8215780343314176
108,JonatanGk/roberta-base-bne-finetuned-cyberbullying-spanish,0.49102317621859415
109,cambridgeltl/guardian_news_distilbert-base-uncased,0.7158644659339745
110,amyma21/sincere_question_classification,0.8059065597670989
111,phailyoor/distilbert-base-uncased-finetuned-yahd,0.700088072295647
112,nreimers/mmarco-mMiniLMv2-L6-H384-v1,0.5888466584738782
113,arianpasquali/distilbert-base-multilingual-cased-toxicity,0.6319230819593364
114,strickvl/nlp-redaction-classifier,0.4437109249716724
115,connectivity/feather_berts_28,0.8448542474914666
116,IMSyPP/hate_speech_it,0.6588910107600332
117,chiragasarpota/scotus-bert,0.47868900342776977
118,saattrupdan/job-listing-relevance-model,0.8511074755330921
119,warwickai/fin-perceiver,0.6643091266164501
120,liangyuant/distilbert-base-uncased-finetuned-num200-450-405cls,0.7068117571732979
121,DoyyingFace/bert-asian-hate-tweets-asian-unclean-freeze-4,0.8168872385823595
122,Jeevesh8/lecun_feather_berts-3,0.84106410885662
123,Giyaseddin/distilroberta-base-finetuned-short-answer-assessment,0.7782189038555323
124,18811449050/bert_finetuning_test,0.7706141466083375
125,Jeevesh8/lecun_feather_berts-51,0.8014275982677856
126,Jeevesh8/feather_berts_96,0.6962736842364409
127,AnonymousSub/dummy_2,0.6618907702989305
128,viviastaari/finetuning-sentiment-analysis-en-id,0.6229032662069167
129,finiteautomata/betonews-tweetcontext,0.6260453803185747
130,Aureliano/distilbert-base-uncased-if,0.7333781834710889
131,rmihaylov/roberta-base-sentiment-bg,0.6396826317381131
132,cardiffnlp/twitter-roberta-base-2021-124m,0.8462813065250294
133,Jeevesh8/lecun_feather_berts-8,0.7954485880738469
134,anferico/bert-for-patents,0.7107192382789146
135,morenolq/SumTO_FNS2020,0.6260372422235605
136,IMSyPP/hate_speech_nl,0.44494461255085493
137,cross-encoder/ms-marco-MiniLM-L-4-v2,0.46260788902237704
138,Jeevesh8/lecun_feather_berts-7,0.7665789199637996
139,matthewburke/korean_sentiment,0.6442144742183419
140,waboucay/camembert-base-finetuned-xnli_fr-finetuned-nli-rua_wl,0.5834708089728957
141,aditeyabaral/finetuned-sail2017-xlm-roberta-base,0.8023345152268896
142,socialmediaie/TRAC2020_IBEN_B_bert-base-multilingual-uncased,0.6775559251109751
143,korca/bae-roberta-base-boolq,0.7897443599836144
144,mrm8488/codebert-base-finetuned-detect-insecure-code,0.7704051248807409
145,M47Labs/spanish_news_classification_headlines_untrained,0.6349080313139209
146,cardiffnlp/bertweet-base-stance-climate,0.7254863081498757
147,zenkri/autotrain-Arabic_Poetry_by_Subject-920730230,0.7992821653317697
148,cointegrated/roberta-base-formality,0.8059274235856133
149,fgaim/tiroberta-geezswitch,0.6291002545107501
150,CAMeL-Lab/bert-base-arabic-camelbert-da-sentiment,0.49371285115573615
151,bondi/bert-semaphore-prediction-w4,0.6066527034897206
152,classla/bcms-bertic-parlasent-bcs-ter,0.689130702910221
153,ali2066/DistilBERTFINAL_ctxSentence_TRAIN_editorials_TEST_NULL_second_train_set_null_False,0.8657944993819248
154,Raychanan/COVID_RandomOver,-0.029080089669767384
155,anvay/finetuning-cardiffnlp-sentiment-model,0.8301013282669588
156,joebobby/finetuning-sentiment-model-5000-samples3,0.8964157851328429
157,JonatanGk/roberta-base-ca-finetuned-hate-speech-offensive-catalan,0.7089588648988225
158,Jeevesh8/feather_berts_92,0.8097596481215211
159,YeRyeongLee/electra-base-discriminator-finetuned-filtered-0602,0.20723805241754578
160,CAMeL-Lab/bert-base-arabic-camelbert-mix-did-nadi,0.6224701833700687
161,Monsia/camembert-fr-covid-tweet-classification,0.758973576639501
162,ASCCCCCCCC/distilbert-base-chinese-amazon_zh_20000,0.6310566367361945
163,kyleinincubated/autonlp-cat333-624217911,0.6458803825615541
