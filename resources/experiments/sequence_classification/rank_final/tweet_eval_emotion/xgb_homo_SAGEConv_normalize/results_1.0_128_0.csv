,model,score
0,Jeevesh8/init_bert_ft_qqp-33,0.6754931
1,ali2066/finetuned_sentence_itr1_2e-05_all_26_02_2022-04_03_26,0.6508275
2,vaariis/distilbert-base-uncased-finetuned-emotion,0.66150796
3,heranm/finetuning-sentiment-model-3000-samples,0.6768114
4,marcelcastrobr/sagemaker-distilbert-emotion,0.66302615
5,jasonyim2/distilbert-base-uncased-finetuned-emotion,0.6604098
6,riyadhctg/distilbert-base-uncased-finetuned-cola,0.64031684
7,dapang/distilroberta-base-mic-sym,0.72205466
8,PrasunMishra/finetuning-sentiment-model-3000-samples,0.6767599
9,nurkayevaa/autonlp-bert-covid-407910458,0.6750465
10,SetFit/distilbert-base-uncased__sst2__train-16-0,0.6743383
11,abdelkader/distilbert-base-uncased-finetuned-emotion,0.6590278
12,SetFit/distilbert-base-uncased__hate_speech_offensive__train-16-1,0.6602772
13,gchhablani/fnet-base-finetuned-sst2,0.64401364
14,Capreolus/bert-base-msmarco,0.69306797
15,Splend1dchan/bert-base-uncased-slue-goldtrascription-e3-lr1e-4,0.7001138
16,crcb/isear_bert,0.70713377
17,connectivity/cola_6ep_ft-33,0.6625584
18,Jeevesh8/init_bert_ft_qqp-49,0.6717351
19,Jeevesh8/feather_berts_46,0.6946801
20,yukta10/finetuning-sentiment-model-3000-samples,0.65519315
21,connectivity/cola_6ep_ft-22,0.6634082
22,JonatanGk/roberta-base-bne-finetuned-cyberbullying-spanish,0.6223752
23,cambridgeltl/guardian_news_distilbert-base-uncased,0.6565889
24,gchhablani/fnet-base-finetuned-cola,0.6281114
25,ncduy/roberta-imdb-sentiment-analysis,0.7100521
26,isakbos/Q8BERT_COLA_L_512,0.60663027
27,connectivity/bert_ft_qqp-7,0.67520195
28,moghis/distilbert-base-uncased-finetuned-emotion,0.6636104
29,uygarkurt/distilbert-base-uncased-finetuned-emotion,0.66130775
30,amyma21/sincere_question_classification,0.69062185
31,phailyoor/distilbert-base-uncased-finetuned-yahd,0.65290034
32,arianpasquali/distilbert-base-multilingual-cased-toxicity,0.64582837
33,neibla/distilbert-base-uncased-finetuned-emotion,0.6596442
34,robertou2/roberta-base-bne-finetuned-amazon_reviews_multi,0.67669034
35,Anthos23/FS-distilroberta-fine-tuned,0.70368636
36,pietrotrope/emotion_final,0.6670852
37,aviator-neural/bert-base-uncased-sst2,0.67793375
38,Jeevesh8/bert_ft_qqp-40,0.67988366
39,jaesun/distilbert-base-uncased-finetuned-cola,0.62123585
40,SetFit/distilbert-base-uncased__sst2__train-32-9,0.67023873
41,usami/distilbert-base-uncased-finetuned-cola,0.64405376
42,connectivity/feather_berts_28,0.6964863
43,Jeevesh8/512seq_len_6ep_bert_ft_cola-91,0.65225285
44,Jeevesh8/bert_ft_qqp-9,0.67306757
45,Jeevesh8/bert_ft_qqp-88,0.6798684
46,Recognai/bert-base-spanish-wwm-cased-xnli,0.6193709
47,markt23917/finetuning-sentiment-model-3000-samples,0.66270083
48,JNK789/distilbert-base-uncased-finetuned-tweets-emoji-dataset,0.4494175
49,warwickai/fin-perceiver,0.7011793
50,anirudh21/bert-base-uncased-finetuned-qnli,0.6857019
51,Jeevesh8/6ep_bert_ft_cola-47,0.64733005
52,oferweintraub/bert-base-finance-sentiment-noisy-search,0.67158663
53,aXhyra/demo_sentiment_31415,0.6763584
54,milyiyo/selectra-small-finetuned-amazon-review,0.64172804
55,aXhyra/presentation_sentiment_1234567,0.6747785
56,Alireza1044/albert-base-v2-qnli,0.6514411
57,liangyuant/distilbert-base-uncased-finetuned-num200-450-405cls,0.66188556
58,DoyyingFace/bert-asian-hate-tweets-asian-unclean-freeze-4,0.6930952
59,connectivity/cola_6ep_ft-10,0.6558839
60,Jeevesh8/lecun_feather_berts-3,0.6944522
61,jb2k/bert-base-multilingual-cased-language-detection,0.61575043
62,Giyaseddin/distilroberta-base-finetuned-short-answer-assessment,0.70836973
63,connectivity/bert_ft_qqp-25,0.67936534
64,Jeevesh8/6ep_bert_ft_cola-12,0.6521552
65,JB173/distilbert-base-uncased-finetuned-emotion,0.6637463
66,aXhyra/emotion_trained_31415,0.67492527
67,aXhyra/presentation_emotion_31415,0.67054135
68,AnonymousSub/dummy_2,0.65075266
69,Jeevesh8/bert_ft_qqp-55,0.67800194
70,Jeevesh8/lecun_feather_berts-51,0.6975832
71,viviastaari/finetuning-sentiment-analysis-en-id,0.62138796
72,vinai/bertweet-base,0.7393981
73,distilbert-base-uncased,0.67102134
74,bert-base-uncased,0.68120337
75,roberta-base,0.73225087
76,Aureliano/distilbert-base-uncased-if,0.6717666
77,rmihaylov/roberta-base-sentiment-bg,0.6649744
78,cardiffnlp/twitter-roberta-base-2021-124m,0.7474706
79,Alassea/glue_sst_classifier,0.6741333
80,Nanatan/distilbert-base-uncased-finetuned-emotion,0.65904886
81,connectivity/bert_ft_qqp-1,0.6744875
82,juliensimon/autonlp-imdb-demo-hf-16622767,0.66616696
83,Jeevesh8/bert_ft_qqp-39,0.6721682
84,Jeevesh8/lecun_feather_berts-8,0.6955086
85,connectivity/bert_ft_qqp-94,0.6760065
86,korca/bae-roberta-base-boolq,0.72376776
87,Jeevesh8/bert_ft_cola-88,0.6592836
88,aditeyabaral/finetuned-sail2017-xlm-roberta-base,0.68778455
89,connectivity/bert_ft_qqp-96,0.6725627
90,boychaboy/MNLI_roberta-base,0.74643576
91,fabriceyhc/bert-base-uncased-imdb,0.6487697
92,emrecan/bert-base-multilingual-cased-snli_tr,0.6748043
93,elozano/tweet_offensive_eval,0.52445996
94,joebobby/finetuning-sentiment-model-5000-samples3,0.7015906
95,YeRyeongLee/electra-base-discriminator-finetuned-filtered-0602,0.5101634
96,Jeevesh8/feather_berts_92,0.71452844
97,ASCCCCCCCC/distilbert-base-chinese-amazon_zh_20000,0.648185
98,Jeevesh8/6ep_bert_ft_cola-29,0.64905655
99,albert-base-v2,0.6773896
100,bert-base-cased,0.6913186
101,Hate-speech-CNERG/bert-base-uncased-hatexplain-rationale-two,0.6948487
102,matthewburke/korean_sentiment,0.6165491
103,aychang/bert-base-cased-trec-coarse,0.6798036
104,IMSyPP/hate_speech_nl,0.6204183
105,cointegrated/roberta-base-formality,0.7346507
106,XSY/albert-base-v2-imdb-calssification,0.6631946
107,philschmid/tiny-distilbert-classification,0.4724793
108,gchhablani/bert-base-cased-finetuned-wnli,0.67430526
109,moshew/bert-mini-sst2-distilled,0.63648206
110,chiragasarpota/scotus-bert,0.52552015
111,vesteinn/XLMR-ENIS-finetuned-cola,0.6400533
112,IMSyPP/hate_speech_it,0.65367836
113,Jeevesh8/init_bert_ft_qqp-24,0.67528516
114,nickmuchi/facebook-data2vec-finetuned-finance-classification,0.65808076
115,Jeevesh8/bert_ft_qqp-68,0.66865647
116,Jeevesh8/init_bert_ft_qqp-28,0.67528516
117,connectivity/bert_ft_qqp-17,0.6739482
118,dhimskyy/wiki-bert,0.6207003
119,18811449050/bert_finetuning_test,0.65975964
120,finiteautomata/betonews-tweetcontext,0.6302411
121,Jeevesh8/feather_berts_96,0.6904812
122,michiyasunaga/LinkBERT-base,0.68874216
123,navsad/navid_test_bert,0.64999574
124,Jeevesh8/bert_ft_cola-60,0.6624362
125,Jeevesh8/lecun_feather_berts-7,0.6975832
126,w11wo/sundanese-bert-base-emotion-classifier,0.6145798
127,mrm8488/codebert-base-finetuned-detect-insecure-code,0.6885371
128,socialmediaie/TRAC2020_IBEN_B_bert-base-multilingual-uncased,0.6333257
129,ishan/bert-base-uncased-mnli,0.68309206
130,zenkri/autotrain-Arabic_Poetry_by_Subject-920730230,0.6972544
131,M47Labs/spanish_news_classification_headlines_untrained,0.6546259
132,bondi/bert-semaphore-prediction-w4,0.6330538
133,gchhablani/bert-base-cased-finetuned-rte,0.6850255
134,classla/bcms-bertic-parlasent-bcs-ter,0.6656947
135,anferico/bert-for-patents,0.6287037
136,waboucay/camembert-base-finetuned-xnli_fr-finetuned-nli-rua_wl,0.5753337
137,ali2066/DistilBERTFINAL_ctxSentence_TRAIN_editorials_TEST_NULL_second_train_set_null_False,0.7660613
138,anvay/finetuning-cardiffnlp-sentiment-model,0.7763122
139,JonatanGk/roberta-base-ca-finetuned-hate-speech-offensive-catalan,0.6615658
140,mrm8488/electricidad-base-finetuned-pawsx-es,0.6372954
141,Raychanan/COVID_RandomOver,0.5383062
142,Monsia/camembert-fr-covid-tweet-classification,0.6733821
143,manueltonneau/bert-twitter-en-is-hired,0.7141818
144,CAMeL-Lab/bert-base-arabic-camelbert-mix-did-nadi,0.6295522
145,kyleinincubated/autonlp-cat333-624217911,0.65857285
146,Guscode/DKbert-hatespeech-detection,0.6260307
147,CAMeL-Lab/bert-base-arabic-camelbert-da-sentiment,0.6117157
148,ChrisUPM/BioBERT_Re_trained,0.64960146
149,roberta-large,0.5176416
150,justinqbui/bertweet-covid19-base-uncased-pretraining-covid-vaccine-tweets,0.7053929
151,vinai/bertweet-covid19-base-cased,0.6861325
152,vinai/bertweet-covid19-base-uncased,0.7275311
153,cardiffnlp/bertweet-base-stance-climate,0.7083833
154,bert-large-uncased,0.56509095
155,fgaim/tiroberta-geezswitch,0.6486009
156,nreimers/mmarco-mMiniLMv2-L6-H384-v1,0.6994304
157,strickvl/nlp-redaction-classifier,0.65778697
158,saattrupdan/job-listing-relevance-model,0.6804793
159,cross-encoder/quora-distilroberta-base,0.6609681
160,morenolq/SumTO_FNS2020,0.6645087
161,navteca/quora-roberta-base,0.6884127
162,cross-encoder/ms-marco-MiniLM-L-4-v2,0.6643476
163,cross-encoder/quora-roberta-base,0.65793884
