,model,score
0,Guscode/DKbert-hatespeech-detection,0.4172825470781163
1,robertou2/roberta-base-bne-finetuned-amazon_reviews_multi,0.5583966229136195
2,milyiyo/selectra-small-finetuned-amazon-review,0.5716609437625948
3,SetFit/distilbert-base-uncased__hate_speech_offensive__train-16-1,0.6550891644841386
4,vinai/bertweet-base,0.5589179817290528
5,vinai/bertweet-covid19-base-cased,0.6611629353903368
6,justinqbui/bertweet-covid19-base-uncased-pretraining-covid-vaccine-tweets,0.6495937130786729
7,vinai/bertweet-covid19-base-uncased,0.6858090214483923
8,jb2k/bert-base-multilingual-cased-language-detection,0.4112400567930763
9,crcb/isear_bert,0.6881274354713014
10,vaariis/distilbert-base-uncased-finetuned-emotion,0.6200164898295952
11,marcelcastrobr/sagemaker-distilbert-emotion,0.6204930209100894
12,jasonyim2/distilbert-base-uncased-finetuned-emotion,0.6200483273319151
13,abdelkader/distilbert-base-uncased-finetuned-emotion,0.6318494572228701
14,moghis/distilbert-base-uncased-finetuned-emotion,0.6202395809782502
15,uygarkurt/distilbert-base-uncased-finetuned-emotion,0.6199847998618679
16,neibla/distilbert-base-uncased-finetuned-emotion,0.620302892883501
17,JB173/distilbert-base-uncased-finetuned-emotion,0.667565801163164
18,Nanatan/distilbert-base-uncased-finetuned-emotion,0.6033325020002849
19,riyadhctg/distilbert-base-uncased-finetuned-cola,0.7058301833951077
20,connectivity/cola_6ep_ft-33,0.7414043982045655
21,connectivity/cola_6ep_ft-22,0.7380941398352547
22,gchhablani/fnet-base-finetuned-cola,0.5451111283820751
23,vesteinn/XLMR-ENIS-finetuned-cola,0.7385042628868064
24,isakbos/Q8BERT_COLA_L_512,0.47752826427876016
25,jaesun/distilbert-base-uncased-finetuned-cola,0.6490493787552509
26,usami/distilbert-base-uncased-finetuned-cola,0.7402311373936641
27,Jeevesh8/512seq_len_6ep_bert_ft_cola-91,0.7060385368806124
28,Jeevesh8/6ep_bert_ft_cola-47,0.7406613952609291
29,connectivity/cola_6ep_ft-10,0.7406608091388875
30,Jeevesh8/6ep_bert_ft_cola-12,0.7757827900770167
31,Jeevesh8/6ep_bert_ft_cola-29,0.6985275167591567
32,Jeevesh8/bert_ft_cola-60,0.7412031669356907
33,navsad/navid_test_bert,0.6870380961101432
34,Jeevesh8/bert_ft_cola-88,0.7757831453038193
35,ishan/bert-base-uncased-mnli,0.5737743222724703
36,boychaboy/MNLI_roberta-base,0.6783240786188571
37,anirudh21/bert-base-uncased-finetuned-qnli,0.686885087771202
38,Alireza1044/albert-base-v2-qnli,0.6398170940868795
39,Jeevesh8/init_bert_ft_qqp-33,0.6208726826012594
40,Jeevesh8/init_bert_ft_qqp-49,0.6636918900990736
41,connectivity/bert_ft_qqp-7,0.6855827596232871
42,Jeevesh8/bert_ft_qqp-40,0.6556372061682509
43,Jeevesh8/bert_ft_qqp-9,0.6855827163313393
44,Jeevesh8/bert_ft_qqp-88,0.6429057982173276
45,connectivity/bert_ft_qqp-25,0.655637235854158
46,Jeevesh8/bert_ft_qqp-55,0.65563716718367
47,Jeevesh8/init_bert_ft_qqp-24,0.6369415620507084
48,Jeevesh8/init_bert_ft_qqp-28,0.6369415814702393
49,connectivity/bert_ft_qqp-17,0.6369415389204391
50,Jeevesh8/bert_ft_qqp-68,0.6369413072321208
51,connectivity/bert_ft_qqp-1,0.6855823607625666
52,connectivity/bert_ft_qqp-94,0.6855830422578606
53,Jeevesh8/bert_ft_qqp-39,0.6556327224175789
54,connectivity/bert_ft_qqp-96,0.6747594957128626
55,gchhablani/bert-base-cased-finetuned-rte,0.6325787473686546
56,philschmid/tiny-distilbert-classification,0.003715786453938108
57,ali2066/finetuned_sentence_itr1_2e-05_all_26_02_2022-04_03_26,0.617003284209602
58,SetFit/distilbert-base-uncased__sst2__train-16-0,0.5940539788174988
59,gchhablani/fnet-base-finetuned-sst2,0.5503654924581838
60,moshew/bert-mini-sst2-distilled,0.4685133851348269
61,aviator-neural/bert-base-uncased-sst2,0.5995990998530374
62,SetFit/distilbert-base-uncased__sst2__train-32-9,0.6109933143565627
63,Alassea/glue_sst_classifier,0.6080228651739503
64,ChrisUPM/BioBERT_Re_trained,0.5716713283149488
65,gchhablani/bert-base-cased-finetuned-wnli,0.5722067452599049
66,Hate-speech-CNERG/bert-base-uncased-hatexplain-rationale-two,0.6090353221119358
67,heranm/finetuning-sentiment-model-3000-samples,0.6062285283341566
68,PrasunMishra/finetuning-sentiment-model-3000-samples,0.6815957374282675
69,yukta10/finetuning-sentiment-model-3000-samples,0.6815963077032734
70,ncduy/roberta-imdb-sentiment-analysis,0.6645759023894584
71,markt23917/finetuning-sentiment-model-3000-samples,0.623229170510001
72,juliensimon/autonlp-imdb-demo-hf-16622767,0.6263170949832215
73,XSY/albert-base-v2-imdb-calssification,0.47676969507386957
74,fabriceyhc/bert-base-uncased-imdb,0.6336522219070844
75,Anthos23/FS-distilroberta-fine-tuned,0.6716786705623008
76,oferweintraub/bert-base-finance-sentiment-noisy-search,0.6828698926805146
77,emrecan/bert-base-multilingual-cased-snli_tr,0.6773767723915967
78,nurkayevaa/autonlp-bert-covid-407910458,0.6889218127438426
79,cross-encoder/quora-distilroberta-base,0.38090840694019334
80,navteca/quora-roberta-base,0.37120841880494027
81,cross-encoder/quora-roberta-base,0.37120882488341067
82,w11wo/sundanese-bert-base-emotion-classifier,0.4197035132132214
83,aychang/bert-base-cased-trec-coarse,0.6287184521648896
84,JNK789/distilbert-base-uncased-finetuned-tweets-emoji-dataset,-0.00543761510823515
85,pietrotrope/emotion_final,0.6184855954019213
86,aXhyra/emotion_trained_31415,0.6718323334756633
87,aXhyra/presentation_emotion_31415,0.6715144016601471
88,elozano/tweet_offensive_eval,0.428563293011166
89,aXhyra/demo_sentiment_31415,0.6819457749405728
90,aXhyra/presentation_sentiment_1234567,0.6715384884408877
91,nickmuchi/facebook-data2vec-finetuned-finance-classification,0.6218355661007422
92,manueltonneau/bert-twitter-en-is-hired,0.6454732044916227
93,bert-base-uncased,0.7041418623306299
94,dhimskyy/wiki-bert,0.4073698914256738
95,distilbert-base-uncased,0.6880889824864198
96,albert-base-v2,0.653513930967506
97,bert-base-cased,0.6276921731881657
98,michiyasunaga/LinkBERT-base,0.6364226366171124
99,roberta-base,0.6982446517325798
100,bert-large-uncased,0.44109750878521936
101,roberta-large,0.8942160078771622
102,Recognai/bert-base-spanish-wwm-cased-xnli,0.42109162742860917
103,mrm8488/electricidad-base-finetuned-pawsx-es,0.5243772547659091
104,dapang/distilroberta-base-mic-sym,0.6691480324119539
105,Capreolus/bert-base-msmarco,0.6545217225105944
106,Splend1dchan/bert-base-uncased-slue-goldtrascription-e3-lr1e-4,0.6545219702423992
107,Jeevesh8/feather_berts_46,0.6824725965601601
108,JonatanGk/roberta-base-bne-finetuned-cyberbullying-spanish,0.47801345421282804
109,cambridgeltl/guardian_news_distilbert-base-uncased,0.6603596244862047
110,amyma21/sincere_question_classification,0.6476281092440104
111,phailyoor/distilbert-base-uncased-finetuned-yahd,0.5897828001874359
112,nreimers/mmarco-mMiniLMv2-L6-H384-v1,0.36866764993862944
113,arianpasquali/distilbert-base-multilingual-cased-toxicity,0.5404954661902366
114,strickvl/nlp-redaction-classifier,0.3577653098512883
115,connectivity/feather_berts_28,0.6764128104590554
116,IMSyPP/hate_speech_it,0.47801244536492504
117,chiragasarpota/scotus-bert,0.4517913552521122
118,saattrupdan/job-listing-relevance-model,0.3296591178990411
119,warwickai/fin-perceiver,0.891685395862055
120,liangyuant/distilbert-base-uncased-finetuned-num200-450-405cls,0.6602891449987283
121,DoyyingFace/bert-asian-hate-tweets-asian-unclean-freeze-4,0.6464672374462452
122,Jeevesh8/lecun_feather_berts-3,0.6764125886514876
123,Giyaseddin/distilroberta-base-finetuned-short-answer-assessment,0.6724909346634149
124,18811449050/bert_finetuning_test,0.6095090323109389
125,Jeevesh8/lecun_feather_berts-51,0.6764128476246469
126,Jeevesh8/feather_berts_96,0.6277712328995904
127,AnonymousSub/dummy_2,0.5482861761159938
128,viviastaari/finetuning-sentiment-analysis-en-id,0.40879998681737106
129,finiteautomata/betonews-tweetcontext,0.4162157708309451
130,Aureliano/distilbert-base-uncased-if,0.6603458108114637
131,rmihaylov/roberta-base-sentiment-bg,0.4924759777535428
132,cardiffnlp/twitter-roberta-base-2021-124m,0.6910124941754248
133,Jeevesh8/lecun_feather_berts-8,0.6764132255742652
134,anferico/bert-for-patents,0.3837829845691658
135,morenolq/SumTO_FNS2020,0.3540966798940417
136,IMSyPP/hate_speech_nl,0.4351883872190001
137,cross-encoder/ms-marco-MiniLM-L-4-v2,0.3744272150328243
138,Jeevesh8/lecun_feather_berts-7,0.6277716133885178
139,matthewburke/korean_sentiment,0.4679043846593913
140,waboucay/camembert-base-finetuned-xnli_fr-finetuned-nli-rua_wl,0.2563661458665365
141,aditeyabaral/finetuned-sail2017-xlm-roberta-base,0.6522427687926893
142,socialmediaie/TRAC2020_IBEN_B_bert-base-multilingual-uncased,0.5537673473194218
143,korca/bae-roberta-base-boolq,0.6513894332568952
144,mrm8488/codebert-base-finetuned-detect-insecure-code,0.6249708149738353
145,M47Labs/spanish_news_classification_headlines_untrained,0.5445626551194209
146,cardiffnlp/bertweet-base-stance-climate,0.6716691702062008
147,zenkri/autotrain-Arabic_Poetry_by_Subject-920730230,0.63095655855102
148,cointegrated/roberta-base-formality,0.6046226503571006
149,fgaim/tiroberta-geezswitch,0.3704734743990912
150,CAMeL-Lab/bert-base-arabic-camelbert-da-sentiment,0.3587257883740449
151,bondi/bert-semaphore-prediction-w4,0.4802203266048082
152,classla/bcms-bertic-parlasent-bcs-ter,0.5480904793042782
153,ali2066/DistilBERTFINAL_ctxSentence_TRAIN_editorials_TEST_NULL_second_train_set_null_False,0.6024850699144508
154,Raychanan/COVID_RandomOver,-0.022300626911260224
155,anvay/finetuning-cardiffnlp-sentiment-model,0.6417125809861091
156,joebobby/finetuning-sentiment-model-5000-samples3,0.676412912678984
157,JonatanGk/roberta-base-ca-finetuned-hate-speech-offensive-catalan,0.49970048053035043
158,Jeevesh8/feather_berts_92,0.6764133200016431
159,YeRyeongLee/electra-base-discriminator-finetuned-filtered-0602,0.24669888485766478
160,CAMeL-Lab/bert-base-arabic-camelbert-mix-did-nadi,0.5371252964727091
161,Monsia/camembert-fr-covid-tweet-classification,0.48375195271034954
162,ASCCCCCCCC/distilbert-base-chinese-amazon_zh_20000,0.522412879702074
163,kyleinincubated/autonlp-cat333-624217911,0.505318977211914
