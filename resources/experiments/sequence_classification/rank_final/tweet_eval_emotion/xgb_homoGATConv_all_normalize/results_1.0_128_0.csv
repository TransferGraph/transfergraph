,model,score
0,Jeevesh8/init_bert_ft_qqp-33,0.698542
1,Jeevesh8/init_bert_ft_qqp-49,0.6960926
2,connectivity/bert_ft_qqp-7,0.6936278
3,Jeevesh8/bert_ft_qqp-40,0.70625234
4,Jeevesh8/bert_ft_qqp-9,0.6993208
5,Jeevesh8/bert_ft_qqp-88,0.7019243
6,connectivity/bert_ft_qqp-25,0.70422155
7,Jeevesh8/bert_ft_qqp-55,0.70214164
8,connectivity/bert_ft_qqp-1,0.70266896
9,Jeevesh8/bert_ft_qqp-39,0.7132104
10,connectivity/bert_ft_qqp-94,0.7055902
11,connectivity/bert_ft_qqp-96,0.7043442
12,Jeevesh8/init_bert_ft_qqp-24,0.7007375
13,Jeevesh8/bert_ft_qqp-68,0.69824815
14,Jeevesh8/init_bert_ft_qqp-28,0.6992352
15,connectivity/bert_ft_qqp-17,0.6991258
16,ali2066/finetuned_sentence_itr1_2e-05_all_26_02_2022-04_03_26,0.68707204
17,SetFit/distilbert-base-uncased__sst2__train-16-0,0.71780014
18,gchhablani/fnet-base-finetuned-sst2,0.67353743
19,aviator-neural/bert-base-uncased-sst2,0.7119965
20,SetFit/distilbert-base-uncased__sst2__train-32-9,0.6913094
21,Alassea/glue_sst_classifier,0.7176372
22,philschmid/tiny-distilbert-classification,0.54329467
23,moshew/bert-mini-sst2-distilled,0.664566
24,ChrisUPM/BioBERT_Re_trained,0.6900199
25,vaariis/distilbert-base-uncased-finetuned-emotion,0.696104
26,marcelcastrobr/sagemaker-distilbert-emotion,0.69525695
27,jasonyim2/distilbert-base-uncased-finetuned-emotion,0.6955105
28,abdelkader/distilbert-base-uncased-finetuned-emotion,0.6814698
29,moghis/distilbert-base-uncased-finetuned-emotion,0.67929083
30,uygarkurt/distilbert-base-uncased-finetuned-emotion,0.69615847
31,neibla/distilbert-base-uncased-finetuned-emotion,0.67808753
32,JB173/distilbert-base-uncased-finetuned-emotion,0.6800956
33,Nanatan/distilbert-base-uncased-finetuned-emotion,0.6974203
34,heranm/finetuning-sentiment-model-3000-samples,0.7029649
35,PrasunMishra/finetuning-sentiment-model-3000-samples,0.7065245
36,yukta10/finetuning-sentiment-model-3000-samples,0.6731357
37,ncduy/roberta-imdb-sentiment-analysis,0.7399909
38,markt23917/finetuning-sentiment-model-3000-samples,0.6845391
39,juliensimon/autonlp-imdb-demo-hf-16622767,0.6779506
40,fabriceyhc/bert-base-uncased-imdb,0.68383867
41,XSY/albert-base-v2-imdb-calssification,0.6819447
42,riyadhctg/distilbert-base-uncased-finetuned-cola,0.6743695
43,connectivity/cola_6ep_ft-33,0.6931482
44,connectivity/cola_6ep_ft-22,0.6912264
45,gchhablani/fnet-base-finetuned-cola,0.6491486
46,isakbos/Q8BERT_COLA_L_512,0.61427605
47,jaesun/distilbert-base-uncased-finetuned-cola,0.64394814
48,usami/distilbert-base-uncased-finetuned-cola,0.66669285
49,Jeevesh8/512seq_len_6ep_bert_ft_cola-91,0.6704234
50,Jeevesh8/6ep_bert_ft_cola-47,0.6822735
51,connectivity/cola_6ep_ft-10,0.69036496
52,Jeevesh8/6ep_bert_ft_cola-12,0.687939
53,Jeevesh8/bert_ft_cola-88,0.6913737
54,Jeevesh8/6ep_bert_ft_cola-29,0.6889409
55,vesteinn/XLMR-ENIS-finetuned-cola,0.6793554
56,navsad/navid_test_bert,0.69057167
57,Jeevesh8/bert_ft_cola-60,0.70565104
58,dapang/distilroberta-base-mic-sym,0.7468139
59,Capreolus/bert-base-msmarco,0.7059431
60,Splend1dchan/bert-base-uncased-slue-goldtrascription-e3-lr1e-4,0.7175618
61,Jeevesh8/feather_berts_46,0.7149495
62,JonatanGk/roberta-base-bne-finetuned-cyberbullying-spanish,0.6496775
63,cambridgeltl/guardian_news_distilbert-base-uncased,0.67137796
64,amyma21/sincere_question_classification,0.7069136
65,phailyoor/distilbert-base-uncased-finetuned-yahd,0.66694444
66,arianpasquali/distilbert-base-multilingual-cased-toxicity,0.66212183
67,connectivity/feather_berts_28,0.7206793
68,warwickai/fin-perceiver,0.71123844
69,liangyuant/distilbert-base-uncased-finetuned-num200-450-405cls,0.6948921
70,DoyyingFace/bert-asian-hate-tweets-asian-unclean-freeze-4,0.7130377
71,Jeevesh8/lecun_feather_berts-3,0.7108591
72,Giyaseddin/distilroberta-base-finetuned-short-answer-assessment,0.72681296
73,AnonymousSub/dummy_2,0.6719507
74,Jeevesh8/lecun_feather_berts-51,0.7161545
75,viviastaari/finetuning-sentiment-analysis-en-id,0.6464289
76,Aureliano/distilbert-base-uncased-if,0.6895101
77,rmihaylov/roberta-base-sentiment-bg,0.68545735
78,cardiffnlp/twitter-roberta-base-2021-124m,0.76856035
79,Jeevesh8/lecun_feather_berts-8,0.7178257
80,korca/bae-roberta-base-boolq,0.7498281
81,aditeyabaral/finetuned-sail2017-xlm-roberta-base,0.71592605
82,joebobby/finetuning-sentiment-model-5000-samples3,0.71321684
83,YeRyeongLee/electra-base-discriminator-finetuned-filtered-0602,0.5735912
84,Jeevesh8/feather_berts_92,0.72733235
85,ASCCCCCCCC/distilbert-base-chinese-amazon_zh_20000,0.66389614
86,matthewburke/korean_sentiment,0.63336796
87,IMSyPP/hate_speech_nl,0.6520224
88,cointegrated/roberta-base-formality,0.7513678
89,chiragasarpota/scotus-bert,0.6145584
90,IMSyPP/hate_speech_it,0.6588532
91,18811449050/bert_finetuning_test,0.67430055
92,finiteautomata/betonews-tweetcontext,0.6496027
93,Jeevesh8/feather_berts_96,0.712663
94,Jeevesh8/lecun_feather_berts-7,0.7198414
95,mrm8488/codebert-base-finetuned-detect-insecure-code,0.72197026
96,socialmediaie/TRAC2020_IBEN_B_bert-base-multilingual-uncased,0.6655987
97,zenkri/autotrain-Arabic_Poetry_by_Subject-920730230,0.72105503
98,M47Labs/spanish_news_classification_headlines_untrained,0.66888475
99,bondi/bert-semaphore-prediction-w4,0.6488568
100,classla/bcms-bertic-parlasent-bcs-ter,0.6877595
101,anferico/bert-for-patents,0.6188724
102,waboucay/camembert-base-finetuned-xnli_fr-finetuned-nli-rua_wl,0.63547707
103,ali2066/DistilBERTFINAL_ctxSentence_TRAIN_editorials_TEST_NULL_second_train_set_null_False,0.7825991
104,anvay/finetuning-cardiffnlp-sentiment-model,0.7849024
105,JonatanGk/roberta-base-ca-finetuned-hate-speech-offensive-catalan,0.64395756
106,Raychanan/COVID_RandomOver,0.5818102
107,Monsia/camembert-fr-covid-tweet-classification,0.70519304
108,CAMeL-Lab/bert-base-arabic-camelbert-mix-did-nadi,0.6518117
109,kyleinincubated/autonlp-cat333-624217911,0.6885881
110,CAMeL-Lab/bert-base-arabic-camelbert-da-sentiment,0.62743807
111,cardiffnlp/bertweet-base-stance-climate,0.7267709
112,fgaim/tiroberta-geezswitch,0.6177726
113,nreimers/mmarco-mMiniLMv2-L6-H384-v1,0.7275033
114,strickvl/nlp-redaction-classifier,0.6754642
115,saattrupdan/job-listing-relevance-model,0.70942986
116,morenolq/SumTO_FNS2020,0.6929361
117,cross-encoder/ms-marco-MiniLM-L-4-v2,0.6760417
118,nurkayevaa/autonlp-bert-covid-407910458,0.7134311
119,SetFit/distilbert-base-uncased__hate_speech_offensive__train-16-1,0.6786539
120,crcb/isear_bert,0.7512897
121,robertou2/roberta-base-bne-finetuned-amazon_reviews_multi,0.7056278
122,milyiyo/selectra-small-finetuned-amazon-review,0.65201217
123,Anthos23/FS-distilroberta-fine-tuned,0.7398598
124,oferweintraub/bert-base-finance-sentiment-noisy-search,0.70511335
125,pietrotrope/emotion_final,0.6857901
126,aXhyra/emotion_trained_31415,0.690838
127,aXhyra/presentation_emotion_31415,0.707508
128,Recognai/bert-base-spanish-wwm-cased-xnli,0.6656847
129,JNK789/distilbert-base-uncased-finetuned-tweets-emoji-dataset,0.5158427
130,anirudh21/bert-base-uncased-finetuned-qnli,0.71543956
131,Alireza1044/albert-base-v2-qnli,0.6972223
132,aXhyra/demo_sentiment_31415,0.69059426
133,aXhyra/presentation_sentiment_1234567,0.69111955
134,jb2k/bert-base-multilingual-cased-language-detection,0.6515093
135,vinai/bertweet-base,0.7515933
136,justinqbui/bertweet-covid19-base-uncased-pretraining-covid-vaccine-tweets,0.7521275
137,vinai/bertweet-covid19-base-cased,0.64557844
138,vinai/bertweet-covid19-base-uncased,0.76540154
139,distilbert-base-uncased,0.6819624
140,bert-base-uncased,0.7097306
141,roberta-base,0.7661383
142,albert-base-v2,0.7110432
143,bert-base-cased,0.71500474
144,dhimskyy/wiki-bert,0.6496235
145,michiyasunaga/LinkBERT-base,0.71656126
146,roberta-large,0.6024743
147,bert-large-uncased,0.6680205
148,boychaboy/MNLI_roberta-base,0.77197397
149,ishan/bert-base-uncased-mnli,0.71082884
150,emrecan/bert-base-multilingual-cased-snli_tr,0.6945446
151,elozano/tweet_offensive_eval,0.5766933
152,Hate-speech-CNERG/bert-base-uncased-hatexplain-rationale-two,0.72220683
153,aychang/bert-base-cased-trec-coarse,0.69304436
154,gchhablani/bert-base-cased-finetuned-wnli,0.69062316
155,nickmuchi/facebook-data2vec-finetuned-finance-classification,0.692525
156,w11wo/sundanese-bert-base-emotion-classifier,0.6602127
157,gchhablani/bert-base-cased-finetuned-rte,0.71763945
158,mrm8488/electricidad-base-finetuned-pawsx-es,0.66850615
159,manueltonneau/bert-twitter-en-is-hired,0.7379636
160,Guscode/DKbert-hatespeech-detection,0.66559017
161,cross-encoder/quora-distilroberta-base,0.7428568
162,navteca/quora-roberta-base,0.75248367
163,cross-encoder/quora-roberta-base,0.75345254
