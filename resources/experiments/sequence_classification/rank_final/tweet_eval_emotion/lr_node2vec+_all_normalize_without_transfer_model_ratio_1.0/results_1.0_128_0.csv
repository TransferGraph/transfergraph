,model,score
0,Guscode/DKbert-hatespeech-detection,0.5158258841138501
1,robertou2/roberta-base-bne-finetuned-amazon_reviews_multi,0.6293314964955438
2,milyiyo/selectra-small-finetuned-amazon-review,0.5137176918735251
3,SetFit/distilbert-base-uncased__hate_speech_offensive__train-16-1,0.7742872357661321
4,vinai/bertweet-base,0.7748690076095517
5,vinai/bertweet-covid19-base-cased,0.7727333271674506
6,justinqbui/bertweet-covid19-base-uncased-pretraining-covid-vaccine-tweets,0.6934285062352573
7,vinai/bertweet-covid19-base-uncased,0.8638303014657311
8,jb2k/bert-base-multilingual-cased-language-detection,0.6364618379155473
9,crcb/isear_bert,0.8050738195500264
10,vaariis/distilbert-base-uncased-finetuned-emotion,0.7665442520722574
11,marcelcastrobr/sagemaker-distilbert-emotion,0.7477069747588654
12,jasonyim2/distilbert-base-uncased-finetuned-emotion,0.7511577088432373
13,abdelkader/distilbert-base-uncased-finetuned-emotion,0.819367713992762
14,moghis/distilbert-base-uncased-finetuned-emotion,0.7377929325294742
15,uygarkurt/distilbert-base-uncased-finetuned-emotion,0.8052868151203505
16,neibla/distilbert-base-uncased-finetuned-emotion,0.7341628548409398
17,JB173/distilbert-base-uncased-finetuned-emotion,0.7483658904638407
18,Nanatan/distilbert-base-uncased-finetuned-emotion,0.8044647178662789
19,riyadhctg/distilbert-base-uncased-finetuned-cola,0.7610509906509484
20,connectivity/cola_6ep_ft-33,0.7847848636301552
21,connectivity/cola_6ep_ft-22,0.7823377717841179
22,gchhablani/fnet-base-finetuned-cola,0.5800131458825923
23,vesteinn/XLMR-ENIS-finetuned-cola,0.7614130085853505
24,isakbos/Q8BERT_COLA_L_512,0.5225587019156365
25,jaesun/distilbert-base-uncased-finetuned-cola,0.6838720587390927
26,usami/distilbert-base-uncased-finetuned-cola,0.7340139684431506
27,Jeevesh8/512seq_len_6ep_bert_ft_cola-91,0.7311266824966003
28,Jeevesh8/6ep_bert_ft_cola-47,0.7542261043691305
29,connectivity/cola_6ep_ft-10,0.7885379288582146
30,Jeevesh8/6ep_bert_ft_cola-12,0.7247452767998968
31,Jeevesh8/6ep_bert_ft_cola-29,0.7689582046442112
32,Jeevesh8/bert_ft_cola-60,0.8285772836080069
33,navsad/navid_test_bert,0.7452873736677292
34,Jeevesh8/bert_ft_cola-88,0.7493542333252358
35,ishan/bert-base-uncased-mnli,0.7798385785104339
36,boychaboy/MNLI_roberta-base,0.9012481354138189
37,anirudh21/bert-base-uncased-finetuned-qnli,0.7370780029898449
38,Alireza1044/albert-base-v2-qnli,0.7345145591701612
39,Jeevesh8/init_bert_ft_qqp-33,0.7264431083510119
40,Jeevesh8/init_bert_ft_qqp-49,0.7807748053302779
41,connectivity/bert_ft_qqp-7,0.7965113735419687
42,Jeevesh8/bert_ft_qqp-40,0.8006813595684443
43,Jeevesh8/bert_ft_qqp-9,0.8281487552803092
44,Jeevesh8/bert_ft_qqp-88,0.8331647610192343
45,connectivity/bert_ft_qqp-25,0.7829533955238818
46,Jeevesh8/bert_ft_qqp-55,0.8069777980763219
47,Jeevesh8/init_bert_ft_qqp-24,0.7214458459359405
48,Jeevesh8/init_bert_ft_qqp-28,0.8321998560524746
49,connectivity/bert_ft_qqp-17,0.7926822814955464
50,Jeevesh8/bert_ft_qqp-68,0.6964268104825837
51,connectivity/bert_ft_qqp-1,0.8635530047277401
52,connectivity/bert_ft_qqp-94,0.7974261984112783
53,Jeevesh8/bert_ft_qqp-39,0.768044364030332
54,connectivity/bert_ft_qqp-96,0.7317719113420259
55,gchhablani/bert-base-cased-finetuned-rte,0.7922031253770746
56,philschmid/tiny-distilbert-classification,-0.020108223565453276
57,ali2066/finetuned_sentence_itr1_2e-05_all_26_02_2022-04_03_26,0.7188791013944715
58,SetFit/distilbert-base-uncased__sst2__train-16-0,0.7367341167802333
59,gchhablani/fnet-base-finetuned-sst2,0.6848376057759521
60,moshew/bert-mini-sst2-distilled,0.7207822784565656
61,aviator-neural/bert-base-uncased-sst2,0.742949236999243
62,SetFit/distilbert-base-uncased__sst2__train-32-9,0.7618646209445756
63,Alassea/glue_sst_classifier,0.7685681449814084
64,ChrisUPM/BioBERT_Re_trained,0.6399628630777958
65,gchhablani/bert-base-cased-finetuned-wnli,0.7144504758565376
66,Hate-speech-CNERG/bert-base-uncased-hatexplain-rationale-two,0.8277764983476359
67,heranm/finetuning-sentiment-model-3000-samples,0.807154365575287
68,PrasunMishra/finetuning-sentiment-model-3000-samples,0.7611616101895409
69,yukta10/finetuning-sentiment-model-3000-samples,0.7593821802790126
70,ncduy/roberta-imdb-sentiment-analysis,0.8486251946651195
71,markt23917/finetuning-sentiment-model-3000-samples,0.7472317559208883
72,juliensimon/autonlp-imdb-demo-hf-16622767,0.7958645958584932
73,XSY/albert-base-v2-imdb-calssification,0.6509221347871914
74,fabriceyhc/bert-base-uncased-imdb,0.7564953940014189
75,Anthos23/FS-distilroberta-fine-tuned,0.8430754774982648
76,oferweintraub/bert-base-finance-sentiment-noisy-search,0.7741272543854246
77,emrecan/bert-base-multilingual-cased-snli_tr,0.7240964812111911
78,nurkayevaa/autonlp-bert-covid-407910458,0.768287193540161
79,cross-encoder/quora-distilroberta-base,0.7552215184460306
80,navteca/quora-roberta-base,0.7034058991798193
81,cross-encoder/quora-roberta-base,0.6618868384271195
82,w11wo/sundanese-bert-base-emotion-classifier,0.5271581410009155
83,aychang/bert-base-cased-trec-coarse,0.7569995533032543
84,JNK789/distilbert-base-uncased-finetuned-tweets-emoji-dataset,0.012043863055762882
85,pietrotrope/emotion_final,0.8248756793291658
86,aXhyra/emotion_trained_31415,0.7488945581897739
87,aXhyra/presentation_emotion_31415,0.8170850039081328
88,elozano/tweet_offensive_eval,0.5934415361742573
89,aXhyra/demo_sentiment_31415,0.7861136603649805
90,aXhyra/presentation_sentiment_1234567,0.8186066283598228
91,nickmuchi/facebook-data2vec-finetuned-finance-classification,0.8163944260637197
92,manueltonneau/bert-twitter-en-is-hired,0.8143220509286901
93,bert-base-uncased,0.7622255941676417
94,dhimskyy/wiki-bert,0.5757989918340873
95,distilbert-base-uncased,0.7604645659451852
96,albert-base-v2,0.7316501744250457
97,bert-base-cased,0.8123131284586544
98,michiyasunaga/LinkBERT-base,0.7852754689058525
99,roberta-base,0.8987777452734306
100,bert-large-uncased,0.6616493658209985
101,roberta-large,0.4703543954552071
102,Recognai/bert-base-spanish-wwm-cased-xnli,0.5526391736710241
103,mrm8488/electricidad-base-finetuned-pawsx-es,0.5717269161175068
104,dapang/distilroberta-base-mic-sym,0.7879375387503961
105,Capreolus/bert-base-msmarco,0.831907791568139
106,Splend1dchan/bert-base-uncased-slue-goldtrascription-e3-lr1e-4,0.7811915142792509
107,Jeevesh8/feather_berts_46,0.7963877875784942
108,JonatanGk/roberta-base-bne-finetuned-cyberbullying-spanish,0.4361525186472154
109,cambridgeltl/guardian_news_distilbert-base-uncased,0.7215198642444864
110,amyma21/sincere_question_classification,0.7519553813091497
111,phailyoor/distilbert-base-uncased-finetuned-yahd,0.7700200788305516
112,nreimers/mmarco-mMiniLMv2-L6-H384-v1,0.5516665779568201
113,arianpasquali/distilbert-base-multilingual-cased-toxicity,0.6841171534191045
114,strickvl/nlp-redaction-classifier,0.6839745041526608
115,connectivity/feather_berts_28,0.7835293174148839
116,IMSyPP/hate_speech_it,0.5927923980563095
117,chiragasarpota/scotus-bert,0.5330374826590354
118,saattrupdan/job-listing-relevance-model,0.8033546396114426
119,warwickai/fin-perceiver,0.672522854512912
120,liangyuant/distilbert-base-uncased-finetuned-num200-450-405cls,0.7701576713502993
121,DoyyingFace/bert-asian-hate-tweets-asian-unclean-freeze-4,0.7947520980699281
122,Jeevesh8/lecun_feather_berts-3,0.7735034497864164
123,Giyaseddin/distilroberta-base-finetuned-short-answer-assessment,0.8199348540864797
124,18811449050/bert_finetuning_test,0.6689703467822412
125,Jeevesh8/lecun_feather_berts-51,0.8068134896682675
126,Jeevesh8/feather_berts_96,0.7576562425058894
127,AnonymousSub/dummy_2,0.6343730032034156
128,viviastaari/finetuning-sentiment-analysis-en-id,0.6165532067861741
129,finiteautomata/betonews-tweetcontext,0.5523785194218535
130,Aureliano/distilbert-base-uncased-if,0.7361432252899707
131,rmihaylov/roberta-base-sentiment-bg,0.6321156667531511
132,cardiffnlp/twitter-roberta-base-2021-124m,0.8737904542243868
133,Jeevesh8/lecun_feather_berts-8,0.8458513712231487
134,anferico/bert-for-patents,0.6353521144340184
135,morenolq/SumTO_FNS2020,0.7992625132096646
136,IMSyPP/hate_speech_nl,0.4390820506683343
137,cross-encoder/ms-marco-MiniLM-L-4-v2,0.5837554723476082
138,Jeevesh8/lecun_feather_berts-7,0.7788120137612129
139,matthewburke/korean_sentiment,0.6081528383108354
140,waboucay/camembert-base-finetuned-xnli_fr-finetuned-nli-rua_wl,0.53102347817253
141,aditeyabaral/finetuned-sail2017-xlm-roberta-base,0.7557515839090978
142,socialmediaie/TRAC2020_IBEN_B_bert-base-multilingual-uncased,0.7076429711091566
143,korca/bae-roberta-base-boolq,0.777510153432346
144,mrm8488/codebert-base-finetuned-detect-insecure-code,0.7834977696019171
145,M47Labs/spanish_news_classification_headlines_untrained,0.6292962612335841
146,cardiffnlp/bertweet-base-stance-climate,0.8042802351124487
147,zenkri/autotrain-Arabic_Poetry_by_Subject-920730230,0.8417057659751301
148,cointegrated/roberta-base-formality,0.8316682866592324
149,fgaim/tiroberta-geezswitch,0.4221622026042511
150,CAMeL-Lab/bert-base-arabic-camelbert-da-sentiment,0.4751399011165208
151,bondi/bert-semaphore-prediction-w4,0.5505588069576062
152,classla/bcms-bertic-parlasent-bcs-ter,0.5983056545569
153,ali2066/DistilBERTFINAL_ctxSentence_TRAIN_editorials_TEST_NULL_second_train_set_null_False,0.8510163738960212
154,Raychanan/COVID_RandomOver,-0.06744557635624315
155,anvay/finetuning-cardiffnlp-sentiment-model,0.87553502745591
156,joebobby/finetuning-sentiment-model-5000-samples3,0.7655547857975328
157,JonatanGk/roberta-base-ca-finetuned-hate-speech-offensive-catalan,0.6029818735257131
158,Jeevesh8/feather_berts_92,0.8143744998757756
159,YeRyeongLee/electra-base-discriminator-finetuned-filtered-0602,0.15940195912428323
160,CAMeL-Lab/bert-base-arabic-camelbert-mix-did-nadi,0.5112876566439856
161,Monsia/camembert-fr-covid-tweet-classification,0.7019811083466165
162,ASCCCCCCCC/distilbert-base-chinese-amazon_zh_20000,0.5787689165443527
163,kyleinincubated/autonlp-cat333-624217911,0.6426513247667438
