,model,score
0,Guscode/DKbert-hatespeech-detection,0.52761394
1,robertou2/roberta-base-bne-finetuned-amazon_reviews_multi,0.64709896
2,milyiyo/selectra-small-finetuned-amazon-review,0.4856769
3,SetFit/distilbert-base-uncased__hate_speech_offensive__train-16-1,0.6976398
4,vinai/bertweet-base,0.8772914
5,vinai/bertweet-covid19-base-cased,0.84068817
6,justinqbui/bertweet-covid19-base-uncased-pretraining-covid-vaccine-tweets,0.9100013
7,vinai/bertweet-covid19-base-uncased,0.82331556
8,jb2k/bert-base-multilingual-cased-language-detection,0.58117956
9,crcb/isear_bert,0.8720064
10,vaariis/distilbert-base-uncased-finetuned-emotion,0.7310047
11,marcelcastrobr/sagemaker-distilbert-emotion,0.7324101
12,jasonyim2/distilbert-base-uncased-finetuned-emotion,0.7352611
13,abdelkader/distilbert-base-uncased-finetuned-emotion,0.67824066
14,moghis/distilbert-base-uncased-finetuned-emotion,0.6929215
15,JB173/distilbert-base-uncased-finetuned-emotion,0.6548094
16,Nanatan/distilbert-base-uncased-finetuned-emotion,0.67518157
17,riyadhctg/distilbert-base-uncased-finetuned-cola,0.6782768
18,connectivity/cola_6ep_ft-33,0.68897635
19,vesteinn/XLMR-ENIS-finetuned-cola,0.6945823
20,isakbos/Q8BERT_COLA_L_512,0.49536413
21,jaesun/distilbert-base-uncased-finetuned-cola,0.56669587
22,Jeevesh8/6ep_bert_ft_cola-47,0.604667
23,connectivity/cola_6ep_ft-10,0.6508694
24,Jeevesh8/6ep_bert_ft_cola-12,0.6323048
25,Jeevesh8/6ep_bert_ft_cola-29,0.6419065
26,Jeevesh8/bert_ft_cola-60,0.6153275
27,navsad/navid_test_bert,0.6140452
28,Jeevesh8/bert_ft_cola-88,0.6263213
29,ishan/bert-base-uncased-mnli,0.7048777
30,boychaboy/MNLI_roberta-base,0.8563007
31,anirudh21/bert-base-uncased-finetuned-qnli,0.7102406
32,Alireza1044/albert-base-v2-qnli,0.6508699
33,Jeevesh8/init_bert_ft_qqp-33,0.63593835
34,Jeevesh8/init_bert_ft_qqp-49,0.65862226
35,connectivity/bert_ft_qqp-7,0.6630113
36,Jeevesh8/bert_ft_qqp-40,0.7189291
37,Jeevesh8/bert_ft_qqp-9,0.6738348
38,Jeevesh8/bert_ft_qqp-88,0.6856853
39,connectivity/bert_ft_qqp-25,0.71406394
40,Jeevesh8/bert_ft_qqp-55,0.6753454
41,Jeevesh8/init_bert_ft_qqp-24,0.6645155
42,Jeevesh8/init_bert_ft_qqp-28,0.66079724
43,connectivity/bert_ft_qqp-17,0.65091467
44,Jeevesh8/bert_ft_qqp-68,0.64410764
45,connectivity/bert_ft_qqp-1,0.6693875
46,Jeevesh8/bert_ft_qqp-39,0.67619956
47,gchhablani/bert-base-cased-finetuned-rte,0.70412266
48,philschmid/tiny-distilbert-classification,-0.0021991718
49,ali2066/finetuned_sentence_itr1_2e-05_all_26_02_2022-04_03_26,0.7499694
50,SetFit/distilbert-base-uncased__sst2__train-16-0,0.7605578
51,gchhablani/fnet-base-finetuned-sst2,0.6220371
52,moshew/bert-mini-sst2-distilled,0.58875906
53,aviator-neural/bert-base-uncased-sst2,0.7786461
54,SetFit/distilbert-base-uncased__sst2__train-32-9,0.71638054
55,ChrisUPM/BioBERT_Re_trained,0.69565445
56,gchhablani/bert-base-cased-finetuned-wnli,0.6893081
57,Hate-speech-CNERG/bert-base-uncased-hatexplain-rationale-two,0.76083565
58,heranm/finetuning-sentiment-model-3000-samples,0.75105906
59,PrasunMishra/finetuning-sentiment-model-3000-samples,0.7607231
60,yukta10/finetuning-sentiment-model-3000-samples,0.6707119
61,ncduy/roberta-imdb-sentiment-analysis,0.85875964
62,markt23917/finetuning-sentiment-model-3000-samples,0.6809222
63,juliensimon/autonlp-imdb-demo-hf-16622767,0.65483516
64,XSY/albert-base-v2-imdb-calssification,0.67780936
65,fabriceyhc/bert-base-uncased-imdb,0.6524341
66,Anthos23/FS-distilroberta-fine-tuned,0.83528876
67,oferweintraub/bert-base-finance-sentiment-noisy-search,0.71531326
68,emrecan/bert-base-multilingual-cased-snli_tr,0.69112194
69,nurkayevaa/autonlp-bert-covid-407910458,0.78147036
70,navteca/quora-roberta-base,0.62850076
71,cross-encoder/quora-roberta-base,0.7005822
72,w11wo/sundanese-bert-base-emotion-classifier,0.44934407
73,aychang/bert-base-cased-trec-coarse,0.64690644
74,JNK789/distilbert-base-uncased-finetuned-tweets-emoji-dataset,0.007965569
75,pietrotrope/emotion_final,0.7045946
76,aXhyra/emotion_trained_31415,0.72044384
77,aXhyra/presentation_emotion_31415,0.7278845
78,elozano/tweet_offensive_eval,0.21986318
79,aXhyra/demo_sentiment_31415,0.70790344
80,aXhyra/presentation_sentiment_1234567,0.7099108
81,manueltonneau/bert-twitter-en-is-hired,0.8206774
82,bert-base-uncased,0.73928106
83,dhimskyy/wiki-bert,0.4874796
84,distilbert-base-uncased,0.68613464
85,albert-base-v2,0.73623145
86,bert-base-cased,0.744644
87,michiyasunaga/LinkBERT-base,0.74462837
88,roberta-base,0.90056175
89,bert-large-uncased,0.43112105
90,Recognai/bert-base-spanish-wwm-cased-xnli,0.49211904
91,mrm8488/electricidad-base-finetuned-pawsx-es,0.5185653
92,dapang/distilroberta-base-mic-sym,0.8269503
93,Capreolus/bert-base-msmarco,0.73897463
94,Splend1dchan/bert-base-uncased-slue-goldtrascription-e3-lr1e-4,0.7691217
95,Jeevesh8/feather_berts_46,0.771417
96,JonatanGk/roberta-base-bne-finetuned-cyberbullying-spanish,0.41920274
97,amyma21/sincere_question_classification,0.7685473
98,phailyoor/distilbert-base-uncased-finetuned-yahd,0.6685819
99,nreimers/mmarco-mMiniLMv2-L6-H384-v1,0.7079834
100,arianpasquali/distilbert-base-multilingual-cased-toxicity,0.5973257
101,strickvl/nlp-redaction-classifier,0.55965465
102,connectivity/feather_berts_28,0.7399506
103,IMSyPP/hate_speech_it,0.6101045
104,chiragasarpota/scotus-bert,0.18679409
105,saattrupdan/job-listing-relevance-model,0.6756773
106,warwickai/fin-perceiver,0.7241155
107,liangyuant/distilbert-base-uncased-finetuned-num200-450-405cls,0.626355
108,DoyyingFace/bert-asian-hate-tweets-asian-unclean-freeze-4,0.7417571
109,Jeevesh8/lecun_feather_berts-3,0.7195586
110,Giyaseddin/distilroberta-base-finetuned-short-answer-assessment,0.8263204
111,18811449050/bert_finetuning_test,0.68414515
112,Jeevesh8/lecun_feather_berts-51,0.7610203
113,Jeevesh8/feather_berts_96,0.7550983
114,AnonymousSub/dummy_2,0.6208371
115,viviastaari/finetuning-sentiment-analysis-en-id,0.5212796
116,finiteautomata/betonews-tweetcontext,0.53310466
117,Aureliano/distilbert-base-uncased-if,0.7021249
118,rmihaylov/roberta-base-sentiment-bg,0.6568862
119,cardiffnlp/twitter-roberta-base-2021-124m,0.8933664
120,Jeevesh8/lecun_feather_berts-8,0.75278115
121,anferico/bert-for-patents,0.6188913
122,morenolq/SumTO_FNS2020,0.5855332
123,cross-encoder/ms-marco-MiniLM-L-4-v2,0.47497573
124,Jeevesh8/lecun_feather_berts-7,0.7652225
125,matthewburke/korean_sentiment,0.44829214
126,waboucay/camembert-base-finetuned-xnli_fr-finetuned-nli-rua_wl,0.3336174
127,aditeyabaral/finetuned-sail2017-xlm-roberta-base,0.79496974
128,korca/bae-roberta-base-boolq,0.8422702
129,mrm8488/codebert-base-finetuned-detect-insecure-code,0.7677163
130,M47Labs/spanish_news_classification_headlines_untrained,0.54311013
131,cardiffnlp/bertweet-base-stance-climate,0.7859059
132,zenkri/autotrain-Arabic_Poetry_by_Subject-920730230,0.73490983
133,cointegrated/roberta-base-formality,0.8921378
134,CAMeL-Lab/bert-base-arabic-camelbert-da-sentiment,0.31133673
135,bondi/bert-semaphore-prediction-w4,0.5159457
136,classla/bcms-bertic-parlasent-bcs-ter,0.67846125
137,ali2066/DistilBERTFINAL_ctxSentence_TRAIN_editorials_TEST_NULL_second_train_set_null_False,0.9240101
138,Raychanan/COVID_RandomOver,0.07638038
139,joebobby/finetuning-sentiment-model-5000-samples3,0.74704224
140,JonatanGk/roberta-base-ca-finetuned-hate-speech-offensive-catalan,0.610045
141,Jeevesh8/feather_berts_92,0.7437185
142,YeRyeongLee/electra-base-discriminator-finetuned-filtered-0602,0.013908333
143,CAMeL-Lab/bert-base-arabic-camelbert-mix-did-nadi,0.4852117
144,Monsia/camembert-fr-covid-tweet-classification,0.634742
145,ASCCCCCCCC/distilbert-base-chinese-amazon_zh_20000,0.5519997
146,kyleinincubated/autonlp-cat333-624217911,0.603295
