,model,score
0,Guscode/DKbert-hatespeech-detection,0.752274198074771
1,robertou2/roberta-base-bne-finetuned-amazon_reviews_multi,0.7835428333609596
2,milyiyo/selectra-small-finetuned-amazon-review,0.7568899558363016
3,SetFit/distilbert-base-uncased__hate_speech_offensive__train-16-1,0.7832171994754376
4,vinai/bertweet-base,0.807345862176756
5,vinai/bertweet-covid19-base-cased,0.7853992670929096
6,justinqbui/bertweet-covid19-base-uncased-pretraining-covid-vaccine-tweets,0.8132835503049874
7,vinai/bertweet-covid19-base-uncased,0.8176005394063917
8,jb2k/bert-base-multilingual-cased-language-detection,0.7901522417840703
9,crcb/isear_bert,0.8201551424752074
10,vaariis/distilbert-base-uncased-finetuned-emotion,0.8142154424419676
11,marcelcastrobr/sagemaker-distilbert-emotion,0.8178701465921572
12,jasonyim2/distilbert-base-uncased-finetuned-emotion,0.8148738969079555
13,abdelkader/distilbert-base-uncased-finetuned-emotion,0.785579872072004
14,moghis/distilbert-base-uncased-finetuned-emotion,0.7857452731756206
15,uygarkurt/distilbert-base-uncased-finetuned-emotion,0.8120748852276235
16,neibla/distilbert-base-uncased-finetuned-emotion,0.8037005842239039
17,JB173/distilbert-base-uncased-finetuned-emotion,0.7830724823441004
18,Nanatan/distilbert-base-uncased-finetuned-emotion,0.813574494098241
19,riyadhctg/distilbert-base-uncased-finetuned-cola,0.8095541161522161
20,connectivity/cola_6ep_ft-33,0.817425530222534
21,connectivity/cola_6ep_ft-22,0.8151547637788313
22,gchhablani/fnet-base-finetuned-cola,0.8048131093174065
23,vesteinn/XLMR-ENIS-finetuned-cola,0.8200955684189534
24,isakbos/Q8BERT_COLA_L_512,0.7623645505274994
25,jaesun/distilbert-base-uncased-finetuned-cola,0.783930583426748
26,usami/distilbert-base-uncased-finetuned-cola,0.7867286449322194
27,Jeevesh8/512seq_len_6ep_bert_ft_cola-91,0.8183540200057408
28,Jeevesh8/6ep_bert_ft_cola-47,0.8172908541494337
29,connectivity/cola_6ep_ft-10,0.8119183681202468
30,Jeevesh8/6ep_bert_ft_cola-12,0.8043138282166405
31,Jeevesh8/6ep_bert_ft_cola-29,0.8129994661253326
32,Jeevesh8/bert_ft_cola-60,0.807600619009598
33,navsad/navid_test_bert,0.8118850719329143
34,Jeevesh8/bert_ft_cola-88,0.8072700700453324
35,ishan/bert-base-uncased-mnli,0.8132769637505387
36,boychaboy/MNLI_roberta-base,0.8152755656144288
37,anirudh21/bert-base-uncased-finetuned-qnli,0.82280313249528
38,Alireza1044/albert-base-v2-qnli,0.8047788719927976
39,Jeevesh8/init_bert_ft_qqp-33,0.8172794359684303
40,Jeevesh8/init_bert_ft_qqp-49,0.8102280520133439
41,connectivity/bert_ft_qqp-7,0.8038564254706223
42,Jeevesh8/bert_ft_qqp-40,0.8113535421272089
43,Jeevesh8/bert_ft_qqp-9,0.8077805218440939
44,Jeevesh8/bert_ft_qqp-88,0.8142014587767966
45,connectivity/bert_ft_qqp-25,0.8048493815552829
46,Jeevesh8/bert_ft_qqp-55,0.8160029227753398
47,Jeevesh8/init_bert_ft_qqp-24,0.7990562055727578
48,Jeevesh8/init_bert_ft_qqp-28,0.8056372497989416
49,connectivity/bert_ft_qqp-17,0.8140802101422632
50,Jeevesh8/bert_ft_qqp-68,0.8144801246685767
51,connectivity/bert_ft_qqp-1,0.8201664718838593
52,connectivity/bert_ft_qqp-94,0.8139711056264062
53,Jeevesh8/bert_ft_qqp-39,0.8141692034297732
54,connectivity/bert_ft_qqp-96,0.8175470495074768
55,gchhablani/bert-base-cased-finetuned-rte,0.804900006555179
56,philschmid/tiny-distilbert-classification,0.23032941558992173
57,ali2066/finetuned_sentence_itr1_2e-05_all_26_02_2022-04_03_26,0.8079806536486644
58,SetFit/distilbert-base-uncased__sst2__train-16-0,0.8128651278302829
59,gchhablani/fnet-base-finetuned-sst2,0.8072531422432099
60,moshew/bert-mini-sst2-distilled,0.7619318986230509
61,aviator-neural/bert-base-uncased-sst2,0.8086374885026018
62,SetFit/distilbert-base-uncased__sst2__train-32-9,0.7830560192698579
63,Alassea/glue_sst_classifier,0.8114619208754164
64,ChrisUPM/BioBERT_Re_trained,0.7974026077313128
65,gchhablani/bert-base-cased-finetuned-wnli,0.8013992637137791
66,Hate-speech-CNERG/bert-base-uncased-hatexplain-rationale-two,0.8084505721583755
67,heranm/finetuning-sentiment-model-3000-samples,0.8078931113822526
68,PrasunMishra/finetuning-sentiment-model-3000-samples,0.815420876606073
69,yukta10/finetuning-sentiment-model-3000-samples,0.7945855857392347
70,ncduy/roberta-imdb-sentiment-analysis,0.8175609051735566
71,markt23917/finetuning-sentiment-model-3000-samples,0.7931695028754061
72,juliensimon/autonlp-imdb-demo-hf-16622767,0.78336746840606
73,XSY/albert-base-v2-imdb-calssification,0.7961073364673225
74,fabriceyhc/bert-base-uncased-imdb,0.8112569649973785
75,Anthos23/FS-distilroberta-fine-tuned,0.808749295855408
76,oferweintraub/bert-base-finance-sentiment-noisy-search,0.808985821366083
77,emrecan/bert-base-multilingual-cased-snli_tr,0.7938889663784776
78,nurkayevaa/autonlp-bert-covid-407910458,0.8185742374046839
79,cross-encoder/quora-distilroberta-base,0.8092446086938918
80,navteca/quora-roberta-base,0.8121550716929339
81,cross-encoder/quora-roberta-base,0.8025761552943464
82,w11wo/sundanese-bert-base-emotion-classifier,0.7691820235713762
83,aychang/bert-base-cased-trec-coarse,0.8188846913867108
84,JNK789/distilbert-base-uncased-finetuned-tweets-emoji-dataset,0.4286160408766477
85,pietrotrope/emotion_final,0.7911832603524839
86,aXhyra/emotion_trained_31415,0.7923111836247654
87,aXhyra/presentation_emotion_31415,0.807585533744325
88,elozano/tweet_offensive_eval,0.7624441496730923
89,aXhyra/demo_sentiment_31415,0.793430444791161
90,aXhyra/presentation_sentiment_1234567,0.7919510982233611
91,nickmuchi/facebook-data2vec-finetuned-finance-classification,0.8148973047813645
92,manueltonneau/bert-twitter-en-is-hired,0.805930462370058
93,bert-base-uncased,0.8170692593534207
94,dhimskyy/wiki-bert,0.7932570150863721
95,distilbert-base-uncased,0.7720994351030176
96,albert-base-v2,0.8168539999542327
97,bert-base-cased,0.8182620071959963
98,michiyasunaga/LinkBERT-base,0.8095815268045002
99,roberta-base,0.8251522487427749
100,bert-large-uncased,0.7661422161239337
101,roberta-large,0.7640979034921461
102,Recognai/bert-base-spanish-wwm-cased-xnli,0.7638430599213503
103,mrm8488/electricidad-base-finetuned-pawsx-es,0.794726257378208
104,dapang/distilroberta-base-mic-sym,0.817601778958627
105,Capreolus/bert-base-msmarco,0.8102396339223915
106,Splend1dchan/bert-base-uncased-slue-goldtrascription-e3-lr1e-4,0.8132130837707426
107,Jeevesh8/feather_berts_46,0.8137858723473935
108,JonatanGk/roberta-base-bne-finetuned-cyberbullying-spanish,0.7452545699060424
109,cambridgeltl/guardian_news_distilbert-base-uncased,0.7804365006120112
110,amyma21/sincere_question_classification,0.8101978735131625
111,phailyoor/distilbert-base-uncased-finetuned-yahd,0.8014808719779403
112,nreimers/mmarco-mMiniLMv2-L6-H384-v1,0.8129667433024116
113,arianpasquali/distilbert-base-multilingual-cased-toxicity,0.7909143447891779
114,strickvl/nlp-redaction-classifier,0.7979985823878121
115,connectivity/feather_berts_28,0.8088135833005594
116,IMSyPP/hate_speech_it,0.7875196221031214
117,chiragasarpota/scotus-bert,0.7076869786051438
118,saattrupdan/job-listing-relevance-model,0.8026747086948635
119,warwickai/fin-perceiver,0.7804367264025812
120,liangyuant/distilbert-base-uncased-finetuned-num200-450-405cls,0.7936932285499677
121,DoyyingFace/bert-asian-hate-tweets-asian-unclean-freeze-4,0.8083494929132009
122,Jeevesh8/lecun_feather_berts-3,0.805089139115363
123,Giyaseddin/distilroberta-base-finetuned-short-answer-assessment,0.8019884681999099
124,18811449050/bert_finetuning_test,0.8040335529048445
125,Jeevesh8/lecun_feather_berts-51,0.8222102846582898
126,Jeevesh8/feather_berts_96,0.8144046165071614
127,AnonymousSub/dummy_2,0.79899676708209
128,viviastaari/finetuning-sentiment-analysis-en-id,0.7728083041113232
129,finiteautomata/betonews-tweetcontext,0.7886869772762145
130,Aureliano/distilbert-base-uncased-if,0.7834461223484034
131,rmihaylov/roberta-base-sentiment-bg,0.7750051438614524
132,cardiffnlp/twitter-roberta-base-2021-124m,0.8231438397861683
133,Jeevesh8/lecun_feather_berts-8,0.8131749792489589
134,anferico/bert-for-patents,0.7736628272911241
135,morenolq/SumTO_FNS2020,0.7590960385738562
136,IMSyPP/hate_speech_nl,0.7935958242400767
137,cross-encoder/ms-marco-MiniLM-L-4-v2,0.7794405546337977
138,Jeevesh8/lecun_feather_berts-7,0.8110102412999963
139,matthewburke/korean_sentiment,0.78960009219902
140,waboucay/camembert-base-finetuned-xnli_fr-finetuned-nli-rua_wl,0.7752585075360376
141,aditeyabaral/finetuned-sail2017-xlm-roberta-base,0.8094367383978281
142,socialmediaie/TRAC2020_IBEN_B_bert-base-multilingual-uncased,0.7933567032724157
143,korca/bae-roberta-base-boolq,0.8153026223955574
144,mrm8488/codebert-base-finetuned-detect-insecure-code,0.8051133547267798
145,M47Labs/spanish_news_classification_headlines_untrained,0.8005881999890844
146,cardiffnlp/bertweet-base-stance-climate,0.8050337834378611
147,zenkri/autotrain-Arabic_Poetry_by_Subject-920730230,0.8008585548875564
148,cointegrated/roberta-base-formality,0.8106201422681276
149,fgaim/tiroberta-geezswitch,0.7548570313207206
150,CAMeL-Lab/bert-base-arabic-camelbert-da-sentiment,0.7378404761461016
151,bondi/bert-semaphore-prediction-w4,0.7813020116525994
152,classla/bcms-bertic-parlasent-bcs-ter,0.7898162779258578
153,ali2066/DistilBERTFINAL_ctxSentence_TRAIN_editorials_TEST_NULL_second_train_set_null_False,0.8161149845970651
154,Raychanan/COVID_RandomOver,0.293036524437571
155,anvay/finetuning-cardiffnlp-sentiment-model,0.8151294462807255
156,joebobby/finetuning-sentiment-model-5000-samples3,0.8121948680383007
157,JonatanGk/roberta-base-ca-finetuned-hate-speech-offensive-catalan,0.7647910524767555
158,Jeevesh8/feather_berts_92,0.8197153277744532
159,YeRyeongLee/electra-base-discriminator-finetuned-filtered-0602,0.5303790638478837
160,CAMeL-Lab/bert-base-arabic-camelbert-mix-did-nadi,0.742577591053361
161,Monsia/camembert-fr-covid-tweet-classification,0.7930211123015509
162,ASCCCCCCCC/distilbert-base-chinese-amazon_zh_20000,0.7907483766592764
163,kyleinincubated/autonlp-cat333-624217911,0.7936978608663131
