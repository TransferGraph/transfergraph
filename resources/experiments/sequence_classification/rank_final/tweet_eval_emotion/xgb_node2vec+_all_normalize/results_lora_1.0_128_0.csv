,model,score
0,Jeevesh8/init_bert_ft_qqp-33,0.8275875
1,Jeevesh8/init_bert_ft_qqp-33,0.8507226
2,Jeevesh8/init_bert_ft_qqp-49,0.8603495
3,Jeevesh8/init_bert_ft_qqp-49,0.81147003
4,connectivity/bert_ft_qqp-7,0.8477587
5,connectivity/bert_ft_qqp-7,0.8298296
6,Jeevesh8/bert_ft_qqp-40,0.88421375
7,Jeevesh8/bert_ft_qqp-40,0.84051526
8,Jeevesh8/bert_ft_qqp-9,0.828332
9,Jeevesh8/bert_ft_qqp-9,0.81767964
10,Jeevesh8/bert_ft_qqp-88,0.8274291
11,Jeevesh8/bert_ft_qqp-88,0.81378996
12,connectivity/bert_ft_qqp-25,0.8298548
13,connectivity/bert_ft_qqp-25,0.8243334
14,Jeevesh8/bert_ft_qqp-55,0.84578556
15,Jeevesh8/bert_ft_qqp-55,0.823332
16,connectivity/bert_ft_qqp-1,0.82201594
17,connectivity/bert_ft_qqp-1,0.82518315
18,Jeevesh8/bert_ft_qqp-39,0.83882123
19,Jeevesh8/bert_ft_qqp-39,0.83224523
20,connectivity/bert_ft_qqp-94,0.803128
21,connectivity/bert_ft_qqp-94,0.8073905
22,connectivity/bert_ft_qqp-96,0.838036
23,connectivity/bert_ft_qqp-96,0.8230962
24,Jeevesh8/init_bert_ft_qqp-24,0.82086396
25,Jeevesh8/init_bert_ft_qqp-24,0.81060326
26,Jeevesh8/bert_ft_qqp-68,0.79655665
27,Jeevesh8/bert_ft_qqp-68,0.8236918
28,Jeevesh8/init_bert_ft_qqp-28,0.83258677
29,Jeevesh8/init_bert_ft_qqp-28,0.8116604
30,connectivity/bert_ft_qqp-17,0.86439353
31,connectivity/bert_ft_qqp-17,0.80591315
32,ali2066/finetuned_sentence_itr1_2e-05_all_26_02_2022-04_03_26,0.8545879
33,ali2066/finetuned_sentence_itr1_2e-05_all_26_02_2022-04_03_26,0.8557543
34,SetFit/distilbert-base-uncased__sst2__train-16-0,0.84180385
35,SetFit/distilbert-base-uncased__sst2__train-16-0,0.8517903
36,aviator-neural/bert-base-uncased-sst2,0.8510596
37,aviator-neural/bert-base-uncased-sst2,0.8217347
38,SetFit/distilbert-base-uncased__sst2__train-32-9,0.8446856
39,SetFit/distilbert-base-uncased__sst2__train-32-9,0.83128566
40,Alassea/glue_sst_classifier,0.856497
41,Alassea/glue_sst_classifier,0.8396608
42,philschmid/tiny-distilbert-classification,0.45791325
43,philschmid/tiny-distilbert-classification,0.44835588
44,moshew/bert-mini-sst2-distilled,0.84835005
45,moshew/bert-mini-sst2-distilled,0.8450318
46,ChrisUPM/BioBERT_Re_trained,0.82809836
47,ChrisUPM/BioBERT_Re_trained,0.82392794
48,vaariis/distilbert-base-uncased-finetuned-emotion,0.8293777
49,vaariis/distilbert-base-uncased-finetuned-emotion,0.8543948
50,marcelcastrobr/sagemaker-distilbert-emotion,0.81995326
51,marcelcastrobr/sagemaker-distilbert-emotion,0.8322211
52,jasonyim2/distilbert-base-uncased-finetuned-emotion,0.8269608
53,jasonyim2/distilbert-base-uncased-finetuned-emotion,0.83984286
54,abdelkader/distilbert-base-uncased-finetuned-emotion,0.8352611
55,abdelkader/distilbert-base-uncased-finetuned-emotion,0.8276049
56,moghis/distilbert-base-uncased-finetuned-emotion,0.84256285
57,moghis/distilbert-base-uncased-finetuned-emotion,0.838141
58,uygarkurt/distilbert-base-uncased-finetuned-emotion,0.82749826
59,uygarkurt/distilbert-base-uncased-finetuned-emotion,0.81861
60,neibla/distilbert-base-uncased-finetuned-emotion,0.8316425
61,neibla/distilbert-base-uncased-finetuned-emotion,0.85456514
62,JB173/distilbert-base-uncased-finetuned-emotion,0.8414839
63,JB173/distilbert-base-uncased-finetuned-emotion,0.83848536
64,Nanatan/distilbert-base-uncased-finetuned-emotion,0.85086316
65,Nanatan/distilbert-base-uncased-finetuned-emotion,0.8258079
66,heranm/finetuning-sentiment-model-3000-samples,0.8413768
67,heranm/finetuning-sentiment-model-3000-samples,0.8413768
68,PrasunMishra/finetuning-sentiment-model-3000-samples,0.84486276
69,PrasunMishra/finetuning-sentiment-model-3000-samples,0.8475431
70,yukta10/finetuning-sentiment-model-3000-samples,0.84310246
71,yukta10/finetuning-sentiment-model-3000-samples,0.8513525
72,ncduy/roberta-imdb-sentiment-analysis,0.8823291
73,ncduy/roberta-imdb-sentiment-analysis,0.86411166
74,markt23917/finetuning-sentiment-model-3000-samples,0.84106946
75,markt23917/finetuning-sentiment-model-3000-samples,0.8400536
76,juliensimon/autonlp-imdb-demo-hf-16622767,0.8389372
77,juliensimon/autonlp-imdb-demo-hf-16622767,0.839873
78,fabriceyhc/bert-base-uncased-imdb,0.80210763
79,fabriceyhc/bert-base-uncased-imdb,0.77783227
80,riyadhctg/distilbert-base-uncased-finetuned-cola,0.8211975
81,riyadhctg/distilbert-base-uncased-finetuned-cola,0.8423555
82,connectivity/cola_6ep_ft-33,0.8737608
83,connectivity/cola_6ep_ft-33,0.8407109
84,connectivity/cola_6ep_ft-22,0.854969
85,connectivity/cola_6ep_ft-22,0.8313681
86,isakbos/Q8BERT_COLA_L_512,0.7165377
87,isakbos/Q8BERT_COLA_L_512,0.67758834
88,jaesun/distilbert-base-uncased-finetuned-cola,0.8126376
89,jaesun/distilbert-base-uncased-finetuned-cola,0.82173043
90,usami/distilbert-base-uncased-finetuned-cola,0.8504115
91,usami/distilbert-base-uncased-finetuned-cola,0.84996957
92,Jeevesh8/512seq_len_6ep_bert_ft_cola-91,0.85346735
93,Jeevesh8/512seq_len_6ep_bert_ft_cola-91,0.80765855
94,Jeevesh8/6ep_bert_ft_cola-47,0.8518107
95,Jeevesh8/6ep_bert_ft_cola-47,0.8181245
96,connectivity/cola_6ep_ft-10,0.83197784
97,connectivity/cola_6ep_ft-10,0.8301091
98,Jeevesh8/6ep_bert_ft_cola-12,0.8485725
99,Jeevesh8/6ep_bert_ft_cola-12,0.84224176
100,Jeevesh8/bert_ft_cola-88,0.84465367
101,Jeevesh8/bert_ft_cola-88,0.8487215
102,Jeevesh8/6ep_bert_ft_cola-29,0.84536976
103,Jeevesh8/6ep_bert_ft_cola-29,0.8417473
104,vesteinn/XLMR-ENIS-finetuned-cola,0.83685553
105,vesteinn/XLMR-ENIS-finetuned-cola,0.83979386
106,navsad/navid_test_bert,0.8295357
107,navsad/navid_test_bert,0.8197497
108,Jeevesh8/bert_ft_cola-60,0.8402217
109,Jeevesh8/bert_ft_cola-60,0.8281205
110,dapang/distilroberta-base-mic-sym,0.87137794
111,dapang/distilroberta-base-mic-sym,0.85688776
112,Capreolus/bert-base-msmarco,0.85591716
113,Capreolus/bert-base-msmarco,0.8505854
114,Splend1dchan/bert-base-uncased-slue-goldtrascription-e3-lr1e-4,0.8798267
115,Splend1dchan/bert-base-uncased-slue-goldtrascription-e3-lr1e-4,0.85197556
116,Jeevesh8/feather_berts_46,0.8852886
117,Jeevesh8/feather_berts_46,0.8527513
118,JonatanGk/roberta-base-bne-finetuned-cyberbullying-spanish,0.64184886
119,JonatanGk/roberta-base-bne-finetuned-cyberbullying-spanish,0.6396341
120,cambridgeltl/guardian_news_distilbert-base-uncased,0.8309189
121,cambridgeltl/guardian_news_distilbert-base-uncased,0.83956933
122,amyma21/sincere_question_classification,0.84348
123,amyma21/sincere_question_classification,0.8461625
124,phailyoor/distilbert-base-uncased-finetuned-yahd,0.8099243
125,phailyoor/distilbert-base-uncased-finetuned-yahd,0.8054953
126,arianpasquali/distilbert-base-multilingual-cased-toxicity,0.7949008
127,arianpasquali/distilbert-base-multilingual-cased-toxicity,0.79238945
128,connectivity/feather_berts_28,0.8608973
129,connectivity/feather_berts_28,0.84143126
130,liangyuant/distilbert-base-uncased-finetuned-num200-450-405cls,0.8239262
131,liangyuant/distilbert-base-uncased-finetuned-num200-450-405cls,0.8267833
132,DoyyingFace/bert-asian-hate-tweets-asian-unclean-freeze-4,0.8577692
133,DoyyingFace/bert-asian-hate-tweets-asian-unclean-freeze-4,0.8549936
134,Jeevesh8/lecun_feather_berts-3,0.85570145
135,Jeevesh8/lecun_feather_berts-3,0.837238
136,Giyaseddin/distilroberta-base-finetuned-short-answer-assessment,0.8509887
137,Giyaseddin/distilroberta-base-finetuned-short-answer-assessment,0.83509415
138,AnonymousSub/dummy_2,0.78202045
139,AnonymousSub/dummy_2,0.77299345
140,Jeevesh8/lecun_feather_berts-51,0.85752344
141,Jeevesh8/lecun_feather_berts-51,0.8335886
142,viviastaari/finetuning-sentiment-analysis-en-id,0.7603944
143,viviastaari/finetuning-sentiment-analysis-en-id,0.7606972
144,Aureliano/distilbert-base-uncased-if,0.83536565
145,Aureliano/distilbert-base-uncased-if,0.8329384
146,rmihaylov/roberta-base-sentiment-bg,0.81070805
147,rmihaylov/roberta-base-sentiment-bg,0.8053829
148,cardiffnlp/twitter-roberta-base-2021-124m,0.8761888
149,cardiffnlp/twitter-roberta-base-2021-124m,0.8701372
150,Jeevesh8/lecun_feather_berts-8,0.83762896
151,Jeevesh8/lecun_feather_berts-8,0.83662903
152,korca/bae-roberta-base-boolq,0.85125893
153,korca/bae-roberta-base-boolq,0.82877165
154,aditeyabaral/finetuned-sail2017-xlm-roberta-base,0.8398566
155,aditeyabaral/finetuned-sail2017-xlm-roberta-base,0.8356079
156,joebobby/finetuning-sentiment-model-5000-samples3,0.84795445
157,joebobby/finetuning-sentiment-model-5000-samples3,0.8445328
158,Jeevesh8/feather_berts_92,0.85456055
159,Jeevesh8/feather_berts_92,0.8529568
160,ASCCCCCCCC/distilbert-base-chinese-amazon_zh_20000,0.773537
161,ASCCCCCCCC/distilbert-base-chinese-amazon_zh_20000,0.7603262
162,matthewburke/korean_sentiment,0.7045234
163,matthewburke/korean_sentiment,0.7064012
164,IMSyPP/hate_speech_nl,0.70201755
165,IMSyPP/hate_speech_nl,0.7066821
166,cointegrated/roberta-base-formality,0.8726414
167,cointegrated/roberta-base-formality,0.84258693
168,IMSyPP/hate_speech_it,0.7626141
169,IMSyPP/hate_speech_it,0.76733786
170,18811449050/bert_finetuning_test,0.83233535
171,18811449050/bert_finetuning_test,0.81815976
172,finiteautomata/betonews-tweetcontext,0.72555405
173,finiteautomata/betonews-tweetcontext,0.73400855
174,Jeevesh8/feather_berts_96,0.8529858
175,Jeevesh8/feather_berts_96,0.85391337
176,Jeevesh8/lecun_feather_berts-7,0.8702666
177,Jeevesh8/lecun_feather_berts-7,0.8437741
178,mrm8488/codebert-base-finetuned-detect-insecure-code,0.8066294
179,mrm8488/codebert-base-finetuned-detect-insecure-code,0.78427845
180,socialmediaie/TRAC2020_IBEN_B_bert-base-multilingual-uncased,0.7764148
181,socialmediaie/TRAC2020_IBEN_B_bert-base-multilingual-uncased,0.7725018
182,zenkri/autotrain-Arabic_Poetry_by_Subject-920730230,0.8279303
183,zenkri/autotrain-Arabic_Poetry_by_Subject-920730230,0.8253217
184,M47Labs/spanish_news_classification_headlines_untrained,0.75399756
185,M47Labs/spanish_news_classification_headlines_untrained,0.77554727
186,bondi/bert-semaphore-prediction-w4,0.6970229
187,bondi/bert-semaphore-prediction-w4,0.7157501
188,classla/bcms-bertic-parlasent-bcs-ter,0.786671
189,classla/bcms-bertic-parlasent-bcs-ter,0.76523
190,anferico/bert-for-patents,0.78976005
191,anferico/bert-for-patents,0.79150087
192,ali2066/DistilBERTFINAL_ctxSentence_TRAIN_editorials_TEST_NULL_second_train_set_null_False,0.8697248
193,ali2066/DistilBERTFINAL_ctxSentence_TRAIN_editorials_TEST_NULL_second_train_set_null_False,0.86655986
194,anvay/finetuning-cardiffnlp-sentiment-model,0.8779127
195,anvay/finetuning-cardiffnlp-sentiment-model,0.8711198
196,JonatanGk/roberta-base-ca-finetuned-hate-speech-offensive-catalan,0.73779136
197,JonatanGk/roberta-base-ca-finetuned-hate-speech-offensive-catalan,0.7563065
198,Raychanan/COVID_RandomOver,0.5621172
199,Raychanan/COVID_RandomOver,0.55376357
200,kyleinincubated/autonlp-cat333-624217911,0.73479766
201,kyleinincubated/autonlp-cat333-624217911,0.7460902
202,cardiffnlp/bertweet-base-stance-climate,0.8536161
203,cardiffnlp/bertweet-base-stance-climate,0.84737605
204,nreimers/mmarco-mMiniLMv2-L6-H384-v1,0.80863106
205,nreimers/mmarco-mMiniLMv2-L6-H384-v1,0.8123354
206,strickvl/nlp-redaction-classifier,0.8217777
207,strickvl/nlp-redaction-classifier,0.8201032
208,saattrupdan/job-listing-relevance-model,0.84484494
209,saattrupdan/job-listing-relevance-model,0.84290683
210,morenolq/SumTO_FNS2020,0.8153726
211,morenolq/SumTO_FNS2020,0.7993434
212,cross-encoder/ms-marco-MiniLM-L-4-v2,0.8125951
213,cross-encoder/ms-marco-MiniLM-L-4-v2,0.81334835
214,nurkayevaa/autonlp-bert-covid-407910458,0.8351118
215,nurkayevaa/autonlp-bert-covid-407910458,0.84062684
216,SetFit/distilbert-base-uncased__hate_speech_offensive__train-16-1,0.8475991
217,SetFit/distilbert-base-uncased__hate_speech_offensive__train-16-1,0.84995615
218,crcb/isear_bert,0.8657298
219,crcb/isear_bert,0.8570303
220,robertou2/roberta-base-bne-finetuned-amazon_reviews_multi,0.7640027
221,robertou2/roberta-base-bne-finetuned-amazon_reviews_multi,0.75356376
222,milyiyo/selectra-small-finetuned-amazon-review,0.721527
223,milyiyo/selectra-small-finetuned-amazon-review,0.7153429
224,Anthos23/FS-distilroberta-fine-tuned,0.8563276
225,Anthos23/FS-distilroberta-fine-tuned,0.87591004
226,oferweintraub/bert-base-finance-sentiment-noisy-search,0.862412
227,oferweintraub/bert-base-finance-sentiment-noisy-search,0.8362227
228,pietrotrope/emotion_final,0.8491919
229,pietrotrope/emotion_final,0.8499951
230,aXhyra/emotion_trained_31415,0.8409044
231,aXhyra/emotion_trained_31415,0.83734816
232,aXhyra/presentation_emotion_31415,0.8282172
233,aXhyra/presentation_emotion_31415,0.8372514
234,Recognai/bert-base-spanish-wwm-cased-xnli,0.7641553
235,Recognai/bert-base-spanish-wwm-cased-xnli,0.7592145
236,anirudh21/bert-base-uncased-finetuned-qnli,0.86391
237,anirudh21/bert-base-uncased-finetuned-qnli,0.8288679
238,aXhyra/demo_sentiment_31415,0.8547195
239,aXhyra/demo_sentiment_31415,0.8517582
240,aXhyra/presentation_sentiment_1234567,0.84894586
241,aXhyra/presentation_sentiment_1234567,0.8442888
242,jb2k/bert-base-multilingual-cased-language-detection,0.7657992
243,jb2k/bert-base-multilingual-cased-language-detection,0.76216274
244,vinai/bertweet-base,0.87565464
245,vinai/bertweet-base,0.86771584
246,justinqbui/bertweet-covid19-base-uncased-pretraining-covid-vaccine-tweets,0.8690753
247,justinqbui/bertweet-covid19-base-uncased-pretraining-covid-vaccine-tweets,0.83437
248,vinai/bertweet-covid19-base-cased,0.8678552
249,vinai/bertweet-covid19-base-cased,0.8507101
250,vinai/bertweet-covid19-base-uncased,0.8627357
251,vinai/bertweet-covid19-base-uncased,0.83918744
252,distilbert-base-uncased,0.8446076
253,distilbert-base-uncased,0.8411646
254,bert-base-uncased,0.8686201
255,bert-base-uncased,0.84296674
256,roberta-base,0.86110157
257,roberta-base,0.8566161
258,bert-base-cased,0.8626471
259,bert-base-cased,0.8504171
260,dhimskyy/wiki-bert,0.72598135
261,dhimskyy/wiki-bert,0.70628744
262,michiyasunaga/LinkBERT-base,0.8527269
263,michiyasunaga/LinkBERT-base,0.83504564
264,bert-large-uncased,0.7699271
265,bert-large-uncased,0.77794343
266,roberta-large,0.7916171
267,roberta-large,0.8467167
268,boychaboy/MNLI_roberta-base,0.8700789
269,boychaboy/MNLI_roberta-base,0.8679329
270,ishan/bert-base-uncased-mnli,0.8381209
271,ishan/bert-base-uncased-mnli,0.8353294
272,emrecan/bert-base-multilingual-cased-snli_tr,0.7884559
273,emrecan/bert-base-multilingual-cased-snli_tr,0.7711382
274,elozano/tweet_offensive_eval,0.7230266
275,elozano/tweet_offensive_eval,0.7371622
276,Hate-speech-CNERG/bert-base-uncased-hatexplain-rationale-two,0.8368875
277,Hate-speech-CNERG/bert-base-uncased-hatexplain-rationale-two,0.84563696
278,aychang/bert-base-cased-trec-coarse,0.840763
279,aychang/bert-base-cased-trec-coarse,0.8399495
280,gchhablani/bert-base-cased-finetuned-wnli,0.85122913
281,gchhablani/bert-base-cased-finetuned-wnli,0.84274286
282,w11wo/sundanese-bert-base-emotion-classifier,0.70199794
283,w11wo/sundanese-bert-base-emotion-classifier,0.69258195
284,gchhablani/bert-base-cased-finetuned-rte,0.817569
285,gchhablani/bert-base-cased-finetuned-rte,0.81080514
286,mrm8488/electricidad-base-finetuned-pawsx-es,0.7141178
287,mrm8488/electricidad-base-finetuned-pawsx-es,0.71602845
288,manueltonneau/bert-twitter-en-is-hired,0.85170317
289,manueltonneau/bert-twitter-en-is-hired,0.8550979
290,Guscode/DKbert-hatespeech-detection,0.7657436
291,Guscode/DKbert-hatespeech-detection,0.7421974
292,cross-encoder/quora-distilroberta-base,0.835374
293,cross-encoder/quora-distilroberta-base,0.8341407
294,navteca/quora-roberta-base,0.85021967
295,navteca/quora-roberta-base,0.84545034
296,cross-encoder/quora-roberta-base,0.84912187
297,cross-encoder/quora-roberta-base,0.8344967
