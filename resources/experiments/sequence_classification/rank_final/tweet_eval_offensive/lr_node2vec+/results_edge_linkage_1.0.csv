,mappedID,model,score
0,0,Jeevesh8/init_bert_ft_qqp-33,23.126463
1,1,ali2066/finetuned_sentence_itr1_2e-05_all_26_02_2022-04_03_26,-1.8311801
2,2,vaariis/distilbert-base-uncased-finetuned-emotion,-0.29628658
3,3,philschmid/tiny-distilbert-classification,-3.921157
4,4,heranm/finetuning-sentiment-model-3000-samples,0.7348074
5,5,marcelcastrobr/sagemaker-distilbert-emotion,0.5267861
6,6,jasonyim2/distilbert-base-uncased-finetuned-emotion,-0.7262938
7,7,riyadhctg/distilbert-base-uncased-finetuned-cola,-1.0793905
8,8,PrasunMishra/finetuning-sentiment-model-3000-samples,19.077345
9,9,nurkayevaa/autonlp-bert-covid-407910458,16.966305
10,10,SetFit/distilbert-base-uncased__sst2__train-16-0,1.5551997
11,11,abdelkader/distilbert-base-uncased-finetuned-emotion,0.45587462
12,12,SetFit/distilbert-base-uncased__hate_speech_offensive__train-16-1,0.52583265
13,13,crcb/isear_bert,0.4810462
14,14,connectivity/cola_6ep_ft-33,-2.6966927
15,15,Jeevesh8/init_bert_ft_qqp-49,-0.5495138
16,16,connectivity/cola_6ep_ft-22,-8.076746
17,17,yukta10/finetuning-sentiment-model-3000-samples,-1.1299307
18,18,ncduy/roberta-imdb-sentiment-analysis,-1.2264919
19,19,vesteinn/XLMR-ENIS-finetuned-cola,-6.890115
20,20,isakbos/Q8BERT_COLA_L_512,2.6610608
21,21,connectivity/bert_ft_qqp-7,2.960947
22,22,moghis/distilbert-base-uncased-finetuned-emotion,1.5325904
23,23,moshew/bert-mini-sst2-distilled,6.748708
24,24,uygarkurt/distilbert-base-uncased-finetuned-emotion,0.5233655
25,25,robertou2/roberta-base-bne-finetuned-amazon_reviews_multi,95.89678
26,26,neibla/distilbert-base-uncased-finetuned-emotion,-1.8904476
27,27,Anthos23/FS-distilroberta-fine-tuned,1.6873703
28,28,pietrotrope/emotion_final,-12.618479
29,29,aviator-neural/bert-base-uncased-sst2,-1.8305938
30,30,Jeevesh8/bert_ft_qqp-40,-12.46221
31,31,jaesun/distilbert-base-uncased-finetuned-cola,-0.25501204
32,32,SetFit/distilbert-base-uncased__sst2__train-32-9,-18.181902
33,33,usami/distilbert-base-uncased-finetuned-cola,-8.078221
34,34,Jeevesh8/512seq_len_6ep_bert_ft_cola-91,-5.346984
35,35,Jeevesh8/bert_ft_qqp-9,0.587724
36,36,Jeevesh8/bert_ft_qqp-88,-2.3623412
37,37,Recognai/bert-base-spanish-wwm-cased-xnli,25.798481
38,38,markt23917/finetuning-sentiment-model-3000-samples,5.32185
39,39,anirudh21/bert-base-uncased-finetuned-qnli,1.5750235
40,40,Jeevesh8/6ep_bert_ft_cola-47,6.3797407
41,41,oferweintraub/bert-base-finance-sentiment-noisy-search,-0.67378473
42,42,aXhyra/demo_sentiment_31415,-2.3097053
43,43,milyiyo/selectra-small-finetuned-amazon-review,-1.7925404
44,44,aXhyra/presentation_sentiment_1234567,1.411153
45,45,connectivity/cola_6ep_ft-10,-0.20484614
46,46,jb2k/bert-base-multilingual-cased-language-detection,-0.27619457
47,47,connectivity/bert_ft_qqp-25,-1.3928916
48,48,Jeevesh8/6ep_bert_ft_cola-12,23.427664
49,49,aXhyra/emotion_trained_31415,-0.80311847
50,50,aXhyra/presentation_emotion_31415,-2.9726906
51,51,JB173/distilbert-base-uncased-finetuned-emotion,-1.930021
52,52,Jeevesh8/init_bert_ft_qqp-24,0.996667
53,53,Jeevesh8/bert_ft_qqp-55,-0.93013287
54,54,Jeevesh8/bert_ft_qqp-68,-1.3437968
55,55,Jeevesh8/6ep_bert_ft_cola-29,0.691144
56,56,connectivity/bert_ft_qqp-17,-8.448021
57,57,Jeevesh8/init_bert_ft_qqp-28,-5.6073866
58,58,vinai/bertweet-base,-2.2714283
59,59,dhimskyy/wiki-bert,16.885626
60,60,bert-base-uncased,-7.9728417
61,61,justinqbui/bertweet-covid19-base-uncased-pretraining-covid-vaccine-tweets,-2.6931005
62,62,vinai/bertweet-covid19-base-cased,0.19056058
63,63,distilbert-base-uncased,1.7585826
64,64,roberta-base,-2.5387053
65,65,bert-base-cased,0.20783281
66,66,cross-encoder/quora-distilroberta-base,0.54714465
67,67,michiyasunaga/LinkBERT-base,-0.8806584
68,68,bert-large-uncased,4.8358645
69,69,roberta-large,-22.278824
70,70,vinai/bertweet-covid19-base-uncased,4.853888
71,71,connectivity/bert_ft_qqp-1,-1.3283134
72,72,juliensimon/autonlp-imdb-demo-hf-16622767,-5.2295103
73,73,Alassea/glue_sst_classifier,-1.1567616
74,74,Nanatan/distilbert-base-uncased-finetuned-emotion,-8.066024
75,75,Jeevesh8/bert_ft_qqp-39,-6.8036146
76,76,Jeevesh8/bert_ft_cola-60,-11.2223
77,77,navsad/navid_test_bert,3.3098428
78,78,navteca/quora-roberta-base,-10.1707735
79,79,connectivity/bert_ft_qqp-94,1.1551142
80,80,w11wo/sundanese-bert-base-emotion-classifier,-0.3457961
81,81,Hate-speech-CNERG/bert-base-uncased-hatexplain-rationale-two,-0.90448844
82,82,Jeevesh8/bert_ft_cola-88,-9.361488
83,83,aychang/bert-base-cased-trec-coarse,1.3710124
84,84,cross-encoder/quora-roberta-base,-5.816638
85,85,ishan/bert-base-uncased-mnli,0.9217355
86,86,connectivity/bert_ft_qqp-96,-0.79247046
87,87,boychaboy/MNLI_roberta-base,-6.818539
88,88,fabriceyhc/bert-base-uncased-imdb,21.905409
89,89,gchhablani/bert-base-cased-finetuned-rte,-9.974515
90,90,emrecan/bert-base-multilingual-cased-snli_tr,-11.499149
91,91,elozano/tweet_offensive_eval,-3.3327775
92,92,mrm8488/electricidad-base-finetuned-pawsx-es,-9.595775
93,93,gchhablani/bert-base-cased-finetuned-wnli,0.25566912
94,94,manueltonneau/bert-twitter-en-is-hired,0.9803076
95,95,Guscode/DKbert-hatespeech-detection,-5.5348983
96,96,ChrisUPM/BioBERT_Re_trained,0.14130157
97,97,dapang/distilroberta-base-mic-sym,7.2544146
98,98,Splend1dchan/bert-base-uncased-slue-goldtrascription-e3-lr1e-4,-5.5797124
99,99,Capreolus/bert-base-msmarco,2.9947953
100,100,amyma21/sincere_question_classification,2.1966918
101,101,phailyoor/distilbert-base-uncased-finetuned-yahd,-1.9743338
102,102,arianpasquali/distilbert-base-multilingual-cased-toxicity,-1.3390703
103,103,cambridgeltl/guardian_news_distilbert-base-uncased,-2.3414226
104,104,Jeevesh8/feather_berts_46,-5.2810593
105,105,strickvl/nlp-redaction-classifier,-1.6570218
106,106,liangyuant/distilbert-base-uncased-finetuned-num200-450-405cls,1.1250377
107,107,connectivity/feather_berts_28,-1.0643699
108,108,IMSyPP/hate_speech_it,7.333695
109,109,JonatanGk/roberta-base-bne-finetuned-cyberbullying-spanish,-0.4744451
110,110,cross-encoder/ms-marco-MiniLM-L-4-v2,-3.5527005
111,111,viviastaari/finetuning-sentiment-analysis-en-id,-4.4372888
112,112,rmihaylov/roberta-base-sentiment-bg,0.6659169
113,113,18811449050/bert_finetuning_test,-1.614569
114,114,Giyaseddin/distilroberta-base-finetuned-short-answer-assessment,-9.202709
115,115,Aureliano/distilbert-base-uncased-if,-1.0214691
116,116,Jeevesh8/lecun_feather_berts-51,-1.2897444
117,117,Jeevesh8/feather_berts_96,0.052500725
118,118,saattrupdan/job-listing-relevance-model,-0.65449786
119,119,AnonymousSub/dummy_2,-0.5610087
120,120,cardiffnlp/twitter-roberta-base-2021-124m,1.5857444
121,121,finiteautomata/betonews-tweetcontext,3.2354646
122,122,Jeevesh8/lecun_feather_berts-8,1.4786887
123,123,Jeevesh8/lecun_feather_berts-7,0.8977795
124,124,DoyyingFace/bert-asian-hate-tweets-asian-unclean-freeze-4,-4.207056
125,125,Jeevesh8/lecun_feather_berts-3,2.7283347
126,126,aditeyabaral/finetuned-sail2017-xlm-roberta-base,-1.0318226
127,127,korca/bae-roberta-base-boolq,-1.7579553
128,128,zenkri/autotrain-Arabic_Poetry_by_Subject-920730230,-8.712471
129,129,cointegrated/roberta-base-formality,-2.1217966
130,130,mrm8488/codebert-base-finetuned-detect-insecure-code,11.469929
131,131,M47Labs/spanish_news_classification_headlines_untrained,-1.2085023
132,132,anvay/finetuning-cardiffnlp-sentiment-model,-0.3456295
133,133,joebobby/finetuning-sentiment-model-5000-samples3,7.4789186
134,134,Jeevesh8/feather_berts_92,-7.851489
135,135,JonatanGk/roberta-base-ca-finetuned-hate-speech-offensive-catalan,1.093856
136,136,nreimers/mmarco-mMiniLMv2-L6-H384-v1,1.7343678
137,137,Raychanan/COVID_RandomOver,-1.5186093
138,138,ASCCCCCCCC/distilbert-base-chinese-amazon_zh_20000,-6.950056
139,139,socialmediaie/TRAC2020_IBEN_B_bert-base-multilingual-uncased,-0.5452342
140,140,anferico/bert-for-patents,1.6826403
141,141,ali2066/DistilBERTFINAL_ctxSentence_TRAIN_editorials_TEST_NULL_second_train_set_null_False,-2.1717772
142,142,kyleinincubated/autonlp-cat333-624217911,0.36213136
143,143,morenolq/SumTO_FNS2020,-1.8156166
144,144,IMSyPP/hate_speech_nl,23.334827
145,145,matthewburke/korean_sentiment,3.4793437
146,146,cardiffnlp/bertweet-base-stance-climate,0.31215477
147,147,bondi/bert-semaphore-prediction-w4,-1.0728095
148,148,classla/bcms-bertic-parlasent-bcs-ter,0.6535158
