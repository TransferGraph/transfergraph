,model,score
0,Jeevesh8/init_bert_ft_qqp-33,0.866113
1,Jeevesh8/init_bert_ft_qqp-33,0.8701468
2,Jeevesh8/init_bert_ft_qqp-49,0.8701468
3,Jeevesh8/init_bert_ft_qqp-49,0.866113
4,connectivity/bert_ft_qqp-7,0.866113
5,connectivity/bert_ft_qqp-7,0.8701468
6,Jeevesh8/bert_ft_qqp-40,0.8701468
7,Jeevesh8/bert_ft_qqp-40,0.8701468
8,Jeevesh8/bert_ft_qqp-9,0.866113
9,Jeevesh8/bert_ft_qqp-9,0.86523795
10,Jeevesh8/bert_ft_qqp-88,0.86523795
11,connectivity/bert_ft_qqp-25,0.866113
12,connectivity/bert_ft_qqp-25,0.8701468
13,Jeevesh8/bert_ft_qqp-55,0.866113
14,Jeevesh8/bert_ft_qqp-55,0.866113
15,connectivity/bert_ft_qqp-1,0.8701468
16,connectivity/bert_ft_qqp-1,0.8701468
17,Jeevesh8/bert_ft_qqp-39,0.8701468
18,Jeevesh8/bert_ft_qqp-39,0.86523795
19,connectivity/bert_ft_qqp-94,0.866113
20,connectivity/bert_ft_qqp-94,0.8701468
21,connectivity/bert_ft_qqp-96,0.866113
22,Jeevesh8/init_bert_ft_qqp-24,0.8643691
23,Jeevesh8/init_bert_ft_qqp-24,0.86523795
24,Jeevesh8/bert_ft_qqp-68,0.866113
25,Jeevesh8/bert_ft_qqp-68,0.8701468
26,Jeevesh8/init_bert_ft_qqp-28,0.866113
27,Jeevesh8/init_bert_ft_qqp-28,0.8701468
28,connectivity/bert_ft_qqp-17,0.866113
29,connectivity/bert_ft_qqp-17,0.866113
30,ali2066/finetuned_sentence_itr1_2e-05_all_26_02_2022-04_03_26,0.8209026
31,ali2066/finetuned_sentence_itr1_2e-05_all_26_02_2022-04_03_26,0.79265064
32,SetFit/distilbert-base-uncased__sst2__train-16-0,0.87161416
33,gchhablani/fnet-base-finetuned-sst2,0.6452472
34,gchhablani/fnet-base-finetuned-sst2,0.64435136
35,aviator-neural/bert-base-uncased-sst2,0.8443659
36,aviator-neural/bert-base-uncased-sst2,0.8461288
37,SetFit/distilbert-base-uncased__sst2__train-32-9,0.84520864
38,SetFit/distilbert-base-uncased__sst2__train-32-9,0.81821793
39,Alassea/glue_sst_classifier,0.85492283
40,Alassea/glue_sst_classifier,0.8657983
41,philschmid/tiny-distilbert-classification,0.08301633
42,philschmid/tiny-distilbert-classification,0.10403613
43,moshew/bert-mini-sst2-distilled,0.6333972
44,moshew/bert-mini-sst2-distilled,0.7211798
45,ChrisUPM/BioBERT_Re_trained,0.8252247
46,ChrisUPM/BioBERT_Re_trained,0.8260149
47,vaariis/distilbert-base-uncased-finetuned-emotion,0.8361293
48,vaariis/distilbert-base-uncased-finetuned-emotion,0.8787023
49,marcelcastrobr/sagemaker-distilbert-emotion,0.80223423
50,marcelcastrobr/sagemaker-distilbert-emotion,0.82608765
51,jasonyim2/distilbert-base-uncased-finetuned-emotion,0.8293985
52,jasonyim2/distilbert-base-uncased-finetuned-emotion,0.85727733
53,abdelkader/distilbert-base-uncased-finetuned-emotion,0.83628494
54,abdelkader/distilbert-base-uncased-finetuned-emotion,0.8092942
55,moghis/distilbert-base-uncased-finetuned-emotion,0.8324448
56,moghis/distilbert-base-uncased-finetuned-emotion,0.88830245
57,uygarkurt/distilbert-base-uncased-finetuned-emotion,0.84532195
58,uygarkurt/distilbert-base-uncased-finetuned-emotion,0.850181
59,neibla/distilbert-base-uncased-finetuned-emotion,0.80462825
60,neibla/distilbert-base-uncased-finetuned-emotion,0.80462825
61,JB173/distilbert-base-uncased-finetuned-emotion,0.818723
62,JB173/distilbert-base-uncased-finetuned-emotion,0.8088811
63,Nanatan/distilbert-base-uncased-finetuned-emotion,0.8123405
64,heranm/finetuning-sentiment-model-3000-samples,0.84746504
65,PrasunMishra/finetuning-sentiment-model-3000-samples,0.8496281
66,PrasunMishra/finetuning-sentiment-model-3000-samples,0.8021522
67,yukta10/finetuning-sentiment-model-3000-samples,0.8202357
68,yukta10/finetuning-sentiment-model-3000-samples,0.8522936
69,ncduy/roberta-imdb-sentiment-analysis,0.9102282
70,ncduy/roberta-imdb-sentiment-analysis,0.9108746
71,markt23917/finetuning-sentiment-model-3000-samples,0.83994585
72,markt23917/finetuning-sentiment-model-3000-samples,0.9123295
73,juliensimon/autonlp-imdb-demo-hf-16622767,0.8803252
74,juliensimon/autonlp-imdb-demo-hf-16622767,0.8961185
75,fabriceyhc/bert-base-uncased-imdb,0.8158055
76,fabriceyhc/bert-base-uncased-imdb,0.81493044
77,XSY/albert-base-v2-imdb-calssification,0.63563085
78,XSY/albert-base-v2-imdb-calssification,0.63378304
79,riyadhctg/distilbert-base-uncased-finetuned-cola,0.8295428
80,riyadhctg/distilbert-base-uncased-finetuned-cola,0.84764415
81,connectivity/cola_6ep_ft-33,0.8573247
82,connectivity/cola_6ep_ft-33,0.8573247
83,connectivity/cola_6ep_ft-22,0.8555618
84,gchhablani/fnet-base-finetuned-cola,0.67509025
85,gchhablani/fnet-base-finetuned-cola,0.6768556
86,isakbos/Q8BERT_COLA_L_512,0.6600729
87,isakbos/Q8BERT_COLA_L_512,0.65743494
88,jaesun/distilbert-base-uncased-finetuned-cola,0.85401195
89,usami/distilbert-base-uncased-finetuned-cola,0.8339212
90,usami/distilbert-base-uncased-finetuned-cola,0.8162442
91,Jeevesh8/512seq_len_6ep_bert_ft_cola-91,0.8555618
92,Jeevesh8/512seq_len_6ep_bert_ft_cola-91,0.8555618
93,Jeevesh8/6ep_bert_ft_cola-47,0.8555618
94,Jeevesh8/6ep_bert_ft_cola-47,0.8573247
95,connectivity/cola_6ep_ft-10,0.8573247
96,connectivity/cola_6ep_ft-10,0.85468674
97,Jeevesh8/6ep_bert_ft_cola-12,0.8573247
98,Jeevesh8/6ep_bert_ft_cola-12,0.8573247
99,Jeevesh8/bert_ft_cola-88,0.8573247
100,Jeevesh8/bert_ft_cola-88,0.8555618
101,Jeevesh8/6ep_bert_ft_cola-29,0.8555618
102,vesteinn/XLMR-ENIS-finetuned-cola,0.8380933
103,navsad/navid_test_bert,0.8298683
104,navsad/navid_test_bert,0.82907814
105,Jeevesh8/bert_ft_cola-60,0.8573247
106,Jeevesh8/bert_ft_cola-60,0.85468674
107,dapang/distilroberta-base-mic-sym,0.86212385
108,dapang/distilroberta-base-mic-sym,0.8921159
109,Capreolus/bert-base-msmarco,0.8544475
110,Capreolus/bert-base-msmarco,0.8528777
111,Splend1dchan/bert-base-uncased-slue-goldtrascription-e3-lr1e-4,0.87243897
112,Splend1dchan/bert-base-uncased-slue-goldtrascription-e3-lr1e-4,0.86840516
113,Jeevesh8/feather_berts_46,0.87243897
114,Jeevesh8/feather_berts_46,0.86840516
115,JonatanGk/roberta-base-bne-finetuned-cyberbullying-spanish,0.509523
116,JonatanGk/roberta-base-bne-finetuned-cyberbullying-spanish,0.509523
117,cambridgeltl/guardian_news_distilbert-base-uncased,0.8116231
118,cambridgeltl/guardian_news_distilbert-base-uncased,0.8116231
119,amyma21/sincere_question_classification,0.82176524
120,phailyoor/distilbert-base-uncased-finetuned-yahd,0.75121814
121,phailyoor/distilbert-base-uncased-finetuned-yahd,0.75121814
122,arianpasquali/distilbert-base-multilingual-cased-toxicity,0.70790774
123,arianpasquali/distilbert-base-multilingual-cased-toxicity,0.7102119
124,connectivity/feather_berts_28,0.8432656
125,connectivity/feather_berts_28,0.87243897
126,warwickai/fin-perceiver,0.739424
127,liangyuant/distilbert-base-uncased-finetuned-num200-450-405cls,0.836051
128,liangyuant/distilbert-base-uncased-finetuned-num200-450-405cls,0.8765132
129,DoyyingFace/bert-asian-hate-tweets-asian-unclean-freeze-4,0.85778654
130,DoyyingFace/bert-asian-hate-tweets-asian-unclean-freeze-4,0.8528777
131,Jeevesh8/lecun_feather_berts-3,0.86840516
132,Jeevesh8/lecun_feather_berts-3,0.87243897
133,Giyaseddin/distilroberta-base-finetuned-short-answer-assessment,0.8900983
134,Giyaseddin/distilroberta-base-finetuned-short-answer-assessment,0.8537382
135,AnonymousSub/dummy_2,0.81875455
136,AnonymousSub/dummy_2,0.7951272
137,Jeevesh8/lecun_feather_berts-51,0.8690999
138,Jeevesh8/lecun_feather_berts-51,0.87243897
139,viviastaari/finetuning-sentiment-analysis-en-id,0.7375528
140,viviastaari/finetuning-sentiment-analysis-en-id,0.673552
141,Aureliano/distilbert-base-uncased-if,0.80680615
142,Aureliano/distilbert-base-uncased-if,0.8396806
143,rmihaylov/roberta-base-sentiment-bg,0.76843965
144,rmihaylov/roberta-base-sentiment-bg,0.6637376
145,cardiffnlp/twitter-roberta-base-2021-124m,0.85699874
146,cardiffnlp/twitter-roberta-base-2021-124m,0.856304
147,Jeevesh8/lecun_feather_berts-8,0.86840516
148,Jeevesh8/lecun_feather_berts-8,0.87243897
149,korca/bae-roberta-base-boolq,0.90778226
150,korca/bae-roberta-base-boolq,0.90778226
151,aditeyabaral/finetuned-sail2017-xlm-roberta-base,0.7850479
152,aditeyabaral/finetuned-sail2017-xlm-roberta-base,0.7850479
153,joebobby/finetuning-sentiment-model-5000-samples3,0.888453
154,joebobby/finetuning-sentiment-model-5000-samples3,0.888453
155,YeRyeongLee/electra-base-discriminator-finetuned-filtered-0602,0.3676649
156,YeRyeongLee/electra-base-discriminator-finetuned-filtered-0602,0.3676649
157,Jeevesh8/feather_berts_92,0.87243897
158,Jeevesh8/feather_berts_92,0.86840516
159,ASCCCCCCCC/distilbert-base-chinese-amazon_zh_20000,0.6665738
160,matthewburke/korean_sentiment,0.69987106
161,matthewburke/korean_sentiment,0.7237262
162,IMSyPP/hate_speech_nl,0.51242
163,IMSyPP/hate_speech_nl,0.50498754
164,cointegrated/roberta-base-formality,0.90842867
165,cointegrated/roberta-base-formality,0.90778226
166,chiragasarpota/scotus-bert,0.60266286
167,chiragasarpota/scotus-bert,0.46621397
168,IMSyPP/hate_speech_it,0.7249773
169,IMSyPP/hate_speech_it,0.73957783
170,18811449050/bert_finetuning_test,0.8528777
171,finiteautomata/betonews-tweetcontext,0.6818205
172,finiteautomata/betonews-tweetcontext,0.6818205
173,Jeevesh8/feather_berts_96,0.8432656
174,Jeevesh8/feather_berts_96,0.8675301
175,Jeevesh8/lecun_feather_berts-7,0.8690999
176,Jeevesh8/lecun_feather_berts-7,0.86840516
177,mrm8488/codebert-base-finetuned-detect-insecure-code,0.81123894
178,mrm8488/codebert-base-finetuned-detect-insecure-code,0.81188536
179,socialmediaie/TRAC2020_IBEN_B_bert-base-multilingual-uncased,0.78253615
180,socialmediaie/TRAC2020_IBEN_B_bert-base-multilingual-uncased,0.7970664
181,zenkri/autotrain-Arabic_Poetry_by_Subject-920730230,0.85707414
182,zenkri/autotrain-Arabic_Poetry_by_Subject-920730230,0.85707414
183,M47Labs/spanish_news_classification_headlines_untrained,0.76884794
184,M47Labs/spanish_news_classification_headlines_untrained,0.78721994
185,bondi/bert-semaphore-prediction-w4,0.7339133
186,bondi/bert-semaphore-prediction-w4,0.7339133
187,classla/bcms-bertic-parlasent-bcs-ter,0.74379027
188,anferico/bert-for-patents,0.65562665
189,anferico/bert-for-patents,0.65562665
190,waboucay/camembert-base-finetuned-xnli_fr-finetuned-nli-rua_wl,0.41265333
191,ali2066/DistilBERTFINAL_ctxSentence_TRAIN_editorials_TEST_NULL_second_train_set_null_False,0.9359344
192,ali2066/DistilBERTFINAL_ctxSentence_TRAIN_editorials_TEST_NULL_second_train_set_null_False,0.9344369
193,anvay/finetuning-cardiffnlp-sentiment-model,0.9032109
194,anvay/finetuning-cardiffnlp-sentiment-model,0.92082644
195,JonatanGk/roberta-base-ca-finetuned-hate-speech-offensive-catalan,0.6900582
196,JonatanGk/roberta-base-ca-finetuned-hate-speech-offensive-catalan,0.72001934
197,Raychanan/COVID_RandomOver,0.02919805
198,Raychanan/COVID_RandomOver,0.02919805
199,Monsia/camembert-fr-covid-tweet-classification,0.78215605
200,Monsia/camembert-fr-covid-tweet-classification,0.81167996
201,CAMeL-Lab/bert-base-arabic-camelbert-mix-did-nadi,0.6906977
202,CAMeL-Lab/bert-base-arabic-camelbert-mix-did-nadi,0.6405808
203,kyleinincubated/autonlp-cat333-624217911,0.7105185
204,kyleinincubated/autonlp-cat333-624217911,0.71770185
205,CAMeL-Lab/bert-base-arabic-camelbert-da-sentiment,0.6046974
206,CAMeL-Lab/bert-base-arabic-camelbert-da-sentiment,0.5845638
207,nurkayevaa/autonlp-bert-covid-407910458,0.9042957
208,nurkayevaa/autonlp-bert-covid-407910458,0.9167291
209,SetFit/distilbert-base-uncased__hate_speech_offensive__train-16-1,0.8580551
210,SetFit/distilbert-base-uncased__hate_speech_offensive__train-16-1,0.9009081
211,crcb/isear_bert,0.90056896
212,crcb/isear_bert,0.90056896
213,robertou2/roberta-base-bne-finetuned-amazon_reviews_multi,0.7676919
214,robertou2/roberta-base-bne-finetuned-amazon_reviews_multi,0.74900305
215,milyiyo/selectra-small-finetuned-amazon-review,0.6275694
216,milyiyo/selectra-small-finetuned-amazon-review,0.6053614
217,Anthos23/FS-distilroberta-fine-tuned,0.8746456
218,Anthos23/FS-distilroberta-fine-tuned,0.91317767
219,oferweintraub/bert-base-finance-sentiment-noisy-search,0.88292354
220,pietrotrope/emotion_final,0.6478513
221,pietrotrope/emotion_final,0.6567668
222,aXhyra/emotion_trained_31415,0.6731305
223,aXhyra/emotion_trained_31415,0.65479016
224,aXhyra/presentation_emotion_31415,0.6598353
225,aXhyra/presentation_emotion_31415,0.68182266
226,Recognai/bert-base-spanish-wwm-cased-xnli,0.78666526
227,Recognai/bert-base-spanish-wwm-cased-xnli,0.78666526
228,JNK789/distilbert-base-uncased-finetuned-tweets-emoji-dataset,0.09967124
229,JNK789/distilbert-base-uncased-finetuned-tweets-emoji-dataset,0.12234024
230,anirudh21/bert-base-uncased-finetuned-qnli,0.8809516
231,anirudh21/bert-base-uncased-finetuned-qnli,0.8838567
232,Alireza1044/albert-base-v2-qnli,0.6252523
233,aXhyra/demo_sentiment_31415,0.84030104
234,aXhyra/demo_sentiment_31415,0.8441262
235,aXhyra/presentation_sentiment_1234567,0.85422045
236,jb2k/bert-base-multilingual-cased-language-detection,0.77401936
237,jb2k/bert-base-multilingual-cased-language-detection,0.77401936
238,vinai/bertweet-base,0.8599252
239,vinai/bertweet-base,0.8599252
240,justinqbui/bertweet-covid19-base-uncased-pretraining-covid-vaccine-tweets,0.86284244
241,distilbert-base-uncased,0.85310376
242,distilbert-base-uncased,0.89843833
243,bert-base-uncased,0.82102466
244,bert-base-uncased,0.82102466
245,roberta-base,0.8515168
246,albert-base-v2,0.6439974
247,albert-base-v2,0.6439974
248,bert-base-cased,0.80503416
249,bert-base-cased,0.804244
250,dhimskyy/wiki-bert,0.6817885
251,dhimskyy/wiki-bert,0.6817885
252,michiyasunaga/LinkBERT-base,0.85770965
253,michiyasunaga/LinkBERT-base,0.85770965
254,bert-large-uncased,0.5361689
255,bert-large-uncased,0.5361689
256,roberta-large,0.4915266
257,boychaboy/MNLI_roberta-base,0.89268625
258,ishan/bert-base-uncased-mnli,0.8512339
259,ishan/bert-base-uncased-mnli,0.88029736
260,emrecan/bert-base-multilingual-cased-snli_tr,0.79727155
261,emrecan/bert-base-multilingual-cased-snli_tr,0.79727155
262,elozano/tweet_offensive_eval,0.8271969
263,Hate-speech-CNERG/bert-base-uncased-hatexplain-rationale-two,0.8659011
264,Hate-speech-CNERG/bert-base-uncased-hatexplain-rationale-two,0.8659011
265,aychang/bert-base-cased-trec-coarse,0.77665055
266,aychang/bert-base-cased-trec-coarse,0.7775599
267,gchhablani/bert-base-cased-finetuned-wnli,0.8686739
268,nickmuchi/facebook-data2vec-finetuned-finance-classification,0.7783191
269,nickmuchi/facebook-data2vec-finetuned-finance-classification,0.7783191
270,w11wo/sundanese-bert-base-emotion-classifier,0.62763304
271,w11wo/sundanese-bert-base-emotion-classifier,0.62763304
272,gchhablani/bert-base-cased-finetuned-rte,0.8636179
273,gchhablani/bert-base-cased-finetuned-rte,0.8636179
274,mrm8488/electricidad-base-finetuned-pawsx-es,0.7241373
275,mrm8488/electricidad-base-finetuned-pawsx-es,0.73644704
276,manueltonneau/bert-twitter-en-is-hired,0.8474283
277,manueltonneau/bert-twitter-en-is-hired,0.8474283
278,Guscode/DKbert-hatespeech-detection,0.6426966
279,Guscode/DKbert-hatespeech-detection,0.6415544
280,,0.78735924
281,,0.7838471
282,,0.78796357
283,,0.78402096
