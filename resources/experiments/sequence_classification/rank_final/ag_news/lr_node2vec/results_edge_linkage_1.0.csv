,mappedID,model,score
0,0,Jeevesh8/init_bert_ft_qqp-33,-3.1496074
1,1,ali2066/finetuned_sentence_itr1_2e-05_all_26_02_2022-04_03_26,-0.29662037
2,2,vaariis/distilbert-base-uncased-finetuned-emotion,2.3596282
3,3,philschmid/tiny-distilbert-classification,33.718464
4,4,heranm/finetuning-sentiment-model-3000-samples,0.6000333
5,5,marcelcastrobr/sagemaker-distilbert-emotion,-0.80574083
6,6,jasonyim2/distilbert-base-uncased-finetuned-emotion,-0.6309457
7,7,riyadhctg/distilbert-base-uncased-finetuned-cola,0.12846613
8,8,PrasunMishra/finetuning-sentiment-model-3000-samples,28.17098
9,9,nurkayevaa/autonlp-bert-covid-407910458,4.536372
10,10,SetFit/distilbert-base-uncased__sst2__train-16-0,1.3144388
11,11,abdelkader/distilbert-base-uncased-finetuned-emotion,-1.4699717
12,12,SetFit/distilbert-base-uncased__hate_speech_offensive__train-16-1,10.471439
13,13,crcb/isear_bert,0.44144297
14,14,connectivity/cola_6ep_ft-33,-0.4833349
15,15,Jeevesh8/init_bert_ft_qqp-49,8.991626
16,16,connectivity/cola_6ep_ft-22,3.983219
17,17,yukta10/finetuning-sentiment-model-3000-samples,0.5448878
18,18,ncduy/roberta-imdb-sentiment-analysis,14.067584
19,19,vesteinn/XLMR-ENIS-finetuned-cola,1.4203238
20,20,isakbos/Q8BERT_COLA_L_512,1.2755984
21,21,connectivity/bert_ft_qqp-7,1.5454893
22,22,moghis/distilbert-base-uncased-finetuned-emotion,10.3892765
23,23,moshew/bert-mini-sst2-distilled,-8.7535925
24,24,uygarkurt/distilbert-base-uncased-finetuned-emotion,-4.019373
25,25,robertou2/roberta-base-bne-finetuned-amazon_reviews_multi,-14.7782
26,26,neibla/distilbert-base-uncased-finetuned-emotion,-0.64011097
27,27,Anthos23/FS-distilroberta-fine-tuned,4.9524593
28,28,pietrotrope/emotion_final,-6.8425283
29,29,aviator-neural/bert-base-uncased-sst2,0.9639473
30,30,Jeevesh8/bert_ft_qqp-40,-7.8083696
31,31,jaesun/distilbert-base-uncased-finetuned-cola,-0.4796145
32,32,SetFit/distilbert-base-uncased__sst2__train-32-9,-14.008756
33,33,usami/distilbert-base-uncased-finetuned-cola,128.75223
34,34,Jeevesh8/512seq_len_6ep_bert_ft_cola-91,-0.50972533
35,35,Jeevesh8/bert_ft_qqp-9,0.8164077
36,36,Jeevesh8/bert_ft_qqp-88,0.34566605
37,37,Recognai/bert-base-spanish-wwm-cased-xnli,2.0368805
38,38,markt23917/finetuning-sentiment-model-3000-samples,-9.58543
39,39,anirudh21/bert-base-uncased-finetuned-qnli,-2.693747
40,40,Jeevesh8/6ep_bert_ft_cola-47,-0.15026402
41,41,oferweintraub/bert-base-finance-sentiment-noisy-search,-2.378971
42,42,aXhyra/demo_sentiment_31415,-9.80829
43,43,aXhyra/presentation_sentiment_1234567,0.18059492
44,44,connectivity/cola_6ep_ft-10,0.9992151
45,45,jb2k/bert-base-multilingual-cased-language-detection,31.902674
46,46,connectivity/bert_ft_qqp-25,-0.48562717
47,47,Jeevesh8/6ep_bert_ft_cola-12,-1.9766402
48,48,aXhyra/emotion_trained_31415,-30.120644
49,49,aXhyra/presentation_emotion_31415,-0.28422272
50,50,JB173/distilbert-base-uncased-finetuned-emotion,3.5553908
51,51,Jeevesh8/init_bert_ft_qqp-24,3.9578087
52,52,Jeevesh8/bert_ft_qqp-55,-12.430116
53,53,Jeevesh8/bert_ft_qqp-68,2.8860464
54,54,Jeevesh8/6ep_bert_ft_cola-29,3.2645483
55,55,connectivity/bert_ft_qqp-17,-6.2172523
56,56,Jeevesh8/init_bert_ft_qqp-28,-1.8132517
57,57,vinai/bertweet-base,2.816399
58,58,bert-base-uncased,2.1167903
59,59,justinqbui/bertweet-covid19-base-uncased-pretraining-covid-vaccine-tweets,-0.12602472
60,60,vinai/bertweet-covid19-base-cased,21.934332
61,61,distilbert-base-uncased,-7.5224323
62,62,roberta-base,-14.724239
63,63,bert-base-cased,-0.4761839
64,64,cross-encoder/quora-distilroberta-base,-8.046471
65,65,michiyasunaga/LinkBERT-base,0.43519592
66,66,bert-large-uncased,1.5723915
67,67,roberta-large,-0.5732112
68,68,vinai/bertweet-covid19-base-uncased,-15.859734
69,69,connectivity/bert_ft_qqp-1,-0.43219805
70,70,juliensimon/autonlp-imdb-demo-hf-16622767,-2.5304337
71,71,Alassea/glue_sst_classifier,-17.703758
72,72,Nanatan/distilbert-base-uncased-finetuned-emotion,-2.743102
73,73,Jeevesh8/bert_ft_qqp-39,3.307936
74,74,Jeevesh8/bert_ft_cola-60,0.2297163
75,75,navsad/navid_test_bert,-24.46921
76,76,navteca/quora-roberta-base,-0.91820765
77,77,connectivity/bert_ft_qqp-94,2.3802402
78,78,Hate-speech-CNERG/bert-base-uncased-hatexplain-rationale-two,1.0286074
79,79,Jeevesh8/bert_ft_cola-88,-17.732143
80,80,aychang/bert-base-cased-trec-coarse,-1.2002158
81,81,cross-encoder/quora-roberta-base,-0.9589044
82,82,ishan/bert-base-uncased-mnli,-3.0406194
83,83,connectivity/bert_ft_qqp-96,25.92187
84,84,boychaboy/MNLI_roberta-base,-7.3235855
85,85,fabriceyhc/bert-base-uncased-imdb,-4.059139
86,86,gchhablani/bert-base-cased-finetuned-rte,-1.7635065
87,87,emrecan/bert-base-multilingual-cased-snli_tr,-7.37181
88,88,elozano/tweet_offensive_eval,-13.270708
89,89,gchhablani/bert-base-cased-finetuned-wnli,-7.27525
90,90,manueltonneau/bert-twitter-en-is-hired,19.054022
91,91,Guscode/DKbert-hatespeech-detection,-2.6304812
92,92,ChrisUPM/BioBERT_Re_trained,-8.756435
93,93,dapang/distilroberta-base-mic-sym,-1.3240013
94,94,Splend1dchan/bert-base-uncased-slue-goldtrascription-e3-lr1e-4,-0.31458092
95,95,Capreolus/bert-base-msmarco,-0.022120953
96,96,Jeevesh8/feather_berts_46,2.3174458
97,97,JonatanGk/roberta-base-bne-finetuned-cyberbullying-spanish,-12.612728
98,98,cambridgeltl/guardian_news_distilbert-base-uncased,1.0298847
99,99,amyma21/sincere_question_classification,0.32635474
100,100,arianpasquali/distilbert-base-multilingual-cased-toxicity,1.7120692
101,101,connectivity/feather_berts_28,-1.2072067
102,102,IMSyPP/hate_speech_it,1.765986
103,103,Giyaseddin/distilroberta-base-finetuned-short-answer-assessment,-5.261856
104,104,liangyuant/distilbert-base-uncased-finetuned-num200-450-405cls,-2.5595055
105,105,Jeevesh8/lecun_feather_berts-3,-9.124811
106,106,DoyyingFace/bert-asian-hate-tweets-asian-unclean-freeze-4,-0.79617065
107,107,18811449050/bert_finetuning_test,-0.7191016
108,108,Jeevesh8/feather_berts_96,-1.0622048
109,109,Jeevesh8/lecun_feather_berts-51,0.7956902
110,110,AnonymousSub/dummy_2,-0.14083076
111,111,viviastaari/finetuning-sentiment-analysis-en-id,0.23214531
112,112,finiteautomata/betonews-tweetcontext,-17.277056
113,113,Aureliano/distilbert-base-uncased-if,-1.1057612
114,114,rmihaylov/roberta-base-sentiment-bg,-1.2735267
115,115,Jeevesh8/lecun_feather_berts-8,-7.1101394
116,116,cardiffnlp/twitter-roberta-base-2021-124m,3.4665442
117,117,Jeevesh8/lecun_feather_berts-7,0.56002766
118,118,matthewburke/korean_sentiment,5.99127
119,119,korca/bae-roberta-base-boolq,12.261093
120,120,anferico/bert-for-patents,-0.2964399
121,121,cardiffnlp/bertweet-base-stance-climate,-1.8980379
122,122,zenkri/autotrain-Arabic_Poetry_by_Subject-920730230,0.23346663
123,123,M47Labs/spanish_news_classification_headlines_untrained,0.8786049
124,124,mrm8488/codebert-base-finetuned-detect-insecure-code,-0.6533884
125,125,socialmediaie/TRAC2020_IBEN_B_bert-base-multilingual-uncased,-0.24552512
126,126,aditeyabaral/finetuned-sail2017-xlm-roberta-base,-7.9066486
127,127,JonatanGk/roberta-base-ca-finetuned-hate-speech-offensive-catalan,0.5246551
128,128,bondi/bert-semaphore-prediction-w4,-2.2180367
129,129,classla/bcms-bertic-parlasent-bcs-ter,30.491444
130,130,cointegrated/roberta-base-formality,-1.0413113
131,131,ASCCCCCCCC/distilbert-base-chinese-amazon_zh_20000,26.63198
132,132,joebobby/finetuning-sentiment-model-5000-samples3,-0.5023706
133,133,Jeevesh8/feather_berts_92,-1.718811
134,134,anvay/finetuning-cardiffnlp-sentiment-model,6.116169
135,135,ali2066/DistilBERTFINAL_ctxSentence_TRAIN_editorials_TEST_NULL_second_train_set_null_False,0.4725697
136,136,kyleinincubated/autonlp-cat333-624217911,2.213604
137,137,phailyoor/distilbert-base-uncased-finetuned-yahd,1.8312156
138,138,strickvl/nlp-redaction-classifier,7.2341385
139,139,saattrupdan/job-listing-relevance-model,18.805145
140,140,cross-encoder/ms-marco-MiniLM-L-4-v2,22.498817
141,141,morenolq/SumTO_FNS2020,-3.1944559
142,142,nreimers/mmarco-mMiniLMv2-L6-H384-v1,-7.25336
